0	Dr Pettifer	The University of Manchester	None	None	None	Target practice: informatic and metabolomic assessment of biological network changes and of drug-cell interactions	There are many occasions where one may wish to know the site of interaction of an effector molecule with a complex biological system (i.e. network), typically by measuring changes in the accessible state variables. These are usually ill-conditioned problems, in the sense that many models can account for the observable data, and to make progress it is necessary to apply constraints and simplifications of various kinds. In contrast to cognate analyses of signalling and gene regulatory networks, the analysis of METABOLIC networks and their fluxes is attractive since they NECESSARILY possess stoichiometric and thermodynamic constraints, which are known, and measurement of the molecules they excrete as end products creates further constraints on the fluxes through the different parts of the network. Initially using baker's yeast as a model organism, we wish to demonstrate that this strategy does indeed work. The necessary simplifications include the use of mass action and lin-log kinetics, while we shall develop and exploit modern methods of multivariate statistical optimisation and machine learning for parameter estimation. These include multi-objective evolutionary algorithms, and the exploitation of probabilistic graphical methods and Gaussian process models. We shall initially develop and test these strategies in baker's yeast, Saccharomyces cerevisiae, since this is a well understood organism. However, our collaborative partner Unilever are extremely interested in Corynebacterium jeikeium, for which a genome sequence and network model exist, and using resources made available by them for this project we shall also exploit these methods in the analysis of metabolic fluxes in this organism. The deliverable will be a suite of novel methods with which to infer the site of action of any effector in a reasonably well understood metabolic network.	Biotechnology and Biological Sciences Research Council	Industrial (IPA)	1287697.0	GBP
1	Professor Douglas Kell	The University of Manchester	None	None	None	Target practice: informatic and metabolomic assessment of biological network changes and of drug-cell interactions	There are many occasions where one may wish to know the site of interaction of an effector molecule with a complex biological system (i.e. network), typically by measuring changes in the accessible state variables. These are usually ill-conditioned problems, in the sense that many models can account for the observable data, and to make progress it is necessary to apply constraints and simplifications of various kinds. In contrast to cognate analyses of signalling and gene regulatory networks, the analysis of METABOLIC networks and their fluxes is attractive since they NECESSARILY possess stoichiometric and thermodynamic constraints, which are known, and measurement of the molecules they excrete as end products creates further constraints on the fluxes through the different parts of the network. Initially using baker's yeast as a model organism, we wish to demonstrate that this strategy does indeed work. The necessary simplifications include the use of mass action and lin-log kinetics, while we shall develop and exploit modern methods of multivariate statistical optimisation and machine learning for parameter estimation. These include multi-objective evolutionary algorithms, and the exploitation of probabilistic graphical methods and Gaussian process models. We shall initially develop and test these strategies in baker's yeast, Saccharomyces cerevisiae, since this is a well understood organism. However, our collaborative partner Unilever are extremely interested in Corynebacterium jeikeium, for which a genome sequence and network model exist, and using resources made available by them for this project we shall also exploit these methods in the analysis of metabolic fluxes in this organism. The deliverable will be a suite of novel methods with which to infer the site of action of any effector in a reasonably well understood metabolic network.	Biotechnology and Biological Sciences Research Council	Industrial (IPA)	1287697.0	GBP
2	Professor Philip Bath	Nottingham,University of	Stroke Trials Unit, Division of Clinical Neuroscience	None	None	Assessment of modern machine learning methods and conventional statistical regression techniques in diagnosis and prediction of outcome after acute stroke using big data	Stroke is common, may be mimicked by other conditions, and often has a poor outcome. We will use high-fidelity big data from acute stroke trials (which will include those with stroke, TIA and mimics) involving up to 90,000 instances/patients with baseline clinical and imaging, on treatment, diagnostic and outcome information. We will assess the accuracy of state-of-the-art machine learning with artificial neural network (ANN) models, including deep neural networks (DNN), in the diagnosis of stroke versus mimics, and prediction of early complications (deterioration, stroke recurrence and re-bleeding) and late outcomes (functional outcome, cognition, mood, quality of life, disposition, death) after stroke. These will be compared with conventional statistical regression models (binary, Cox, ordinal and linear regression). Neither ANN/DNN nor statistical approaches are used routinely in stroke management in part because of poor accuracy and acceptability to clinicians. If diagnostic and prediction models are accurate and acceptable to patients and clinicians then their use could be rapidly introduced into clinical care to improve patient management, for example through the use of apps on phones/tablets/computers.	British Heart Foundation	Project Grant	145079.0	GBP
3	Professor Gordon Jayson	University of Manchester	None	2005-01-01	2008-06-30	The human serum metabolome in health and disease	Many arguments, including those based on metabolic Control Analysis (MCA), indicate that the metabolome should be a particularly high-resolution method for amplifying and thereby reflecting changes in the levels of gene products, especially those which accompany disease pathogenesis. A key imperative is therefore to develop and industrialise the technology optimal for determining the serum metabolome reliably, to establish the disease-independent ranges of the many hundreds of metabolites that can be observed with such technology, to recognise the disease-independent changes that occur `simply as a function of diet, gender, age, therapeutic interventions and lifestyle, and to make these data for `normals available in a web-accessible manner. Such data will form the reference baseline that will allow prognostic and diagnostic biomarkers for disease progression to be identified reliably; this will show the high- resolution discrimination possible with metabolomic data for both diagnosis and treatment. In parallel, we shall contribute to the development of (i) robust data models for metabolome data, and (ii) machine learning methods of classification in which the `gold standard diagnosis may be imperfectly reliable. The deliverables will be both underpinning knowledge of the human serum metabolome (probably including the discovery of many novel metabolites) and the identification of candidate biomarkers for two diseases.	Biotechnology and Biological Sciences Research Council	LINK project	168047.0	GBP
4	Professor Ariane Herrick	University of Manchester	None	2019-09-01	2022-08-05	Development of a measuring app for finger lesions as an outcome measure for systemic sclerosis-related digital ulceration (SALVE: Scleroderma App for Lesion VErification)’	Background. Digital (finger) ulcers are common in systemic sclerosis (SSc), occurring in approximately 50% of patients, and represent a huge unmet clinical need because they are painful, disabling, and disfiguring. Effective therapies are urgently required. Disappointingly, several recent clinical trials of promising new therapies have been 'negative' possibly (even probably) because of inadequacy of the primary outcome measure: clinician definition of digital ulcers/ulcer healing is notoriously unreliable. We believe that incorporating photographic assessment of digital 'lesions' is the way forward, building on successful pilot studies undertaken at the University of Manchester. Aims and purpose. We shall test the hypothesis that data collected daily using a smartphone app designed specifically for digital lesions will provide a reliable and objective outcome measure, sensitive to change, for use in clinical trials. Specific objectives include to: a.Develop a robust, device-agnostic protocol for patients to capture images of their own digital lesions using their own phones. b.Design/develop a smartphone app that guides patients through the image capture process, and 'adds in'/captures non-imaging data on other aspects of digital lesions. c.Develop automated methods to extract and analyse all available data from smartphone camera images of digital lesions to reliably track healing status. Brief experimental plan. Patient involvement in co-designing the app will be crucial to the success of the project, and will be ensured via a series of seven user group meetings between months 1 and 29. The three main stages (mapping into objectives) will be: 1. Development of a digital lesion imaging protocol, then testing this by inviting 25-30 patients with SSc-related finger lesions to collect short 1-2 second videos (which we shall refer to as 'images') at least daily over approximately 30 days (generating in the order of 1000 images in total). 2. Development of version 1 of the app, which in addition to images will also capture non-imaging patient reported outcome measures (PROMs) specific to digital lesions (assessing pain, impact on hand function, etc.). Once the app is developed, we shall invite 30 patients with SSc and current digital lesions to test this (with some overlap of patients from Stage 1). Analysis of the images collected will include lesion size, how this changes over time, and colour information to assess the lesion state (e.g. inflammation). We have the relevant expertise within our group to carry out all technical aspects of the work (medical image analysis, machine learning, optical physics). 3. Further development of the app (into version 2) to develop a tool that provides auto-analysis of finger lesion images and feedback to the patient. Patient user group input will be imperative here (i.e. what would patients be prepared to collect and what elements do they perceive as as most useful?). Relevance/potential patient benefit. By providing an objective outcome measure, the app will revitalise interest in clinical trials into SSc-related digital lesions, and thereby help to identify effective treatment(s) which will reduce pain and disability and improve quality of life. The app will also have potential as a monitoring tool in everyday practice.	Versus Arthritis	Full Application Treatment	216773.0	GBP
5	Professor Andrew Richard Collins	University of Southampton	None	2011-10-01	2014-09-30	Using machine learning methods to characterise the role of genetic factors in early onset breast cancer	Currently only about 30% of the genetic contribution to breast cancer risk has been identified. These risk factors comprise a small number of rare and moderate penetrance disease genes along with common variants identified through genome-wide association studies. Some of the 'missing heritability' is likely to remain within the phenotype: focus on 'simple' case and control disease phenotypes may be less powerful than testing for genes underlying disease sub-types. Furthermore, analytical methods have not adequately modelled interactions between genes, phenotypic variables and other factors. Finally, a proportion of genetic variation is likely to arise through rarer moderate penetrance genes that have not been tested for through association studies, but justify the effort towards sequencing. This studentship develops novel analyses in a large early onset breast cancer phenotype and genotype sample. Through collaborative supervision between the Southampton Schools of Medical and Mathematics, machine learning methods will be developed, evaluated and employed for the analyses, thereby avoiding the limitations of conventional parametric models. A particular focus will be the characterisation of the genetic basis of breast cancer sub-phenotypes (including for example, categories based on tumour grade, type and tumour biomarkers). Modelling the role of genetic variation using SNP genotype data to identify novel genetic variation underlying early onset disease is the basis of the studentship. An understanding of the role of this variation on breast cancer phenotypes is essential for the development of novel therapies in the future.	Breast Cancer Now	PhD	61400.0	GBP
6	Professor John Draper	Aberystwyth University	None	None	2014-09-30	Analysis of Magnaporthe grisea pathogenicity by insertion mutagenesis and hierarchical metabolomics	The project aims to utilise metabolomics approaches to identify metabolic processes associated with pathogenicity in the fungus Magnaporthe grisea, a major disease of a range of cereals and grasses. The genome sequence of the fungus has been determined and tools are available for generating targeted gene replacement mutants, studying gene expression using genome microarrays, and carrying out detailed cell biological studies of plant infection (for review see Talbot, 2003). M. grisea is being subjected to intensive functional genomics analysis, including large-scale insertion mutagenesis projects. To date, mutants affecting pathogenicity are almost without exception impaired in ability to form infection structures (appressoria) and penetrate host epidermal cells. However, in new mutant screens carried out at Exeter and elsewhere, several new classes of mutant are emerging where the timing of lesion formation and subsequent lesion expansion is impaired. We hypothesize that the corresponding genes may make important contributions to plant tissue colonization and disease symptom formation by M. grisea. Molecular genetic analysis of early-phase infection mutants in M. grisea have largely been carried out ex planta by germination of spores on inert plastic surfaces, providing large synchronous populations of infection structures for biochemical analysis. In parallel, we have developed an accurate sampling system for in planta infection sites based on microscopy and GFP-tagging of the pathogen, and by using such sampling approaches have shown that metabolomic fingerprinting and supervised data analysis can detect reproducible major changes in metabolome during lesion development. We will carry out detailed metabolome phenotyping of M. grisea in order to understand the precise roles of genes involved in the development of fungal infection structures using already available mutants. We will also refine and carry out a screen for mutants affected in the timing, rate of growth and sporulation of disease lesions. Mutants representative of different phenotypic classes will be inoculated onto hosts in controlled environments and lesion material collected at several time points. Metabolome analysis will follow a hierarchical procedure initiated with high-throughput, low-resolution ESI- MS fingerprinting (LTQ linear ion trap) and GC-tof-MS fingerprinting (LECO Pegasus II). Discrimination of appropriate sample combinations will be determined by supervised data analysis. If there is evidence for metabolome differences (e.g. comparing mutants with an isogenic wild type strain at the same stage of infection) then a further subset of the same samples will be subjected to ESI-FTMS fingerprinting to generate high resolution peak tables. Corresponding GC-tof-MS chromatograms will also be processed to deconvolute and annotate peaks for data mining. Explanatory metabolite signals between different sample classes will be determined using machine learning procedures. In ESI-MS data, high ranked m/z signals will be examined in chromatograms of further LC-FTMS analyses to predict the mass of possible parent ions which will be further fragmented to obtain MS(n) spectral data. Metabolite mass tables and spectral libraries will be searched for matches with spectra representing discriminatory peaks, and predicted metabolites will be quantified against standards using targeted GC-tof-MS or LC-MS as appropriate. Metabolome differences centred on specific metabolites in the various mutants will be used to determine areas of metabolism that may impact on fungal pathogenicity in future experiments. Parallel genetic analysis of insertional mutant collections of M. grisea will focus on those in which metabolome differences are apparent during plant tissue invasion. Gene isolation by inverse PCR, complementation and validation by targeted gene replacement experiments will be used to define genes associated with disease lesion formation by M. grisea.	Biotechnology and Biological Sciences Research Council	grant	203644.0	GBP
7	Professor John Draper	Aberystwyth University	None	None	2014-09-30	The Rothamsted Metabolomics Centre (MeT-RO)	Metabolomics is one of several technologies that will contribute to our quest to understand the function of all genes. MeT-RO will build and operate a high-throughput primary and secondary metabolite fingerprinting service for plants and microbes. We will develop and utilise a large- scale analytical chemistry facility generating NMR, GC, GC- MS, HPLC and LC-MS data at Rothamsted. Data will be managed in LIMS system at Rothamsted and transferred electronically to our partners at the University of Aberystwyth and UMIST and used to construct a metabolomics database from which comparative information will be extracted with chemometric, machine learning and other bioinformatic tools. MeT-RO and its partners will act as foci for research training in metabolomic technology while contributing data and interpretation tools towards systematic functional genomics, as well as to many other applications in the food, pharmaceutical and agrochemical industries. (Joint with MET20482 and MET20484)	Biotechnology and Biological Sciences Research Council	None	462262.0	GBP
8	Prof Roy Goodacre	The University of Manchester	None	None	2014-09-30	The human serum metabolome in health and disease	Many arguments, including those based on metabolic Control Analysis (MCA), indicate that the metabolome should be a particularly high-resolution method for amplifying and thereby reflecting changes in the levels of gene products, especially those which accompany disease pathogenesis. A key imperative is therefore to develop and industrialise the technology optimal for determining the serum metabolome reliably, to establish the disease-independent ranges of the many hundreds of metabolites that can be observed with such technology, to recognise the disease-independent changes that occur `simply as a function of diet, gender, age, therapeutic interventions and lifestyle, and to make these data for `normals available in a web-accessible manner. Such data will form the reference baseline that will allow prognostic and diagnostic biomarkers for disease progression to be identified reliably; this will show the high-resolution discrimination possible with metabolomic data for both diagnosis and treatment. In parallel, we shall contribute to the development of (i) robust data models for metabolome data, and (ii) machine learning methods of classification in which the `gold standard diagnosis may be imperfectly reliable. The deliverables will be both underpinning knowledge of the human serum metabolome (probably including the discovery of many novel metabolites) and the identification of candidate biomarkers for two diseases.	Biotechnology and Biological Sciences Research Council	grant	1083263.0	GBP
9	Professor Douglas Kell	The University of Manchester	None	None	2014-09-30	The human serum metabolome in health and disease	Many arguments, including those based on metabolic Control Analysis (MCA), indicate that the metabolome should be a particularly high-resolution method for amplifying and thereby reflecting changes in the levels of gene products, especially those which accompany disease pathogenesis. A key imperative is therefore to develop and industrialise the technology optimal for determining the serum metabolome reliably, to establish the disease-independent ranges of the many hundreds of metabolites that can be observed with such technology, to recognise the disease-independent changes that occur `simply as a function of diet, gender, age, therapeutic interventions and lifestyle, and to make these data for `normals available in a web-accessible manner. Such data will form the reference baseline that will allow prognostic and diagnostic biomarkers for disease progression to be identified reliably; this will show the high-resolution discrimination possible with metabolomic data for both diagnosis and treatment. In parallel, we shall contribute to the development of (i) robust data models for metabolome data, and (ii) machine learning methods of classification in which the `gold standard diagnosis may be imperfectly reliable. The deliverables will be both underpinning knowledge of the human serum metabolome (probably including the discovery of many novel metabolites) and the identification of candidate biomarkers for two diseases.	Biotechnology and Biological Sciences Research Council	grant	1083263.0	GBP
10	Professor David Stuart	Diamond Light Source Ltd	None	2018-10-01	2021-09-30	SuRVoS Workbench: Enhanced machine learning for segmentation across structural biology	Very high-resolution 3D biological images can be directly interpreted in terms of atomic structures, lower-resolution data however is interpreted by segmenting into separate volumes. Volumetric biological image data has many complexities which make segmentation difficult. These data are often low contrast, with low signal-to-noise and can be terabytes in size, so that segmentation is an error-prone and time-consuming bottleneck. SuRVoS uses machine learning, advanced image filters and over-segmentation methods to semi-automate the process, dramatically reducing the time to segment data from weeks to days. This project aims to further reduce that time and increase reliability using the latest developments in machine vision and enhanced training sets. The ultimate goal is to completely automate segmentation using advances in deep learning. Such methods require significant quantities of already segmented data to train the systems. To build segmented data for this development the segmentation tools in SuRVoS will be incorporated into a citizen science platform (Zooniverse), enabling the segmentation of many datasets from a wide range of techniques and model systems, without placing a large burden on individual researchers. This platform will then feed-back firstly to enhance segmentation across the bio-imaging facilities at Diamond enabling users’ research, and ultimately the broader user community.	Wellcome Trust	Biomedical Resources Grant	605412.0	GBP
11	Professor Paul McKeigue	University of Edinburgh	Sch of Community Health Sciences	2009-03-16	2012-03-15	Development of Bayesian methods for genetic epidemiology	This project aims to tackle several problems in genetic epidemiology that are intractable to classical statistical methods, using a common set of methods and tools that exploit recent advances in machine learning, computer science and probabilistic inference. 1.Analysis of genome-wide association studies using tag SNP arrays in combination with HapMap data, to impute HapMap haplotypes and test for association at both typed and untyped loci. This will build on the program HAPMIXMAP already developed, which combines Bayesian modelling with classical hypothesis tests. To overcome the limitations of current approaches based on fixed-dimensional hidden Markov models, we plan to evaluate alternative approaches based on Dirichlet process mixtures and variational Bayes approximations. 2.Analysis of ?mendelian randomization? studies in which genotype is used as an ?instrumental variable? to infer a causal effect of an intermediate phenotype on disease risk. This will be developed using a freely-available program (JAGS) for Bayesian inference in graphical models. 3.Analysis of gene-gene interactions, gene-environment interactions and pathways through which genotype and environmental factors influence intermediate phenotypes and disease outcomes. This will use a comparatively novel approach - variational Bayes approximation combined with automatic relevance determination - to learn the structure of graphical models. Development will be based on extending the freely-available VIBES package1&#8288; for variational Bayes inference, but we shall also evaluate a commercial package (INFER.NET) that is expected to be available soon. 4.Analysis of genome-wide association studies in isolated populations, exploiting both association and haplotype sharing through cryptic relatedness. For this we plan to develop approaches based on hidden Markov Dirichlet process models, with inference using either MCMC or variational Bayes approximations. Two different Bayesian learning algorithms will be used: Markov chain Monte Carlo simulation (MCMC) to sample the posterior of a specified model, and variational Bayes approximation with automatic relevance determination where the object is to learn model structure.	Medical Research Council	Research Grant	317659.0	GBP
12	Professor Sophia Ananiadou	The University of Manchester	None	None	2012-03-15	Tools for the text mining-based visualisation of the provenance of biochemical networks	Systems biology is concerned with the modelling, visualisation and analysis of biochemical networks in which, for instance, metabolites are 'linked' by arrows representing the enzymes which turn one molecule into another or which are modified by particular substances. SBML provides a computer- readable 'standard' for describing such biochemical or signalling networks. However, these diagrams (and thus the SBML models) are divorced from the scientific evidence on which they are based, represented by the scientific literature (and increasingly by online databases). In order to overcome the problems of reading the burgeoning scientific literature, we shall deploy Text Mining TM. TM involves named entity recognition (i.e. semantic annotation of enzymes, metabolites, etc) and information extraction (i.e. relationship extraction between named entities). An important part of this proposal is to find solutions for the terminology problem in systems biology, by developing techniques for recognising synonym terms.Based on our efficient parsing techniques, we shall extract relationships between entities that will form the basis by which we shall can discover, index, store and display the scientific evidence for such linkages. The selection of the most pertinent relationships will be performed using our preferred methods of advanced machine learning (Support Vector Machines and Genetic Programming). The overall aim of the project is thus to develop and deploy the necessary TM tools and to use them to display the different relationships to the user together with the literature from which they have been extracted. The different types (and strength) of evidence for these interactions will then be visualised directly and linked to a dynamic website of the literature. This will thus give users a direct linkage between the systems biology diagrams encoded in (an advanced form of) SBML and the scientific evidence for them. Where available, linkages to kinetic data will also be made.	Biotechnology and Biological Sciences Research Council	Standard grant	549458.0	GBP
13	Professor Douglas Kell	The University of Manchester	None	None	2012-03-15	Tools for the text mining-based visualisation of the provenance of biochemical networks	Systems biology is concerned with the modelling, visualisation and analysis of biochemical networks in which, for instance, metabolites are 'linked' by arrows representing the enzymes which turn one molecule into another or which are modified by particular substances. SBML provides a computer- readable 'standard' for describing such biochemical or signalling networks. However, these diagrams (and thus the SBML models) are divorced from the scientific evidence on which they are based, represented by the scientific literature (and increasingly by online databases). In order to overcome the problems of reading the burgeoning scientific literature, we shall deploy Text Mining TM. TM involves named entity recognition (i.e. semantic annotation of enzymes, metabolites, etc) and information extraction (i.e. relationship extraction between named entities). An important part of this proposal is to find solutions for the terminology problem in systems biology, by developing techniques for recognising synonym terms.Based on our efficient parsing techniques, we shall extract relationships between entities that will form the basis by which we shall can discover, index, store and display the scientific evidence for such linkages. The selection of the most pertinent relationships will be performed using our preferred methods of advanced machine learning (Support Vector Machines and Genetic Programming). The overall aim of the project is thus to develop and deploy the necessary TM tools and to use them to display the different relationships to the user together with the literature from which they have been extracted. The different types (and strength) of evidence for these interactions will then be visualised directly and linked to a dynamic website of the literature. This will thus give users a direct linkage between the systems biology diagrams encoded in (an advanced form of) SBML and the scientific evidence for them. Where available, linkages to kinetic data will also be made.	Biotechnology and Biological Sciences Research Council	Standard grant	549458.0	GBP
14	Professor Ross King	Aberystwyth University	None	None	2012-03-15	Bio-Logical: an intelligent database for knowledge discovery in functional genomics	A consortium will be formed to develop intelligent database technology for functional genomics using data from S. cerevisiae (bakers yeast) as a model. Existing bioinformatic databases are generally designed only to store data and to make these data available to other biologists. We propose a reasoned but radically different type of database, one of which will have the capacity to aid biologists infer new biological knowledge. Such intelligent databases are needed to transform the flood of functional genomics data into knowledge. The database will store a curated collection of functional genomics data and background knowledge on S. cerevisiae. This database will be used to develop a logical inference tools based on: deduction, abduction, and induction (machine learning). These tools which will aid users to identify interesting new patterns and hypotheses in the data.	Biotechnology and Biological Sciences Research Council	None	591244.0	GBP
15	Professor Ross King	Aberystwyth University	None	None	2012-03-15	Improved protein secondary structure prediction using advanced statistics and machine learning	None	Biotechnology and Biological Sciences Research Council	None	None	None
16	Dr Claire Walsh	University College London	Medicine	2018-08-01	2021-07-31	Creating high fidelity digital tissue substrates for the development of non-invasive microstructural MRI	Diffusion-weighted MRI (DW-MRI) is a technique used to aid in the clinical diagnosis of cancer and ischemic stroke. Recent application of microstructural tissue models to DW-MR signals has enabled quantitative assessment of tissue parameters e.g. cell size or vascular volume, and has been applied in clinical feasibility studies. Digital tissue substrates (DTS) have been central to the development of microstructural MRI. Synthetic DW-MR signals can be simulated from a DTSs and microstructural parameters extracted. The DTSs then provide a ground truth to evaluate the extracted parameters. As DTSs can be easily manipulated, they provide an ideal tool for systematically investigating how DW contrast is dependent on tissue geometry; and for developing new methods of DW-MR signal quantification, such as machine learning. Current DTSs consist of collections of spheres and cylinders to represent cells and vessels respectively. There is growing realisation in the field that these simple geometries may not capture key changes in tissue microstructure associated with certain pathologies; and cannot provide adequate validation. Recent advances in three-dimensional optical imaging provide a unique opportunity to create empirically-derived DTSs with much greater scale, complexity and realism than has previously been achieved. These optical imaging techniques (optical projection tomography (OPT) and high-resolution episcopic microscopy (HREM)) can generate image data from large tissue volumes (~2cm3) at sub cellular resolution (typically ~1um). In this fellowship, I will create a library of DTSs using 3D optical imaging data and a 3-dimensional cellular Potts modelling platform. To create such a library, I will extract the morphometric parameters from 3D imaging data using machine learning segmentation. These parameter spaces will then be used to parameterise the computational model, which can then generate DTSs within a particular parameter space.	Medical Research Council	Fellowship	289629.0	GBP
17	Professor Marchant	University College London	Medicine	None	2021-07-31	Inference and learning in machine vision	None	Biotechnology and Biological Sciences Research Council	Institute Project	None	None
18	Professor Lorenz Wernisch	University of Cambridge	None	2016-12-01	2019-03-31	Statistical bioinformatics and genetics	We focus our research on gene regulation and biopathways as derived from genetic, phylogenetic, gene expression, and molecular biomarker data. Biological systems of particular interest are stem and cancer cells (human, mouse, and drosophila), blood cells (platelets involved in artherothrombosis), and bacteria (Mycobacterium tuberculosis). Statistical modelling of such systems is challenging. Experimental data as well as other sources of information, such as bioinformatics databases, are challenging. Statistical and mathematical models which are able to represent key features of a biological system, features important for its understanding, prediction, and manipulation, are quite complex. We explore how to combine statistical inference methods, machine learning algorithms, and mathematical modelling to derive useful representations of the biological systems of interest. We will anticipate new technologies for high throughput whole genome sequencing, by developing methods for direct analysis of DNA sequences, as opposed to genetic markers. Integrating evidence from multiple data sources from different levels of organisation of a biological system will enable the discovery of important functional links and the assessment of the predictive import of molecular biomarkers with respect to phenotypes of direct clinical interest. Development of application-specific methods will result in the creation of generic computational tools and software for use by a larger community of bioinformaticians and biologists, not necessarily experts in the detailed statistical background.	Medical Research Council	Unit	None	None
19	Professor Beale	Rothamsted Research	None	None	2019-03-31	The Rothamsted Metabolomics Centre (MeT-RO)	Metabolomics is one of several technologies that will contribute to our quest to understand the function of all genes. MeT-RO will build and operate a high-throughput primary and secondary metabolite fingerprinting service for plants and microbes. We will develop and utilise a large- scale analytical chemistry facility generating NMR, GC, GC- MS, HPLC and LC-MS data at Rothamsted. Data will be managed in LIMS system at Rothamsted and transferred electronically to our partners at the University of Aberystwyth and UMIST and used to construct a metabolomics database from which comparative information will be extracted with chemometric, machine learning and other bioinformatic tools. MeT-RO and its partners will act as foci for research training in metabolomic technology while contributing data and interpretation tools towards systematic functional genomics, as well as to many other applications in the food, pharmaceutical and agrochemical industries. (Joint with MET20483 and MET20484)	Biotechnology and Biological Sciences Research Council	None	1461648.0	GBP
20	Professor Jones	University College London	None	None	2019-03-31	Biological information extraction for genome and superfamily annotation	There are two aspects of the proposed research: first, creating, populating and annotating biological databases, and second, creating the software to do so via information extraction. The proposed system will use templates to perform information extraction from biological texts, to create new database records. A template is a representation of a text pattern that allows the system to identify the information of interest. It consists of a number of predefined slots to be filled in by the system from information contained in the text. One major drawback of existing information extraction tools is that new templates must be created by hand for each information extraction task, and this requires considerable computational expertise, as well as time. Our goal is a system that will be able to generate its own templates automatically. We propose a sequence of research steps, moving from manual template creation to fully automatic template creation. The aim is to reduce systematically the dependence on technical expertise, either in the form of a technical expert, or in requiring biological researchers to spend time developing the required computational knowledge. The end result will be a system that can create its own templates for biological (as opposed to computational) users. As the system develops, we will apply it to a variety of biological problems that we have identified with our collaborators. These include superfamily assignment, genome annotation, gene product characterisation and pathway inference. In each case, the system will be validated by comparison with known results in existing databases, and by being used to extend well-understood domains, before being deployed by the biological research partners to work on new domain areas. This sequence will provide confidence in the system's abilities. We plan to represent documents and templates in a single format, using Hidden Markov models (HMMs). Each node in the model will represent a word, a part of speech (noun, verb etc.) or a semantic biological category (protein, gene, metabolite etc.). A template is a sub-graph within this model, and so the problem becomes one of learning to identify useful sub- graphs automatically. We shall apply different machine learning technologies to the problem, including supervised learning, semi-supervised learning and active learning. In supervised learning, a labelled example is a sentence or document fragment that a domain expert has chosen as being of interest (positive example) or irrelevance (negative example). It takes considerable time and expertise to create a set of such labelled examples, and this must be repeated for each new domain. In contrast, unlabelled examples are easy to acquire in large quantities. Semi-supervised learning makes use of both labelled and unlabelled examples to model the domain. Active learning systems work by generating potential solutions, and asking the user to evaluate them. In this way, the users expert knowledge can be incorporated within the system, without requiring the user to learn new technical specification languages, or spend time learning to use a complex tool.	Biotechnology and Biological Sciences Research Council	grant	264049.0	GBP
21	Prof Michael Sternberg	University College London	None	None	2019-03-31	Protein structure prediction - development and benchmarking of machine learning algorithms	None	Biotechnology and Biological Sciences Research Council	None	None	None
22	Prof Michael Sternberg	Imperial College London	None	None	2019-03-31	Protein Function Prediction using Machine Learning by an Enhanced Novel Support Vector Logic-based Approach	This proposal has two inter-related aims: 1) to develop a method to predict the function of a protein from its experimental or predicted structure using a novel machine learning method - support vector inductive logic programming (SVILP); 2) to enhance the prototype version of SVILP into a robust tool for use in protein function prediction and in a broad range of other application areas. To develop function prediction, will use the Catalytic Site Atlas and eFsite (electrostatic-surface of Functional site). The first step is to predict which residues are functional. A pool of method will be used: our in-house program PHUNCTIONER that identifies residues specific for function, graph theoretic measures, electrostatics, evolutionary and statistical propensities, spatial clustering and cleft geometry. We will use SVILP to learn rules to predict functional residues using the above as background knowledge. The second step is to learn 3D motifs to specific function using the SVILP to yield rules. We will develop a web server for dissemination of the methodology. We will interact with structural genomics projects to employ and test our method. To improve SVILP, we will consider 4 topics. (1) Feature Selection will select a small number of rules that are highly effective and will be implemented using both filter and embedded methods. (2) Estimation of probabilistic parameters on ILP rules will use maximum a posteriori estimations to give different weights to rules. (3) Novel Kernel Functions will be designed that are efficient and effective for protein function modelling. We will prove the properties of symmetry and positive semi definiteness that will establish the validity of the developed functions as kernel functions. (4) A Multi-class prediction method will implemented that allows SVILP-based techniques to perform robust and accurate multi-class predictors based on schemes which weight the predictive contributions of individual rules and class predictors.	Biotechnology and Biological Sciences Research Council	Standard grant	683503.0	GBP
23	Professor Malcolm Macleod	University of Edinburgh	Centre for Clinical Brain Sciences	2016-04-01	2018-03-31	Pilot study of the utility of text mining and machine learning tools to accelerate systematic review and meta-analysis of findings of in vivo research	Firstly we will convene an expert panel to establish "required" and "desired" performance thresholds for the performance of text mining and machine learning tools. Then, for each of the three tasks of identifying and retrieving relevant publications, extracting meta-data from identified publications, and extracting outcome data from relevant publications we will (1) where not already performed, conduct a systematic review to identify all candidate approaches; (2) implement the most promising approaches using existing systematic review datasets; and then (3) prospectively validate these approaches in ongoing systematic reviews. These tasks will be conducted by a team which brings together expertise in text mining and machine learning as applied to systematic review (Thomas, Ananiadou) and in the conduct of systematic reviews of in vivo data (Sena, Rice, Macleod), supported by external collabortators. The development datasets are (1) a systematic review of in vivo studies in neuropathic pain, (2) a systematic review of in vivo publications from leading UK institutions, and (3) a selection of in vivo publications describing different outcome measures curated on the CAMARADES database. For the validation datasets we will use a systematic review of in vivo models of depression. For each, we will ascertain the sensitivity, specificity and where relevant the accuracy of the text mining/ machine learning approach, and the reduction in human work (eg number of articles needed to screen) possible whilst maintaining performance at the "desired" threshold.	Medical Research Council	Research Grant	352793.0	GBP
24	Professor Simon Hubbard	University of Edinburgh	Centre for Clinical Brain Sciences	None	2018-03-31	Improved identification of proteins from fragment ion spectra using machine learning in proteomics	None	Biotechnology and Biological Sciences Research Council	None	None	None
25	Professor Troscianko	University of Bristol	None	2007-02-01	2010-09-30	Cognitive Systems Foresight: Human Attention and Machine Learning	None	Wellcome Trust	Project Grant	67918.0	GBP
26	Professor David Stuart	Diamond Light Source Ltd	None	2018-10-01	2021-09-30	SuRVoS Workbench: Enhanced machine learning for segmentation across structural biology	Very high-resolution 3D biological images can be directly interpreted in terms of atomic structures, lower-resolution data however is interpreted by segmenting into separate volumes. Volumetric biological image data has many complexities which make segmentation difficult. These data are often low contrast, with low signal-to-noise and can be terabytes in size, so that segmentation is an error-prone and time-consuming bottleneck. SuRVoS uses machine learning, advanced image filters and over-segmentation methods to semi-automate the process, dramatically reducing the time to segment data from weeks to days. This project aims to further reduce that time and increase reliability using the latest developments in machine vision and enhanced training sets. The ultimate goal is to completely automate segmentation using advances in deep learning. Such methods require significant quantities of already segmented data to train the systems. To build segmented data for this development the segmentation tools in SuRVoS will be incorporated into a citizen science platform (Zooniverse), enabling the segmentation of many datasets from a wide range of techniques and model systems, without placing a large burden on individual researchers. This platform will then feed-back firstly to enhance segmentation across the bio-imaging facilities at Diamond enabling users’ research, and ultimately the broader user community.	Wellcome Trust	Biomedical Resources Grant	605412.0	GBP
27	Dr Francesco Falciani	University of Birmingham	None	2008-08-01	2011-11-30	Modelling cell-to-cell communication networks:an integrated approach to studying cell interactions during tissue angiogenesis.	The recent development of functional genomics technologies, particularly gene expression profiling, has provided the scientific community with the tools to characterize the molecular state of cells and tissues at a genomic level. The analysis of these datasets using statistical modelling and more advanced machine learning techniques designed to reconstruct and model the structure of biologically relevant pathways has contributed to reshaping biological investigation. Despite the paramount importance of this work, very little has been done to apply such network inference methodologies to reconstruct and model the structure of networks representing cell-to-cell communication events. The project we propose develops from preliminary work performed in the applicants research groups, aiming to develop the mathematical and experimental framework to infer the structure of regulatory pathways from both steady-state and temporal data. From an experimental prospective we will focus on the understanding of the general mechanisms involved in endothelia-tumor cell interactions. The project involves an initial component of genome-wide expression profiling and proteomics data generation followed by iterative cycles of computational modelling, hypothesis formulation and experimental verification using a set of state of the art gene modulation tools applicable to both in vitro and in vivo systems. Initially, we will identify informative genes and map these on known functional networks and protein-protein interaction networks in order to identify functionally interesting gene modules (for example derived from KEGG, BioGrid, REACTOME, etc). This modularization process will help in the selection of the genes to model using ARACNE, Bayesian networks and other similar computational approaches. The project will ultimately lead to the development of computational models representing cell-to-cell interaction networks from both time course and steady-state datasets. The analysis and Biological interpretation of these networks will allow us to develop hypothesis and experimentally verify them using gene manipulation techniques in both in vitro and in vivo systems. We expect this project to lead to the identification of regulatory circuits that are important in the interaction between endothelial and tumour cells during tumour growth and to a better understanding of the biological and molecular events associated to known factors involved in the tumour vascularization.	Cancer Research UK	Project Award	None	None
28	Professor Sir Walter Bodmer	University of Oxford	None	2009-07-12	2016-07-11	Genetics of the people of the british isles and their faces.	We will add 1,000 samples from the Ancient British western fringe, and from the eastern areas that most reflect the Anglo-Saxon influence, to the 3,500 already collected (rural areas, all four grandparents from the same area). A further 1,500 samples will be collected from populations surrounding the British Isles. Genetic variation determining facial features will be identified through association analysis of candidate gene markers with statistically determined facial characteristics obtained from photographs of the newly collected volunteers and of MZ and DZ twins from the TRU study. Lymphoblastoid cell lines will be grown out from a subset of 1,000 individuals to enable study of the genetic control of tissue specific protein and mRNA levels. Surname distributions will be used to enhance information about the locality of volunteers. Extensive genotyping will be done on the new samples. Analysis of the results of this and previous genotype data, using machine learning algorithms a nd second level haplotyping, together with the facial genetic and certain other markers, will be used to construct a panel of highly informative AIMs. These will be typed on all samples and form the basis for an extensive analysis of population substructure using a wide variety of statistical approaches.	Wellcome Trust	Programme Grant	2067797.0	GBP
29	Professor Philip Bath	Nottingham,University of	Stroke Trials Unit, Division of Clinical Neuroscience	None	2016-07-11	Assessment of modern machine learning methods and conventional statistical regression techniques in diagnosis and prediction of outcome after acute stroke using big data	Stroke is common, may be mimicked by other conditions, and often has a poor outcome. We will use high-fidelity big data from acute stroke trials (which will include those with stroke, TIA and mimics) involving up to 90,000 instances/patients with baseline clinical and imaging, on treatment, diagnostic and outcome information. We will assess the accuracy of state-of-the-art machine learning with artificial neural network (ANN) models, including deep neural networks (DNN), in the diagnosis of stroke versus mimics, and prediction of early complications (deterioration, stroke recurrence and re-bleeding) and late outcomes (functional outcome, cognition, mood, quality of life, disposition, death) after stroke. These will be compared with conventional statistical regression models (binary, Cox, ordinal and linear regression). Neither ANN/DNN nor statistical approaches are used routinely in stroke management in part because of poor accuracy and acceptability to clinicians. If diagnostic and prediction models are accurate and acceptable to patients and clinicians then their use could be rapidly introduced into clinical care to improve patient management, for example through the use of apps on phones/tablets/computers.	British Heart Foundation	Project Grant	145079.0	GBP
30	Professor Joanna Wardlaw	Edinburgh, University of	Neuroimaging Sciences	None	2016-07-11	The BHF-Turing Cardiovascular Data Science Awards (Second Call): Uncovering retinal microvascular predictors of compromised brain haemodynamics in small vessel disease (joint funding with The Alan Turing Institute)	Cerebral small vessel disease (SVD) is a common neurological disease which causes up to 45% of dementias and about 20% of all strokes worldwide. The cause of the underlying pathology is poorly understood and there is no proven treatment. A limitation in human SVD research is that current MRI brain imaging technology has millimetre resolution while the vessels where SVD start are microscopic. However, retinal and cerebral microvasculature are developmentally related, and the former can be fully resolved in routinely acquired optical coherence tomography angiography (OCTA) retinal imaging. In this project, we will use Data Science to deeply phenotype retinal images in two ongoing clinical SVD studies. First, we will develop convolutional neural network approaches for OCTA image segmentation and Graph Theory approaches for structural phenotyping. Second, we will use computational fluid dynamics and high performance computing to carry out haemodynamic characterisation of the retinal vascular networks beyond what is observable clinically. Finally, we will uncover associations between structural and functional retinal phenotypes and SVD-related compromised brain haemodynamics. We expect this work to be an important step towards delivering Precision Medicine for SVD.	British Heart Foundation	Special Project	66000.0	GBP
31	Professor Stephen McMahon	King's College London	Neuroimaging	2017-01-01	2021-12-31	Stratifying Chronic Pain Patients By Pathological Mechanism- A Multimodal Investigation Using Functional MRI, Psychometric And Clinical Assessment	Chronic pain remains an area of considerable unmet need. Up to 20% of the population suffer psychological distress and poor health status. Classification remains disease-based, despite evidence that multiple pathophysiological processes underpin diseases, and that patients with similar symptoms can have different aetiologies. As most current pharmacotherapies target only one mechanism, it is not perhaps surprising that many offer only moderate pain relief. Mechanism-based patient stratification should facilitate timely, appropriate and cost-effective treatments. We will use multimodal techniques to stratify patients according to their underlying pain mechanisms, examining patients with intractable painful osteoarthritis, orofacial pain and pain-free controls. Evoked-response and resting-state functional and perfusion magnetic resonance imaging will be employed to investigate brain, brainstem and spinal cord structures underpinning mechanisms of ongoing peripheral drive, central sensitisation, descending pain modulation (DPM) and functional connectivity. We will decouple peripheral from central phenomena using anaesthetic blocks. Gold-standard subjective report, psychometric and sensory testing data will also be acquired. We will use multimodal machine learning across all data to predict the mechanisms underlying patients' persistent pain, namely: (i) does persistent pain originate peripherally, centrally or as a combined state? (ii) is the DPM system functioning? We will determine which data types contribute most to patient stratification, deriving simple, identifiable fingerprints of each pathophysiological state for clinical use. Success in this project should impact on clinical practice. Diagnostic uncertainty is associated with poor outcomes, distress and suffering. Delivery of new mechanistic insights should catalyse treatment development; better identification of aetiologies should expedite implementation of treatments tailored to individual patients.	Medical Research Council	Research Grant	2718044.0	GBP
32	Professor Simon Hubbard	King's College London	Neuroimaging	None	2021-12-31	Improved identification of proteins from fragment ion spectra using machine learning in proteomics	None	Biotechnology and Biological Sciences Research Council	None	None	None
33	Professor Olga Ciccarelli	University College London	None	2019-01-01	2023-12-31	Predicting individual treatment responses towards personalised medicine in Multiple Sclerosis	BackgroundMultiple sclerosis (MS) is the most widespread disabling disease of young people. Thirteen disease-modifying treatments (DMTs) are approved in the UK to reduce the risk of relapses. Patients can switch from one first-line DMT to a more effective medication, if they present with relapses.The consequences of this policy, that requires failure of DMTs before using another DMT are continuous relapses and disability accumulation. We cannot currently predict which DMT will work best for an individual patient.The goal of this project is to predict the individual treatment response in MS by translating machine learning from the computer science field into clinical practice. This will bridge the gap between clinical trials, which focus on the average response to a therapy, to clinical practice, where the focus should be on the individual treatment response.Aims To develop deep phenotyping and genotyping of patients initiating DMTs in the clinical setting To generate and validate a high-dimensional model that predicts treatment response earlyThe study design will offer the possibility to pursue additional aims, which are to: improve our understanding of disease pathobiology by defining responders' profiles collect data for the evaluation of the health-economic impact of stratificationPlan of investigation MS patients Retrospective cohort: 1,566 (1,494 adults, 72 children) currently on DMTs at UCLH NHS Trust and in the UK paediatric neuroinflammation centres, who are undergoing clinical and MRI assessments according to standard-of-care protocols. In the NIHR UCLH BRC Imaging initiative, we have already collected all the patients' MRI scans and carried out a pilot study that demonstrates the feasibility of our approach.Prospective cohort: 780 patients (700 adults, 80 children (>12yrs)) who initiate any DMT during the course of two years. Patients will be studied at baseline and after 6 and 18 months. A standardised acquisition of demographic factors, diet quality and life-style, clinical scales, comorbidities, MRI scans and blood tests for safety data and neurofilaments-light levels, will be collected. Genetic factors will be obtained through NIHR UCL BioResource biobank.Independent, international cohorts: MSBase (www.msbase.org,>55,000 patients); Swedish MS registry (http://www.neuroreg.se/en.html/multiple-sclerosis,>19,000 patients); FutureMS (www.stratmed.co.uk/programs-and-projects/future-ms/); EU Paediatric Demyelinating Disease Network.Predictive modelling Treatment response will be defined on clinical and MRI grounds. Machine learning techniques will be used to develop a high-dimensional model that predicts individual treatment response, using all the information collected. The model will be constructed from retrospective and prospective data, and then validated on independent cohorts. Benefit for patients and NHSThe outputs of this project are: Access to deep phenotyping and genotyping directly for NHS patients Prototype software running on local machines to guide treatment choice Improved understanding of the mechanisms that lead to a positive treatment response Data registry for the evaluation of health-economic impact of stratification Predicting individual treatment response is crucial to practice personalised medicine, which will have a huge impact at a personal level, societal level and on the NHS. This project will position the UK as a world leader for research in personalised medicine in neurology.	National Institute for Health Research (Department of Health)	Full Grant	1853695.0	GBP
34	Professor Ken Stein	University of Exeter	None	2019-02-01	2021-01-31	Use of simulation and machine learning to identify key levers for maximising the disability benefit of intravenous thrombolysis in acute stroke pathways	Background: Stroke is a leading cause of death and disability worldwide. Currently the only licensed drug treatment for acute stroke is thrombolysis with alteplase the benefit of which is critically time-dependent. There is significant variation between hospitals both in rates of thrombolysis use and door-to-needle times for ischaemic stroke. Aim: Our aim is to use simulation and machine learning technologies to identify key levers of improvement in thrombolysis use and speed developing this analysis to be run as part of the routine quarterly national stroke audit. Qualitative research will be undertaken to maximise the acceptance and influence of these techniques.Methods: Discrete event simulation allows for the prediction of the effect of changing key aspects of the acute stroke pathway (e.g. change in speed). Machine learning techniques allow for an understanding of differences in decision making between different hospitals and offer the potential for ‘exporting’ decision making from one location to another. For example training a machine-learning model based on decision making in a set of benchmark hospitals acknowledged to be centres of clinical excellence allows an estimation of the effect of similar decision making in different hospitals which might have a different patient mix. All models will be built in Python allowing easy transfer of techniques. Qualitative research will be based on 1:1 interviews focus groups and workshops. Pilot work: Methods have been trialled in seven hospitals in which thrombolysis use for stroke ranged from 7% to 14% of admitted patients. Three factors were pivotal in governing thrombolysis use: (1) the proportion of patients with a known stroke onset time (2) pathway speed and (3) predisposition to use thrombolysis for those patients canned with time to treat. A pathway simulation model could predict the potential benefit of improving individual stages of the clinical pathway speed whereas a machine learning model could predict the benefit of ‘exporting’ clinical decision making from one hospital to another whilst allowing for differences in patient population between hospitals. By applying both techniques together we found a realistic ceiling of 15-25% in use of thrombolysis across different hospitals and more importantly in the hospitals studied a realistic opportunity to double the number of patients with no significant disability following treatment with thrombolysis.Summary of planned work: Models will be refined and developed to run on the national stroke data set as part of routine quarterly audit. This will involve defining a reference group of benchmark hospitals for the decision-making (machine learning model). Pilot work has shown good promise for these techniques but there is significant scope for optimising models testing different types of machine learning models and combining multiple machine learning models. We will pilot different ways of visualising output of models and conduct qualitative research to understand how best to present model output to maximise their influence and impact in the clinical community. Public advisors have already informed the project and patient involvement will continue throughout the study. Support for this work has been obtained from the National Clinical Director of Stroke with the Stroke Association offering support and assistance with dissemination.	National Institute for Health Research (Department of Health)	Full Grant	329261.0	GBP
35	Professor Malcolm Macleod	University of Edinburgh	Centre for Clinical Brain Sciences	2016-04-01	2018-03-31	Pilot study of the utility of text mining and machine learning tools to accelerate systematic review and meta-analysis of findings of in vivo research	Firstly we will convene an expert panel to establish "required" and "desired" performance thresholds for the performance of text mining and machine learning tools. Then, for each of the three tasks of identifying and retrieving relevant publications, extracting meta-data from identified publications, and extracting outcome data from relevant publications we will (1) where not already performed, conduct a systematic review to identify all candidate approaches; (2) implement the most promising approaches using existing systematic review datasets; and then (3) prospectively validate these approaches in ongoing systematic reviews. These tasks will be conducted by a team which brings together expertise in text mining and machine learning as applied to systematic review (Thomas, Ananiadou) and in the conduct of systematic reviews of in vivo data (Sena, Rice, Macleod), supported by external collabortators. The development datasets are (1) a systematic review of in vivo studies in neuropathic pain, (2) a systematic review of in vivo publications from leading UK institutions, and (3) a selection of in vivo publications describing different outcome measures curated on the CAMARADES database. For the validation datasets we will use a systematic review of in vivo models of depression. For each, we will ascertain the sensitivity, specificity and where relevant the accuracy of the text mining/ machine learning approach, and the reduction in human work (eg number of articles needed to screen) possible whilst maintaining performance at the "desired" threshold.	Medical Research Council	Research Grant	352793.0	GBP
36	Professor Andrea Rockall	The Royal Marsden NHS Foundation Trust	None	2018-06-01	2021-08-31	MAchine Learning In MyelomA Response (MALIMAR study): Development of machine learning support for reading whole body diffusion weighted magnetic resonance imaging (WB-MRI) in myeloma for the detection and quantification of the extent of disease before and after treatment	HYPOTHESIS AND AIMS: Machine learning (ML) methods to post-process whole body (WB) diffusion-weighted (DW) MRI scans in myeloma patients will improve the detection & assessment of the extent of active disease before and after treatment and reduce the radiological reading time (RT). DESIGN POPULATION & ASSESSMENTS:Phase 1 (training): WB-MRI scans from a cohort of 160 myeloma patients (120 with active disease) from a single centre and 40 age-relevant healthy volunteers (HV) will be used to develop a ML detection tool to recognise active myeloma.Phase 2 (validation): Sensitivity and RT assessment using WB-MRI -/+ ML in 203 active myeloma 100 inactive myeloma and 50 HV.Phase 3 (disease quantity): A ML quantification tool will be developed then tested on WB-MRI of 60 patients having scans before and after myeloma treatment on iTIMM trial. Quantification score RT and categorisation of response will be assessed +/- ML. Reference standard will be expert panel. INTERVENTION:No patient intervention is planned. Study intervention is the addition of ML detection and quantification tools to existing WB-MRI scans on patients with myeloma and HVs. Expert and non-expert radiology readers will review scans in mixed order such that paired reads +/- ML are available for analysis. OUTCOME MEASURES:Phase 1: Sensitivity of ML detection tool for active myeloma when compared to reference standard. Phase2: Primary: Difference in sensitivity of WB-MRI+/-ML to diagnose active myeloma on a per-patient basis by expert readers against the reference standard.Secondary: per-site sensitivity RT specificity and categorization of disease type of WB-MRI-/+ML; difference in sensitivity and specificity of WB-MRI+/-ML support using new readers.Phase 3: Primary: Agreement between experienced readers and reference standard in scoring disease burden assessed +/- ML. Secondary: RT agreement between readers in response category compared to reference; cost analysis. SAMPLE SIZE: Phase 1: 40 HV & 160 myeloma patients (120 with active disease).Phase 2: 50 HV & 100 patients with no active disease); 203 patients with active diseasePhase 3: 60 patients 120 WB-MRI scans (2 time points). STATISTICAL ANALYSIS AND ECONOMIC BENEFIT:Phase 1: Sensitivity based on ML cross-validation methods.Phase 2: % of patients with active disease who have positive reference standard on WBMRI-/+ML will be compared using McNemar’s test. Per patient and per site sensitivity -/+ML will be reported with 95% CI. Per patient and per site specificity -/+ML will be reported with 95% CI. RT will be compared using the most appropriate test.Phase 3: Differences from scores given by experienced readers and the reference will be described using Bland-Altman plots +/- ML. A simple economic benefit analysis will be performed based on reading times. DURATION OF THE STUDY:Total duration is 39 months. MAIN STAGES OF THE PROPOSED PROJECT WITH EXPECTED DURATIONS (MONTHS): Phase 1: (Months 0-16): Segmentation and development of ML detection tool. Phase 2: (Months 9-28): Validation of ML detection tool. Paired radiology reads of 353 WB-MRI +/- ML support. Further optimisation of the ML tool may be undertaken. Phase 3: (Months 16-39): Development and validation of ML quantification tool. Sequential WB-MRI scan from patients before and after treatment will be evaluated qualitatively and quantitatively for extent of disease +/- ML support. Complete report.	National Institute for Health Research (Department of Health)	Full Award	646787.62	GBP
37	Professor Andrea Rockall	Imperial College London	Department of Radiology	2015-02-01	2019-09-30	Development and evaluation of machine learning methods in whole body magnetic resonance imaging with diffusion weighted imaging for staging of patients with cancer. (MAchine Learning In whole Body Oncology, MALIBO)	BACKGROUND: Whole body magnetic resonance with diffusion weighted imaging (WB-DW-MR) is a technique that shows tumour sites in many different parts of the body, based on the appearance of different tissue types and the water motion within tumour tissue when compared to healthy tissue. There is no burden of ionising radiation. Although WB-DW-MR allows for “at a glance” assessment of disease extent, it is subject to some error, for example, some normal structures may resemble the appearance of tumour. Also, WB-MR is time-consuming to report by the radiologist due to the large number of images. HOW THE PROPOSAL ADDRESSES THE RESEARCH PROPOSED: We propose to conduct a study during which we will develop and evaluate an innovative machine learning (ML) method to support radiology reporting by automatically detecting lesions and potentially increasing the diagnostic accuracy (DA) and reducing the reading time (RT) of WB-DW-MRI scans in patients with cancer. HOW AND WHERE THE RESEARCH WILL BE CARRIED OUT: Research will be carried out at Imperial College London in collaboration with the teams of main studies (NIHR STREAMLINE (colon & lung cancer patients) and CRUK MELT (lymphoma patients)) who have recruited all the patients for WB-DW-MR datasets. The proposed study has three stages: firstly, WB-DW-MR from 50 healthy volunteers will be used to develop the ML method for automatic recognition of normal appearances. Secondly, the ML method will be tested on 150 WB-MR scans from the main studies, in whom the different sites of disease have already been confirmed. The ML method will be refined by radiologists who will identify the correct sites of disease and find ML errors. This will be used to improve the ML method. Thirdly, the refined ML method will be tested in a 2nd group of 169 patients from the main studies to see if the technique can improve radiology reporting by improving DA and RT. WHAT OUTCOMES WILL BE USED TO ASSESS THE SUCCESS OF THE RESEARCH: The primary outcome measure will be correct identification of patients with or without metastatic disease. We will also assess the reduction in RT, the variability between the same and different readers and between different combinations of acquired MRI data. An estimate of the possible reduction of additional patient staging tests needed due to the use of ML will be made. WHAT ARE THE ETHICAL ISSUES INVOLVED IN THIS STUDY: Ethical approval for the normal volunteer study is in place, as part of development of WB-MR at Imperial College. Ethical approval has been obtained for the main studies, which are now recruiting. We will seek ethical approval for use of the anonymised WB-MR datasets for ML evaluation; there will be no change to patient management. WHY THIS TEAM IS WELL PLACED TO CARRY OUT THE RESEARCH: Our team has experts in clinical cancer imaging, MRI physics and all have run imaging based trials. D Rueckert is internationally recognized image computing expert with ML expertise. PROVIDE A JUSTIFICATION FOR THE COSTS REQUESTED (including NHS costs): The costs of all volunteer and patient WB-MR scans have been previously funded, making this a highly cost-effective study. Grant funding will cover the costs for the time of the applicants and researchers that will organise and conduct the study and analyse the results. Also included are expenses for equipment and consumables, trial management and dissemination of results at European and International conferencesr	National Institute for Health Research (Department of Health)	Full Grant	578090.0	GBP
38	Prof Zoe Kourtzi	University of Birmingham	None	None	2019-09-30	Classification decisions in machines and human brains	Our ability to extract abstract information from our experiences and group it into meaningful units (categories) is a fundamental cognitive skill for interpreting the complex environments we inhabit. How does the human brain learn about the regularities and context of novel perceptual experiences that have not been honed by evolution and development and decide on their interpretation and classification? We propose a novel interdisciplinary approach that integrates advanced multimodal imaging (fMRI, MEG, EEG) methods and state-of-the art machine learning algorithms to examine the neural architecture that underlies classification learning and decisions in the human brain. We aim to a) create an electrical-haemodynamic signal space in which neuronal assemblies and their interactions can be characterised, and b) to develop a unified algorithmic method for efficiently analyzing neural imaging and behavioural data. In particular, we will use machine pattern classifiers to define perceptual decision images that reveal the critical stimulus features on which the observers base their perceptual classifications, and neural decision images that reveal the neural selectivity, plasticity and dynamics with which these features are encoded and learnt by the human brain. Our methodological and theoretical developments will provide a) novel and sensitive tools for the assessment of the behavioural and neural signatures of perceptual decisions in neuroscience, and b) novel challenges and insights in machine learning for the optimisation of biologically-constrained algorithms with direct applications for expert recognition systems. Further, our findings will advance our understanding of the link between sensory input, neural code and human behaviour and have potential applications for studying the development of perceptual decision processes across the life span, and their impairment and potential for recovery of function in ageing and disorders of visual and social cognition.	Biotechnology and Biological Sciences Research Council	Standard grant	936093.0	GBP
39	Professor Morgan	University of Liverpool	None	None	2019-09-30	The application of support vector machine feature selection to cross sectional studies in epidemiology	This proposal builds on an EPSRC small grant GR/S73631/01, graded tending to outstanding" in its final report. It is a resubmission from March 2005 of application GR/EP/DO3O684 sent EPRSC Life Sciences Interface as a continuation of GR/S73631/01 and recommended for submission to BBSRC with a contribution in financial support from EPSRC if successful. Epidemiologists from Liverpool Veterinary School and computer scientist from DIMACS, a National Science Foundations Institute at Rutgers, New Jersey, USA, have recently reported the use of Support Vector Machine learning as a method of identifying risk factors for disease from observational epidemiological data. Support Vector Machine classification was developed in the mid 90's and although related to neural networks, the technique is simpler more robust and founded on statistical learning theory. In particular the use of SVM overcomes overfitting associated with the empirical risk minimisation, (ERM) which aims to minimise the error on the training data set but results in poor generalisation (i.e. performance on unseen datasets). SVM are arguably the single most important development in supervised classification in recent years. They are known to generalise well in high dimensional space even with small training sample conditions, when the data are noisy. SVM are not only good classifiers but are also good feature selection techniques. SVM has been used for the verification and recognition of faces, speech, handwriting and such diverse events as goal detection in football matches and financial forecasting. In life sciences it has been applied to gene expression, proteomics and disease diagnosis With the exception of a recent report, using single nucleotide polymorphisms (SNPs) to predict an increased risk of breast cancer there have been no published reports of the application of SVM in epidemiology. This project aims to further develop the application of SVM, to improve kernel selection and to produce a user-friendly SVM program for wider epidemiological use Data for the development of this program will be provided from an epidemiological study of an emerging disease of poultry (wet litter). Because meat birds live for only 6-7 weeks broiler flocks provide the opportunity to validate the classifications made by SVM during the period of study. The final program will provide a new paradigm in epidemiology and act as an easily applicable "second opinion" for statistical models generated using the "epidemiological standard" of logisitic regression. It will also, as a by-product, improve our understanding of wet litter in poultry. The final program will be applicable to observational studies of non-infectious and infectious human and animal disease."	Biotechnology and Biological Sciences Research Council	Standard grant	400793.0	GBP
40	Mr Boorman	University of Oxford	None	2010-05-01	2014-04-30	Dissecting the contribution of anterior prefrontal cortex to decision making with computational, statistical and neuroimaging approaches.	The first experiments would combine computational modelling from machine learning and mathematical economics with functional MRI to examine the neural computations underlying decision-making between multiple uncertain prospects in a changing environment. We would then directly compare competing computational models with subject behaviour and neural data. This would enable us to address several pivotal questions for the first time, such as how the values of different decision variables are repre sented in the vmPFC and FPC and whether there are dissociable neural routes guiding exploratory decision-making. To examine the causal contribution of FPC to decision-making, I propose to combine interference and recording methodologies. Specifically, I would interfere with FPC processing and record the effects from downstream brain regions whose signals are hypothesized to depend on FPC. This would reveal precisely when the FPC is essential for value-based decision-making. Recent ad vances in diffusion-weighted imaging (DWI) have made it feasible for the first time to examine the trajectories of anatomical pathways in the brain in vivo. I propose to combine the approaches outlined above with DWI to examine how inter-individual variability in functional interactions between the FPC and other brain regions during decision-making relates to the anatomical connectivity of the FPC.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	250000.0	GBP
41	Prof Ammar Al-Chalabi	King's College London	Clinical Neuroscience	2018-02-01	2021-01-31	JPND Biological Resource Analysis to Identify New MEchanisms and phenotypes in Neurodegenerative Diseases (BRAIN-MEND)	Current classification of neurodegenerative diseases (ND) is based on clinical phenotypes and does not account for underlying disease heterogeneity or overlapping disease mechanisms, hindering therapy development. Reclassification of NDs is therefore urgently needed. From a therapeutic perspective, reclassification should be based on causal and druggable factors. BRAIN-MEND will reclassify existing phenotypes using pathway and network analyses within and across complex NDs including Alzheimer Disease, Parkinson Disease, ALS, FTD, Corticobasal Degeneration, MSA, and PSP. We will use three innovative approaches, pioneered or adopted by the consortium: WP1 will apply the latest methods to identify causal genetic factors acting on molecular pathways; WP2 will apply cutting edge methods to identify epigenetic factors associated with molecular pathways of ND; and WP3 will identify drug targets from network analyses using results from WP1 and WP2 without requiring prior knowledge of mechanism. WP4 will use analysis of medical literature and patient records to identify novel or under-recognized clusters of related clinical features. These complementary approaches allow for iterative cross-validation of elucidated factors by WP1-4. BRAIN-MEND will reclassify ND phenotypes based on biologically meaningful categories corresponding to subgroups (heterogeneity) and common pathways (pleiotropy) to enhance disease understanding and facilitate drug development across the entire complex ND landscape. WP5 will manage the project and disseminate results. Patients and caregivers will be intimately involved throughout the project. Our consortium is highly qualified to perform the work proposed, as evidenced by a mean PI h-index of 61, major impact in research in neurodegeneration and neuropsychiatry, direct expertise with and access to a large and rich dataset spanning all complex NDs, track record in cross disorder analyses, and the related tools, biobanks and cell models needed.	Medical Research Council	Research Grant	549837.0	GBP
42	Professor Sophia Ananiadou	The University of Manchester	None	None	2021-01-31	Tools for the text mining-based visualisation of the provenance of biochemical networks	Systems biology is concerned with the modelling, visualisation and analysis of biochemical networks in which, for instance, metabolites are 'linked' by arrows representing the enzymes which turn one molecule into another or which are modified by particular substances. SBML provides a computer- readable 'standard' for describing such biochemical or signalling networks. However, these diagrams (and thus the SBML models) are divorced from the scientific evidence on which they are based, represented by the scientific literature (and increasingly by online databases). In order to overcome the problems of reading the burgeoning scientific literature, we shall deploy Text Mining TM. TM involves named entity recognition (i.e. semantic annotation of enzymes, metabolites, etc) and information extraction (i.e. relationship extraction between named entities). An important part of this proposal is to find solutions for the terminology problem in systems biology, by developing techniques for recognising synonym terms.Based on our efficient parsing techniques, we shall extract relationships between entities that will form the basis by which we shall can discover, index, store and display the scientific evidence for such linkages. The selection of the most pertinent relationships will be performed using our preferred methods of advanced machine learning (Support Vector Machines and Genetic Programming). The overall aim of the project is thus to develop and deploy the necessary TM tools and to use them to display the different relationships to the user together with the literature from which they have been extracted. The different types (and strength) of evidence for these interactions will then be visualised directly and linked to a dynamic website of the literature. This will thus give users a direct linkage between the systems biology diagrams encoded in (an advanced form of) SBML and the scientific evidence for them. Where available, linkages to kinetic data will also be made.	Biotechnology and Biological Sciences Research Council	Standard grant	549458.0	GBP
43	Professor Douglas Kell	The University of Manchester	None	None	2021-01-31	Tools for the text mining-based visualisation of the provenance of biochemical networks	Systems biology is concerned with the modelling, visualisation and analysis of biochemical networks in which, for instance, metabolites are 'linked' by arrows representing the enzymes which turn one molecule into another or which are modified by particular substances. SBML provides a computer- readable 'standard' for describing such biochemical or signalling networks. However, these diagrams (and thus the SBML models) are divorced from the scientific evidence on which they are based, represented by the scientific literature (and increasingly by online databases). In order to overcome the problems of reading the burgeoning scientific literature, we shall deploy Text Mining TM. TM involves named entity recognition (i.e. semantic annotation of enzymes, metabolites, etc) and information extraction (i.e. relationship extraction between named entities). An important part of this proposal is to find solutions for the terminology problem in systems biology, by developing techniques for recognising synonym terms.Based on our efficient parsing techniques, we shall extract relationships between entities that will form the basis by which we shall can discover, index, store and display the scientific evidence for such linkages. The selection of the most pertinent relationships will be performed using our preferred methods of advanced machine learning (Support Vector Machines and Genetic Programming). The overall aim of the project is thus to develop and deploy the necessary TM tools and to use them to display the different relationships to the user together with the literature from which they have been extracted. The different types (and strength) of evidence for these interactions will then be visualised directly and linked to a dynamic website of the literature. This will thus give users a direct linkage between the systems biology diagrams encoded in (an advanced form of) SBML and the scientific evidence for them. Where available, linkages to kinetic data will also be made.	Biotechnology and Biological Sciences Research Council	Standard grant	549458.0	GBP
44	Professor Derrick Crook	University of Oxford	None	2016-10-01	2020-10-01	Comprehensive Resistance Prediction for Tuberculosis: an International Consortium (CRyPTIC)	Our aim is to achieve sufficiently accurate genetic prediction of resistance to all anti-tuberculosis drugs for whole genome sequencing (WGS) to replace slow, cumbersome, culture-based drug susceptibility testing (DST) for Mycobacterium tuberculosis complex (MTBC). This would enable rapid-turnaround near-to-patient assays to revolutionize drug-resistant TB identification and management. This multidisciplinary collaboration including TB experts from five continents, WHO, statisticians/mathematicians and software engineers will integrate machine-learning, statistical genetics and molecular genetics methods to uncover all genomic variation causing at least 1% resistance to first- and second-line anti-TB drugs with >1% resistance prevalence. We will use large-scale global and clade-representative WGS (>90,000), with initially >37,000 isolates with extended DST. Approaches include better WGS assembly to identify more variants with more precision, improved statistical methods to detect associations between variants and DST, and selected molecular validation of predicted resistant variants. The project will create an automatically-updating, free, publically accessible, comprehensive data repository of resistance-conferring variants. This will provide accurate genetic resistance prediction for all drugs for any new MTBC WGS; superior design of near-to-patient amplification-based molecular drug-resistance tests as alternatives to ‘WGS-only’ solutions; and better, faster and more targeted drug-resistant TB treatment, facilitating improved control and WHO’s initiative to eliminate TB by 2050.	Wellcome Trust	Collaborative Award in Science	4095865.0	GBP
45	Professor Lord Ara Darzi	Imperial College London	None	2017-04-01	2022-03-31	Cancer Research UK Imperial Centre	The Cancer Research UK Imperial Centre will enhance cancer prevention, expedite early cancer detection, and improve the precision of cancer treatments and outcomes for patients, by leveraging Imperial’s core strengths in engineering, technology, physical sciences, imaging and systems medicine. Our vision is to unify technologies and platforms and re-orientate them in a co-ordinated effort to tackle cancer treatment and prevention. We will focus on reducing the burden of cancer by: improving the identification of high-risk populations; capitalising on advances in metabolic phenotyping; developing novel screening tests; enhancing screening uptake; improving clinical decision-making through machine learning and digital health systems. Our efforts to improve precision of cancer care will lead to improvements in: tumour boundary identification; cancer resectability via medical robotics, augmented reality, and intraoperative tissue characterisation; identification of risk for relapse through lab-on-chip technologies enabling interrogation of single cells, cell free DNA, and microRNAs; prediction of stage and spread by exploiting changes in microbiome composition; treatment monitoring of response and resistance by imaging apoptosis and studying epigenetic reprogramming. The Cancer Research UK Imperial Centre and Imperial Experimental Cancer Research Centre will utilise a broad and unique set of strengths across engineering and the physical sciences, surgery, imaging and diagnostics - underpinned with high-quality clinical practice - to realise a transformative research programme aimed at improving cancer survival for patients and the public.	Cancer Research UK	None	None	None
46	Professor Marchant	Imperial College London	None	None	2022-03-31	Inference and learning in machine vision	None	Biotechnology and Biological Sciences Research Council	Institute Project	None	None
47	Professor Lorenz Wernisch	University of Cambridge	None	2016-12-01	2019-03-31	Statistical bioinformatics and genetics	We focus our research on gene regulation and biopathways as derived from genetic, phylogenetic, gene expression, and molecular biomarker data. Biological systems of particular interest are stem and cancer cells (human, mouse, and drosophila), blood cells (platelets involved in artherothrombosis), and bacteria (Mycobacterium tuberculosis). Statistical modelling of such systems is challenging. Experimental data as well as other sources of information, such as bioinformatics databases, are challenging. Statistical and mathematical models which are able to represent key features of a biological system, features important for its understanding, prediction, and manipulation, are quite complex. We explore how to combine statistical inference methods, machine learning algorithms, and mathematical modelling to derive useful representations of the biological systems of interest. We will anticipate new technologies for high throughput whole genome sequencing, by developing methods for direct analysis of DNA sequences, as opposed to genetic markers. Integrating evidence from multiple data sources from different levels of organisation of a biological system will enable the discovery of important functional links and the assessment of the predictive import of molecular biomarkers with respect to phenotypes of direct clinical interest. Development of application-specific methods will result in the creation of generic computational tools and software for use by a larger community of bioinformaticians and biologists, not necessarily experts in the detailed statistical background.	Medical Research Council	Unit	None	None
48	Professor Beale	Rothamsted Research	None	None	2019-03-31	The Rothamsted Metabolomics Centre (MeT-RO)	Metabolomics is one of several technologies that will contribute to our quest to understand the function of all genes. MeT-RO will build and operate a high-throughput primary and secondary metabolite fingerprinting service for plants and microbes. We will develop and utilise a large- scale analytical chemistry facility generating NMR, GC, GC- MS, HPLC and LC-MS data at Rothamsted. Data will be managed in LIMS system at Rothamsted and transferred electronically to our partners at the University of Aberystwyth and UMIST and used to construct a metabolomics database from which comparative information will be extracted with chemometric, machine learning and other bioinformatic tools. MeT-RO and its partners will act as foci for research training in metabolomic technology while contributing data and interpretation tools towards systematic functional genomics, as well as to many other applications in the food, pharmaceutical and agrochemical industries. (Joint with MET20483 and MET20484)	Biotechnology and Biological Sciences Research Council	None	1461648.0	GBP
49	Professor Gordon Jayson	University of Manchester	None	2005-01-01	2008-06-30	The human serum metabolome in health and disease	Many arguments, including those based on metabolic Control Analysis (MCA), indicate that the metabolome should be a particularly high-resolution method for amplifying and thereby reflecting changes in the levels of gene products, especially those which accompany disease pathogenesis. A key imperative is therefore to develop and industrialise the technology optimal for determining the serum metabolome reliably, to establish the disease-independent ranges of the many hundreds of metabolites that can be observed with such technology, to recognise the disease-independent changes that occur `simply as a function of diet, gender, age, therapeutic interventions and lifestyle, and to make these data for `normals available in a web-accessible manner. Such data will form the reference baseline that will allow prognostic and diagnostic biomarkers for disease progression to be identified reliably; this will show the high- resolution discrimination possible with metabolomic data for both diagnosis and treatment. In parallel, we shall contribute to the development of (i) robust data models for metabolome data, and (ii) machine learning methods of classification in which the `gold standard diagnosis may be imperfectly reliable. The deliverables will be both underpinning knowledge of the human serum metabolome (probably including the discovery of many novel metabolites) and the identification of candidate biomarkers for two diseases.	Biotechnology and Biological Sciences Research Council	LINK project	168047.0	GBP
50	Mr Boorman	University of Oxford	None	2010-05-01	2014-04-30	Dissecting the contribution of anterior prefrontal cortex to decision making with computational, statistical and neuroimaging approaches.	The first experiments would combine computational modelling from machine learning and mathematical economics with functional MRI to examine the neural computations underlying decision-making between multiple uncertain prospects in a changing environment. We would then directly compare competing computational models with subject behaviour and neural data. This would enable us to address several pivotal questions for the first time, such as how the values of different decision variables are repre sented in the vmPFC and FPC and whether there are dissociable neural routes guiding exploratory decision-making. To examine the causal contribution of FPC to decision-making, I propose to combine interference and recording methodologies. Specifically, I would interfere with FPC processing and record the effects from downstream brain regions whose signals are hypothesized to depend on FPC. This would reveal precisely when the FPC is essential for value-based decision-making. Recent ad vances in diffusion-weighted imaging (DWI) have made it feasible for the first time to examine the trajectories of anatomical pathways in the brain in vivo. I propose to combine the approaches outlined above with DWI to examine how inter-individual variability in functional interactions between the FPC and other brain regions during decision-making relates to the anatomical connectivity of the FPC.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	250000.0	GBP
51	Prof Ammar Al-Chalabi	King's College London	Clinical Neuroscience	2018-02-01	2021-01-31	JPND Biological Resource Analysis to Identify New MEchanisms and phenotypes in Neurodegenerative Diseases (BRAIN-MEND)	Current classification of neurodegenerative diseases (ND) is based on clinical phenotypes and does not account for underlying disease heterogeneity or overlapping disease mechanisms, hindering therapy development. Reclassification of NDs is therefore urgently needed. From a therapeutic perspective, reclassification should be based on causal and druggable factors. BRAIN-MEND will reclassify existing phenotypes using pathway and network analyses within and across complex NDs including Alzheimer Disease, Parkinson Disease, ALS, FTD, Corticobasal Degeneration, MSA, and PSP. We will use three innovative approaches, pioneered or adopted by the consortium: WP1 will apply the latest methods to identify causal genetic factors acting on molecular pathways; WP2 will apply cutting edge methods to identify epigenetic factors associated with molecular pathways of ND; and WP3 will identify drug targets from network analyses using results from WP1 and WP2 without requiring prior knowledge of mechanism. WP4 will use analysis of medical literature and patient records to identify novel or under-recognized clusters of related clinical features. These complementary approaches allow for iterative cross-validation of elucidated factors by WP1-4. BRAIN-MEND will reclassify ND phenotypes based on biologically meaningful categories corresponding to subgroups (heterogeneity) and common pathways (pleiotropy) to enhance disease understanding and facilitate drug development across the entire complex ND landscape. WP5 will manage the project and disseminate results. Patients and caregivers will be intimately involved throughout the project. Our consortium is highly qualified to perform the work proposed, as evidenced by a mean PI h-index of 61, major impact in research in neurodegeneration and neuropsychiatry, direct expertise with and access to a large and rich dataset spanning all complex NDs, track record in cross disorder analyses, and the related tools, biobanks and cell models needed.	Medical Research Council	Research Grant	549837.0	GBP
52	Professor Lord Ara Darzi	Imperial College London	None	2017-04-01	2022-03-31	Cancer Research UK Imperial Centre	The Cancer Research UK Imperial Centre will enhance cancer prevention, expedite early cancer detection, and improve the precision of cancer treatments and outcomes for patients, by leveraging Imperial’s core strengths in engineering, technology, physical sciences, imaging and systems medicine. Our vision is to unify technologies and platforms and re-orientate them in a co-ordinated effort to tackle cancer treatment and prevention. We will focus on reducing the burden of cancer by: improving the identification of high-risk populations; capitalising on advances in metabolic phenotyping; developing novel screening tests; enhancing screening uptake; improving clinical decision-making through machine learning and digital health systems. Our efforts to improve precision of cancer care will lead to improvements in: tumour boundary identification; cancer resectability via medical robotics, augmented reality, and intraoperative tissue characterisation; identification of risk for relapse through lab-on-chip technologies enabling interrogation of single cells, cell free DNA, and microRNAs; prediction of stage and spread by exploiting changes in microbiome composition; treatment monitoring of response and resistance by imaging apoptosis and studying epigenetic reprogramming. The Cancer Research UK Imperial Centre and Imperial Experimental Cancer Research Centre will utilise a broad and unique set of strengths across engineering and the physical sciences, surgery, imaging and diagnostics - underpinned with high-quality clinical practice - to realise a transformative research programme aimed at improving cancer survival for patients and the public.	Cancer Research UK	None	None	None
53	Dr Janaina Mourao-Miranda	University College London	None	2014-09-15	2020-03-14	Learning from neuroimaging and clinical data: a multiple-source machine learning approach for mental health disorders	This proposal aims to develop Multiple-Source Machine Learning models to investigate complex relationships between multivariate measures of brain anatomy or function (e.g. functional/structural Magnetic Resonance Imaging) and multidimensional descriptions of the mental health disorder and individual differences (e.g. clinical assessments, personality traits). Neuroimaging and machine learning techniques show potential as tools to identify biological measures that may help diagnosis and prognosi s of mental health disorders. However, so far, most of the studies using these techniques have focused on binary classification problems using a single imaging modality, i.e. they summarize the clinical assessment into a single measure and the output of the models is limited to a probability value and in most cases a binary decision (patients/healthy control). Although these studies represent an important advance in the field, they do not enable patient stratification and provide limited informa tion about the underlying biological mechanisms of the diseases. Considering the complexity of mental health disorders, it is potentially beneficial to embed a multidimensional description of the disorder into the models. The aim of this proposal is to move away from treating neuroimaging-based diagnosis as a binary classification problem towards models that: (i) are able to merge multi-modal neuroimaging and clinical information for diagnoses and prognoses of psychiatric disorders; (ii) can im prove stratification of patients with mental health disorders (e.g. identify subgroups of patients for helping treatment allocation or illness course prediction); (iii) are able to deal with large multi-center datasets; (iv) provide insights about underlying biological mechanisms of the diseases (e.g. biological markers).	Wellcome Trust	Senior Research Fellowship Basic	1295649.0	GBP
54	Professor Nicola Minling Low	University of Berne	Institut für Sozial- und Präventivmedizin Universität Bern	2017-11-01	2021-10-31	Zika virus: causality, open science and risks of emerging infectious diseases	BackgroundZika virus infection was established as a cause of congenital abnormalities, including microcephaly, and of Guillain-Barré syndrome during a Public Health Emergency of International Concern that the World Health Organization (WHO) announced in February 2016. The Public Health Emergency ended in November 2016 but substantial gaps remain in the causality framework of Zika complications, knowledge about population level susceptibility to Zika virus infection and the risks of the newly recognised route of sexual transmission of Zika virus. Objectives1. To produce a web platform that will allow the production and updating of living systematic reviews of evidence about Zika virus infection; 2. To estimate key parameters that will allow refined inferences about the sexual transmissibility of Zika virus in endemic and non-endemic settings; 3. To investigate the seroprevalence of antibodies to Zika virus in different geographic settings and to use seroprevalence data to allow estimation of the duration of immunity after Zika virus infection. Methods1. We will produce an open access web application to produce living systematic reviews that allow continual updating of evidence about causal associations between Zika virus and its complications, and emerging research questions. The application will automate searching and deduplication, use text mining and machine learning to assist screening and allow automated updates of review output for rapid publication. 2. We have developed a sexual transmission framework to identify key parameters needed to understand the potential for ongoing spread of Zika virus through sexual transmission. We will analyse data to determine the duration of persistence of Zika virus in semen, vaginal fluid, urine, breast milk and other bodily fluids. We will then use a transmission model to estimate the per sex act probability of Zika virus transmission. 3. We will use data from ongoing longitudinal studies and repeated cross-sectional studies in Nicaragua that will determine antibody levels to Zika virus using new diagnostic tests (taking into account exposure to dengue and chikungunya). We will apply “back-calculation” methods to determine the duration of immunity of Zika virus infection. We will also pilot a method for the collection and assessment of seroprevalence data collected in a range of settings that have experienced new Zika transmission since 2013 and where Zika is presumed to be endemic to improve understanding of population level susceptibility to Zika virus infection.Timeline: The project will last four yearsImportance and impactThis project has considerable importance for research on Zika virus infection and transmission. Whilst vaccine development is advancing rapidly, there are still important gaps in our knowledge about vulnerability to Zika virus in large proportion of the world’s population that lives in areas where Aedes mosquito vectors are distributed. The project objectives are aligned with the research agenda of the WHO and with international initiatives to increase capacity for preparedness for infectious disease pandemics. The outputs are therefore relevant to current research priorities. By working within a culture of open science and with the living systematic review network, our research outputs, including publications and software will be publicly available as quickly as possible.	Swiss National Science Foundation	Project funding (Div. I-III)	700000.0	CHF
55	Univ.Prof. Dr. Wolfgang MAASS	Graz University of Technology	None	2003-10-07	2006-11-06	Computer Models for Biological Vision Systems	Each of us might have encountered the situation to desperately search for a personal item or a location in an unknown environment. At present there is no technical solution for such an assistive system. The newly granted Joint Research Project Cognitive Vision attempts to find first solutions in this direction. A human shall be supported with a system that can not only find things, but that can understand the relationship between the human activities and objects involved. This understanding of new information and new knowledge is the key aspect of the cognitive approach to computer vision. The solution proposed is based on a trans-disciplinary approach. It integrates partners from theoretical computer science (TU Graz), neuroscience (Max-Planck-Institut Tübingen), artificial intelligence (öFAI, Wien), machine learning (MU Leoben), user engineering (CURE, Wien) and different areas of computer vision and pattern recognition (ACIN &amp; PRIP TU Wien, EMT &amp; ICG TU Graz and Joanneum Research Graz). One aspect of the project is to investigate the relations of the different brain regions in visual cortex. While individual functions of these regions are relatively well studied, new methods of screening brain functions enable deeper insights that contradict present hypotheses. It could be shown that human vision profits enormously from expectations in a given situation. For example, objects in an atypical environment are spotted much more quickly than in the expected environment. Using this analysis of the only working vision system we will develop computer models to describe objects under different conditions, for example, different illumination, shape, scale, clutter and occlusion, and to describe the relationships between objects and the environment. A particular emphasis is on learning these models and relationships. In the same way one shows a new object to a child, we want to relieve the user from the present exhaustive learning phases. Another aspect of the research work is the analysis of the interrelations of the different seeing functions, namely, mechanisms to guide attention, the detection and identification of objects, the prediction of motions and intentions of the user, the integration of knowledge of the present situation, and the creation of an appropriate system reaction. The coordination of these functions is resolved using an agent/based optimisation of the utility to the system's functioning. The techniques devised will be implemented in prototype systems. In a user study it will be evaluated how the expectations are met or not to further improve system performance. The objective of the next three years is to track and predict where objects are moved to and where locations can be found. A user could then ask the system where her mug is or where a specific shop is when entering unknown parts of a city. In both cases the user would be assisted and guided to the location.	Austrian Science Fund FWF	National Research Networks NFN	None	None
56	Univ.Prof. Dr. Matthias SCHMUTH	Medical University of Innsbruck	None	2019-05-01	2022-04-30	Biomolecular Analyses for Tailored Medicine in AcneiNversa (BATMAN)	Acne Inversa (AI) is a chronic inflammatory disease involving hair follicles that imposes a major physical and psychological burden on patients with significant costs for health systems. Genetic variants affecting different pathways result in wide spectrum of AI phenotypes and tracking gene variants is essential to design personalized treatments. The proposal aims to bring together medical, genetic, experimental and lifestyle data to create holistic health records (HHR), which will allow us to build a personalized model of each patient and to tailor specific treatments based on their personal characteristics. Research on animal or cellular models will be harnessed to validate hypotheses on genetic variants, generating useful information with immediate translational impact on patient stratification and therapeutic options, and also providing a wide-scale overview of previously identified and novel risk markers. DNA will be obtained from AI cases from 3 different locations in Europe. Data will be compiled from whole exome sequencing, whole genome genotyping SNPs arrays and transcriptomic signatures of hair follicle cells and novel mouse models. Genomic information will be merged with clinical evaluations and lifestyle data by advanced machine-learning and data mining algorithms. By the end of the project, our consortium intends to: • identify genetic variants associated with AI susceptibility, severity and response to treatment • design in vivo and in vitro models for investigations on the main biological pathways affected by AI and testing the impact of genetic variants on immune and cutaneous cell biology • produce an HHR to complement medical record by developing a smartphone application to remotely monitor the physical and psychological wellbeing of patients and advise them on physical activity and dietary and smoking habits • propose novel stratification methods that clinicians can use to assess severity, choose the therapy and follow the outcome	Austrian Science Fund FWF	02 International programmes	91230.13	EUR
57	Professor Jones	University College London	None	None	2022-04-30	Prediction of protein-protein interaction hot spots using a combination of physics and machine learning	Protein-protein interactions are central to most biological processes, from signal transduction to immune response. Understanding these functional associations requires knowledge of the three-dimensional structure of the complex as this reveal the underlying molecular mechanism. However, determining experimentally the 3D structure of a protein complex present considerable difficulties. There is therefore a need for accurate and reliable computational methods. Several experiments have shown that protein interactions are critically dependent on just a few residues, or hot spots, at the binding interface. Hot spots make a dominant contribution to the free energy of binding and if mutated they can disrupt the interaction. In this project we aim to develop a computational method that can identify hot spot residues (and the contacts they form across the interface) in unbound proteins (i.e. without prior knowledge of the complex). This would significantly improve our ability at predicting the overall structure of the complex (the so-called docking problem). We plan to combine and integrate the basic energetic terms that contribute to the stability of protein complexes (e.g. van der Waals potential, hydrogen bonds,etc.) using state of the art machine learning techniques. In the first part of the project, we will develop a method to predict hot-spot residues at protein protein interfaces when the structure of complex is available. In the second part, we plan to systematically dock structural fragments of the two unbound proteins and test them for the presence of potential hot spots (using the classifier developed in the first part). Eventually, we will combine different sources of information (energetic, evolutionary and structural) to predict few important contacts across the interface of two proteins.	Biotechnology and Biological Sciences Research Council	Standard grant	310931.0	GBP
58	Prof Wiebke Arlt	University of Birmingham	Clinical and Experimental Medicine	2009-03-01	2012-02-29	Steroid profiling as a biomarker tool in the diagnosis and monitoring of adrenal tumours	Adrenal tumours are common, with a prevalence of 1-2% in the general population. Prevalence increases with age, with 3% of 40-year-olds and 10% of 70-year-olds harbouring an adrenal tumour. In an ageing society and with the increasingly widespread use of abdominal imaging the number of incidentally discovered adrenal tumours is rapidly increasing and represents a huge burden for the health system. Diagnostic work-up of adrenal incidentalomas aims to exclude malignancy and steroid excess, but is currently compromised by a lack of sensitive diagnostic tools. This shortcoming is addressed by this proposal that aims to establish steroid profiling as a biomarker tool in the differential diagnosis of adrenal incidentaloma. Feasibility studies analysing urinary steroid metabolite excretion in 83 benign and 35 malignant adrenal tumours by gas chromatography/mass spectrometry indicate significant differences in steroid excretion, with high androgen and glucocorticoid precursors in malignant tumours. Preliminary analysis indicates a high diagnostic sensitivity and specificity of a distinct subset of steroid metabolites. Based on these data we plan to analyse 24-h urinary steroid excretion in a large cohort of adrenal incidentaloma patients (n=1000) to prospectively evaluate the diagnostic value of this novel biomarker tool. In an important transfer step to implementation of the biomarker tool in routine clinical practice, we will establish liquid chromatography/tandem mass spectrometry (LC/MS/MS) for rapid high throughput measurement of steroid markers identified as most differentiating by biocomputational analysis. The latter will apply machine learning techniques, taking two different but complementary approaches, prototype-based relevance learning and probabilistic Bayesian kernel models. These methods will be utilised to identify discriminative steroids, determine their prognostic and predictive value and develop generative models that could also give mechanistic insights. Recruitment to the study will be facilitated by local, national and international networks including the European Network for the Study of Adrenal Tumours (ENS@T), which already contributed 500 urine samples in 12 months, facilitating preliminary analysis. Clinical data will be stored in a common database format that has been developed, agreed and implemented by ENS@T and that will be made available to all participating centres of the UK Adrenocortical Tumour Network (UK ACT). This proposal links an extensive team of researchers and research facilities across the UK and Europe, generating a unique, interdisciplinary expertise that will ensure the success of this project; results will improve the diagnostic management of a common condition.	Medical Research Council	Research Grant	727149.0	GBP
59	Professor Joanna Wardlaw	Edinburgh, University of	Neuroimaging Sciences	None	2012-02-29	The BHF-Turing Cardiovascular Data Science Awards (Second Call): Uncovering retinal microvascular predictors of compromised brain haemodynamics in small vessel disease (joint funding with The Alan Turing Institute)	Cerebral small vessel disease (SVD) is a common neurological disease which causes up to 45% of dementias and about 20% of all strokes worldwide. The cause of the underlying pathology is poorly understood and there is no proven treatment. A limitation in human SVD research is that current MRI brain imaging technology has millimetre resolution while the vessels where SVD start are microscopic. However, retinal and cerebral microvasculature are developmentally related, and the former can be fully resolved in routinely acquired optical coherence tomography angiography (OCTA) retinal imaging. In this project, we will use Data Science to deeply phenotype retinal images in two ongoing clinical SVD studies. First, we will develop convolutional neural network approaches for OCTA image segmentation and Graph Theory approaches for structural phenotyping. Second, we will use computational fluid dynamics and high performance computing to carry out haemodynamic characterisation of the retinal vascular networks beyond what is observable clinically. Finally, we will uncover associations between structural and functional retinal phenotypes and SVD-related compromised brain haemodynamics. We expect this work to be an important step towards delivering Precision Medicine for SVD.	British Heart Foundation	Special Project	66000.0	GBP
60	Prof Sir Simon Lovestone	University of Oxford	Psychiatry	2016-10-01	2021-09-30	Deep and Frequent Phenotyping; combinatorial biomarkers for dementia experimental medicine	The D&FPhen study follows from a pilot phase that has established technical feasibility and participant acceptability. The study is for a repeated measures observational design in prodromal disease defined as no dementia but presence of episodic memory impairment >1.5SD from age adjusted norms in the context of AD pathology assessed using PET and CSF. Key design points include: - Participant recruitment through pre-existing parent cohorts. Ethical approval for this process, agreement from cohorts, technical platforms and proof of numbers meeting recruitment criteria are all in place - Utilisation of an algorithm established on ADNI data, tested in other datasets and proposed for US GAP-PAD studies to reduce screen failure based on age, cognition and APOE genotype. - Screen by PET amyloid with entry to study on a 4:1 ratio of screen positive and negative to avoid inadvertent disclosure of genotype or biomarker data - Repeated measures of both outcome comparator modalities (cognition and pathology) and assessment modalities between 2 months and 6 months in frequency based on projected one year change and acceptability criteria (see main section for full details) - Protocols harmonised with EPAD where shared and established in pilot phase for structural and functional MRI, electrophysiology by EEG and MEG, optical measures including ultra wide field studies and OCT and connected devices for gait, activity and cognition (see main section for full details) - Participant engagement including a start-up with a track record of increasing participation, a study within a study for participant engagement and burden in precision medicine studies and a process led by the Alzheimer's Society for Patient and Public Engagement (see main section for full details) - Sharing of data with minimal delay and facilitated data-use including building analytical communities through the leading global not-for-profit organisation for scientific data sharing.	Medical Research Council	Research Grant	6301078.0	GBP
61	Prof. Dr. Eugen TRINKA	SALK	None	2011-11-01	2016-10-31	Physiological Markers for the Prognosis of Memory Decline	Against our scientific background, we found an analogy in one of their most disabling symptoms between the two different clinical groups that form the focus of our research interest: Epilepsies, especially temporal lobe epilepsies (TLE) and degenerative dementia in its earliest stage, mild cognitive impairment (MCI). While it is obvious that memory problems are the main concern of people with MCI, they are also a major predictor of impaired quality of life and social disability in TLE. Moreover, memory impairments are not only a link between MCI and TLE, but may also act as a starting point from which researchers in each field may add innovative aspects to the corresponding research area. Specifically, the pathogenesis of memory disturbance in both conditions is unclear when patients of each clinical group perform normally on standard neuropsychological tests of memory. This is the case in early stages of MCI as well as in TLE. However, correlates of the subjective observation of memory problems would be detectable with neuroimaging and neurophysiology. Thus, the overall aims of our study are: • To identify eventual analogies in the pattern of memory impairments in TLE and MCI and to better understand the mechanisms of memory problems in both conditions. This objective will be addressed by comparing these groups by several measures. • To increase the validity for prognosis of memory decline by implementing multimodal examination on a single subject base. In this study, MCI patients will be divided into a subgroup of evidenced memory impairment, as assessed by standardized tests, and in a subgroup of patients with subjective cognitive complaint, but without objectively measurable abnormality. TLE patients will be divided in a group of early TLE and in a group of pharmacoresistant TLE. By entering the study, each patient undergoes several neuropsychological tests on memory performance, document confounding variables, event-related electroencephalography and magnetic resonance imaging. In order to find individual abnormalities, we will use innovative data-processing techniques and single-subject non-parametric statistics. The extracted features of the clinical groups will be compared with those of a sample of healthy controls in order to determine abnormalities. Specifically, we will assess features which were shown to be of diagnostic or predictive value in one of the two assessed disorders (MCI or TLE). After 1.5 years, a second session of neuropsychological testing will reveal the degree of memory decline. To determine which features from neuroimaging and/or neurophysiology perform best for prognosis, being used alone or in some combination, support vector machines will be applied. Moreover, several automatic classifiers will be compared in order to identify the best suited machine-learning algorithm for prognosis of memory decline.	Austrian Science Fund FWF	Clinical Research	312295.2	EUR
62	Univ.Prof. Dipl.Ing. Dr. Zlatko TRAJANOSKI	MEDIZINISCHE UNIVERSITAT INNSBRUCK	None	2018-10-01	2023-09-30	Enabling Precision Immuno-oncology in Colorectal cancer	Immunotherapy with checkpoints blockers is transforming the treatment of advanced cancers. Colorectal cancer (CRC), a cancer with 1.4 million new cases diagnosed annually worldwide, is refractory to immunotherapy (with the exception of a minority of tumors with microsatellite instability). This is somehow paradoxical as CRC is a cancer for which we have shown that it is under immunological control and that tumor infiltrating lymphocytes represent a strong independent predictor of survival. Thus, there is an urgent need to broaden the clinical benefits of immune checkpoint blockers to CRC by combining agents with synergistic mechanisms of action. An attractive approach to sensitize tumors to immunotherapy is to harness immunogenic effects induced by approved conventional or targeted agents. Here I propose a new paradigm to identify molecular determinants of resistance to immunotherapy and develop personalized in silico and in vitro models for predicting response to combination therapy in CRC. The EPIC concept is based on three pillars: 1) emphasis on antitumor T cell activity; 2) systematic interrogation of tumor-immune cell interactions using data-driven modeling and knowledge-based mechanistic modeling, and 3) generation of key quantitative data to train and validate algorithms using perturbation experiments with patient-derived tumor organoids and cutting-edge technologies for multidimensional profiling. We will investigate three immunomodulatory processes: 1) immunostimulatory effects of chemotherapeutics, 2) rewiring of signaling networks induced by targeted drugs and their interference with immunity, and 3) metabolic reprogramming of T cells to enhance antitumor immunity. The anticipated outcome of EPIC is a precision immuno-oncology platform that integrates tumor organoids with high-throughput and high-content data for testing drug combinations, and machine learning for making therapeutic recommendations for individual patients.	European Research Council	Advanced Grant	2460500.0	EUR
63	Dr. Werner GOEBL	University of Music and Performing Arts Vienna	None	2012-11-01	2016-09-30	Performing Together:Synchronisation and Communication in Music Ensembles	Performing Together: Synchronization and Communication in Music Ensembles Communicating, coordinating, and synchronizing thoughts and actions with one another is a fundamental faculty of human beings. Ensemble music performance represents a particular challenge to this ability, because movements and sounds have to be synchronized with highest precision while tempo and other expressive parameters vary permanently over time. The bulk of this world’s music is performed by more than one person, resulting in a wealth of possible combinations: a piano duo for four hands, a classical string quartet, a spontaneously improvising Jazz combo, or a symphony orchestra with choir and soloists, just to name a few. Every possible combination yields its own characteristic dynamics of interpersonal communication. From the democratic organization of small ensembles, in which one musician takes the lead at one moment only to be led by others at the next, the range extends to more hierarchical organizations where many have to follow the sounds or the gestures of one (soloist versus accompanists, conductor versus orchestra). This research project investigates interpersonal synchronization in small music ensembles and the role of gestural communication among the ensemble members. The guiding vision is to understand the underlying mechanisms and learning processes of musical synchronization at a level of detail that can be implemented into computational models that operate in real time. Such real-time frameworks will be employed for interactive experimentation with humans: musicians co-perform jointly with computational models of which the behavioral characteristics are controlled and manipulated (reactivity, disposition to follow or lead, attentional focus to particular ensemble members, etc.). Further experimentation focuses on the motion kinematics in communicative gestures of ensemble members (e.g., pick-up head movements) and the evolution of a common musical goal of each musician over multiple sessions of rehearsal. To measure these complex phenomena, hybrid pianos are combined with optical capturing systems to record the individual performance and the movements of the musicians playing together. Data collected from both real-world performances and controlled laboratory experiments involving both student and expert musicians will be subjected to different modeling approaches (such as dynamical systems or machine learning) to understand the dynamics and mechanisms of interpersonal music making. Applications of this research may emerge for educational settings where computational visualization tools could help to enhance the awareness of movement and sound synchrony among musicians, new performance interfaces for computer music and dislocated interaction, or intelligent accompaniment systems that not only react, but act as full musical companions, even understanding visually the gestures of their human partners.	Austrian Science Fund FWF	Stand-Alone Project	351237.09	EUR
64	Univ.Prof. Dr. Reinhold SCHMIDT	Medical University of Graz	None	2012-03-01	2016-02-29	Mechanisms of Small Vessel Related Brain Damage and Cognitive Impairment	Neuroimaging in combination with detailed neuropsychological testing has been by far the most fruitful approach to uncover the pleiotropic effects of cerebral small vessel disease (SVD) on the brain and on cognition. This approach has recently been combined with genetics. In this international collaborative effort we hypothesize that CADASIL, a hereditary SVD, and common sporadic forms of SVD have shared mechanisms and that integrating imaging data from both conditions will allow defining key mechanisms of small-vessel related brain damage and associated cognitive impairment. We propose to use our combined patient, family and population-based resources and apply state of the art image post-processing and analytical tools to address the following scientific aims in a collaborative effort: ? To delineate the mechanisms of incident lacunar infarcts and their consequences on anatomically connected brain regions ? To identify strategic locations for subcortical ischemic lesions and cognitive performance ? To explore the mechanisms and clinical impact of cortical changes in patients with SVD. This will include investigations at ultra-high field MRI (7 Tesla) ? To provide a detailed account of microstructural changes in the normal appearing brain (as seen on conventional MRI) and their imaging and cognitive correlates. This will included diffusion tensor and magnetization transfer imaging and an investigation of the role of iron deposition as a novel marker ? To provide integrated models predicting cognitive impairment in SVD using multiple imaging markers Our proposal builds on two prospective observational cohorts collected by three of the PIs with longitudinal data already available: 320 patients with CADASIL and documented mutations in the NOTCH3 gene and 820 community-dwelling middle-aged and elderly participants from the Austrian Stroke Prevention Study (ASPS). Both cohorts have received standardized and extensive neuropsychological testing with regular follow-up. The four PIs will each focus on specific questions and apply their methodological tools to both datasets. Using machine learning (ML) processes and the specific expertise provided within the group, data will be integrated into joint models to identify general mechanisms of small vessel related brain damage and cognitive impairment. Validation of the final models will then be possible in external cohorts. By combining our resources and analytical tools we will maximise the chances to achieve our scientific aims. Our ultimate goal will be to provide novel predictive instruments, markers and targets for therapeutic trials.	Austrian Science Fund FWF	International programmes	191457.0	EUR
65	Professor Andrea Rockall	The Royal Marsden NHS Foundation Trust	None	2018-06-01	2021-08-31	MAchine Learning In MyelomA Response (MALIMAR study): Development of machine learning support for reading whole body diffusion weighted magnetic resonance imaging (WB-MRI) in myeloma for the detection and quantification of the extent of disease before and after treatment	HYPOTHESIS AND AIMS: Machine learning (ML) methods to post-process whole body (WB) diffusion-weighted (DW) MRI scans in myeloma patients will improve the detection & assessment of the extent of active disease before and after treatment and reduce the radiological reading time (RT). DESIGN POPULATION & ASSESSMENTS:Phase 1 (training): WB-MRI scans from a cohort of 160 myeloma patients (120 with active disease) from a single centre and 40 age-relevant healthy volunteers (HV) will be used to develop a ML detection tool to recognise active myeloma.Phase 2 (validation): Sensitivity and RT assessment using WB-MRI -/+ ML in 203 active myeloma 100 inactive myeloma and 50 HV.Phase 3 (disease quantity): A ML quantification tool will be developed then tested on WB-MRI of 60 patients having scans before and after myeloma treatment on iTIMM trial. Quantification score RT and categorisation of response will be assessed +/- ML. Reference standard will be expert panel. INTERVENTION:No patient intervention is planned. Study intervention is the addition of ML detection and quantification tools to existing WB-MRI scans on patients with myeloma and HVs. Expert and non-expert radiology readers will review scans in mixed order such that paired reads +/- ML are available for analysis. OUTCOME MEASURES:Phase 1: Sensitivity of ML detection tool for active myeloma when compared to reference standard. Phase2: Primary: Difference in sensitivity of WB-MRI+/-ML to diagnose active myeloma on a per-patient basis by expert readers against the reference standard.Secondary: per-site sensitivity RT specificity and categorization of disease type of WB-MRI-/+ML; difference in sensitivity and specificity of WB-MRI+/-ML support using new readers.Phase 3: Primary: Agreement between experienced readers and reference standard in scoring disease burden assessed +/- ML. Secondary: RT agreement between readers in response category compared to reference; cost analysis. SAMPLE SIZE: Phase 1: 40 HV & 160 myeloma patients (120 with active disease).Phase 2: 50 HV & 100 patients with no active disease); 203 patients with active diseasePhase 3: 60 patients 120 WB-MRI scans (2 time points). STATISTICAL ANALYSIS AND ECONOMIC BENEFIT:Phase 1: Sensitivity based on ML cross-validation methods.Phase 2: % of patients with active disease who have positive reference standard on WBMRI-/+ML will be compared using McNemar’s test. Per patient and per site sensitivity -/+ML will be reported with 95% CI. Per patient and per site specificity -/+ML will be reported with 95% CI. RT will be compared using the most appropriate test.Phase 3: Differences from scores given by experienced readers and the reference will be described using Bland-Altman plots +/- ML. A simple economic benefit analysis will be performed based on reading times. DURATION OF THE STUDY:Total duration is 39 months. MAIN STAGES OF THE PROPOSED PROJECT WITH EXPECTED DURATIONS (MONTHS): Phase 1: (Months 0-16): Segmentation and development of ML detection tool. Phase 2: (Months 9-28): Validation of ML detection tool. Paired radiology reads of 353 WB-MRI +/- ML support. Further optimisation of the ML tool may be undertaken. Phase 3: (Months 16-39): Development and validation of ML quantification tool. Sequential WB-MRI scan from patients before and after treatment will be evaluated qualitatively and quantitatively for extent of disease +/- ML support. Complete report.	National Institute for Health Research (Department of Health)	Full Award	646787.62	GBP
66	Professor Morgan	University of Liverpool	None	None	2021-08-31	The application of support vector machine feature selection to cross sectional studies in epidemiology	This proposal builds on an EPSRC small grant GR/S73631/01, graded tending to outstanding" in its final report. It is a resubmission from March 2005 of application GR/EP/DO3O684 sent EPRSC Life Sciences Interface as a continuation of GR/S73631/01 and recommended for submission to BBSRC with a contribution in financial support from EPSRC if successful. Epidemiologists from Liverpool Veterinary School and computer scientist from DIMACS, a National Science Foundations Institute at Rutgers, New Jersey, USA, have recently reported the use of Support Vector Machine learning as a method of identifying risk factors for disease from observational epidemiological data. Support Vector Machine classification was developed in the mid 90's and although related to neural networks, the technique is simpler more robust and founded on statistical learning theory. In particular the use of SVM overcomes overfitting associated with the empirical risk minimisation, (ERM) which aims to minimise the error on the training data set but results in poor generalisation (i.e. performance on unseen datasets). SVM are arguably the single most important development in supervised classification in recent years. They are known to generalise well in high dimensional space even with small training sample conditions, when the data are noisy. SVM are not only good classifiers but are also good feature selection techniques. SVM has been used for the verification and recognition of faces, speech, handwriting and such diverse events as goal detection in football matches and financial forecasting. In life sciences it has been applied to gene expression, proteomics and disease diagnosis With the exception of a recent report, using single nucleotide polymorphisms (SNPs) to predict an increased risk of breast cancer there have been no published reports of the application of SVM in epidemiology. This project aims to further develop the application of SVM, to improve kernel selection and to produce a user-friendly SVM program for wider epidemiological use Data for the development of this program will be provided from an epidemiological study of an emerging disease of poultry (wet litter). Because meat birds live for only 6-7 weeks broiler flocks provide the opportunity to validate the classifications made by SVM during the period of study. The final program will provide a new paradigm in epidemiology and act as an easily applicable "second opinion" for statistical models generated using the "epidemiological standard" of logisitic regression. It will also, as a by-product, improve our understanding of wet litter in poultry. The final program will be applicable to observational studies of non-infectious and infectious human and animal disease."	Biotechnology and Biological Sciences Research Council	Standard grant	400793.0	GBP
67	Professor Reza Razavi	King's College London	None	2019-09-01	2022-12-31	Innovative biomedical engineering and computational science to improve the management of critical illness in resource-limited settings	<p>Our project&rsquo;s primary objective is to provide proof-of-principle that new technology can help improve the care of critically ill patients with infectious diseases in resource-limited settings. To achieve this objective we will develop a new inter-disciplinary &lsquo;innovations for critical care&rsquo; team within Oxford University Clinical Research Unit (OUCRU), a Wellcome Africa Asia Programme in Vietnam. The team will consist of Vietnamese and International clinicians, biomedical engineers, and computational scientists in OUCRU, linked to biomedical engineering groups at Oxford University, King&rsquo;s College London, Imperial College London, and Eidgen&ouml;ssische Technische Hochschule, Zurich.<br> The team will develop and test technology with the potential to save lives and prevent disability from the common causes of critical illness in Asia. We will also investigate whether novel technologies can improve rehabilitation and long-term outcomes in survivors from critical illness.<br> We have 4 key goals:<br> 1: To develop new devices, or test existing devices, including point-of-care ultrasound, that will enable lost-cost capture and monitoring of key clinical and physiological variables in critically ill patients<br> 2: To use artificial intelligence and computer-assisted and machine learning to devise clinical decision-support systems from clinical, physiological, and imaging data<br> 3: To investigate whether interventions such as in-bed cycling and rectus femoris ultrasound can aid physical rehabilitation, and whether low-cost wearable devices can promote and predict better functional recovery after critical illness<br> 4: To determine the current costs of critical illness care in Vietnam and to assess the potential acceptability, affordability and cost-effectiveness of the technology tested in Vietnam and similar settings.</p>	Wellcome Trust	Innovations Priority Project	4030521.01	GBP
68	Dr Sophie Yacoub	Oxford University Clinical Research Unit	None	2019-09-01	2022-12-31	Innovative biomedical engineering and computational science to improve the management of critical illness in resource-limited settings	<p>Our project&rsquo;s primary objective is to provide proof-of-principle that new technology can help improve the care of critically ill patients with infectious diseases in resource-limited settings. To achieve this objective we will develop a new inter-disciplinary &lsquo;innovations for critical care&rsquo; team within Oxford University Clinical Research Unit (OUCRU), a Wellcome Africa Asia Programme in Vietnam. The team will consist of Vietnamese and International clinicians, biomedical engineers, and computational scientists in OUCRU, linked to biomedical engineering groups at Oxford University, King&rsquo;s College London, Imperial College London, and Eidgen&ouml;ssische Technische Hochschule, Zurich.<br> The team will develop and test technology with the potential to save lives and prevent disability from the common causes of critical illness in Asia. We will also investigate whether novel technologies can improve rehabilitation and long-term outcomes in survivors from critical illness.<br> We have 4 key goals:<br> 1: To develop new devices, or test existing devices, including point-of-care ultrasound, that will enable lost-cost capture and monitoring of key clinical and physiological variables in critically ill patients<br> 2: To use artificial intelligence and computer-assisted and machine learning to devise clinical decision-support systems from clinical, physiological, and imaging data<br> 3: To investigate whether interventions such as in-bed cycling and rectus femoris ultrasound can aid physical rehabilitation, and whether low-cost wearable devices can promote and predict better functional recovery after critical illness<br> 4: To determine the current costs of critical illness care in Vietnam and to assess the potential acceptability, affordability and cost-effectiveness of the technology tested in Vietnam and similar settings.</p>	Wellcome Trust	Innovations Priority Project	4030521.01	GBP
69	Dr Catherine Thwaites	University of Oxford	None	2019-09-01	2022-12-31	Innovative biomedical engineering and computational science to improve the management of critical illness in resource-limited settings	<p>Our project&rsquo;s primary objective is to provide proof-of-principle that new technology can help improve the care of critically ill patients with infectious diseases in resource-limited settings. To achieve this objective we will develop a new inter-disciplinary &lsquo;innovations for critical care&rsquo; team within Oxford University Clinical Research Unit (OUCRU), a Wellcome Africa Asia Programme in Vietnam. The team will consist of Vietnamese and International clinicians, biomedical engineers, and computational scientists in OUCRU, linked to biomedical engineering groups at Oxford University, King&rsquo;s College London, Imperial College London, and Eidgen&ouml;ssische Technische Hochschule, Zurich.<br> The team will develop and test technology with the potential to save lives and prevent disability from the common causes of critical illness in Asia. We will also investigate whether novel technologies can improve rehabilitation and long-term outcomes in survivors from critical illness.<br> We have 4 key goals:<br> 1: To develop new devices, or test existing devices, including point-of-care ultrasound, that will enable lost-cost capture and monitoring of key clinical and physiological variables in critically ill patients<br> 2: To use artificial intelligence and computer-assisted and machine learning to devise clinical decision-support systems from clinical, physiological, and imaging data<br> 3: To investigate whether interventions such as in-bed cycling and rectus femoris ultrasound can aid physical rehabilitation, and whether low-cost wearable devices can promote and predict better functional recovery after critical illness<br> 4: To determine the current costs of critical illness care in Vietnam and to assess the potential acceptability, affordability and cost-effectiveness of the technology tested in Vietnam and similar settings.</p>	Wellcome Trust	Innovations Priority Project	4030521.01	GBP
70	Dr Marc Modat	King's College London	None	2019-09-01	2022-12-31	Innovative biomedical engineering and computational science to improve the management of critical illness in resource-limited settings	<p>Our project&rsquo;s primary objective is to provide proof-of-principle that new technology can help improve the care of critically ill patients with infectious diseases in resource-limited settings. To achieve this objective we will develop a new inter-disciplinary &lsquo;innovations for critical care&rsquo; team within Oxford University Clinical Research Unit (OUCRU), a Wellcome Africa Asia Programme in Vietnam. The team will consist of Vietnamese and International clinicians, biomedical engineers, and computational scientists in OUCRU, linked to biomedical engineering groups at Oxford University, King&rsquo;s College London, Imperial College London, and Eidgen&ouml;ssische Technische Hochschule, Zurich.<br> The team will develop and test technology with the potential to save lives and prevent disability from the common causes of critical illness in Asia. We will also investigate whether novel technologies can improve rehabilitation and long-term outcomes in survivors from critical illness.<br> We have 4 key goals:<br> 1: To develop new devices, or test existing devices, including point-of-care ultrasound, that will enable lost-cost capture and monitoring of key clinical and physiological variables in critically ill patients<br> 2: To use artificial intelligence and computer-assisted and machine learning to devise clinical decision-support systems from clinical, physiological, and imaging data<br> 3: To investigate whether interventions such as in-bed cycling and rectus femoris ultrasound can aid physical rehabilitation, and whether low-cost wearable devices can promote and predict better functional recovery after critical illness<br> 4: To determine the current costs of critical illness care in Vietnam and to assess the potential acceptability, affordability and cost-effectiveness of the technology tested in Vietnam and similar settings.</p>	Wellcome Trust	Innovations Priority Project	4030521.01	GBP
71	Prof Arjen Dondorp	University of Oxford	None	2019-09-01	2022-12-31	Innovative biomedical engineering and computational science to improve the management of critical illness in resource-limited settings	<p>Our project&rsquo;s primary objective is to provide proof-of-principle that new technology can help improve the care of critically ill patients with infectious diseases in resource-limited settings. To achieve this objective we will develop a new inter-disciplinary &lsquo;innovations for critical care&rsquo; team within Oxford University Clinical Research Unit (OUCRU), a Wellcome Africa Asia Programme in Vietnam. The team will consist of Vietnamese and International clinicians, biomedical engineers, and computational scientists in OUCRU, linked to biomedical engineering groups at Oxford University, King&rsquo;s College London, Imperial College London, and Eidgen&ouml;ssische Technische Hochschule, Zurich.<br> The team will develop and test technology with the potential to save lives and prevent disability from the common causes of critical illness in Asia. We will also investigate whether novel technologies can improve rehabilitation and long-term outcomes in survivors from critical illness.<br> We have 4 key goals:<br> 1: To develop new devices, or test existing devices, including point-of-care ultrasound, that will enable lost-cost capture and monitoring of key clinical and physiological variables in critically ill patients<br> 2: To use artificial intelligence and computer-assisted and machine learning to devise clinical decision-support systems from clinical, physiological, and imaging data<br> 3: To investigate whether interventions such as in-bed cycling and rectus femoris ultrasound can aid physical rehabilitation, and whether low-cost wearable devices can promote and predict better functional recovery after critical illness<br> 4: To determine the current costs of critical illness care in Vietnam and to assess the potential acceptability, affordability and cost-effectiveness of the technology tested in Vietnam and similar settings.</p>	Wellcome Trust	Innovations Priority Project	4030521.01	GBP
72	Dr Vinh Chau Nguyen	Oxford University Clinical Research Unit	None	2019-09-01	2022-12-31	Innovative biomedical engineering and computational science to improve the management of critical illness in resource-limited settings	<p>Our project&rsquo;s primary objective is to provide proof-of-principle that new technology can help improve the care of critically ill patients with infectious diseases in resource-limited settings. To achieve this objective we will develop a new inter-disciplinary &lsquo;innovations for critical care&rsquo; team within Oxford University Clinical Research Unit (OUCRU), a Wellcome Africa Asia Programme in Vietnam. The team will consist of Vietnamese and International clinicians, biomedical engineers, and computational scientists in OUCRU, linked to biomedical engineering groups at Oxford University, King&rsquo;s College London, Imperial College London, and Eidgen&ouml;ssische Technische Hochschule, Zurich.<br> The team will develop and test technology with the potential to save lives and prevent disability from the common causes of critical illness in Asia. We will also investigate whether novel technologies can improve rehabilitation and long-term outcomes in survivors from critical illness.<br> We have 4 key goals:<br> 1: To develop new devices, or test existing devices, including point-of-care ultrasound, that will enable lost-cost capture and monitoring of key clinical and physiological variables in critically ill patients<br> 2: To use artificial intelligence and computer-assisted and machine learning to devise clinical decision-support systems from clinical, physiological, and imaging data<br> 3: To investigate whether interventions such as in-bed cycling and rectus femoris ultrasound can aid physical rehabilitation, and whether low-cost wearable devices can promote and predict better functional recovery after critical illness<br> 4: To determine the current costs of critical illness care in Vietnam and to assess the potential acceptability, affordability and cost-effectiveness of the technology tested in Vietnam and similar settings.</p>	Wellcome Trust	Innovations Priority Project	4030521.01	GBP
73	Prof Walter Karlen	ETH Zurich	None	2019-09-01	2022-12-31	Innovative biomedical engineering and computational science to improve the management of critical illness in resource-limited settings	<p>Our project&rsquo;s primary objective is to provide proof-of-principle that new technology can help improve the care of critically ill patients with infectious diseases in resource-limited settings. To achieve this objective we will develop a new inter-disciplinary &lsquo;innovations for critical care&rsquo; team within Oxford University Clinical Research Unit (OUCRU), a Wellcome Africa Asia Programme in Vietnam. The team will consist of Vietnamese and International clinicians, biomedical engineers, and computational scientists in OUCRU, linked to biomedical engineering groups at Oxford University, King&rsquo;s College London, Imperial College London, and Eidgen&ouml;ssische Technische Hochschule, Zurich.<br> The team will develop and test technology with the potential to save lives and prevent disability from the common causes of critical illness in Asia. We will also investigate whether novel technologies can improve rehabilitation and long-term outcomes in survivors from critical illness.<br> We have 4 key goals:<br> 1: To develop new devices, or test existing devices, including point-of-care ultrasound, that will enable lost-cost capture and monitoring of key clinical and physiological variables in critically ill patients<br> 2: To use artificial intelligence and computer-assisted and machine learning to devise clinical decision-support systems from clinical, physiological, and imaging data<br> 3: To investigate whether interventions such as in-bed cycling and rectus femoris ultrasound can aid physical rehabilitation, and whether low-cost wearable devices can promote and predict better functional recovery after critical illness<br> 4: To determine the current costs of critical illness care in Vietnam and to assess the potential acceptability, affordability and cost-effectiveness of the technology tested in Vietnam and similar settings.</p>	Wellcome Trust	Innovations Priority Project	4030521.01	GBP
74	Dr Pantelis Georgiou	Imperial College London	None	2019-09-01	2022-12-31	Innovative biomedical engineering and computational science to improve the management of critical illness in resource-limited settings	<p>Our project&rsquo;s primary objective is to provide proof-of-principle that new technology can help improve the care of critically ill patients with infectious diseases in resource-limited settings. To achieve this objective we will develop a new inter-disciplinary &lsquo;innovations for critical care&rsquo; team within Oxford University Clinical Research Unit (OUCRU), a Wellcome Africa Asia Programme in Vietnam. The team will consist of Vietnamese and International clinicians, biomedical engineers, and computational scientists in OUCRU, linked to biomedical engineering groups at Oxford University, King&rsquo;s College London, Imperial College London, and Eidgen&ouml;ssische Technische Hochschule, Zurich.<br> The team will develop and test technology with the potential to save lives and prevent disability from the common causes of critical illness in Asia. We will also investigate whether novel technologies can improve rehabilitation and long-term outcomes in survivors from critical illness.<br> We have 4 key goals:<br> 1: To develop new devices, or test existing devices, including point-of-care ultrasound, that will enable lost-cost capture and monitoring of key clinical and physiological variables in critically ill patients<br> 2: To use artificial intelligence and computer-assisted and machine learning to devise clinical decision-support systems from clinical, physiological, and imaging data<br> 3: To investigate whether interventions such as in-bed cycling and rectus femoris ultrasound can aid physical rehabilitation, and whether low-cost wearable devices can promote and predict better functional recovery after critical illness<br> 4: To determine the current costs of critical illness care in Vietnam and to assess the potential acceptability, affordability and cost-effectiveness of the technology tested in Vietnam and similar settings.</p>	Wellcome Trust	Innovations Priority Project	4030521.01	GBP
75	Univ.Prof. Dipl.Ing. Dr. Zlatko TRAJANOSKI	MEDIZINISCHE UNIVERSITAT INNSBRUCK	None	2018-10-01	2023-09-30	Enabling Precision Immuno-oncology in Colorectal cancer	Immunotherapy with checkpoints blockers is transforming the treatment of advanced cancers. Colorectal cancer (CRC), a cancer with 1.4 million new cases diagnosed annually worldwide, is refractory to immunotherapy (with the exception of a minority of tumors with microsatellite instability). This is somehow paradoxical as CRC is a cancer for which we have shown that it is under immunological control and that tumor infiltrating lymphocytes represent a strong independent predictor of survival. Thus, there is an urgent need to broaden the clinical benefits of immune checkpoint blockers to CRC by combining agents with synergistic mechanisms of action. An attractive approach to sensitize tumors to immunotherapy is to harness immunogenic effects induced by approved conventional or targeted agents. Here I propose a new paradigm to identify molecular determinants of resistance to immunotherapy and develop personalized in silico and in vitro models for predicting response to combination therapy in CRC. The EPIC concept is based on three pillars: 1) emphasis on antitumor T cell activity; 2) systematic interrogation of tumor-immune cell interactions using data-driven modeling and knowledge-based mechanistic modeling, and 3) generation of key quantitative data to train and validate algorithms using perturbation experiments with patient-derived tumor organoids and cutting-edge technologies for multidimensional profiling. We will investigate three immunomodulatory processes: 1) immunostimulatory effects of chemotherapeutics, 2) rewiring of signaling networks induced by targeted drugs and their interference with immunity, and 3) metabolic reprogramming of T cells to enhance antitumor immunity. The anticipated outcome of EPIC is a precision immuno-oncology platform that integrates tumor organoids with high-throughput and high-content data for testing drug combinations, and machine learning for making therapeutic recommendations for individual patients.	European Research Council	Advanced Grant	2460500.0	EUR
76	Dr Parashkev Nachev	University College London	None	2019-06-01	2023-10-01	Programme for High Dimensional Translation in Neurology	To accelerate translation in neurology we must begin to model the brain in its full complexity. Without such high-dimensional modelling, we cannot understand the multifactorial mechanisms of disease causation, nor deliver individualised personalised medicine Innovating across several administrative, clinical, scientific, and technological domains, the Programme for High-Dimensional Translation in Neurology, headed by Parashkev Nachev at University College London, will a build high-dimensional, regulatorily-approved decision systems that predict clinical outcome and thereby support decision making at the individual, clinical level, and at the institutional, operational level. The team will do this by combining the richest source of structural information about the brain-magnetic resonance (MR) and computed tomography (CT) imaging-with comprehensive clinical data and create a replicable blueprint for embedding this approach within healthcare. The aim is to integrate the use of multidimensional data in this way into established ciinicai pathways in order to derive vaiue with minimai change to clinical practice. This will accelerate adoption and allow the benefits of such a system to be more easily achieved. Working in tandem with healthcare and enterprise partners, the Programme will focus on near to medium term goals, delivering real-world impact addressed to defined operational, clinical, and scientific objectives, within areas of neurology with greatest population-level significance. Additionally, the model weights on each factor will illuminate complex mechanisms of disease. We shall focus on a set of interlocking investigational and disease-specific areas: stroke, neuroradiology, and acute cognitive dysfunction in acute medicine.	Wellcome Trust	Innovations Priority Project	4557675.0	GBP
77	Prof Sebastien Ourselin	King's College London	None	2019-06-01	2023-10-01	Programme for High Dimensional Translation in Neurology	To accelerate translation in neurology we must begin to model the brain in its full complexity. Without such high-dimensional modelling, we cannot understand the multifactorial mechanisms of disease causation, nor deliver individualised personalised medicine Innovating across several administrative, clinical, scientific, and technological domains, the Programme for High-Dimensional Translation in Neurology, headed by Parashkev Nachev at University College London, will a build high-dimensional, regulatorily-approved decision systems that predict clinical outcome and thereby support decision making at the individual, clinical level, and at the institutional, operational level. The team will do this by combining the richest source of structural information about the brain-magnetic resonance (MR) and computed tomography (CT) imaging-with comprehensive clinical data and create a replicable blueprint for embedding this approach within healthcare. The aim is to integrate the use of multidimensional data in this way into established ciinicai pathways in order to derive vaiue with minimai change to clinical practice. This will accelerate adoption and allow the benefits of such a system to be more easily achieved. Working in tandem with healthcare and enterprise partners, the Programme will focus on near to medium term goals, delivering real-world impact addressed to defined operational, clinical, and scientific objectives, within areas of neurology with greatest population-level significance. Additionally, the model weights on each factor will illuminate complex mechanisms of disease. We shall focus on a set of interlocking investigational and disease-specific areas: stroke, neuroradiology, and acute cognitive dysfunction in acute medicine.	Wellcome Trust	Innovations Priority Project	4557675.0	GBP
78	Dr M Jorge Cardoso	King's College London	None	2019-06-01	2023-10-01	Programme for High Dimensional Translation in Neurology	To accelerate translation in neurology we must begin to model the brain in its full complexity. Without such high-dimensional modelling, we cannot understand the multifactorial mechanisms of disease causation, nor deliver individualised personalised medicine Innovating across several administrative, clinical, scientific, and technological domains, the Programme for High-Dimensional Translation in Neurology, headed by Parashkev Nachev at University College London, will a build high-dimensional, regulatorily-approved decision systems that predict clinical outcome and thereby support decision making at the individual, clinical level, and at the institutional, operational level. The team will do this by combining the richest source of structural information about the brain-magnetic resonance (MR) and computed tomography (CT) imaging-with comprehensive clinical data and create a replicable blueprint for embedding this approach within healthcare. The aim is to integrate the use of multidimensional data in this way into established ciinicai pathways in order to derive vaiue with minimai change to clinical practice. This will accelerate adoption and allow the benefits of such a system to be more easily achieved. Working in tandem with healthcare and enterprise partners, the Programme will focus on near to medium term goals, delivering real-world impact addressed to defined operational, clinical, and scientific objectives, within areas of neurology with greatest population-level significance. Additionally, the model weights on each factor will illuminate complex mechanisms of disease. We shall focus on a set of interlocking investigational and disease-specific areas: stroke, neuroradiology, and acute cognitive dysfunction in acute medicine.	Wellcome Trust	Innovations Priority Project	4557675.0	GBP
79	Prof Geraint Rees	University College London	None	2019-06-01	2023-10-01	Programme for High Dimensional Translation in Neurology	To accelerate translation in neurology we must begin to model the brain in its full complexity. Without such high-dimensional modelling, we cannot understand the multifactorial mechanisms of disease causation, nor deliver individualised personalised medicine Innovating across several administrative, clinical, scientific, and technological domains, the Programme for High-Dimensional Translation in Neurology, headed by Parashkev Nachev at University College London, will a build high-dimensional, regulatorily-approved decision systems that predict clinical outcome and thereby support decision making at the individual, clinical level, and at the institutional, operational level. The team will do this by combining the richest source of structural information about the brain-magnetic resonance (MR) and computed tomography (CT) imaging-with comprehensive clinical data and create a replicable blueprint for embedding this approach within healthcare. The aim is to integrate the use of multidimensional data in this way into established ciinicai pathways in order to derive vaiue with minimai change to clinical practice. This will accelerate adoption and allow the benefits of such a system to be more easily achieved. Working in tandem with healthcare and enterprise partners, the Programme will focus on near to medium term goals, delivering real-world impact addressed to defined operational, clinical, and scientific objectives, within areas of neurology with greatest population-level significance. Additionally, the model weights on each factor will illuminate complex mechanisms of disease. We shall focus on a set of interlocking investigational and disease-specific areas: stroke, neuroradiology, and acute cognitive dysfunction in acute medicine.	Wellcome Trust	Innovations Priority Project	4557675.0	GBP
80	Dr. Werner GOEBL	University of Music and Performing Arts Vienna	None	2012-11-01	2016-09-30	Performing Together:Synchronisation and Communication in Music Ensembles	Performing Together: Synchronization and Communication in Music Ensembles Communicating, coordinating, and synchronizing thoughts and actions with one another is a fundamental faculty of human beings. Ensemble music performance represents a particular challenge to this ability, because movements and sounds have to be synchronized with highest precision while tempo and other expressive parameters vary permanently over time. The bulk of this world’s music is performed by more than one person, resulting in a wealth of possible combinations: a piano duo for four hands, a classical string quartet, a spontaneously improvising Jazz combo, or a symphony orchestra with choir and soloists, just to name a few. Every possible combination yields its own characteristic dynamics of interpersonal communication. From the democratic organization of small ensembles, in which one musician takes the lead at one moment only to be led by others at the next, the range extends to more hierarchical organizations where many have to follow the sounds or the gestures of one (soloist versus accompanists, conductor versus orchestra). This research project investigates interpersonal synchronization in small music ensembles and the role of gestural communication among the ensemble members. The guiding vision is to understand the underlying mechanisms and learning processes of musical synchronization at a level of detail that can be implemented into computational models that operate in real time. Such real-time frameworks will be employed for interactive experimentation with humans: musicians co-perform jointly with computational models of which the behavioral characteristics are controlled and manipulated (reactivity, disposition to follow or lead, attentional focus to particular ensemble members, etc.). Further experimentation focuses on the motion kinematics in communicative gestures of ensemble members (e.g., pick-up head movements) and the evolution of a common musical goal of each musician over multiple sessions of rehearsal. To measure these complex phenomena, hybrid pianos are combined with optical capturing systems to record the individual performance and the movements of the musicians playing together. Data collected from both real-world performances and controlled laboratory experiments involving both student and expert musicians will be subjected to different modeling approaches (such as dynamical systems or machine learning) to understand the dynamics and mechanisms of interpersonal music making. Applications of this research may emerge for educational settings where computational visualization tools could help to enhance the awareness of movement and sound synchrony among musicians, new performance interfaces for computer music and dislocated interaction, or intelligent accompaniment systems that not only react, but act as full musical companions, even understanding visually the gestures of their human partners.	Austrian Science Fund FWF	Stand-Alone Project	351237.09	EUR
81	Univ.Prof. Dr. Reinhold SCHMIDT	Medical University of Graz	None	2012-03-01	2016-02-29	Mechanisms of Small Vessel Related Brain Damage and Cognitive Impairment	Neuroimaging in combination with detailed neuropsychological testing has been by far the most fruitful approach to uncover the pleiotropic effects of cerebral small vessel disease (SVD) on the brain and on cognition. This approach has recently been combined with genetics. In this international collaborative effort we hypothesize that CADASIL, a hereditary SVD, and common sporadic forms of SVD have shared mechanisms and that integrating imaging data from both conditions will allow defining key mechanisms of small-vessel related brain damage and associated cognitive impairment. We propose to use our combined patient, family and population-based resources and apply state of the art image post-processing and analytical tools to address the following scientific aims in a collaborative effort: ? To delineate the mechanisms of incident lacunar infarcts and their consequences on anatomically connected brain regions ? To identify strategic locations for subcortical ischemic lesions and cognitive performance ? To explore the mechanisms and clinical impact of cortical changes in patients with SVD. This will include investigations at ultra-high field MRI (7 Tesla) ? To provide a detailed account of microstructural changes in the normal appearing brain (as seen on conventional MRI) and their imaging and cognitive correlates. This will included diffusion tensor and magnetization transfer imaging and an investigation of the role of iron deposition as a novel marker ? To provide integrated models predicting cognitive impairment in SVD using multiple imaging markers Our proposal builds on two prospective observational cohorts collected by three of the PIs with longitudinal data already available: 320 patients with CADASIL and documented mutations in the NOTCH3 gene and 820 community-dwelling middle-aged and elderly participants from the Austrian Stroke Prevention Study (ASPS). Both cohorts have received standardized and extensive neuropsychological testing with regular follow-up. The four PIs will each focus on specific questions and apply their methodological tools to both datasets. Using machine learning (ML) processes and the specific expertise provided within the group, data will be integrated into joint models to identify general mechanisms of small vessel related brain damage and cognitive impairment. Validation of the final models will then be possible in external cohorts. By combining our resources and analytical tools we will maximise the chances to achieve our scientific aims. Our ultimate goal will be to provide novel predictive instruments, markers and targets for therapeutic trials.	Austrian Science Fund FWF	International programmes	191457.0	EUR
82	Dr Lucy Colwell	University of Cambridge	None	2019-10-01	2021-10-01	Next Generation Drug Discovery Enabled by Digital Molecular Technologies: Machine learning enabled high throughput synthesis to repurpose drugs and failed clinical candidates	<p>Access to novel biologically-active molecules that treat disease is a bottleneck in drug discovery,<br> costing thousands of lives and &pound;millions per-year. For every drug marketed, more than 50 programs<br> fail, often due to toxicity detected late in the process. We will develop a transformative system that<br> uses novel MLIAI-based models to understand the mechanism of toxicity, and predict how these<br> endpoints can be mitigated through late-stage functionalization. In parallel, we will merge state-ofthe-<br> art high-throughput synthesis with machine-learning technology to implement structural<br> modifications, turning existing drugs or failed candidates into potential new medicines ready for<br> testing, in a matter of days rather than months. The existing substances will already have optimized<br> biological properties and so a chemical system that introduces pinpoint changes in a controlled<br> fashion will immediately change and improve their properties, thereby dramatically accelerating<br> access to new potential medicines. Importantly, this platform can be applied to any disease area.</p>	Wellcome Trust	Innovator Award: Digital Technologies	575926.0	GBP
83	Dr Matthew Gaunt	University of Cambridge	None	2019-10-01	2021-10-01	Next Generation Drug Discovery Enabled by Digital Molecular Technologies: Machine learning enabled high throughput synthesis to repurpose drugs and failed clinical candidates	<p>Access to novel biologically-active molecules that treat disease is a bottleneck in drug discovery,<br> costing thousands of lives and &pound;millions per-year. For every drug marketed, more than 50 programs<br> fail, often due to toxicity detected late in the process. We will develop a transformative system that<br> uses novel MLIAI-based models to understand the mechanism of toxicity, and predict how these<br> endpoints can be mitigated through late-stage functionalization. In parallel, we will merge state-ofthe-<br> art high-throughput synthesis with machine-learning technology to implement structural<br> modifications, turning existing drugs or failed candidates into potential new medicines ready for<br> testing, in a matter of days rather than months. The existing substances will already have optimized<br> biological properties and so a chemical system that introduces pinpoint changes in a controlled<br> fashion will immediately change and improve their properties, thereby dramatically accelerating<br> access to new potential medicines. Importantly, this platform can be applied to any disease area.</p>	Wellcome Trust	Innovator Award: Digital Technologies	575926.0	GBP
84	Univ.Prof. Dipl.Ing. Dr. Markus VINCZE	Vienna University of Technology	None	2003-12-15	2006-11-14	Cognitive Vision - A Key Technology for Personal Assistance - Coordination Project	Each of us might have encountered the situation to desperately search for a personal item or a location in an unknown environment. At present there is no technical solution for such an assistive system. The newly granted Joint Research Project Cognitive Vision attempts to find first solutions in this direction. A human shall be supported with a system that can not only find things, but that can understand the relationship between the human activities and objects involved. This understanding of new information and new knowledge is the key aspect of the cognitive approach to computer vision. The solution proposed is based on a trans-disciplinary approach. It integrates partners from theoretical computer science (TU Graz), neuroscience (Max-Planck-Institut Tübingen), artificial intelligence (öFAI, Wien), machine learning (MU Leoben), user engineering (CURE, Wien) and different areas of computer vision and pattern recognition (ACIN &amp; PRIP TU Wien, EMT &amp; ICG TU Graz and Joanneum Research Graz). One aspect of the project is to investigate the relations of the different brain regions in visual cortex. While individual functions of these regions are relatively well studied, new methods of screening brain functions enable deeper insights that contradict present hypotheses. It could be shown that human vision profits enormously from expectations in a given situation. For example, objects in an atypical environment are spotted much more quickly than in the expected environment. Using this analysis of the only working vision system we will develop computer models to describe objects under different conditions, for example, different illumination, shape, scale, clutter and occlusion, and to describe the relationships between objects and the environment. A particular emphasis is on learning these models and relationships. In the same way one shows a new object to a child, we want to relieve the user from the present exhaustive learning phases. Another aspect of the research work is the analysis of the interrelations of the different seeing functions, namely, mechanisms to guide attention, the detection and identification of objects, the prediction of motions and intentions of the user, the integration of knowledge of the present situation, and the creation of an appropriate system reaction. The coordination of these functions is resolved using an agent/based optimisation of the utility to the system's functioning. The techniques devised will be implemented in prototype systems. In a user study it will be evaluated how the expectations are met or not to further improve system performance. The objective of the next three years is to track and predict where objects are moved to and where locations can be found. A user could then ask the system where her mug is or where a specific shop is when entering unknown parts of a city. In both cases the user would be assisted and guided to the location.	Austrian Science Fund FWF	National Research Networks NFN	None	None
85	Dr Florian Markowetz	University of Cambridge	None	2014-03-01	2019-02-28	Computational Biology Laboratory	Recent advances in biotechnology have produced a wealth of genomic data, which capture a variety of complementary cellular features. While these data promise to yield key insights into molecular biology and medicine, much of the information present remains underutilized because of the lack of scalable approaches for detecting signals across large, diverse data sets. A proper framework for capturing these numerous snapshots of complementary phenomena under a variety of conditions can provide the holistic view necessary for developing relevant and precise systems-level hypotheses of new drug targets and disease mechanisms. My research is concerned with developing statistical and mathematical models of complex biological systems and analyzing large-scale molecular data. My research interests range from the analysis of microarray data in clinical settings to inference of cellular networks from high-throughput gene perturbation screens and integration of heterogeneous data sources using machine learning techniques and probabilistic graphical models Research Directions at the Cambridge Research Institute My goal is to continue research on computational and statistical analysis of high-throughput data. In my lab at the Institute, I aim to develop comprehensive descriptions of genetic systems of cellular controls, including: 1. regulation of cell differentiation and development, and 2. controls whose failure may lead to developmental defects or genetic disorders, such as cancer. Together with my group, I will investigate the structure and function of biological regulatory networks and their relationship to disease mechanisms and drug targets. This includes an investigation of topological and functional units in regulatory networks as well as time-dependent or condition-specific alterations. In the immediate future, my lab will work in collaboration with the Ponder and Caldas groups on projects in breast cancer genetics and genomics, which aim to identify key drivers of disease by integrating genome-wide data from SNP, array CGH, gene expression, and microRNA profiling studies.	Cancer Research UK	SEB - Institute Group Award	None	None
86	Professor Mauricio L. Barreto	Fiocruz (Oswaldo Cruz Foundation)	None	2020-04-01	2021-09-30	The risk of a chronic clinical condition following a previous hospitalisation by a psychiatric disorder: a linkage nationwide study in Brazil	This project will analyse electronic data routinely collected within the Brazilian Public Health System (SUS). It involves enriching this type of data by linking them to other Brazilian governmental databases destined to national social protection programmes, which have important socio-economic variables of the individuals. A very large dataset with over 114 million people (The 100 Million Brazilian Cohort), which more than half of the Brazilian population, will be consolidated to the study of multimorbidity and its socio-economic determinants nationwide. Therefore, establishing foundations on the magnitude of the problem, in particular on the most impoverished population and for further studies on this subject in Brazil and other similar middle-income countries. We aim to study the risk of hospitalisation or death by diabetes mellitus, cardiovascular disease, stroke, or tuberculosis associated with previous hospitalisation by the following psychiatric disorders: depression, alcohol and substance use-related, and schizophrenia. We also intend to identify disease clusters and their related patterns, and how these patterns interact over time to influence the formation of such clusters. "Big data" is seen as having great potential to answer numerous questions and CIDACS collection of Brazilian data is unique in low-middle income countries. Our access to this collection of data allows for unprecedented study of morbidity and mortality in a nationwide scope.	Medical Research Council	P&Cs	161780.0	GBP
87	Professor Olga Ciccarelli	Institute of Neurology, UCL	None	2019-01-01	2021-12-31	Assessing treatment responses using machine learning	Thirteen disease-modifying treatments (DMTs) are approved in the UK to reduce the risk of relapses. Patients can switch from one first-line DMT to a more effective medication, if they present with relapses. The consequences of this policy, that requires "failure" of DMTs before using another DMT are continuous relapses and disability accumulation. We cannot currently predict which DMT will work best for an individual patient. The goal of this project is to predict the individual treatment response in MS by translating machine learning from the computer science field into clinical practice. All patients (adults and children) currently on DMTs and due to start a treatment at UCLH NHS Trust and in the UK paediatric neuroinflammation centres will be studied. Demographic factors, diet quality and life-style, clinical scales, comorbidities, MRI scans and blood tests for safety data, neurofilaments-light levels, and genetic analysis will be collected. This information will be used to predict treatment response in each individual using a high-dimensional model. The model will be validated on independent, international cohorts. This project will bridge the gap between clinical trials, which focus on the "average" response to a therapy, to clinical practice, where the focus should be on the individual treatment response.	Multiple Sclerosis Society	Project grant application	355293.0	GBP
88	Professor Derrick Crook	University of Oxford	None	2016-10-01	2020-03-31	Comprehensive Resistance Prediction for Tuberculosis: an International Consortium (CRyPTIC)	Our aim is to achieve sufficiently accurate genetic prediction of resistance to all anti-tuberculosis drugs for whole genome sequencing (WGS) to replace slow, cumbersome, culture-based drug susceptibility testing (DST) for Mycobacterium tuberculosis complex (MTBC). This would enable rapid-turnaround near-to-patient assays to revolutionize drug-resistant TB identification and management. This multidisciplinary collaboration including TB experts from five continents, WHO, statisticians/mathematicians and software engineers will integrate machine-learning, statistical genetics and molecular genetics methods to uncover all genomic variation causing at least 1% resistance to first- and second-line anti-TB drugs with >1% resistance prevalence. We will use largescale global and clade-representative WGS (>90,000), with initially >37,000 isolates with extended DST. Approaches include better WGS assembly to identify more variants with more precision, improved statistical methods to detect associations between variants and DST, and selected molecular validation of predicted resistant variants. The project will create an automatically-updating, free, publically accessible, comprehensive data repository of resistance-conferring variants. This will provide accurate genetic resistance prediction for all drugs for any new MTBC WGS; superior design of near-to-patient amplification-based molecular drug-resistance tests as alternatives to ‘WGS-only’ solutions; and better, faster and more targeted drug-resistant TB treatment, facilitating improved control and WHO’s initiative to eliminate TB by 2050.	Medical Research Council	P&Cs	1999934.0	GBP
89	Dr Jennifer Bizley	University College London	Ear Institute	2016-06-20	2016-08-12	Neural mechanisms underlying complex sound identification	The aim of the project is to better understand how brain processes complex sound information by measuring responses of cortical neurons (nerve cells) to artificial vowel sounds. The student will construct artificial network of neurons called the convolutional neural networks to make sense of sound identity from neural responses. Dataset has already been collected from 8 ferrets. Student has strong computational and programming skills and experience in programmes needed to analyse the data such as MATLAB and machine learning. Student will be supervised by Dr Stephen Town (Pauline Ashley grant holder) who collected the primary electrophysiology data. The work is feasible for a summer student as the primary data (neural responses to pure tones, single and multi-formant vowels in anesthetised and behaving ferrets) has already been collected and formatted for analysis. Dr Bizley has also developed some basic models with which to analyse data, and from which the student can build and develop his own ideas with support and assistance as necessary.	Action on Hearing Loss	Summer studentship	1600.0	GBP
90	Dr Parashkev Nachev	University College London	None	2010-07-01	2013-12-31	Automated high-dimensional outcome prediction in stroke.	Stroke is the leading cause of adult disability in the UK at an estimated overall annual cost of ?7 billion. Alarmingly, clinical outcomes in stroke are not improving as fast as conditions of similar aetiology. A major cause is the difficulty in providing targeted care in a patient group with such hugely diverse requirements: indeed, the government predicts that better organisation of care can both save lives and optimize resource allocation. We therefore propose to develop a system for predicting clinical outcomes so as to provide advance information on the optimal clinical management of each patient. Our solution automated brain image analysis with high-dimensional machine-learning inference exploits the fine scale functional specialization of the brain, capturing the relation between the pattern of brain damage and clinical outcome at very high resolution. As our pilot data demonstrate, this approach permits much greater predictive power than is offered by current techniques which all rely on crude, global features such as the volume of damaged brain or its rough location and yet adds minimal resource overhead because it uses routinely acquired clinical data. Our proposal seeks to develop this technology to the point of direct clinical application.	Wellcome Trust	Translation Award	392444.0	GBP
91	Dr Parashkev Nachev	University College London	None	2014-09-15	2018-02-01	Automatic anomaly detection for brain imaging triage and classification	Modern brain imaging generates many thousands of data observations per patient, yet its clinical impact remains determined only by the summary points in a radiologist's verbal report. This information gap shows that we are not fully exploiting all potentially relevant clinical information from this expensively acquired data. Our technology will seek dramatically to reduce this gap within current clinical pathways by applying novel machine-learning algorithms to routine brain imaging data, with the aim of automatically extracting rich, high-dimensional information of clinical utility. The system will deliver automatic quantification of the anomaly of each data point of an image to assist radiological reporting and automated outcome prediction based on disease patterns and an anomaly score for the whole image to aid radiological triage and resource/performance management. Our goal is to demonstrate the feasibility, robustness, clinical, and managerial value of the approach using a large dataset of routine clinical brain imaging, delivering a pilot system translatable into a full clinical product. Merely by adding an inexpensive layer of computation to existing pathways, the system should improve report fidelity and optimise radiological triage and management, while creating a scalable new platform for facilitating big data' approaches to major neurological disorders.	Wellcome Trust	Health Innovation Challenge Fund Award	1088636.0	GBP
92	Dr Rudolf Cardinal	University of Cambridge	None	2018-03-31	2021-03-31	MICA: Mental Health Data Pathfinder: University of Cambridge, Cambridgeshire & Peterborough NHS Foundation Trust, and Microsoft	With strong NHS partnerships and recent contributions to national mental health (MH) informatics, we shall add novel methods, epidemiology and phenotyping to the MH Platform. We envisage a modular pipeline that de-identifies MH data; supports flexible consent for sharing/contact; and links MH, cognitive, physical, psychosocial and biomarker data. Project (P) 1. Our open-source tools de-identify clinical records to create CPFT’s Research Database, supporting research and participation. We shall extend them to generate anonymised subsets and link data from consenting patients across MH/community services, acute care, and research organizations, including from existing deeply phenotyped longitudinal cohorts. We emphasize rigorous interface standards and NHS governance over identifiable/pseudonymised data. We shall collaborate on a national natural language processing framework, allowing NHS/research organizations to generate structured data from free text. P2. We have created novel open-source neuropsychiatric assessment software. We shall extend it for broad and integrated NHS and research use. This will take automated cognitive testing into routine clinical practice. As a bold but tractable exemplar with research and clinical applications, we shall use it to apply electronic diagnostic algorithms and neuropsychiatric phenotyping, and link these detailed data to clinical records and biomarkers that include immunophenotyping. P3. We shall apply P1 tools to a public health crisis: the premature death of those with serious mental illness. We shall link MH, national and acute Trust data and use machine learning to develop early predictors of mortality. P4. We shall democratize MH research though broad consultation on generic tiered consent models for data-sharing and participation, by giving the research database direct clinical interfaces, and by enhancing data visualization to help clinicians and service users develop research and the NHS improve local services.	Medical Research Council	P&Cs	1496194.0	GBP
93	Professor Mike Slade	Nottinghamshire Healthcare NHS Foundation Trust	None	2017-04-01	2022-03-31	Personal experience as a recovery resource in psychosis: Narrative Experiences ONline (NEON) Programme	Aims and Objectives Recovery narratives involve people describing the understanding they have developed about their mental health problems and their recovery. The aim of this study is to use recorded recovery narratives to support the recovery of people experiencing psychosis. The objectives are: 1. To collect recovery narratives from four under-researched groups (n=120) 2. To develop and validate (n=20) a conceptual framework characterising recovery narratives and their benefits to others 3. To develop (n=40), refine (n=30) and optimise (n=81) an intervention using recorded narratives to benefit people experiencing psychosis 4. To conduct a definitive randomised controlled trial to assess the effectiveness and cost-effectiveness of the intervention on current mental health service users experiencing psychosis from across England (n=683) Hypothesis: participants receiving the narratives intervention will have improved quality of life at one-year follow-up compared with those not receiving the intervention. 5. To develop an online intervention for mental health professionals to increase hopefulness in staff about recovery. Background and rationale Psychosis is burdensome to individuals and their families, and costly to society (see Importance to the NHS section). People experiencing psychosis benefit from meeting others who share their narrative of recovery5, and recorded narratives provide a low-cost approach to increasing access. This programme builds on a previous Programme Grant (RP-PG-0707-10040) on recovery. Research plan The scientific framework is the 2015 MRC Framework for Complex Interventions6. MRC Development Stage Work Package 1 addresses knowledge gaps relating to four important under-researched groups: experiencing psychosis and not using mental health services; mental health service users from non-majority groups; people who are under-served by mental health services; and peer workers. Semi-structured interviews (n=120) will explore how their narratives may benefit others. Work Package 2 synthesises existing research and Work Package 1 findings to develop a conceptual framework characterising the defining features of recovery narratives and the mechanisms by which they benefit others. After further refinement through semi-structured interviews with service users (n=20), this forms the basis for Work Packages 3 and 4. MRC Feasibility/Piloting and Evaluation Stages Work Package 3 develops and evaluates the NEON intervention, an online intervention using recorded recovery narratives for mental health service users experiencing psychosis. English-language narratives will be collated from multiple sources. Guided by Work Package 2, a preliminary matching approach for selecting the most helpful narrative(s) for individuals will be developed, using the Narratives of Recovery Scale (NORSE) to characterise narratives and ratings of hope-promotion from 40 service users to characterise their impact. As further participants use the intervention, the machine-learning approach will refine the matching algorithm. Informed by workshops with 30 healthcare professionals, an online intervention will be developed to match individuals to narratives. Feasibility of trial procedures and engagement approaches will be tested with 30 mental health service users, and clinical relevance maximised through focus groups with health professionals (n=24). A definitive randomised controlled trial with an internal pilot will then be conducted across England, involving 683 mental health service users with a psychosis diagnosis, randomised to either usual care or usual care plus NEON. The intervention will comprise an internet-based experience of recorded recovery narratives, with the narrative chosen using the matching algorithm (recommended approach), by the service user, or randomly presented. The primary outcome is quality of life measure with Manchester Short Assessment. Outcome evaluation will use intention-to-treat analysis of the primary outcome at one week, three months and one year (primary end-point) after baseline. Economic evaluation will estimate the impact on service costs, and assess relative cost-effectiveness compared with current practice. Process evaluation will investigate the relationship between implementation, mechanism and context, including mechanisms of change and interpretation of outcome. Work Package 4 will address the therapeutic pessimism of some health workers. It will develop and undertake a preliminary evaluation of a new online professional development intervention. The intervention will involve staff viewing narratives showing positive role models of recovery, selected using theory developed in Work Package 2 from narratives collated in Work Package 3. Projected outputs & dissemination plans Outputs will include a sound theoretical basis for this and other narratives research, a new and rigorously evaluated intervention for service users, a new intervention for workforce development with preliminary evaluation, and a library of quality-assured online narratives with substantial potential for further applications and evaluations. The extensive health technology assessment will provide commissioners with essential information to support local budget impact analysis and commissioning. MRC Implementation stage Work Package 5 uses a range of researcher-led and PPI-led approaches to dissemination, including knowledge transfer events, co-production of a summary of findings, implementation within England through linkage with national transformation programmes, and the development of practical guides. The online intervention will be made freely available. Benefits to patients and the NHS A low-cost, low-intensity free-to-access self-management intervention for patients experiencing psychosis, which will benefit patients and inform judicious use of NHS resources.	National Institute for Health Research (Department of Health)	Full Award	2295609.0	GBP
94	Dr Richard Stephen Savage	University of Warwick	Warwick Systems Biology Centre	2010-06-01	2014-05-31	Applications of probabilistic machine learning to medical biostatistics	Biomedical research accumulates huge volumes of scientific data. Because of this, it is necessary to develop computational and statistical methods that can effectively extract important information from these data. These data-sets can present a number of challenges. The underlying biological systems are often highly complex, leading to rich structure in the data. They are typically also noisy, both as the result of measurement imprecision and also any biological variation that may be intrinsic to the system studied. The data-sets are often also large, particularly from high-throughput technologies such as microarrays that allow simultaneous measurement of whole genomes. This work will develop novel non-parametric Bayesian methods to address key questions in three areas of medical biostatistics. Firstly, the integration of multiple sources of data into combined biomarker discovery/outcome prediction models. Secondly, the use of Bayesian model averaging techniques to develop more effective data models for clustering of gene expression data. Thirdly, the creation of hierarchical data models that can simultaneously cluster, identify biomarkers and make outcome predictions. Non-parametric Bayesian methods represent a powerful way to address these challenges. Because they are highly flexible, they can accurately model the sort of complex structure often found in biomedical data-sets and can select in a principled way the most appropriate model structure, leading directly to superior data modelling results. Their Bayesian nature also makes them suitable for modelling uncertainty in the data and for using all available sources of information for a given analysis. The particular families of non-parametric models I‘ll be using are Gaussian Process and Dirichlet Process models, both of which are on the cutting-edge of current machine learning research. The medical focus of this work will be cancer, with a particular early focus on data-sets investigating breast canc, myeloma, ovarian carcinogenesis and basal cell carcinoma. My collaborators and I will extend this work both as new data-sets become available, and also as we identify promising analysis results to follow up, for example in the design of new experiments or clinical trials. This work will produce original research in probabilistic machine learning and I will develop these innovations into robust software tools so that the broader scientific community can benefit fully from this work.	Medical Research Council	Fellowship	351627.0	GBP
95	Prof Wiebke Arlt	University of Birmingham	None	2018-04-01	2023-04-01	Dissecting Androgen excess and metabolic dysfunction – an Integrated SYstems approach to PolyCystic Ovary Syndrome (DAISY-PCOS)	Polycystic ovary syndrome (PCOS) affects 5-10% of all women; androgen excess is one of its major diagnostic features. While often perceived as a reproductive disorder, PCOS is now emerging as a lifelong, complex metabolic disorder, with increased risk of type 2 diabetes, hypertension, cardiovascular disease, and, as recently documented, non-alcoholic fatty liver disease (NAFLD). However, there has been no recent breakthrough regarding risk stratification or therapeutic intervention in PCOS. Our work has provided evidence for a key role of androgens in the development of PCOS-related metabolic complications. We will combine cutting edge in vivo physiology techniques, state-of-the-art metabolomics and machine learning-based computational approaches to address our overarching hypothesis that androgens are major drivers of metabolic risk in PCOS. We will use an integrated set of in vitro, ex vivo and in vivo experimental medicine studies to test this hypothesis and answer our specific questions: Does the control of androgen excess improve metabolic function? What is the role of different androgen pathways in conveying metabolic risk? Can we integrate phenome and metabolome data by machine learning to predict metabolic risk in PCOS? Our overall aim is the identification of novel personalized approaches and therapeutic targets for patients with PCOS.	Wellcome Trust	Investigator Award in Science	2389852.0	GBP
96	Dr Rhodri Cusack	MRC Cognition and Brain Sciences Unit	None	2008-04-01	2011-06-30	ACA4: Selective attention, short-term memory and the parietal lobe	Selection and short-term memory dramatically shape perception, and when disrupted the results can be dramatic and disabling. Perceptual systems impose structure upon the tremendous quantity of chaotic confusing clutter that arrives from the environment, the important parts are selected, and a stable representation of them formed in short-term memory. In some ways, performance is surprisingly constrained, even in the healthy brain. Attention, short-term memory, and other cognitive processes have a limited span of only three or four objects at any one time. The understanding of this bottleneck in human cognition as an important question, and one that will be the focus of this programme. An investigation of these cognitive processes and their capacity limits is intertwined with the overarching neural theme of investigation of the posterior parietal lobe. Understanding this part of the brain also presents an intriguing and important problem for cognitive neuroscience. It is recruited by many tasks, but its function is often generalised in a broad way (e.g., attention, spatial, vision-for-action), which for such a substantial portion of cortex is likely to be of limited use. Instead, it is more productive to partition it into distinct functional regions, a strategy that has met with success in both humans (Simon et al, 2001; Rushworth et al, 2006; Cusack & Owen, 2008) and non-human primates (Van Essen, 2004). This programme will continue to use new techniques to parcellate the parietal cortex into functional subdivisions, and then FMRI to understand the function of each of these parts. A particular emphasis will be given to methods that allow the distinction of more finely differentiated neural states, using machine learning pattern analysis techniques to characterise the neural state within brain regions. This will be combined with real-time iterative search techniques that allow FMRI experiments with many possible outcomes to be run in a practical time period.	Medical Research Council	Unit	None	None
97	Prof Jonathan Rees	University of Edinburgh	None	2008-09-15	2011-11-14	Dermofit: A cognitive prosthesis to aid focal skin lesion diagnosis.	We want to allow non-experts to diagnose skin lesions by taking advantage of the ability of humans to make visual matches even when they are not able to describe the lesions (using words) in a consistent way. In order to attach semantics to images we have to discover the basis of similarity between different lesions such that we can construct a database in which those lesion images that are similar are tagged as similar. If the search space can be structured in this way then it becomes possible for non-experts to search it efficiently, and match an index case with a tagged-reference case. We will acquire images, construct a user interface, and use iterative testing and user interaction coupled with machine vision and machine learning techniques, to order the database. Just as the pattern of hypertext links reflects a webpage s importance, so does the pattern of clicks from one image to another reveal what users consider as similar. The approach is therefore that of computer based i mage retrieval. Our goal is a device that assists non-experts achieve the correct diagnosis suitable for use wherever PCs are available.	Wellcome Trust	Project Grant	348877.0	GBP
98	Professor Daniel Haydon	University of Glasgow	Environmental and Evolutionary Biology	2007-03-12	2010-09-11	Predicting immunological cross-reactivity: from genotype to antigenic phenotype	An important goal of both epidemiological and viral evolutionary studies is to predict the antigenic similarity of different viral genotypes. The ability to easily determine antigenic similarity would greatly facilitate the empirical study of the evolution of antigenic novelty, informing us about when and how fast we can expect viruses to exhibit antigenic change. In this proposal I lay out a research program that aims to provide tools that will enable prediction of the antigenic similarity of different strains of FMDV from their capsid gene sequences alone. In stage 1 we will develop simplified 'in silico' models of immune reactions that simulate a polyclonal antibody response to different viral strains as represented by complete amino acid sequences of their capsid proteins. This immune model will exploit the substantial amount that is known about the structure and distribution of epitopes across the FMDV capsid, and will use as input existing capsid genotypes and additional strains predicted to derive from them. This immune model will enable the reactivity of the polyclonal response to one viral strain to be measured against another, thereby allowing pairwise antigenic similarity of different viral strains to be predicted. In stage 2 we will use these simulated data sets containing full-length capsid genes, and matrices containing estimates of their antigenic similarity to develop bioinformatic algorithms that will be able to predict the antigenic similarity of new pairs of capsid sequences for which antigenic data is lacking. We propose to try two different approaches: artificial neural networks, and kernel based machine learning methods. The performance of these algorithms can be assessed using simulated data, and pre-existing empirical data.	Biotechnology and Biological Sciences Research Council	Standard grant	265364.0	GBP
99	Professor Nikolaj Gadegaard	University of Glasgow	None	2015-08-01	2020-07-31	Focal Adhesion Kinetics In nanosurface Recognition	The provision of advanced functional materials in the area of regenerative medicine and discovery applications depends on many different factors to provide the appropriate targeted function. As adherent cells also read their environment through substrate interactions there is a great interest in developing such substrates in a predictable manner. Their first point of contact is through their focal adhesions and it is also though them that forces are applied allowing the cell to migrate and establish cytoskeletal tension which in turn regulates cell function. The objective of this project is to investigate the cell-substrate interaction at the nanoscale and correlate that to the surface topography for predictable biomaterials. Through the application of state-of-the-art nanofabrication we will fabricate precise surface topographies with length scales comparable to the structural units found in the focal adhesions. The aim is to map and understand the topographical influence in the architectural arrangement of the proteins in the adhesions. Aided by high resolution microscopy we will classify cell types on different nanotopographies. Combining that information with machine learning, we will be able to gain information about cell characteristics from the rule set. That information can also be used in reverse to identify cell types with the previously defined characteristic. This approach is similar to face recognition seen on cameras and mobile phones. The proposed research project will not only provide insight to an area of biomaterials not previously explored, yet aim to provide a blueprint for future design of biomaterials.	European Research Council	Consolidator Grant	2128895.0	EUR
100	Prof. Christopher Yau	University of Birmingham	Institute of Cancer and Genomic Sciences	2017-10-09	2020-01-06	From single cells to populations: generalized pseudotime analysis to identify patient trajectories from cross-sectional data in cancer genomics	Longitudinal multiple tumour sampling studies are the ideal approach for the study of cancer evolution and its impact on patient outcome. However, such studies are logistically challenging and expensive to operate, and typically involve relatively smaller cohorts than a cross-sectional study involving the collection of a single tumour sample (or perhaps multiple samples obtained at the same time) from each patient. This project proposes novel statistical approaches to inferring (pseudo)temporal information by integrating cross-sectional studies involving whole genome sequencing and gene expression analysis of cancers along with clinical covariates. The model probabilistically assigns patients to a latent "pseudotime", which measures a marker of disease progression, based on their molecular and clinical profiles. The transformation from high-dimensional molecular observations to the one-dimensional pseudotime is implemented using a covariate-adjusted Gaussian Process Latent Variable Model that can model a different disease progression trajectory for each combination of the covariates. This will allow us to test if putative molecular mechanisms distinguish between patients, for example, whose disease progresses to metastatic status or become radio and/or chemotherapy resistant by looking for statistically significant differences in the trajectories of each phenotypic group. This project will also develop novel approaches for integrating methods that can predict the functional annotation of somatic mutations and their impact on cellular programming. These models will provide probabilistic genome annotations that can be used as input into the pseudotime ordering algorithms. We will integrate all this work and apply about application to the Genomics England 100,000 Genomes Project.	Medical Research Council	Research Grant	325589.0	GBP
101	Professor Sophia Ananiadou	The University of Manchester	None	2009-09-01	2012-08-31	Automated Biological Event Extraction from the Literature for Drug Discovery	In establishing drug target confidence, it is essential to have evidence of the type of relationship between the target and key protein-bioprocesses. However, the primary starting point for target choice, and the context for interpretation of all pre-clinical observations is the literature. Text mining (TM) is ideally suited to support the discovery of reliable drug targets. But for TM systems to help researchers understand the role proteins play in biological processes, they have to extract, normalise and identify the context of complex relationships between genes, diseases and their underlying bioprocesses. Our TM techniques will recognise diverse surface forms in text describing bioprocesses and will link them with events and the proteins associated with them. Our methods are based on a combination of advanced semantic text mining (deep parsing, named entity recognition) and machine learning techniques, as we shall automatically identify events (involving proteins) such as decrease [in concentration], phosphorylation, ubiquitination, etc. Bioprocesses such as angiogenesis are composed of individual events described in the literature. We propose to identify these bioprocesses automatically and to link them with the associated events. A combination of kernel methods with knowledge resources and annotated texts (evaluated by biologists) will be used to automatically learn how bioprocesses underlying higher level processes are linked with which events. We shall concentrate on angiogenesis as an example. We shall thereby produce and make available a text mining service for researchers working in drug discovery. Both the software tools used for event extraction as well as the annotated texts used for training purposes will be made available. Co-funded by EPSRC under the RCUK Cross-Council Funding Agreement.	Biotechnology and Biological Sciences Research Council	Industrial (IPA)	288468.0	GBP
102	Professor Rawlings	Rothamsted Research	None	None	2012-08-31	Integration of 'omics databases and novel approaches to data analysis and annotation	The objective is to develop a common data infrastructure for integrating data from relevant technology platforms and enable linkage with other 'omics (proteomics, metabolomics) data available in Rothamsted Research. These data will be combined with public domain sources of gene annotation and classification that will facilitate the analysis and interpretation of experimental results. The intial focus will be on interpretation of microarray data. This system will create a platform for the development of new methods for data analysis and gene annotation based on graph theoretic, statistical, machine learning and visualisation methods.	Biotechnology and Biological Sciences Research Council	Institute CSG	528470.0	GBP
103	Dr Zameel Cader	University of Oxford	None	2017-03-01	2021-03-31	University of Oxford Momentum Award – Dementias	Research and drug discovery for Alzheimer’s disease (AD) is undergoing a minor crisis with a paucity of novel therapeutic approaches that is human evidence-based. Whilst, human genetic studies have identified AD associated variants important for CNS glial function, there is uncertainty over whether inflammation plays a beneficial or deleterious role. As a result, many pharma companies are hesitant before committing significant resources to this novel therapeutic opportunity. Our proposal is therefore focused on the scientific theme “Microglial interactions in Alzheimer’s Disease”. The indicative projects will leverage four key capabilities within the University of Oxford that represent untapped potential and are ripe for development for dementia research, (1) access to human primary CNS cell types from human tissue coupled with single cell analysis, (2) Human iPSC derived microglia, (3) High order imaging analysis of cellular phenotypes driven by machine learning, (4) Protein-protein interaction disruption to probe signalling pathways. The proposed projects approaches neuro-inflammation in AD through these technical capabilities and are supported by world-leading bioinformatics and unrivalled structural genomics consortium (SGC) pharmacological tools. These tools enable pharmacological pilot studies within the projects, which if successful, will more rapidly lead to drug discovery projects because of the enabling structural knowledge and chemical starting points held within the SGC. Momentum funds will support the recruitment of a new research leader from outside the UK, as well as supporting early career high flyers within Oxford. Our pharma partners and institution leverages the MRC funds with significant institutional funds, platforms, space and expertise totalling ~£2million (~£850K from the institution and $1.5million industry in-kind). We have developed strong partnerships with Oxford University Hospital NHS Trust and industry including world-leaders in single cell biology and dementia drug discovery. The Award will support the diversification of target identification and develop human in vitro models that are more likely to be predictive of clinical outcomes compared to current dominant murine models. Our approach will facilitate synergy between disciplines and maximise the contribution of the grant towards the acceleration of new dementia research in Oxford.	Medical Research Council	P&Cs	1005900.0	GBP
104	Professor Mark Emberton	University College London	Targeted Intervention	2018-06-01	2022-05-31	MICA: The exploitation of a novel image-based risk stratification tool in early prostate cancer - the Re-IMAGINE Consortium	For the last 50 years we have been applying PSA-Biopsy risk-stratification to men at risk of prostate cancer and we now know it is unfit for purpose. It results in the greatest burden in all oncology of over-diagnosis, over-treatment, and of missed cancers that are of clinical importance. This systematic error has biased our tissue archives, skewed our risk calculators, rendered our trials un-representative and undermined policy-making. We have shown that MRI provides almost complete correction for each error associated with the traditional PSA-Biopsy approach by identifying a distinct stratum from the wider population at risk that is closely correlated to the two strongest progression predictors - grade and volume. Encouraged by our patient/user groups within the Re-IMAGINE consortium, our aim has been to create a novel, image-based, measurable-disease endotype and to use it to risk stratify men with PCa and, as a result, improve our ability to derive prognostic information and allocate men to the most appropriate and effective therapies. We will achieve this by creating unique cohorts, each defined by the presence of a specific MRI-derived endotype that will provide clinical, molecular and radiological inputs into a progression model that will be specified to predict disease status, radiological, clinical and metastatic progression. During this process, insight into the key mechanistic events that drive progression will be available to us for the first time. Machine learning algorithms from the radiology-pathology annotated training data sets will inform computer-assisted diagnosis. Our 12 commercial partners (that have created biomarkers to risk-stratify, predict and prognosticate) are excited about the opportunity that Re-IMAGINE provides to refine their performance by means of enhanced precision and, in addition, create new risk models that integrate MRI-derived radiomics with their improved proprietary offerings.	Medical Research Council	Research Grant	5179122.0	GBP
105	Dr. Karl MECHTLER	IMP - Research Institute of Molecular Pathology	None	2013-03-01	2016-02-29	Self-Learning Search Algorithms for High-Res Mass Spectra	To identify proteins in biological samples mass spectrometry (MS) is most often applied: proteins are digested to peptides which are subsequently analyzed. Within the last decade, a new generation of mass spectrometers has been developed that are capable of acquiring mass spectra with high resolution and high mass accuracy. This has significantly changed the characteristics of mass spectra; however, this development has not been accompanied by a corresponding progress in peptide identification algorithms capable of fully exploiting the available information. We therefore propose to develop a set of novel identification algorithms that are specifically designed for the analysis of modern mass spectra and incorporate multiple sources of information in the here proposed bioinformatics research project. Preliminary research results are promising: The project consortium consisting of the Proteomics Group at IMP Vienna and the Bioinformatics Research Group at FH OÖ (Campus Hagenberg) has already conducted successful joint research in the analysis of MS data: Identification rates comparable or even superior to Mascot, the current gold-standard, have been achieved using a first version of a scoring function designed by the proposing consortium. Encouraged by these preliminary research results, we are convinced that considering additional sources of information will further improve identification rates of mass spectra – therefore this project is dedicated to research on a combination of the following novel approaches: We plan to use machine learning techniques to analyze peptide elution times, fragmentation patterns and mass accuracy characteristics specific to the instrument; in addition, observed m/z values will be recalibrated based on the mass error of highly reliable identifications, and the remaining mass error with regard to the learned distribution will be incorporated into the scoring function. Sophisticated peak picking strategies will also be designed using machine learning. These improvements will help increase identification rates in challenging situations such as hybrid spectra and exhaustive searches for a wide range of post-translational modifications. The latter approach leads to exponentially growing search spaces and an accompanying drop in spectra identification rates because the information in MS spectra on its own is not sufficient to cope with the increased search space. Instead of applying brute force methods we plan to solve this problem using construction heuristics, i.e., evolutionary algorithms that realize intelligent search strategies for large numbers of unknown post-translational modifications based on a combination of database search and de novo identification. All research results achieved in this project will be published and made freely available to the bioinformatics and proteomics communities. Improving identification rates of peptides in general and of unknown modifications in particular will permit a deeper insight into the proteome; computer science shall thus form a new basis for finding answers to important medical and biological questions.	Austrian Science Fund FWF	Translational Research	419816.26	EUR
106	Dr Gareth Ball	King's College London	Imaging & Biomedical Engineering	2012-07-01	2015-06-30	Machine learning to understand brain development	We will analyse images acquired from 820 preterm infants (as part of ePrime) and an existing dataset of 50 control infants. Network characterisation will be performed using graph theoretical approaches and combined with measures of shape and appearance (Bullmore and Sporns 2009, Aljabar et al. 2011). Techniques for mapping low-dimensional manifold representations of high-dimensional datasets will be optimised and applied to provide a more complete characterisation of the developing brain-comprising anatomy on a macro- and micro-scale and functional development of neural networks. Using these techniques, features will be extracted that describe the influences of prematurity at birth, and a number of potentially modifiable perinatal risk factors, including postnatal sepsis (Adams-Chapman and Stoll 2006) and neonatal respiratory morbidity (Doyle and Anderson 2010), on the developing brain. This will be performed with post hoc comparisons of image-derived data with clinical metadata collected as part of the ongoing image acquisition project and by incorporating the metadata into the models provided by manifold learning (Wolz et al. 2011). In addition, we aim to identify early markers of poor neurodevelopment outcome. Outcome data will be available for the full cohort after two years and will be used to assess the predictive power of the machine learning techniques described above. By combining a unique dataset, advanced imaging and high-level, exploratory statistical analysis this project will identify potential biomarkers for future developmental performance and provide tools for assessing efficacy of therapeutic intervention in this at-risk population. Adams-Chapman I, Stoll BJ. 2006. Curr Opin Infect Dis 19:290-297 Aljabar P et al. 2011. IEEE Trans Med Imaging: doi:10.1109/TMI.2011.2162529 Bullmore E, Sporns O. 2009. Nat Rev Neurosci 10:186-198 Doyle LW, Anderson PJ. 2010. Neonatology 97:388-394 Wolz R et al. 2011. ISBI: From Nano to Macro 1:1637-1640	Medical Research Council	Fellowship	299148.0	GBP
107	Professor Adnan Custovic	The University of Manchester	Medical and Human Sciences	2013-01-25	2015-09-13	MICA: STELAR (Study Team for Early Life Asthma Research) consortium - Asthma e-lab and identification of novel endotypes of childhood asthma	Asthma epidemiology is reaching the limit of what can be achieved through conventional hypothesis-driven research. We hypothesise that asthma is not a single disease, but a condition comprising multiple distinct disease entities (asthma endotypes), each with characteristic pathophysiology and risk factors, and that unbiased novel endotypes of asthma can be identified using complex, rich and expanding datasets from existing UK birth cohort studies by applying a combination of biostatistical and machine learning methods. We propose to form a major Alliance between MRC-funded network of all UK-based birth cohorts designed to study asthma (STELAR consortium), expertise in epidemiologically oriented health informatics research (NW Institute for Bio-Health Informatics) and experts in statistical machine learning (Microsoft Research Cambridge). We will capitalise on the unique collection of well characterised birth cohorts with harmonised clinical outcomes (ALSPAC, SEATON, MAAS, Ashford, Isle of Wight). We will create a secure web-based research environment (Asthma e-Lab) to support consistent recording, description and sharing of data and emerging findings across all partners, thus enabling collaborative epidemiology in near-real-time. The activities of data managers and researchers from the 5 STELAR sites will be made visible to one another, supporting team coordination and peer support and creating a scientific social network to enrich the ongoing modelling and interpretation. We will create and maintain across the consortium annotated dependency graphs of the problem space around the organising principles underlying asthma, and use a machine learning approach interactively over the combined datasets via Asthma e-Lab to discover the unbiased endotypes of asthma. Our findings may underpin new trials of asthma prevention and treatment, personalised for specific endotypes and may help identify novel targets for the discovery of endotypes-specific stratified treatments.	Medical Research Council	Research Grant	1498108.0	GBP
108	Professor Adnan Custovic	Imperial College London	National Heart and Lung Institute	2020-08-01	2023-07-31	Endotypes of childhood wheezing after severe RSV lower respiratory tract illness in infancy in socially vulnerable Argentinian children	Respiratory syncytial virus (RSV) lower respiratory tract illness (LRTI) is the main cause of hospitalisation in infants worldwide. Severe RSV LRTI may contribute to asthma development, but it identifying infants who will progress to chronic symptoms is not possible to date. We hypothesise that RSV LRTI causally contributes to one or more specific asthma endotypes, We further postulate that different wheezing trajectories from infancy to school age are associated with different patterns of cytokine & gene expression profiles at initial LRTI in infancy, allowing early recognition of infants at risk. We will test our hypotheses in a unique prospective study of 1,153 children in low-income region of Argentina; 419 with severe RSV LRTI in infancy, 344 with severe non-RSV LRTI, and 390 healthy controls. Extensive data has been collected through the initial hospitalisation, and biological samples from the initial episode obtained for future analyses. Participants were followed to age 3 years (retention 91%). We propose to extend follow up to age 6 years and derive subtypes of wheeze using machine learning applied to longitudinal data. In parallel, we will carry out a series of mechanistic studies in biobanked respiratory secretions to identify immunophenotypes of antiviral responses and their relationship with outcomes. Concentrations of 39 cytokines will be assessed, and machine learning used to cluster children based on their cytokine levels. We will also investigate the transcriptional response to infection in the airway and perform unbiased analyses for differentially expressed genes and pathways in severe RSV infection and infection caused by and other viruses. We will investigate developmental profiles of wheezing through childhood across clusters using longitudinal regression models. This study represents a unique opportunity to identify RSV-specific chronic wheezing endotypes and define endotype-specific indicators of progression to long-term respiratory illness.	Medical Research Council	Research Grant	913705.0	GBP
109	Dr Richard Edmondson	University of Manchester	None	2016-04-01	2018-03-31	Artificial Intelligence and surgical decision making: an oxymoron or the way ahead	Some patients with ovarian cancer have surgery before chemotherapy whilst others have surgery after chemotherapy. For some, it may be best not to have an operation at all. Deciding the role and timing of surgery for individual patients remains a key clinical question with enormous ramifications for patients and also for the health service. The situation is almost exactly the same for oligometastatic colorectal cancer where the key question remains whether patients should have simultaneous resection of visceral metastases at the time of their initial surgery. It is no surprise that MDT decision making and subsequent practice is non uniform across the UK. Whilst predictive tools are clearly needed, previous attempts to generate these have failed, principally because they have used limited numbers of factors. A successful predictive algorithm is likely to need a combination of patient factors, tumour biology factors and importantly surgeon factors. We believe that the answer lies in using a big data and machine learning approach. Machine learning algorithms underpin many areas of commerce, banking and other areas of daily life but have not yet been utilised in clinical decision making. We propose to extract data that already exist, but are ?hidden? in NHS data silos, into a usable format. We will then use them to develop, train and validate machine learning algorithms, including neural networks that are ideally suited for this purpose, to predict surgical outcome. This project will provide important tools to answer highly relevant clinical questions but perhaps even more importantly will serve as an exemplar and develop the infrastructure to use big data to improve outcomes for patients with cancer.	Cancer Research UK	Pioneer Award Committee - Pioneer Award	None	None
110	Dr. Alexander LEX	Graz University of Technology	None	2013-05-01	2015-08-31	Visual Analysis of Heterogeneous Data using Semantic Subsets	Analyzing and understanding very large and heterogeneous datasets is a fundamental challenge researchers face in many scientific domains. Disciplines such as astronomy, physics and biology have to deal with datasets of an unprecedented scale and complexity. While analyzing these datasets is challenging, they also have the potential to revolutionize our understanding of the underlying processes. To realize this potential, novel analysis approaches have to be developed in all fields of the data sciences. In this proposal for an Erwin Schrödinger fellowship I introduce semantic subsets as a novel method for the visual analysis of large, heterogeneous, and multiple datasets. I propose to leverage machine learning, statistical and other methods to first partition datasets into meaningful subsets, and then use a tight integration of computational and visualization methods to support experts in choosing subsets relevant to a task. These subsets and their relationships are then visualized, facilitating an open, exploratory analysis of the data. The core research challenges addressed in this proposal are how to efficiently and effectively find suitable subsets, manage multiple subsets, and visualize the relationships between them. I argue that this approach is suitable to address the problems posed by the analysis of multiple large and heterogeneous datasets, as it scales well, is highly flexible, and naturally integrates multiple datasets. I intend to develop prototypes realizing the semantic subsets concept for the analysis of biomolecular data in design studies. These applications will be the product of a user-centered design process involving close collaboration with domain experts. The applications will address the domain expert's data analysis problems and aid them in their scientific discovery process. The formal evaluation of the utility of the approach will be conducted using case studies based on longitudinal observations of the deployed applications in addition to controlled user studies. I plan to conduct this research at the Visual Computing Group at Harvard University, lead by Professor Hanspeter Pfister. Professor Pfister and his group have considerable expertise in developing visualization methods for molecular biology. In addition, the greater Boston area is home to many top-tier molecular biology research labs, including the Harvard Medical School and the Broad Institute of MIT and Harvard, to which Professor Pfister and myself have established ties. This environment is therefore uniquely suited to the proposed kind of research. During the planned return phase at the Institute for Computer Graphics and Vision at Graz University of Technology I will not only be able to pass on my gained knowledge to my peers and to students, but will also be able to support Professor Schmalstieg in his agenda of building a strong data visualization group in Graz and thereby strengthen the already sizable Austrian visualization research community.	Austrian Science Fund FWF	Erwin Schrödinger Programme	145130.0	EUR
111	Professor Karim Brohi	Queen Mary University of London	Blizard Institute of Cell and Molecular	2019-01-01	2021-12-31	Defining and predicting the innate immune response to critical injury	Samples: This research will use existing and future blood samples from critically injured patients (ISS 25+) collected at the Royal London Major Trauma Centre in the "hyper-acute window" (within 2 hours of injury). Samples are processed for plasma, protease-inhibited plasma, and leucocytes (as PAXGENE and buffy coat). 676 existing samples meeting study criteria are available. Methodologies: Aim 1: To understand the relationship between tissue damage and advserse clinical outcomes by; 1.1: Whole genome transcriptomic analysis using RNA sequencing on samples taken in the hyper-acute window 1.2: Measurement of objective intrinsic indicators of tissue damage and inflammation-associated cytokines/chemokines 1.3: Latent class mixed modelling machine learning approaches combined with support vector algorithms Methodologies: Aim 2: To gain mechanistic insight into differential hyper-acute immune responses to trauma, by; 2.1: Single cell immune cell profiling using mass spectrometry (cyTOF) on a prospective cohort 2.2: Measurement of plasma levels of IL-6, sIL-6R, and sgp130 in our new cohort 2.3: 10X Genomics single-cell-RNA-seq platform to generate single-cell transcriptomic data for 5-10K purified PBMCs to identify differentially regulated biomarkers and critical signaling modalities 2.4: Flow cytometry & functional analyses of leukocytes from healthy volunteers cultured with hyper-acute plasma from trauma patients who subsequently developed (or did not) MODS Exploitation of results: Key applications will be; A) The generation of new knowledge in understanding the human immune response to tissue damage and its relationship with MODS and immunosuppression; B) Hyper-acute biomarkers and stratification tools for prognostication, clinical trials and precision approaches to resuscitation; and C) novel targets for therapeutic repositioning and drug discovery to reduce the incidence and severity of organ dysfunction and infection in trauma patients.	Medical Research Council	Research Grant	874563.0	GBP
112	Prof. Kwiatkowska	University of Oxford	None	2010-05-01	2015-05-01	From Software Verification to Everyware Verification	In the words of Adam Greenfield, ?the age of ubiquitous computing is here: a computing without computers, where information processing has diffused into everyday life, and virtually disappeared from view?. Conventional hardware and software has evolved into ?everyware' sensor-enabled electronic devices, virtually invisible and wirelessly connected on which we increasingly often rely for everyday activities and access to services such as banking and healthcare. The key component of ?everyware' is embedded software, continuously interacting with its environment by means of sensors and actuators. Ubiquitous computing must deal with the challenges posed by the complex scenario of communities of ?everyware', in presence of environmental uncertainty and resource limitations, while at the same time aiming to meet high-level expectations of autonomous operation, predictability and robustness. This calls for the use of quantitative measures, stochastic modelling, discrete and continuous dynamics and goal-driven approaches, which the emerging quantitative software verification is unable to address at present. The central premise of the proposal is that there is a need for a paradigm shift in verification to enable ?everyware' verification, which can be achieved through a model-based approach that admits discrete and continuous dynamics, the replacement of offline methods with online techniques such as machine learning, and the use of game-theoretic and planning techniques. The project will significantly advance quantitative probabilistic verification in new and previously unexplored directions. I will lead a team of researchers investigating the fundamental principles of ?everyware' verification, development of algorithms and prototype implementations, and experimenting with case studies. I will also provide continued scientific leadership in the area of ubiquitous computing.	European Research Council	Advanced Grant	2060360.0	EUR
113	Dr Crispin Miller	University of Manchester	None	2016-10-18	2020-10-17	noncoding RNA derived classifiers as biomarkers of patient response to therapy	BACKGROUND PCa is a highly heterogeneous disease with complex characteristics of progression. New therapies have produced some clinical successes, but a subset of patients progress to incurable castration-resistant PCa (CRPC) and it is not yet possible to predict which patients will respond best to which treatments. There is an urgent need to develop better biomarkers with which to stratify patient populations and to personalise therapies in order improve clinical outcome. PROPOSED AIMS There is a rapidly accruing body of evidence that noncoding RNAs are frequently involved in regulating processes within the cell by interacting with the epigenetic machinery. We will use in vitro studies to generate combined RNA and epigenetic profiles of sensitive and resistant PCa cell lines in response to drug treatment. We will establish a catalogue of noncoding RNAs with putative mechanistic impact on drug response. These genes will then be used as the basis to define and then validate biomarkers of sensitivity and resistance, by combining expression data generated from a large cohort of matched tumour normal clinical samples obtained from the Manchester Cancer Research centre Biobank with public domain TCGA expression datasets. EXPECTED OUTCOMES We expect first to develop a list of noncoding RNAs of mechanistic importance in PCa. This will be of great utility to the nascent noncoding RNA community. We will then using Machine Learning (ML) approaches to build and validate classifiers of drug sensitivity before investigating their utility when applied to circulating tumour cells. Successful validation of the signature will lead to the development of a companion diagnostic with which to inform PCa patient treatment decisions.	Prostate Cancer UK	PhD Studentships	139722.0	GBP
114	Dr Laureen Lui Yan Chan	CARDIFF UNIVERSITY	None	2010-09-01	2011-08-31	MSc in Bioinformatics and Genetic Epidemiology & Bioinformatics	The aim of the MSc Bioinformatics programme is to gain skills in computational power to investigate genetic epidemiology and post-genomics biology. The exponential growth of epigenetics and genomic data facilitates innovative approaches to investigate risk of having cancer and underlying mechanisms. As some genes play a dual role in cancer and obesity, association between cancer and obesity can be assessed. I have reported that Bitter melon possesses anti-diabetic and anti-obesity effects. Recent studies revealed its anti-tumour property. It was shown that Bitter melon decreased O6-methylguanine DNA adduct in colonic mucosa. It is hypothesized that localization of CpG island in genes and hence mechanisms could substantiate effects of Bitter melon in obesity-related cancer. Besides, maternal nutrition remodels underlying mechanism of obesity which may exaggerate the growth of tumours and then hinder treatment outcome. Genetics and epigenetics may be clues to delineate mechanisms of obesity-related cancer. The effects of diet on the obesity-cancer association could be investigated in network pathway analysis. Genetic epidemiology and artificial biological models can be established to study time-dependent effects. Having been trained in machine learning, pattern recognition, genetic epidemiology, likelihood and quantitative trait analysis, cutting edge methods could be used to further investigate these polygenic diseases.	Cancer Research UK	Bursary	None	None
115	Dr Vishal Nangalia	University College London	Medicine	2013-06-03	2016-08-02	Machine Learning - Early Warning System (ML-EWS)	Serious adverse events (SAEs, such as cardiac arrest, unexpected intensive care unit admission, the need for emergency surgery, or death) are commonplace in hospitalised patients. A key factor in reducing the burden of unexpected in-hospital morbidity and mortality is the identification of those at risk of deterioration. Previous attempts to do this have focused only on limited variables (often at one timepoint), have had poor sensitivity/specificity, and/or have necessitated the introduction of expensive new technical systems and management processes. As a result, no effective system has yet been implemented. I therefore propose to develop a simple and widely- applicable multivariate decision tool for continuous tracking of SAE risk in all patients admitted to hospital. This will use high- dimension multivariate analysis of routinely collected blood tests will be married to existing patient data relating to co-morbidities, interventions and demographics. Little additional resource would be required to collate the data, interpret and act upon it, as all of these data are already stored electronically. If successful, this research will permit automatic and continuous individual risk stratification to guide clinical decision making and resource allocation, ultimately helping prevent serious adverse events.	Medical Research Council	Fellowship	260560.0	GBP
116	Dr Joseph Hayes	University College London	None	2019-01-01	2022-01-01	Personalising the pharmacological treatment of bipolar disorder	Background Prescribing for bipolar disorder is a major clinical dilemma as long-term pharmacological treatment is often necessary. Lithium is the most effective mood stabiliser. However, only 30% of individuals have a good therapeutic response. Presently, there is no reliable way to predict response or adverse event risk, or if an alternative treatment would be better for that patient. Aim To personalise prescribing for people with bipolar disorder via prediction models that quantify potential benefits and risks of existing treatments based on clinical phenotypic characteristics of the individual. Objectives • Identify individualised clinical predictors of lithium and second-generation antipsychotic response. • Determine clinical predictors of chronic kidney disease in individuals taking lithium. • Determine clinical predictors of pathological weight gain in individuals taking second-generation antipsychotics. Methodology Data sources Swedish population registers, Hong-Kong health registers, Taiwanese health insurance database, UK primary care data linked to secondary care admission records, and UK mental health care data. Analyses Traditional epidemiological and machine learning methods; drawing on the strengths of each approach. Prediction model generation I will combine predictors from different datasets; resulting in models predicting drug response, chronic kidney disease and weight gain. Application Prediction models will be presented as online and smartphone application clinician decision aids.	Wellcome Trust	Clinical Research Career Development Fellowship	460704.0	GBP
117	Dr. Poirazi	Foundation For Research And Technology - Hellas	None	2012-10-01	2017-10-01	Dissecting the Role of Dendrites in Memory	Understanding the rules and mechanisms underlying memory formation, storage and retrieval is a grand challenge in neuroscience. In light of cumulating evidence regarding non-linear dendritic events (dendritic-spikes, branch strength potentiation, temporal sequence detection etc) together with activity-dependent rewiring of the connection matrix, the classical notion of information storage via Hebbian-like changes in synaptic connections is inadequate. While more recent plasticity theories consider non-linear dendritic properties, a unifying theory of how dendrites are utilized to achieve memory coding, storing and/or retrieval is cruelly missing. Using computational models, we will simulate memory processes in three key brain regions: the hippocampus, the amygdala and the prefrontal cortex. Models will incorporate biologically constrained dendrites and state-of-the-art plasticity rules and will span different levels of abstraction, ranging from detailed biophysical single neurons and circuits to integrate-and-fire networks and abstract theoretical models. Our main goal is to dissect the role of dendrites in information processing and storage across the three different regions by systematically altering their anatomical, biophysical and plasticity properties. Findings will further our understanding of the fundamental computations supported by these structures and how these computations, reinforced by plasticity mechanisms, sub-serve memory formation and associated dysfunctions, thus opening new avenues for hypothesis driven experimentation and development of novel treatments for memory-related diseases. Identification of dendrites as the key processing units across brain regions and complexity levels will lay the foundations for a new era in computational and experimental neuroscience and serve as the basis for groundbreaking advances in the robotics and artificial intelligence fields while also having a large impact on the machine learning community.	European Research Council	Starting Grant	1398000.0	EUR
118	Dr Alex Bottle	Imperial College London	Primary Care And Public Health	2010-09-01	2014-02-28	Can valid and practical risk-prediction or casemix adjustment models, including adjustment for co-morbidity, be generated from English hospital administrative data (Hospital Episode Statistics)?	Using routine NHS hospital admissions data (Hospital Episode Statistics, HES) we aim to derive a series of predictive models for in-hospital mortality, unplanned readmission, unplanned reoperation and non-attendance in outpatients departments. For the last three of these, there is a need to define them in terms of ICD/OPCS codes and time lags so that they will be of most use to the NHS. There will be a focus on the measurement of and adjustment for comorbidity, including an update of the popular Charlson index which we will calibrate for use in the NHS. We will use not just traditional logistic regression but machine learning methods such as artificial neural networks, which have shown promising results with other datasets and are particularly suited to looking for hidden relations between variables. The outcome measures will be specified empirically from the data but with input from clinical and coding experts. These models will be based on national data and will therefore allow us to observe the variation between hospitals in mortality and each of the other outcome measures. This benchmarking will help the NHS and its hospitals drive quality improvement in accordance with the NHS Next Stage Review. At an individual patient level, knowledge of their risk of adverse outcomes such as these aids clinical decision making and informs clinical discussion. The models from this project could be used for both purposes. HES now captures some 60 million OPD appointments each year since 2003/4. The quality of this interesting new resource is uncertain, however. As well as answering the questions concerning optimal time lag and outcomes in non-attenders, this project will afford valuable experience in the use of these data in prediction of non-attendance and health services research in general.	National Institute for Health Research (Department of Health)	Full Grant	400921.33	GBP
119	Prof. Ramsey	UNIVERSITAIR MEDISCH CENTRUM UTRECHT	None	2013-08-01	2018-08-01	Intracranial COnnection with Neural Networks for Enabling Communication in Total paralysis	iCONNECT aims to give severely paralyzed people the means to communicate by merely imagining to talk or make hand gestures. Imagining specific movements generates spatiotemporal patterns of neuronal activity in the brain which I intend to record and decode with an intracranial Brain-Computer Interface (BCI) system. Many people suffer from partial or full loss of control over their body due to stroke, disease or trauma, and this will increase with population ageing. With both duration and quality of life beyond 60 increasing in the western world, more and more people will suffer from the consequences of function loss (mostly stroke) with the prospect of living for decades with the handicap, and will stand to benefit from restorative technology that has yet to be developed. I believe that functionality can be restored with brain implants. My goal is to develop a BCI that can interpret activity patterns on the surface of the brain in real-time. For this we need to discover how the brain codes for (imagined) actions, how codes can be captured and decoded and how an intracranial BCI system impacts on a user. I will use state of the art techniques (7 Tesla MRI and electrocorticography, ECoG) to explore brain codes and develop decoding strategies. Interactions between user and implanted device will be studied in paralyzed people. I will directly link decoded movements to animated visual feedback of the same body part, expecting to induce a feeling of ownership of the animation, and thereby a sense of actual movement. This research is only possible because of the latest developments in imaging of human brain activity, machine learning techniques, and micro systems technology. My lab is unique in bringing together all these techniques. Success of the project will lead to deeper understanding of how sensorimotor functions are represented in the human brain. The ability to ?read' the brain will add a new dimension to the field of neural prosthetics.	European Research Council	Advanced Grant	2498829.0	EUR
120	Dr Rodrigo Braga	Imperial College London	None	2014-11-01	2018-10-31	Local functional architecture and individual differences in cognitive and clinical states.	Functional connectivity within and between large-scale brain networks is disrupted in a range of mental disorders. Current network-based explanations of mental disorders have led to ambiguous conclusions, with different clinical conditions being associated with disruption of the same functional networks. My recent work has shown that heteromodal regions of the cortex can be decomposed to reveal a 'local functional architecture' (LFA) of separable subregions with distinct activation timecourses. Exploring this deeper LFA-level could disambiguate the neural basis of a range of mental illnesses. I will develop a novel analysis technique for the study of individual differences in brain activity at the LFA-level. My first goal will be to optimise a group-wise analysis technique I have developed (2,3) for use within individual subjects. I will apply the technique to large fMRI databases to explore to what extent LFA-level features such as subregion size and functional connectivity with ot her brain structures are conserved across the population. I will then use machine-learning techniques to test which LFA features relate to individual variability in a range of cognitive and personality inventories. Having identified candidate LFA features, I will test for group-wise differences in LFA properties in two psychiatric populations, schizophrenia and unipolar depression.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	250000.0	GBP
121	Prof Alison Noble	University of Oxford	None	2016-11-01	2021-10-31	Perception Ultrasound by Learning Sonographic Experience	PULSE will develop a new generation of ultrasound imaging capabilities to revolutionize the use of this low-cost and portable imaging technology across clinical medicine worldwide. The greatest barrier to the universal implementation of ultrasound (US) in clinical medicine today is the need to train sonographers to the highest level to ensure diagnostic images are of consistently high quality and fit for purpose. Unfortunately, the non-expert finds US images very difficult to interpret by eye alone. Perception Ultrasound by Learning Sonographic Experience (PULSE) is an innovative inter-disciplinary project designed to eliminate the need for highly skilled operators of the technology. It is motivated by the observation that sonographers find it easier to interpret their own scans than review those taken by others. The innovation in PULSE is to apply the latest ideas from machine learning and computer vision to build, from real world training video data, computational models that describe how an expert sonographer performs a diagnostic study of a subject from multiple perceptual cues. Novel machine-learning based computational models will be derived based on probe and eye motion tracking, image processing, and knowledge of how to interpret real-world clinical images and videos acquired to a standardised protocol. By building models that more closely mimic how a human makes decisions from US images we believe we will build considerably more powerful assistive interpretation methods than have previously been possible from still US images and videos alone. Software demonstrators will be developed and evaluated on real world obstetric US data in collaboration with clinical experts and novices to demonstrate the new approach and its potential to move routine US scanning services from hospitals into the community which would have clear economic, healthcare and social benefits across Europe and beyond.	European Research Council	Advanced Grant	2462015.0	EUR
122	Dr Gary Mirams	University of Oxford	None	2014-02-01	2019-02-01	Improving assessment of drug-induced cardiac risk with mathematical electrophysiology models.	Drug-induced cardiac arrhythmia is a leading cause of withdrawal of drugs from the market, and risk of this (both real and perceived) is one of the leading causes of attrition during compound development. The earliest cardiac safety test consists of measuring hERG channel blockade, but its predictive power for human clinical pro-arrhythmic risk is limited. My novel approach is to use experimental data on multiple ion-channel screens for a large number of drugs. In order to integrate this info rmation I will use, and develop further, computational models of cardiac cells and tissue. I will also harness machine learning methods to quantify the predictive power of in-silico markers for safety test results and pro-arrhythmic risk. This work will require a re-calibration of cardiac electrophysiology models, and the design of optimal experiments, to establish the ion-channel conductances in different species and cell types as accurately as possible. I will also extend the existing basic models of drug/ion-channel interaction to capture more subtle, yet perhaps crucial, effects, such as heart rate-dependent blockade. Computational models including pro-arrhythmic risk factors such as age, gender and disease will be developed and utilised to improve the understanding and prediction of susceptibility to drug-induced arrhythmias.	Wellcome Trust	Sir Henry Dale Fellowship	534961.0	GBP
123	Professor Peter Holmans	CARDIFF UNIVERSITY	None	2006-09-01	2009-08-31	MSc in Bioinformatics	The Biostatistics and Bioinformatics Unit (BBU), in close collaboration with five internationally recognised cancer research groups with substantial Cancer Research UK support, requests funding to enable cancer researchers (or future cancer researchers) to study on an MSc course in bioinformatics. We seek this funding to enable highly motivated individuals to train in bioinformatics in order to boost the use of higher level bioinformatics in cancer research. The course will develop the appropriate complementary skills to provide students with the multidisciplinary bioinformatic skill set required to work effectively in the post genomic era in cancer research. The course contains core modules in computer science, statistics and the use of bioinformatics in the postgenomic era and specialist modules in databasing, machine learning and data mining, algorithmic aspects of sequence analysis and molecular modelling. Students complete a mini-research project as well as a full-time 3 month research project and the latter two components are embedded within the collaborating groups. We envisage individuals already in cancer research will obtain these bursaries in order to develop new skills but in some circumstances highly motivated individuals with no previous cancer research experience but with clear aspirations to move into cancer research may be accepted.	Cancer Research UK	Bursary	None	None
124	Dr Lucy Colwell	University of Cambridge	None	2019-10-01	2021-10-01	Next Generation Drug Discovery Enabled by Digital Molecular Technologies: Machine learning enabled high throughput synthesis to repurpose drugs and failed clinical candidates	<p>Access to novel biologically-active molecules that treat disease is a bottleneck in drug discovery,<br> costing thousands of lives and &pound;millions per-year. For every drug marketed, more than 50 programs<br> fail, often due to toxicity detected late in the process. We will develop a transformative system that<br> uses novel MLIAI-based models to understand the mechanism of toxicity, and predict how these<br> endpoints can be mitigated through late-stage functionalization. In parallel, we will merge state-ofthe-<br> art high-throughput synthesis with machine-learning technology to implement structural<br> modifications, turning existing drugs or failed candidates into potential new medicines ready for<br> testing, in a matter of days rather than months. The existing substances will already have optimized<br> biological properties and so a chemical system that introduces pinpoint changes in a controlled<br> fashion will immediately change and improve their properties, thereby dramatically accelerating<br> access to new potential medicines. Importantly, this platform can be applied to any disease area.</p>	Wellcome Trust	Innovator Award: Digital Technologies	575926.0	GBP
125	Dr Sanguinetti	University of Edinburgh	None	2012-10-01	2017-10-01	Machine learning for computational science:statistical and formal modelling of biological systems	Computational modelling is changing the face of science. Many complex systems can be understood as embodied computational systems performing distributed computations on a massive scale. Biology is the discipline where these ideas find their most natural application: cells can be viewed as input/ output devices, with proteins and organelles behaving as finite state machines performing distributed computations inside the cell. This led to the influential framework of cell as computation, and the successful deployment of formal verification and analysis on models of biological systems. This paradigm shift in our understanding of biology has been possible due to the increasingly quantitative experimental techniques being developed in experimental biology. Formal modelling techniques, however, do not have mechanisms to directly include the information obtained from experimental observations in a statistically consistent way. This difficulty in relating the experimental and theoretical developments in biology is a central problem: without incorporating observations, it is extremely difficult to obtain reliable parametrisations of models. More importantly, it is impossible to assess the confidence of model predictions. This means that the central scientific task of falsifying hypotheses cannot be performed in a statistically meaningful way, and that it is very difficult to employ model predictions to rationally plan novel experiments.In this project we will build and develop machine learning tools for continuous time stochastic processes to obtain a principled treatment of the uncertainty at every step of the modelling pipeline. We will use and extend probabilistic programming languages to fully automate the inference tasks, and link to advanced modelling languages to allow formal analysis tools to be deployed in a data modelling framework. We will pursue twoapplications to fundamental problems in systems biology, guaranteeing impact on exciting scientific questions.	European Research Council	Starting Grant	1421944.0	EUR
126	Dr Nicholas Myers	University of Oxford	None	2017-01-01	2021-01-01	Dynamic cortical networks for cognitive flexibility	This project will test the neural basis of cognitive flexibility. Cognitive flexibility allows us to change the rules governing our behaviour to fit the current context. Flexibility is important because we need it even for common tasks, such as changing our normal route home to stop by the supermarket. Prefrontal cortex (PFC) is necessary for cognitive flexibility: damage leads to severe impairments. However, the functional mechanism is largely unknown. I propose that flexible rule switches are implemented through dynamic changes in functional connectivity within the PFC and across the brain. Connectivity sub-selects a local PFC ensemble and links it to appropriate input and output regions, ensuring that new input triggers a state-dependent cascade of neural activation that underpins context-appropriate action selection. I will test whether oscillatory synchronization within PFC and across context-relevant areas is central to this dynamic coding of flexible rule switches by combining multivariate analysis and computational modeling with recordings from macaques and humans (intracranial recordings and MEG). Both dynamic coding and synchronization are fundamental building blocks of neural coding. Therefore, synthesizing these ideas in a coherent framework would be of wide interest in systems neuroscience and psychology.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	250000.0	GBP
127	Dr Pedro Ballester Aristin	EMBL - European Bioinformatics Institute	Thornton Group	2010-07-01	2014-06-30	New computational methods for protein function prediction using structural, binding and sequence data	Structural Genomics projects determine a large number of protein structures that have little or no functional information associated with them. Therefore, there is an increasing need for tools to analyse and characterise the possible functional attributes of such structures. The main objective of the proposed research is to investigate, implement and validate new methods for protein function prediction exploiting the fast growing volume of publicly available structural, binding and sequence data. A full suite of protein function prediction tools (ProFunc) based on principles such as having similar sequence, fold or binding sites has been recently developed at the European Bioinformatics Institute (EBI). Experience shows that no single method, either sequence-based or structure-based, provides a high proportion of correct predictions in all cases. Furthermore, methods exploiting binding data are not currently incorporated to this holistic effort. This is in contrast with the imminent availability of StARLite, a medicinal chemistry database containing vast bioactivity data, which constitutes an extremely valuable resource for the development of such methods. In order to fill this gap, a new method for protein function prediction exploiting StARLite binding data will be investigated and ultimately integrated with ProFunc using an automatic consensus protocol. This class of methods are based on the principle that protein binding similar sets of molecules are likely to have similar biochemical function, which means that their effectiveness is limited by our ability to predict protein-ligand binding via docking techniques. The candidate has recently developed a very promising machine learning based improvement to docking. The massive volume of structural and binding data that will be used for machine learning training, allied with the availability CREDO?s detailed characterisation of inter-molecular interactions, means that the methodology will be made even more accurate in the course of the fellowship. The successful outcome of the proposed research will represent a major advance in our ability to predict the biochemical function of new structures from Structural Genomics projects. Also, this investigation is expected to increase our understanding of what combination of structural, binding and sequence features confer biochemical function. Furthermore, the proposed chemogenomics studies will improve drug target validation and polypharmacological drug lead profiling. In addition, improved docking will permit more effective identification of biologically active molecules as a way to reduce expensive and slow empirical High-Throughput Screening. Overall, the widespread application of these methodologies would strongly contribute to the understanding and exploitation of biological systems (e.g. pharmaceutical discovery).	Medical Research Council	Fellowship	400905.0	GBP
128	Professor Ronan Lyons	Swansea University	Institute of Life Science Medical School	2019-10-01	2022-03-31	Application of machine learning to discover new multimorbidity phenotypes associated with poorer outcomes	We will exploit the most deeply phenotyped population e-cohort in the UK, created by HDRUK investment, containing detailed multi-sourced data on a 2.5M population with GP records in Wales from 2000-2020, augmented with demographic, multiple disease registry, hospital inpatient, outpatient data and laboratory results from 2007. No other part of the UK has this depth of records in a stable population with low levels of migration and loss to follow up. Useful algorithms will be adopted by the NHS with tracking of intervention and subsequent impact. Objectives A. complete the most deeply phenotyped population e-cohort in the UK using existing data from the Secure Anonymised Information Linkage (SAIL) system augmented with Census data B. apply innovative machine learning approaches to validate and refine clusters of conditions detected across the adult life course C. use cohort data to identify mechanistic pathways underlying disease combinations D. report on prevalence, social patterning and health inequalities using small area, census, taxation, and household composition data E. identify potential biomarkers predicting individual and multiple morbidities through longitudinal trajectories of values in routinely collected laboratory data F. undertake a comprehensive analysis of variables used in established morbidity/comorbidity indices with multiple correspondence analysis and factor analysis of mixed data to identify clusters G. provide new variables for linkage to the 20,000 Welsh participants in UK Biobank, 7,000 in Airwave and 15,000+ in Healthwise Wales and use algorithms for 40+ cohorts in DPUK for further studies into the genetics of shared mechanistic pathways H. contribute data on incidence, prevalence and burden to the Global Burden of Diseases I. contribute validated algorithms into NHS systems to allow for early NHS adoption, supporting precision medicine and impact measurement	Medical Research Council	Research Grant	563132.0	GBP
129	Professor Steven Williams	King's College London	Neuroimaging	2012-08-06	2014-07-05	Cerebral Blood Flow Imaging - Towards an Efficient, Automated Assay of Ongoing Pain and its Treatment	Despite our in depth knowledge of the basic mechanisms underlying pain, we still struggle to develop effective new analgesics. This is largely because the development of novel therapies and a clearer understanding of how we process pain are almost wholly reliant on self-reported measures that are inherently subjective. We will address these existing limitations, building upon a neuroimaging protocol recently developed in this laboratory that has demonstrated the central representation of ongoing pain, in both acute and persistent pain states, independently of patient self-report. First, we will validate the robustness of this quantitative, cerebral blood flow (CBF) assay in a new patient cohort, using these new, independent data to train our recently developed, automated machine learning algorithms. These algorithms will discriminate between individuals in pain-free, pre-surgical states, compared to the ongoing pain experienced following third molar surgery. In a second study, we will test this 'pain discrimination' algorithm in the presence and absence of a widely used, generic analgesic, to provide probabilistic discrimination between post-surgical pain response and treatment with analgesia. These methods will enable us to visualise the central effects of both pain and drug uptake as well as their interaction (i.e. analgesia). While focussed here on examining analgesic response in acute post-surgical pain, these methods should translate into the study and treatment of persistent pain. We envisage the development of shorter duration, reduced cost, analgesic trials requiring fewer patients, facilitating more rapid "go/no-go" decision-making.	Medical Research Council	Research Grant	394246.0	GBP
130	Prof. Stanislas Pierre Joseph Dehaene	French Alternative Energies and Atomic Energy Commission	None	2016-10-01	2021-09-30	The cerebral representation of sequences and roles : investigating the origins of human uniqueness.	What are the origins of humans’ remarkable capacities to grasp, memorize, and produce complex sequences and rules, as manifested in language and mathematics? During its evolution, the human brain may have acquired a capacity to represent nested rules, based in part on the expansion of circuits involving the inferior frontal gyrus. This hypothesis will be tested using behavioral measures, functional MRI, magneto-encephalography (MEG), electro-corticography (ECOG) and machine learning techniques in human and non-human primates tested in identical paradigms. (1) We will design a hierarchy of non-linguistic visual and auditory sequences that place increasing demands on abstract rule coding.(2) Behavioral studies of pointing time and eye tracking will investigate the memory for such sequences in human adults, children, and macaque monkeys, and their extrapolation to future items. (3) Functional MRI, MEG, and ECOG will probe the localization, time course, and neural coding of such non-linguistic sequences in human adults. (4) In the same subjects, we will investigate the representation of linguistic and mathematical structures and determine if they involve the same areas and coding principles. (5) We will also record fMRI and ECOG responses to this hierarchy of non-linguistic sequences in macaque monkeys, in search of both correspondences and sharp differences with humans. (6) The same non-linguistic materials will be used in fMRI and EEG studies of human children and infants. Our hypothesis predicts that human children may perform better than adult monkeys. (7) We will formulate and test mathematical models that propose that the human brain “compresses” incoming sequences using nested rules (Kolmogorov complexity), uses predictive codes to anticipate on future inputs, and encodes syntax via tensor-product representations. The results will clarify the brain mechanisms of human language and abstraction abilities, and shed light on their ontogeny and phylogeny.	European Research Council	Advanced Grant	2499747.0	EUR
131	Prof. Jäger	Eberhard Karls Universität Tübingen	None	2013-04-01	2018-04-01	Language Evolution: The Empirical Turn	This proposal describes a highly interdisciplinary approach to the empirical study of cultural language evolution. It draws on ideas and methods from *historical linguistics and typology*, *natural language processing*, *biology*, *bioinformatics*, *computer science*, and *statistics*.The computer aided study of cultural language evolution has seen a tremendous upturn over the past fifteen years. This comprises both model-driven approaches - studying the consequences of design assumptions regarding language production, comprehension, and learning for their long-term population-wide consequences - and data-driven approaches that employ algorithmic techniques from bioinformatics to recover otherwise inaccessible information about language history. At the current junction, the field faces two challenges:- The specifics of language evolution - which includes parallels with but also key differences to biological evolution - require central attention.- Model-driven and data-driven approaches need to inform each other to achieve explanatory power and to assess the statistical significance of the findings.The project will establish a radically data-oriented framework for the study of language evolution. This includes three aspects:- replacing the off-the-shelf tools from bioinformatics that are currently in use in computational language classification by linguistically informed algorithms, esp.  *multiple sequence alignment techniques*,- identifying characteristic traits of language evolution via *exploratory data analysis*, guided by the theory of *complex systems* and employing cutting-edge methods from *machine learning* such as *kernel methods* and *causal inference*, and- developing, implementing and testing models of language evolution that correctly predict the *statistical fingerprints of language evolution*, i.e. pay sufficient attention to the domain specific features of language evolution that have no counterpart in biological evolution.	European Research Council	Advanced Grant	2003580.0	EUR
132	Dr Niina Kolehmainen	Newcastle University	Population Health Sciences Institute	2020-05-01	2020-10-31	Understanding early life determinants and mechanisms to preventing life course multimorbidity	We seek to prevent life course multimorbidity (any two or more chronic conditions or disabilities) through early life biopsychosocial interventions. We focus on two multimorbidity clusters: cardiometabolic and mental health. Our aims are to: 1 Identify biological and behavioural mechanisms underlying drivers of multimorbidity from preconception through first years of life 2 Assess the involvement of regional clustering 3 Generate proof-of-concept interventions Our plan has four integrated streams: 1 Synthesising existing evidence about early life drivers of multimorbidity using causal modelling and presenting the results in a dynamic map co-designed with stakeholders (parents, children, policy, providers). This enables clear understanding of mechanisms to multimorbidity and knowledge gaps. 2 Charting and linking up existing UK-based biopsychosocial data, and using novel statistical and machine learning methods to process and analyse it to address the knowledge gaps from stream 1. 3 Developing health technologies for targeting the multimorbidity mechanisms established in streams 1-2. 4 Engaging all stakeholders to co-design the research and maximise real-world relevance and translation. In the first 6 months' Consolidator phase, we will pilot methods and build shared theory in three areas where the mechanisms to multimorbidity are not yet clear, there is great potential for innovation and we have substantial expertise: influence of mother's cardiovascular health on foetus/child; effect of stress on hormones and child health; effect of mother/child physical activity on cardiometabolic and mental health. This research can shift health and care systems from single conditions to preventing multiple problems, and will directly improve child and parent health, reduce burden on families and the system, and inform governments on early life data to collect to monitor public health.	Medical Research Council	Research Grant	99268.0	GBP
133	Professor Dow-Mu Koh	The Royal Marsden NHS Foundation Trust	None	2017-01-02	2020-01-01	Advanced computer diagnostics for whole body magnetic resonance imaging to improve management of patients with metastatic bone cancer	This project will create advanced image analysis software to be used with WB-MR to provide doctors with timely information to treat patients with bone disease from prostate cancer. The software will be commercialised and made available for potential adoption within the NHS. WB-MRI on its own can reveal bone disease across the body, but the MR scanners used to produce the images lack sophisticated software to measure all the disease demonstrated. Using our prototype software with WB-MRI, we can measure the total body bone disease volume (TDV) and also the total disese apparent diffusion coefficient (ADC), which reflects tumour cell density. We have proof of concept data that shows that TDV decreases whilst ADC values increase (reflecting reduction in tumour cell density) when bone disease responds to treatment, thus aiding the decision to continue, stop or change therapy. However, our software is scripted using interactive data language (IDL), which has limitations: (1) image processing is time consuming, (2) it lacks a user-friendly interface, (3) pre-processing steps are needed, and (4) visual selection by a doctor is required to define disease, which introduces inter-/intra-operator variability of 5%/12% for ADC/TDV estimations. We aim to deliver our invention for innovation by: Software development. We have forged a commercial/research collaboration with Mint Medical GmbH. The Company has an excellent image analysis and reporting platform used for assessing tumour response to treatment. We will develop a powerful software toolkit that will automate WB-MRI analysis, which will be integrated onto this platform. Specific innovations include: (1) Novel image processing (Noise-Corrected eDWI; patent filed) to improve/ automate disease identification and segmentation, (2) improved tools for measuring ADC/TDV statistics, (3) machine learning of imaging trial data to develop treatment response classifiers. Components (1) & (2) will be incorporated into a plugin for the widely used image-viewer (OsiriX) for testing in our multicentre imaging trial. We will roadmap a commercial version, which will include components (1), (2) & (3) for CE marking, in collaboration with Mint Medical GmbH. Imaging trial validation: We will evaluate our software toolkit in 96 patients with prostate bone disease included in a multicentre clinical trial [CTC-STOP] using a test-validation set design. We assume the response rate to chemotherapy is 30% and the sensitivity of WB-MRI for response assessment at 8-12 weeks after treatment is 86% [Blackledge M, 2014]. A sample size of 43 patients will have 90% power to show that the sensitivity of WB-MRI is > 50% at one-sided 5% significance level; an improvement from the Health Economics evaluation: We will evaluate the cost and cost-effectiveness to the NHS of WB-MRI plus the software versus conventional tests (CT, BS) for disease management in patients with prostate bone disease. This will include the cost of WB-MRI (including using the software), CT and BS tests. It will also include economic modelling to evaluate the cost-effectiveness of both options, accounting for the impact of the testing regime on subsequent treatment, as well as disease outcomes and treatment costs.	National Institute for Health Research (Department of Health)	Full Award	1142228.0	GBP
134	Dr Duncan Sproul	University of Edinburgh	None	2016-09-01	2022-08-31	The impact of genetic interactions on DNA methylation in breast cancer	Background:Epigenetic dysfunction is a near universal feature of carcinogenesis. DNA methylation alterations affect key breast cancer genes such as BRCA1 suggesting their importance to carcinogenesis and progression. However, the mechanisms underpinning such alterations in DNA methylation are unknown, so their significance remains unclear.My recent work suggests epigenetic marks are strongly programmed by the underlying DNA sequence. This means that sequence variants are likely to be an important and underexplored influence on breast cancer epigenomes.Aims:This project aims to understand the role of the genome in programming the epigenetic mark DNA methylation in breast cancer through two aims.1. Define the extent to which germ-line and somatic DNA sequence variants modulate local levels of DNA methylation in breast tumours in vivo.2. Understand how the effects of regulatory variants on DNA methylation and gene expression interact and how such variants impact on clinical phenotypes.Methods:I will elucidate the frequency to which germ-line and somatic sequence variants affect DNA methylation in breast cancer through machine-learning analyses of HER2-driven mouse mammary tumours and clinical high-grade luminal breast tumours. The interaction between variant-modulated alterations in DNA methylation and gene expression will be tested using genome editing technologies and the promoter of BRCA1 as a paradigm. The phenotypic impact of BRCA1 regulatory mutations will be assessed through engineering into mice. These synergistic approaches reinforce one another to uncover the global impact of sequence variation on DNA methylation, the mechanistic details underlying these effects and their clinical relevance. How the results of this research will be used:This project uses state-of-the-art computational and laboratory approaches to leverage genetics towards tackling our lack of understanding regarding the impact of DNA sequence variation on epigenetic alterations in cancer. In doing so, it impacts on our understanding of the regulation of a key breast and ovarian cancer risk gene, BRCA1, and provides new approaches to delineate the contribution of regulatory variants to carcinogenesis and progression.	Cancer Research UK	NIC - Career Development Fellowship	None	None
135	Dr Ian Overton	University of Edinburgh	None	2012-04-01	2017-07-31	Computational studies of phenotypic plasticity in development, metastasis and drug response; towards new clinical tools	We study molecular control of phenotype in epithelial remodelling and drug resistance to inform cancer medicine and fundamental biology. Major interests: 1. Understanding molecular control and consequences of cell phenotypic plasticity in metastasis and drug resistance. 2. Developing more effective approaches for cancer patient stratification. 3. Generation of novel algorithms, techniques and computational workflows in line with 1 and 2 the above. The spread of cells from a primary tumour to a secondary site remains one of the most life-threatening pathological events. Epithelial-Mesenchymal Transition (EMT) is a cell programme involving loss of cell-cell adhesion, gain of motility, invasiveness and survival; these properties are fundamental for metastasis. Epithelial remodelling is also crucial for development (e.g. gastrulation). Reactivation of a programme resembling EMT is a credible mechanism for key aspects of the invasion-metastasis cascade and an MET-like process may produce the (re)differentiation frequently observed in secondary tumours. Indeed, oncofetal signalling pathways (e.g. Hedgehog, Wnt, TGF-beta) activate EMT, and promote metastasis in multiple cancers. Navigating from molecular measurements to phenotype implies understanding gene function (including gene products). However, many coding genes are poorly characterised, but coordinately regulated (e.g. in differentiation). Furthermore, new functions continue to be discovered even for deeply studied genes, and most noncoding genes are not well understood (e.g. lncRNA, miRNA). Thus, a substantial portion of gene function is uncharted. Data driven networks provide useful abstractions to fill these knowledge gaps, enabling testing and generation of mechanistic hypotheses. Indeed, understanding control of phenotype intrinsically implies modelling. We have developed systems-wide gene networks and are using these to investigate subtypes, stages and fingerprints of EMT/MET in different contexts (e.g. cardiac cushions, neural crest); additionally to identify new EMT players, pathway crosstalk and drivers of metastasis (eg colorectal, breast cancers). Collaborative experimental work (RNAi) has validated all predictions tested to date. We also infer small scale networks combining ex vivo immunohistochemical and clinical measurements (renal, ovarian, breast cancers). These models integrate carefully selected datasets to represent the specific biological/clinical context of interest. Therefore, this work involves integration of multiple datasets (e.g. ChIP-seq, microarray, proteomic) for machine learning and graph theoretic/statistical analyses. Supervised as well as unsupervised learning techniques are employed, including support vector machine and information-theoretic approaches (e.g. conditional mutual information). Prediction performance is assessed by rigorous benchmarking with blind test data. We develop novel algorithms where required to advance biological understanding, for example we are working on methods to enable systems-wide dynamic modelling of renal cancer drug resistance to inform design of candidate combination therapies. We also make methods widely accessible (e.g. www.tmanavigator.org). We collaborate closely with clinical colleagues and aim to translate results into medical practise. For example, we are currently working on a method to predict response of clear cell renal cell carcinoma patients to therapy (Sutent).	Medical Research Council	Unit	None	None
136	Dr Caswell Barry	University College London	None	2018-12-01	2023-11-30	Non-local computations in hippocampal circuits: neural mechanisms	The overall goal of this proposal is to build a neural-level understanding of how non-local cortico-hippocampal communication mediates memory consolidation and spatial computations. The well-studied network of spatially modulated neurons in the hippocampus and associated regions provides the pre-eminent cellular-model of memory for events and places. However, the activity of these neurons mainly encodes local information, that is, the current configuration of an animal in its environment. Work conducted by us, and others, have identified transient reactivations of hippocampal neurons and cortical counterparts as a key mechanism supporting systems consolidation and spatial planning. These brief ‘non-local’ events provide a means by which remembered experiences can gradually update memory networks, equally they are theorised to support the calculations necessary for route planning. Our aims are: 1) to understand how hippocampus and cortex interacts during reactivations; 2) determine how reactivated information affects existing representations; 3) precisely define the spatial computations that guide navigation; 4) investigate how neuromodulation controls the occurrence of reactivations. To this end, our approach is to combine computational modelling, machine learning, and state-of-the-art experimental techniques. Developing a basic understanding of these processes opens the way to understand how they fail in disease and may ultimately deliver tremendous therapeutic benefits.	Wellcome Trust	Senior Research Fellowship Basic	1670136.0	GBP
137	Professor Nicholas Mills	Edinburgh, University of	BHF Centre for Cardiovascular Sciences	None	2023-11-30	High-sensitivity cardiac troponin beyond the acute coronary syndrome	Our understanding of the acute coronary syndrome is rapidly evolving through the use of high-sensitivity cardiac troponin assays. We have systematically evaluated the impact of introducing these tests into clinical practice on the diagnosis, treatment and outcomes of consecutive patients with suspected acute coronary syndrome. Our findings have informed and challenged the international guidelines and definition of myocardial infarction. In this programme of research, we propose to use novel technologies and machine learning algorithms to improve the effectiveness of high-sensitivity cardiac troponin testing for the diagnosis, classification and treatment of patients with acute coronary syndromes. Through a combination of prospective cohort studies, analysis of big data, and randomised trials, we will develop and evaluate novel point-of-care tests and machine learning algorithms to improve the diagnosis of myocardial infarction. Furthermore, we will evaluate whether testing beyond the acute coronary syndrome can be used to guide the duration of anti-platelet therapies. We anticipate our findings will change practice and future guidelines on diagnosis and management of the acute coronary syndrome.	British Heart Foundation	Programme Grant	1270434.0	GBP
138	Dr Marshall	University of Sheffield	None	2015-08-01	2020-08-01	Distributed Algorithms for Optimal Decision-Making	This grant will develop and translate a unifying framework for optimal decision-theory, and observations of natural systems, to design distributed algorithms for decentralised decision-making. This will enable a technological step-change in techniques for controlling distributed systems, primarily demonstrated during the grant by decentralised control of robot swarms. These algorithms and associated methodology will also provide hypotheses and tools to change the way scientists think about and interrogate natural decision mechanisms, from intracellular regulatory networks, via neural decision circuits, to decision-making populations of animals. Specific objectives are: 1. Distributed value-sensitive decision-making: undertake optimality analyses of the applicant's existing decentralised decision-making algorithms based on observations of collective iterated voting-processes in honeybees, and extend these. 2. Distributed sampling and decision-making: design distributed mechanisms that implement optimal compromises between sampling information and making decisions based on that information. 3. Individual-confidence and distributed decision-making: translate machine learning theory to collective behaviour models, designing mechanisms in which weak decision-makers optimally combine their decisions to optimise group performance. 4. Optimal distributed decision-making in collective robotics: translate theory from objective 1 to 3 towards practical applications in artificial systems, demonstrated using collectively-deciding robots. 5. Development of tools for life scientists and validation of theoretical predictions in natural systems: interact with named collaborators to investigate identified decision mechanisms in single cells, in neural circuits, and in social groups. Develop accessible modelling tools to facilitate investigations by life scientists.	European Research Council	Consolidator Grant	1413705.0	EUR
139	Dr Nitin Purandare	The University of Manchester	None	2005-10-01	2009-03-31	The human serum metabolome in health and disease	Many arguments, including those based on metabolic Control Analysis (MCA), indicate that the metabolome should be a particularly high-resolution method for amplifying and thereby reflecting changes in the levels of gene products, especially those which accompany disease pathogenesis. A key imperative is therefore to develop and industrialise the technology optimal for determining the serum metabolome reliably, to establish the disease-independent ranges of the many hundreds of metabolites that can be observed with such technology, to recognise the disease-independent changes that occur `simply as a function of diet, gender, age, therapeutic interventions and lifestyle, and to make these data for `normals available in a web-accessible manner. Such data will form the reference baseline that will allow prognostic and diagnostic biomarkers for disease progression to be identified reliably; this will show the high- resolution discrimination possible with metabolomic data for both diagnosis and treatment. In parallel, we shall contribute to the development of (i) robust data models for metabolome data, and (ii) machine learning methods of classification in which the `gold standard diagnosis may be imperfectly reliable. The deliverables will be both underpinning knowledge of the human serum metabolome (probably including the discovery of many novel metabolites) and the identification of candidate biomarkers for two diseases.	Biotechnology and Biological Sciences Research Council	LINK project	197915.0	GBP
140	Prof Karla Miller	University of Oxford	None	2016-10-01	2021-10-01	Linking MRI and microscopy for multi-scale neuroscience: Mechanisms, diagnostics and anatomy	MRI has tremendous potential to provide diagnostic and mechanistic insights into brain health and disease in living subjects, but is limited by its poorly defined relationship to histology. My group has pioneered techniques for combining MRI and histology that will enable us to define these relationships to provide more biologically interpretable MRI measures. We will construct models relating MRI and histology both from the bottom up (using microscopy to predict MRI signals) and top down (predicting histopathology from MRI). The top-down approach will use machine-learning methods to predict histological stains from in-vivo MRI, providing “virtual neuropathology” for improved diagnosis in living patients. The bottom-up approach will use electron and optical microscopy for hyper-realistic predictions of the MRI signal with the goal of identifying novel MRI signatures relating to mechanisms of neural health and disease. My group is poised to leverage our unique expertise within a comprehensive research program spanning scales (microscopic to macroscopic), species (rodent to humans) and expertise (physics to neuroscience). We will deploy these methods with neuroscience collaborators for: (i) virtual neuropathology in ALS; (ii) mechanisms of experience-induced plasticity; and (iii) high-resolution neuroanatomy. A primary output will be the “Oxford Digital Brain Bank”, a freely available data repository.	Wellcome Trust	Senior Research Fellowship Basic	1793980.0	GBP
141	Professor Dr Paulus Kirchhof	Birmingham, University of	Institute of Cardiovascular Sciences	None	2021-10-01	Defining clusters of patients with atrial fibrillation at risk of heart failure and death	Atrial fibrillation (AF) is a common condition associated with significant morbidity and mortality. Many patients with AF, once anticoagulated and on rate control therapy, live life largely undisturbed and with a low risk of stroke. However, heart failure and cardiovascular death are still common in anticoagulated and rate-controlled patients with AF. Clinical tools to identify patients at risk of such events could improve research efforts aiming to reduce AF-related complications and enable targeted management to prevent these severe complications. In this study we aim to use machine learning and novel analytical techniques to identify clusters of variables that can be reliably used to identify novel AF endotypes that are at high risk of heart failure associated morbidity and mortality. This will be conducted in an unselected, phenotypically rich cohort of patients with and without AF who are on contemporary management.	British Heart Foundation	Project Grant	73801.0	GBP
142	Professor Gunter Schumann	King's College London	None	2016-10-01	2021-09-30	Brain network based stratification of mental illness	To reduce the burden of mental disorders it is a formidable aim to identify widely applicable disease markers based on neural processes, which predict psychopathology and allow for targeted interventions. We will generate a neurobehavioural framework for stratification of psychopathology by characterising links between network properties of brain function and structure and reinforcement–related behaviours, which are fundamental components of some of the most prevalent mental disorders, major depression, alcohol use disorder and ADHD. We will assess if network configurations define subtypes within and if they correspond to comorbidity across these diagnoses. We will identify discriminative data modalities and characterize predictors of future psychopathology. To identify specific neurobehavioural clusters we will carry out precision phenotyping of 900 patients with major depression, ADHD and alcohol use disorders and 300 controls, which we will investigate with innovative deep machine learning methods derived from artifical intelligence research. Development of these methods will optimize exploitation of a wide range of assessment modalities, including functional and structural neuroimaging, cognitive, emotional as well as environmental measures. The neurobehavioural clusters resulting from this analysis will be validated in a longitudinal population-based imaging genomics cohort, the IMAGEN sample of over 2000 participants spanning the period from adolescence to adulthood and integrated with information generated from genomic and imaging-genomic meta-analyses of >300.000 individuals. By targeting specific neural processes the resulting stratification markers will serve as paradigmatic examples for a diagnostic classification, which is based upon quantifiable neurobiological measures, thus enabling targetted early intervention, identification of novel pharmaceutical targets and the establishment of neurobehaviourally informed endpoints for clinical trials.	European Research Council	Advanced Grant	3394215.0	GBP
143	Professor Vicky Goh	King's College London	None	2015-07-01	2018-06-30	Evaluation of treatment response and resistance in metastatic renal cell cancer using integrated positron emission tomography/magnetic resonance imaging (PET/MRI) with 18F-Fluorodeoxyglucose (FDG)	Background: Anti-angiogenic therapies improve outcome for metastatic renal cancer (mRCC), however, evaluation of response/resistance remains challenging. Computed tomography CT) performs poorly in differentiating response/non-response &amp; in evaluating its heterogeneity. We propose that integrated 18F-FDG PET/MRI is more sensitive than CT, by demonstrating physiological changes ahead of size change with these response biomarkers: 18F-FDG standardised uptake value, SUL (reflecting cellular metabolism), apparent diffusion coefficient, ADC (cellular volume) &amp; relative signal intensity, rSI (vascularisation). <br/><br/>Hypotheses: 1: 18F-FDG PET/MRI improves detection &amp; per-patient response classification of disease progression (PD) over CT at 12 (early) &amp; 24 weeks (late) on treatment with anti-angiogenic therapies; 2: 18F-FDG PET/MRI demonstrates the inter-lesional heterogeneity in response/non-response better than CT; 4: 18F-FDG PET/MRI is synergistic compared to PET or MRI or CT alone. <br/><br/>Aims: Primary: 1: To compare 18F-FDG PET/MRI to CT for response categorisation at 12/24 weeks on treatment; 2: To determine the sensitivity &amp; specificity of 18F-FDG PET/MRI (&amp; PET &amp; MRI separately) to detect PD after 12/24 weeks on treatment. <br/>Secondary: 1: To develop post-processing segmentation tools for whole body tumour burden; 2: To assess inter-lesional heterogeneity of imaging response/non-response; 3: To develop computational methods for predicting response using machine learning &amp; neural networks architectures.<br/><br/>Methods: Design: Pilot cohort study; Patients: 38 mRCCs, 1 or more measurable sites (2cm or greater), undergoing anti-angiogenic therapy. <br/><br/>Research imaging: 18F-FDG PET/MRI at 0/12/24 weeks. Comparator: CT at same time-points. Reference standard: Consensus panel disease status (clinical &amp; imaging by 36 weeks). <br/><br/>Imaging biomarkers:<br/>Target lesion(s): SULpeak, ADCmean, rSInormalised<br/>Exploratory whole body: WB-volume, SUVtotalvol ADCtotalvol, rSItotalvol. <br/><br/>Response categorisation (PD/non-PD): <br/>At 12/24 weeks CT RECIST 1.1 versus PET-MRI: PD - 30% increase in PET SULpeak, or ADCmean reduction 25%, or increase in rSI 40%. Sensitivity of PET/MRI to detect patients with PD calculated as percentage with PD at 12/36 weeks versus CT &amp; reference standard. <br/><br/>Using our results: 1)Improving response categorisation: Our ultimate aim is to improve therapeutic triage. Our next phase is to apply optimised 18F-FDG PET/MRI in a clinical trial to confirm clinical efficacy. 2)Validation of post-processing response tools: Our aim is to translate these tools into clinical practice. 3) Whole body response evaluation: This time-consuming read-out will be facilitated by novel machine learning methods. Our novel methods will be compared to human performance. If successful, these will be applicable to other cancers.	Cancer Research UK	SC - Biomarker Project Award	None	None
144	Dr. Christina MÜLLER-MANG	Medical University of Vienna	None	2010-12-01	2014-11-30	Computerized 3D pulmonary architecture analysis	The differential diagnosis of idiopathic interstitial pneumonias (IIPs) with thin-section computed tomography (CT) is an important and particularly difficult task in clinical radiology. The distinction between the two most common entities, idiopathic pulmonary fibrosis (IPF) and nonspecific interstitial pneumonia (NSIP) is especially important because these two entities have substantially different prognoses and usually require different treatment. This project will create an automated computer-aided diagnosis (CAD) system with two main aims: 1) To differentiate between the textural expression of usual interstitial pneumonia (UIP, the histopathological counterpart of IPF) and NSIP in a fully automated fashion while providing increased sensitivity/specificity over today's differential diagnosis; 2) To allow early diagnosis by performing spatiotemporal analysis of disease progression, yielding novel insights into disease formation. The computational framework we will develop during the project first segments the lung in the CT volume, then computes and selects relevant three-dimensional texture features, and, subsequently differentiates automatically between IPF/UIP and NSIP. The change in the lung's interstitial architectures is assessed by a classification pipeline based on three-dimensional features that represent the texture sub-types ground-glass opacities, reticular opacities, honeycombing, etc.). The diagnostic power of the system is improved by machine learning approaches, which are used for the automatic selection of the associated texture features. This leads to a classification of IPF/UIP versus NSIP based on an optimal differentiation between the texture sub-types. Tracking the local texture changes between the first examination and all follow-up examinations will yield mathematical models that precisely describe the spatiotemporal progression of the disease, allowing the study of trends within the cohort. The resulting automatic, quantitative analysis of the spatiotemporal progression of IIPs will provide new insights into the disease course characteristics. The proposed CAD framework will enable the quantification and prediction of the progression of IPF/UIP and NSIP, thus aiding the radiologic assessment of IIPs. This method has the potential of being extended to other interstitial lung diseases, considerably impacting clinical applications and future research efforts in this area. The system will also be made available to the research community, providing a common base for lung CT analysis and study comparison.	Austrian Science Fund FWF	Stand-Alone Project	None	None
145	Dr Declan O'Regan	Imperial College London	Mansfield Centre, MRC Clinical Sciences Centre	2017-09-18	2020-09-17	Using machine learning to predict clinical outcomes in heart failure.	Heart failure is a complex clinical syndrome associated with differing adaptations of ventricular contractility and geometry as a consequence of altered loading conditions, intrinsic myocardial disease and ischaemia. Although prognosis depends on eventual ventricular decompensation, conventional measures of cardiac function are often poor predictors of outcome in individual patients. Three-dimensional cardiac phenotyping coupled with advanced segmentation and machine learning (ML) algorithms offers a powerful new approach for risk stratification which can be trained on large cohorts of patients with known outcomes. We will determine if ML approaches allow high-precision prediction of individual outcomes by exploiting both complex cardiac phenotypes and conventional risk factors. We will apply this to patient cohorts with dilated cardiomyopathy and pulmonary arterial hypertension. To determine the true predictive performance in unseen patients outcome prediction will be externally validated on an independent cohort and compared to contemporary risk prediction models. The expected result is a validated technique of autonomous image interpretation to predict outcomes and guide management. This work will lay the foundation for introducing ML to decision-making and risk prediction in cardiology by exploiting massive multimodal datasets for classifier training.	British Heart Foundation	New Horizons Grant	297017.0	GBP
146	Dr Declan O'Regan	Imperial College London	Mansfield Centre, MRC London Institute of Medical Sciences	None	2020-09-17	Machine learning to model disease mechanisms and predict outcomes in cardiomyopathy	Cardiomyopathies represent a spectrum of intrinsic heart muscle diseases arising from a complex interaction between genetic and environmental factors associated with differing adaptations of ventricular contractility and geometry frequently leading to functional decompensation or sudden death. Current tools for characterising dysfunction and predicting adverse events rely on crude explanatory variables that are insensitive to the complex pathophysiology of heart disease. Machine learning (ML) could offer a significant advance in developing integrative approaches to modelling heart disease and is well-suited to a variety of classification and prediction tasks that exploit complex input data. We will leverage discoveries from our BHF New Horizons project to develop state-of-the-art approaches for inference and prediction using rich 4-dimensional (3D + time) models of cardiac motion that also integrate functional, genetic and biochemical biomarkers of disease. This approach could be transformative in delivering patient-specific tools for predicting time-to-events, identifying causative mechanisms, and accelerating the discovery of molecular targets amenable to therapy.	British Heart Foundation	Programme Grant	1011285.0	GBP
147	Dr Andrew Swift	University of Sheffield	None	2019-10-01	2021-09-30	Developing a machine learning tool to improve prognostic and treatment response assessment on cardiac MRI data	<p>Cardiovascular diseases account for 26% of deaths in the UK. Current clinical imaging assessments rely on manual or semi-automated measurements. Emerging approaches focus on individual parts of the heart. We have developed the first tensorbased machine learning approach that holistically assesses the heart and surrounding structures on cardiovascular magnetic resonance imaging (CMRI) scans. We will develop this approach into a tool that can identify patients who respond to treatment or who will die early. Key advantages are rapid holistic assessment, minimal human error and full transparency with direct visualisation of features for the disease. We will assemble a large cohort of CMRI scans from 5, 000 patients with pulmonary hypertension, a severe condition affecting the heart, and assess the ability to predict treatment response and likelihood of early death. This tool will revolutionise disease<br> assessment, and improve treatment delivery and patient care.</p>	Wellcome Trust	Innovator Award: Digital Technologies	639873.0	GBP
148	Dr Haiping Lu	University of Sheffield	None	2019-10-01	2021-09-30	Developing a machine learning tool to improve prognostic and treatment response assessment on cardiac MRI data	<p>Cardiovascular diseases account for 26% of deaths in the UK. Current clinical imaging assessments rely on manual or semi-automated measurements. Emerging approaches focus on individual parts of the heart. We have developed the first tensorbased machine learning approach that holistically assesses the heart and surrounding structures on cardiovascular magnetic resonance imaging (CMRI) scans. We will develop this approach into a tool that can identify patients who respond to treatment or who will die early. Key advantages are rapid holistic assessment, minimal human error and full transparency with direct visualisation of features for the disease. We will assemble a large cohort of CMRI scans from 5, 000 patients with pulmonary hypertension, a severe condition affecting the heart, and assess the ability to predict treatment response and likelihood of early death. This tool will revolutionise disease<br> assessment, and improve treatment delivery and patient care.</p>	Wellcome Trust	Innovator Award: Digital Technologies	639873.0	GBP
149	Professor Seneviratne	Eidgenössische Technische Hochschule Zürich	None	2014-09-01	2019-09-01	Land-Climate Interactions: Constraints for Droughts and Heatwaves in a Changing Climate	Land-climate interactions mediated through soil moisture and vegetation play a critical role in the climate system, in particular for the occurrence of extreme events such as droughts and heatwaves. They are, however, poorly constrained in current Earth System Models (ESMs), leading to large uncertainties in climate projections. These uncertainties affect the quality and accuracy of projections of temperature, water availability, and carbon concentrations, as well as that of projected impacts on agriculture, ecosystems, and health. In the past years, in-situ and remote sensing-based datasets of soil moisture, evapotranspiration, and energy and carbon fluxes have become increasingly available, providing untapped potential for reducing associated uncertainties in current climate models. The DROUGHT-HEAT project aims at innovatively exploiting these new information sources in order to 1) derive observations-based diagnostics to quantify and isolate the role of land-climate interactions in past extreme events ("Diagnostic Atlas"), 2) evaluate and improve current ESMs and constrain climate-change projections using the derived diagnostics, and 3) apply the newly gained knowledge to frontier developments in the attribution of climate extremes to land processes and their mitigation through "land geoengineering". The DROUGHT-HEAT project integrates the newest land observational datasets with the latest stream of ESMs. Novel methodologies will be applied to extract functional relationships from the data, and identify key gaps in the ESMs' representation of underlying processes. These will build on physically-based relationships, machine learning tools, and model calibration. In addition, they will encompass the mapping and merging of derived diagnostics in space and time to reduce "blank spaces" in the datasets. The project is unprecedented in its breadth and scope and will allow a major breakthrough in our understanding of the processes leading to heatwaves and droughts.	European Research Council	Consolidator Grant	1952285.0	EUR
150	Dr Peter Taylor	Newcastle University	None	2018-08-13	2020-08-13	EpiChange: Quantifying longitudinal changes after epilepsy surgery	Resective surgery for epilepsy, where the part of the brain thought to cause seizures is removed, leads to seizure freedom in around 70% of patients 1 year post-surgery. This falls to around 50% at 5 years post-surgery. It is not fully understood why surgery only works initially for some patients, and why this falls over time post-operatively. Surgery has a substantial immediate impact on brain structure, however, the long-term impact of surgery on brain dynamics is poorly understood. In order to make progress in this area we will perform a retrospective analysis of longitudinally acquired electroencephalographic (EEG) data. EEG recordings were made pre-operatively, and post-operatively in 76 patients for up to 5 years. Using univariate and multivariate data analysis, in conjunction with machine learning, we will learn how brain dynamics change after surgery, and if this change relates to outcome. Crucially, we will attempt to identify which factors in brain dynamics correlate with seizure relapse, even years after surgery. If successful, this will pave the way to a larger project where changes can be reverse engineered to give predictions of post-operative decline using pre-operative data. Long-term, this research has implications for other disorders involving longitudinal decline following structural brain damage.	Wellcome Trust	Seed Award in Science	99978.0	GBP
151	Carlos Ciller Ruiz	Department of Computing Imperial College London	Department of Computing Imperial College London	2015-09-01	2016-02-29	Multimodal patient-specific eye model for delineation and treatment planning of ocular tumors	In the past few years, retinoblastoma and uveal melanoma, the most common cancers of the eye, have witnessed an important advance in the field of medical imaging and its applications in ophthalmology. MRI, CT, Fundus Photography and Ultrasound are among the image modalities of reference for treatment planning and diagnosis confirmation of the disease. However, existing methods for modeling the eye are still imprecise and they do not benefit from state of the art techniques developed in other medical image processing applications. In addition, there is a disconnection between the different image modalities due to the lack of common anatomical landmarks and to the difficult method standardization in ophthalmic radiation oncology. This situation mainly affects the treatment planning (radiation dose optimization) step involved in External Beam Radiotherapy (EBRT), Cryotherapy and Brachytherapy, thus precluding optimal preservation of healthy tissue in patients. Furthermore, some patients need to undergo eye surgery prior to treatment planning, with the objective of offering a better tracking of the tumor location during therapy, therefore they require the implant of tantalum fiducial markers in the posterior part of the eye. Hence, techniques for preventing eye surgery while providing similar tracking results would offer an unprecedented opportunity for improving the patient’s quality of life during and after treatment. During the last two years we have developed a method to fully automatically segment the eye in the 3D MRI, and collaborated in the preliminary fusion of MRI with Fundus photography. These contributions follow the motivations of the presented project: i) create a method for the automatic delineation of pathological areas inside the eye in the MRI by combining multiple MRI sequences and machine learning techniques, ii) propose a framework for the fusion of MRI and Fundus photography for robust and accurate eye tumor delineation towards preventing eye surgery and iii) to set the basis for techniques to predict the tumor growth based on the shape and location of the tumor, and the technique applied for treatment. These ideas and the extended motivation can be read in detail in the research plan.	Swiss National Science Foundation	Doc.Mobility	None	None
152	Ms. Laura Linnea Maria Elo-Uhlgren	University of Turku	None	2016-06-01	2021-05-31	From longitudinal proteomics to dynamic individualized diagnostics	Longitudinal omics data hold great promise to improve biomarker detection and enable dynamic individualized predictions. Recent technological advances have made proteomics an increasingly attractive option but clinical longitudinal proteomic datasets are still rare and computational tools for their analysis underdeveloped. The objective of this proposal is to create a roadmap to detect clinically feasible protein markers using longitudinal data and effective computational tools. A biomedical focus is on early detection of Type 1 diabetes (T1D). Specific objectives are: 1) Novel biomarker detector using longitudinal data. DynaOmics introduces novel types of multi-level dynamic markers that are undetectable in conventional single-time cross-sectional studies (e.g. within-individual changes in abundance or associations), develops optimization methods for their robust and reproducible detection within and across individuals, and validates their utility in well-defined samples. 2) Individualized disease risk prediction dynamically. DynaOmics develops dynamic individualized predictive models using the multi-level longitudinal proteome features and novel statistical and machine learning methods that have previously not been used in this context, including joint models of longitudinal and time-to-event data, and one-class classification type techniques. 3) Dynamic prediction of T1D. DynaOmics builds a predictive model of dynamic T1D risk to assist early detection of the disease, which is crucial for developing future therapeutic and preventive strategies. T1D typically involves a relatively long symptom-free period before clinical diagnosis but current tools to predict early T1D risk have restricted power. The objectives involve innovative and unconventional approaches and address major unmet challenges in the field, having high potential to open new avenues for diagnosis and treatment of complex diseases and fundamentally novel insights towards precision medicine.	European Research Council	Starting Grant	1499869.0	EUR
153	Ao. Prof. Dr. Peter LACKNER	University of Salzburg	None	2017-07-01	2020-06-30	Structure based prediction of MHC II binding peptides	A key event in immune reactions is the binding of a pathogen derived antigen peptide to a MHC class II molecule. Only the resulting complex binds to the T-Cell receptor and triggers responses against the pathogen. These processes also play a role in allergies and they are associated with different autoimmune diseases such as diabetes or multiple sclerosis. In this respect, the identification of MHC-II binding peptides is a central task in biomedical research. Potential wet lab experiments are time consuming and costly. This constraint has driven the development of computational prediction methods for MHC-II binding peptides. However, to date their accuracy and/or range of applicability is still limited. Sequence-based approaches normally apply machine learning, utilizing sequence data of known binders and non-binders for certain MHC-II allotypes. The accuracy can be rather good, but in general these approaches can only be reliably applied to MHC-II allotypes where sufficient experimental data are available. In contrast, structure based methods operate on known 3D structures of MHC-II molecules and usually employ physical force fields. In general, they do not build on experimental binding data. However, they are yet limited by the number experimentally determined MHC-II structures and lack in prediction accuracy. We here propose a new structure based approach. We hypothesize that the application of statistical scoring functions (SSFs) in combination with information about intrinsic features of the binding peptides such as flexibility or preference for a certain local conformation can considerably improves the prediction accuracy. SSFs have been successfully used in protein structure bioinformatics for many years. Several parameters such as the compilation data set composition, the reference state, and the method for significance estimate calculation restrains the utilization of SSFs for a certain problem. We will investigate the influence of the different parameters on the prediction accuracy. In order to achieve a practical solution, two further points are important. First, the calculation of high-quality structural models for all presently known MHC-II allotypes applying comparative modeling accompanied by exhaustive model assessment. And second, the subsequent reduction of the molecular representation to the main chain, such that a fast threading approach can be applied for binding prediction. This simplified model has the prime advantage that the potential errors in side chain modeling will not obstruct the binder prediction. The final software will be released as standalone program for high throughput predictions and as a web-service for small scale experiments. We further will provide the set of MHC-II models annotated with quality scores and allotype information as a separate database. Finally we intend to use the method in In-house collaborations to design hypo-allergens.	Austrian Science Fund FWF	Stand-Alone Project	203710.5	EUR
154	Professor Nikolaj Gadegaard	University of Glasgow	None	2015-08-01	2020-07-31	Focal Adhesion Kinetics In nanosurface Recognition	The provision of advanced functional materials in the area of regenerative medicine and discovery applications depends on many different factors to provide the appropriate targeted function. As adherent cells also read their environment through substrate interactions there is a great interest in developing such substrates in a predictable manner. Their first point of contact is through their focal adhesions and it is also though them that forces are applied allowing the cell to migrate and establish cytoskeletal tension which in turn regulates cell function. The objective of this project is to investigate the cell-substrate interaction at the nanoscale and correlate that to the surface topography for predictable biomaterials. Through the application of state-of-the-art nanofabrication we will fabricate precise surface topographies with length scales comparable to the structural units found in the focal adhesions. The aim is to map and understand the topographical influence in the architectural arrangement of the proteins in the adhesions. Aided by high resolution microscopy we will classify cell types on different nanotopographies. Combining that information with machine learning, we will be able to gain information about cell characteristics from the rule set. That information can also be used in reverse to identify cell types with the previously defined characteristic. This approach is similar to face recognition seen on cameras and mobile phones. The proposed research project will not only provide insight to an area of biomaterials not previously explored, yet aim to provide a blueprint for future design of biomaterials.	European Research Council	Consolidator Grant	2128895.0	EUR
155	Univ.Prof. Dr. Immanuel BOMZE	University of Vienna	None	2014-05-01	2019-04-30	Network Optimization in Bioinformatics and Systems Biology	Mathematical models and algorithmic approaches for solving combinatorial optimization problems from the field of network optimization are known to be essential in telecommunications and the design of transportation and supply chain networks. More recently, it has been discovered that network optimization algorithms are also crucial in the context of bioinformatics and systems biology. Numerous publications in systems biology point out that studying functions, structures and interactions of proteins in combination with networks can provide new insights regarding robust biomarkers, can allow new discoveries regarding protein functions, or testing of new hypothesis regarding their interactions. Network optimization algorithms have also been applied in the analysis of functional modules in protein-protein interaction networks, the discovery of regulatory subnetworks, in revealing hidden components in biological processes, or in detecting transcription factor modules. Motivated by these recent developments, we aim to study several network optimization problems that are among the most challenging ones in these fields and that were not sufficiently studied or understood so far. One of them is essential for the analysis of protein-protein interaction networks, and the other one is an innovative way of combining machine learning and network optimization techniques for extracting signaling pathways or building network-driven classifiers. Existing approaches for these benchmark problems in particular are not able to tackle the supernetworks of very large-scale arising in real world. Thus, in this project we aim at developing the first supernetwork-driven approach in combinatorial optimization that will seamlessly integrate various methodologies from operations research (exact and metaheuristic approaches for network optimization) and computer science (machine learning) into a single mathematical framework. To capture important real world characteristics of the problems to be studied, we will thereby combine techniques of combinatorial, robust optimization and bi-objective optimization. In order to ensure that our algorithms will be able to cope with the enormous size of supernetworks, the tools we will develop will rely on decomposition approaches for mixed integer programming, metaheuristics and parallelization techniques. The obtained results will be important contributions to the fields of combinatorial optimization and bioinformatics.	Austrian Science Fund FWF	Stand-Alone Project	347760.0	EUR
156	Dr Romy Lorenz	University of Cambridge	None	2018-09-01	2022-09-01	Fractionating the human frontoparietal cortex: combining meta-analytic and real-time optimization approaches	Disruptions in the same set of frontal and parietal brain regions are seen across a striking range of psychiatric and neurological conditions. This network of regions has been referred to as multiple-demand (MD) system and can be divided into at least two closely coupled subnetworks. However, despite extensive research efforts, the specific functional mechanism each subnetwork supports remains poorly understood using available neuroimaging technology. To overcome these limitations, I have recently developed a novel technique based on real-time neuroimaging and machine learning: Neuroadaptive Bayesian Optimization (NaBO). The key goal of this fellowship is to develop a complementary approach that leverages the strength of large-scale, automated meta-analyses and NaBO to obtain a fine-grained functional mapping between MD subnetworks and the cognitive processes they support. This approach will exploit the wealth of data generated by neuroimaging to date (meta-analysis) for defining a prior model of how cognitive functions relate to MD subnetworks and then refine this model in unprecedented detail (NaBO). The resulting model will be validated using behavioural assessment. Advancing our understanding of these subnetworks in normal brain function is an important first step for developing targeted clinical interventions and informing the design of sensitive diagnostic test batteries.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	250000.0	GBP
157	Dr Bender	University of Cambridge	None	2018-10-01	2021-09-30	Moving the Adverse Outcome Pathways Framework towards Practical Utility by Integrating Compound Profiling Data and Using Deep Learning	Despite a significant investment in in vitro and in vivo screening, clinical safety concerns are still a major cause of compounds being withdrawn from the development process. A lack of mechanistic understanding of safety findings, combined with sparse data sets, restricts the development of approaches capable of predicting earlier potential safety concerns for new chemical entities. It is often unclear whether these are truly surprise events or, with hindsight, could actually have been predicted based on the available data at the time. This failure to detect early signals of safety issues may arise due to problems at the interface between three main components of predictive analysis: observer, data and technology. In this work we propose to employ novel mathematical approaches to data representation and modelling, such as deep learning, of the processes that lead to an adverse outcome in order to reduce or eliminate events of this type. Data will be compiled from within AZ and GSK and shared via Lhasa Limited Ltd, with the student having access to both data sources for model generation. Depending on the adverse event considered, we will either compile AOP frameworks for adverse events, and/or use deep learning approaches for cases where only observational data is available, and hence extend current AOP frameworks where indicated. In particular, nodes in deep networks can be interpreted with respect to their contribution to output toxicity, and hence information for AOPs can be derived from them. The current project will involve GSK and AstraZeneca as industrial partners, with the charity Lhasa Ltd. as an 'honest broker', to exchange and pool compound profiling data for model generation. This framework is currently already being established in the context of the Cambridge Alliance on Medicines Safety (CAMS), and it hence improves significantly upon previous analyses which were based either on public data, or data from only a single source. A pilot study on Structural Cardiotoxicity has already been completed and it is currently being written up for publication, proving the viability and benefit of exchanging data for safety prediction in this framework. We now would like to broaden the approach to other adverse events where data is available. This proposal directly puts into practice recommendations published recently, and it represents an advancement over previous approaches (such as eTox) in being able to have broader access to internal safety data from two major pharmaceutical companies in the UK, AstraZeneca and GSK, shared under confidentiality agreements via a Trusted Broker, Lhasa. This means that all biological data will be made available in the context of the project, including experimental protocols, quantitative data on exposure of compounds, and additional target-based and biological profiling information of compounds can be used in this project. Hence, we expect that the combination of access to data, and the utilization of state-of-the-art machine learning methods, will enhance our ability to predict drug safety and toxicity events considerably. Increasing our understanding of the molecular mechanisms by which compounds can cause adverse events will lead to the implementation of much improved in silico and in vitro screens to detect safety risks will avoid unnecessary investments in preclinical and clinical studies.	National Centre for the Replacement, Refinement and Reduction of Animals in Research	Studentship	90000.0	GBP
158	Professor Fergus Gleeson	Oxford University Hospitals NHS Foundation Trust	None	2017-10-01	2021-09-30	IDEAL: Artificial Intelligence and Big Data for Early Lung Cancer Diagnosis	IDEAL comprises 6 work packages (WP) over 36 months. Each WP has a leader, with Milestones, Tasks (T) and Deliverables (D). See Appendix A for a GANTT chart. WP1: Project Management (M1-M36)(Lead: FG, Involved: VP-DB-MC-SMB, FTE:1.35) The project will be led by FG supported by a Project Manager (PM), who will ensure that the project meets the required quality, time & cost, identify risks, manage spend & provide reports. D1.1. Risk assessment (M1) D1.2. Regular progress reports WP2: Planning for a Big Dataset (M1-M9)(Lead: FG, Involved: LP-MC-DB, FTE:3.75) T2.1. Database Definition (M1) We will define the database architecture to enable selection of data subsets to adaptively re-train a best classifier for the patient demographic/scanner/pathway. Project partners will test the baseline system and decide what annotations will be included, including making the database multi-use (e.g. including COPD annotations). We will define thresholds for minimum acceptable performance. T2.2. Big Data Acquisition and Testing (M2-M9) We will collect >500 patients containing pulmonary nodules (PN) with ground-truth per site (total: 1500). The PN Clinics at three sites see 90 patients per month and have a database of over 1000 patients. The new database will be used to augment pre-existing datasets. The database creation will require an innovative data science approach, so that the thousands of images represent the millions of possible patient, scanner, and protocol combinations. The clinical research fellow and radiographers will collect, annotate and anonymize data. They will iteratively re-train and test the algorithms in collaboration with Optellum, in order to identify nodule types (e.g. sizes, characteristics, clinical pathways) and scan types (scanner model, protocol, kernel, resolution) to be added in order to create a balanced and unbiased set. Milestone 1: Database defined (M1) Milestone 2: Database ready (M9) D2.1. New PN database with 1500 patients WP3: Product Development (M1-M15)(Lead: VP, Involved: LP-SMB, FTE:4.625) T3.1. Machine Learning on Multi-Center Data (M1-M9, FTE:1.5) The evolving database from WP2 will be integrated into a “lean product development” to improve machine learning and guide data acquisition, so that the DIB handles heterogeneous data. Optellum will productize the LVB prototype so that it can be robustly deployed in a hospital setting. T3.2. Front-end Prototype (M1-M3)(FTE:0.5) User interface prototype defined and developed, with frequent Usability Tests with the end users. T3.3. Back-end Prototype(M3-M9)(FTE:0.5) Back-end server ready for PACS integration developed and tested. T3.4. Final Product Development (M10-M15)(FTE:1.5) T3.5. CE-marking (M1-M15)(FTE:0.625) We determine regulatory classification according to CE-MDD. Quality Management System (QMS) will be introduced and user testing conducted with help of consultant from ScreenPoint Medical. We expect to apply for CE-marking in M12. Milestone 3: Prototype ready for clinical study (M9) Milestone 4: CE-marking (M15) D3.1. Full software D3.2. CE-mark WP4: Texture Risk-model (M1-M12)(Lead: FG, Involved: LP-MC-DB-SMB, FTE:1.0) T4.1. Risk-model development. We will develop a risk model for small pulmonary nodules that incorporates texture using retrospective data. Milestone 5: Texture included in risk model (M9) D4.1. Risk model report (M12) WP5: Clinical Study (M9-M33)(Lead FG, Involved: MC-DB, FTE:10.0) T5.1. Prospective clinical study (M9-M33) Research radiographers at the three sites, under the guidance of the clinical research fellow, will assess patients with PN and enter them into the clinical trial and follow them for up to 12 months with established methods (volumetry, PET) compared against the initial DIB score. Milestone 6: Final patient follow up (M33) D5.1. Study results report (M36) WP6: Analysis & Dissemination (M21-M36)(Lead FG, Involved: MC-DB-VP, FTE:1.25) T6.1. NHS dissemination: Results presented at BTS and BSTI meetings. T6.2. International dissemination LVB launched at the 2018 European Congress of Radiology. Milestone 7: Project finished (M36)	National Institute for Health Research (Department of Health)	Full Grant	1425634.0	GBP
159	Dr. Demian WASSERMANN	National Institute for Research in Computer Science and Automatic Control (INRIA)	None	2018-03-01	2023-02-28	Accelerating Neuroscience Research by Unifying Knowledge Representation and Analysis Through a Domain Specific Language	Neuroscience is at an inflection point. The 150-year old cortical specialization paradigm, in which cortical brain areas have a distinct set of functions, is experiencing an unprecedented momentum with over 1000 articles being published every year. However, this paradigm is reaching its limits. Recent studies show that current approaches to atlas brain areas, like relative location, cellular population type, or connectivity, are not enough on their own to characterize a cortical area and its function unequivocally. This hinders the reproducibility and advancement of neuroscience. Neuroscience is thus in dire need of a universal standard to specify neuroanatomy and function: a novel formal language allowing neuroscientists to simultaneously specify tissue characteristics, relative location, known function and connectional topology for the unequivocal identification of a given brain region. The vision of NeuroLang is that a unified formal language for neuroanatomy will boost our understanding of the brain. By defining brain regions, networks, and cognitive tasks through a set of formal criteria, researchers will be able to synthesize and integrate data within and across diverse studies. NeuroLang will accelerate the development of neuroscience by providing a way to evaluate anatomical specificity, test current theories, and develop new hypotheses. NeuroLang will lead to a new generation of computational tools for neuroscience research. In doing so, we will be shedding a novel light onto neurological research and possibly disease treatment and palliative care. Our project complements current developments in large multimodal studies across different databases. This project will bring the power of Domain Specific Languages to neuroscience research, driving the field towards a new paradigm articulating classical neuroanatomy with current statistical and machine learning-based approaches.	European Research Council	Starting Grant	1497045.0	EUR
160	Peter Achermann	University of Zurich	Institut für Pharmakologie und Toxikologie Universität Zürich	2017-11-01	2019-01-31	EEG based microsleep episode detection in the maintenance of wakefulness test and the driving simulator using a machine learning approach	Road traffic injuries are the leading cause of death for those aged 15-29 years. Excessive daytime sleepiness (EDS) is estimated to be the underlying cause in up to 15-20% of motor vehicle accidents (MVA), and is most often caused by socially induced sleep deprivation or poor sleep hygiene in otherwise healthy individuals, followed by medical disorders, or the intake of drugs. Methods for reliably objectifying sleepiness are urgently sought, primarily for sleepiness detection while driving but also for predicting the risk of sleepiness induced accidents during laboratory assessments of patients. The EEG is widely recognized as the gold standard for determining sleep-wake stages and their sudden, as well as gradual, changes. In the clinical and scientific context, standard EEG scoring criteria are generally applied, in which sleep is scored based on 30-s epochs. These sleep criteria consider neither the occurrence of microsleep episodes (MSE) nor the local aspects of sleep demonstrated in both animals and humans. Falling asleep is a gradual, not a sudden, process and shows fluctuations between waking and sleep. Particularly when assessing objective sleepiness in the context of driving ability, MSE of short duration originating in any brain area become an important criterion.We aim to characterize and identify MSE by defining visual scoring rules for MSE as short as 1 s, extracting relevant features based on quantitative EEG analyses, and by developing machine learning algorithms to detect MSE. First, we will only consider occipital EEG leads but will extend our analyses to central EEG leads in a second step. Our algorithms will be trained and verified on MWT data of patients and subsequently applied to MWT data of sleep deprived healthy individuals, and simulated driving conditions. In the driving simulator, we will investigate the association of MSE with impaired driving performance and spontaneously perceived sleepiness (SPS). In the context of fitness to drive assessments, one generally assumes that the perception of sleepiness precedes the occurrence of MSE. Our approach should allow to validate or disprove such an assumption. Previous studies mainly assessed relationships based on mean values or pooled data. Our aim is to take inter-individual variations into account and relate single events (i.e. MSE) with quantitative EEG measures. Therefore, we intend to track the sleep-wake transition zone (e.g. occurrence of MSE, vigilance fluctuations) with high temporal resolution on a second-by-second basis. In summary, we intend to develop and formulate the first standardized MSE scoring rules worldwide and to establish reliable automatic detection algorithms. This will have a major impact in sleep medicine and research and open new areas of research and diagnostic procedures. Since sleepiness is among the most frequent causes of car accidents, and an important risk factor for train and truck drivers and in many surveillance tasks such as air traffic or nuclear power plant control, reliable diagnostic tools to judge fitness to drive or fitness on the job become essential for reducing car and work accidents, catastrophic incidents, and the immense costs related to excessive daytime sleepiness.	Swiss National Science Foundation	Project funding (Div. I-III)	217848.0	CHF
161	Maria Anisimova	ETH Zurich	Informationstechnologie und Ausbildung ETH Zürich	2010-08-01	2013-07-31	The evolution of proteins with tandem repeats: a large-scale study of rates, selective forces, complex patterns and associations with human disease	Protein repeats are predominantly found in muscle, brain, synaptic cell adhesion proteins, but underrepresented in very basic cellular functions. Over the last years, the important and versatile roles of tandem repeats have been documented by an increasing number of studies. Repeat lengths vary from homorepeats (eg. in the Huntington disease gene) to long repeats with multiple domains (eg. the cytoskeletal protein titin). Functional classification of proteins with tandem repeats suggests that they are often involved in multiple binding, and so facilitate protein-protein interactions and are required for the formation of multi-protein complexes. Protein repeats tend to have structural roles in proteins with fundamental biological functions, including survival facilitation. Antigenic and other virulence related proteins such as toxins and allergens may also be encoded by sequences with repeats. Proteins with tandem repeats are frequently associated with infectious, neurodegenerative diseases. Along this line, the discovery of repeat-containing proteins and their structure-function study promise to be a fertile direction for research leading to the identification of targets for new medicaments and vaccines. The systematic bioinformatics analysis of protein repeats in genomes can provide a global view on these motifs, their structures, functions and evolution. This should facilitate a significant improvement of our understanding of structural and functional changes during the evolution of proteins with repeats and their protein-protein interaction networks.Despite several studies of protein repeats, the fundamental questions about the evolution and roles of repeats are far from being answered. Hardly any previous studies went beyond the classification-type summaries of single repeats and proteins containing them. This project aims to make a major contribution to the understanding of repeat-containing proteins, their structure, function and the dynamics of protein-protein interactions. • The project will assemble the most complete set of protein repeats using a novel algorithm for the identification of repeats that have diverged via substitution and indel events, based on the K-clustering-based approach. Data will be made publicly available through our Protein Repeat DataBase (PRDB). • We will study biological forces shaping the mutational landscape of proteins with repeats. Several purpose-built novel codon substitution models will be developed for this task. For example, using these models we will assess selective forces modulating the number and length of repeats. We will obtain estimates of rates of repeat duplications (and mutations) relative to point mutation. The project will seek to compare and characterize the selective forces acting on the globular and the repetitive parts of the proteins as well as the composition bias, recombination and co-evolutionary forces. PI’s expertise in codon models will be important for the proposed development of novel tailor-made Markov models, which will consequently be used to assess selective forces modulating the number and length of repeats, and the rates of evolution of the globular part vs the periodic part. The developed methods will be implemented in a user-friendly software package and made available to the users.• Complementary information (expression, disease associations, biochemical pathways, etc.) will be assembled for each repeat protein. Together with evolutionary rates and selection estimates, these data will be analyzed using machine learning and pattern discovery techniques. A particular emphasis will be on the trends observed for disease-associated genes. Do the disease genes exhibit unusual evolutionary patterns, selective pressures, expression profiles, etc. compared to genes lacking such associations? Prediction of genes with roles in disease will have invaluable medical applications. • Important examples of disease-related genes will be analyzed in more detail, applying most suitable evolutionary models to the expanded datasets. In particular, codon models that we will develop will be used to evaluate the selective pressure acting on the length of homorepeats during their evolution. These models will assess protein fitness changes as a result of altered numbers of repeats or their lengths. While the conservation is observed in protein coding homorepeats, their length and variability in population is not conserved, suggesting differential selection. The codon models will provide powerful means to evaluate various selection scenarios. Structural modeling techniques will be applied to a set of important proteins (collaboration with Dr Kajava, CRBM-CNRS, Montpellier, France), which will also be studied further using experimental techniques. For the empirical studies we will work in collaboration with biophysicists, experimental biologists and biochemists (Dr Padilla, CBS-CNRS, Montpellier, France).• We will study repeat-containing proteins in pathogenic organisms. Due to their binding properties, proteins with repeats are potential candidate genes influencing the pathogeneicity and disease progression. Indeed, many repeat-containing proteins are expressed on the surface of rapidly evolving pathogens, such as bacteria, viruses that are serious human pathogens or have agricultural or environmental importance. Their antigenic proteins are under strong selective pressure to escape host immune response. A combination of adaptive mutations in such genes may be at the origin of emerging infectious diseases. We will aim to identify the genes and residues that may be used as drug/vaccine targets, essential for controlling and preventing epidemics. Studies of protein with repeats in plant or animal pathogens, are of agricultural and environmental importance. • All assembled data on repeat-containing proteins will be available via mirror web-server. Our database PRDB will be regularly updated, and will incorporate basic tools for categorized searches of repeats, their basic analysis and organization. The goal is to create an integrated data resource for proteins with repeats. Such approach will enable researchers to combine the multitude of available resources and consider them in their integrity. This will facilitate a more efficient and rapid progress in studying structure-function relationship of proteins with tandem repeats and subsequent medical, agricultural and environmental applications. The project will lay a sound foundation for further work on structure of proteins with repeats. The discovery process has high potential and may open new aspects of theoretical biology, molecular evolution, protein structure, and medical related research.	Swiss National Science Foundation	Project funding (Div. I-III)	260278.0	CHF
162	Daniel Wegmann	University of Fribourg	None	2012-10-01	2013-09-30	Coestimating selection and demography	Detecting signatures of past selective events provides insights into the evolutionary history of a species by evidencing adaptive events. The identification of molecular targets of selection in humans, for instance, pinpoints biologically relevant differences between us and other apes. In addition, inferences regarding selection provide important functional information by elucidating the interaction between genotype and phenotype. Since positions in the genome that are under selection are functionally important by definition, detecting signatures of selection has also been used extensively to identify functional regions or protein residues. Finally, inferring the molecular locations at which selection is acting may help us to predict responses to selective pressures in organisms such as viruses, which would revolutionize the management of pandemics and the development of drugs. Unfortunately, the demographic history of a population or species is a major confounding factor when inferring past selective events. Indeed, neutrality tests are very sensitive to violations of the underlying demographic assumption of constant population size - and it is often impossible to distinguish between adaptive or demographic processes in putatively identified regions. After a population bottleneck, for instance, false positive rates of up to 90 % are not uncommon. Current approaches to deal with this problem rely on the assumption that selection is acting on a few loci only, while demography affects all loci equally. A two step procedure has been proposed in which a set of selectively neutral loci are used to calibrate a demographic model against which putatively selected loci are compared. However, recent evidence suggests that selection may be common in the genome of many organisms and a priori knowledge on the neutrality of markers is often difficult to obtain. As a result, this approach suffers from high false negative rates - not to mention relying on very strong assumptions regarding the pervasiveness of adaptive mutations.There is currently no flexible approach to estimate demography and selection jointly. However, recent advances in computational approaches offer new hopes to tackle such an inference. A particularly promising approach is Approximate Bayesian Computation (ABC), a technique to sidestep analytical likelihood calculations with simulations. To this end, ABC has been used to infer a wide range of evolutionary scenarios such as population bottlenecks, population splits and migration, but also to distinguish between a classic selective sweep and recurrent selective events.Here I propose to develop an ABC framework to estimate demography and selection jointly, and to apply it to a variety of organisms with very different evolutionary histories. Major new developments are needed to reach this goal. Firstly, the application of ABC to large scale data sets is tenuous without novel techniques to reduce the computational effort required. I will address this through various innovations including new ABC-MCMC algorithms with increased performance, an efficient recycling of simulations, and extending recent approaches to hybridize ABC with traditional full-likelihood methods. Such a hybridization will enable us to profit from the rich literature on full-likelihood solutions to simpler problems and to take linkage properly into account. Secondly, the joint inference of demography and selection calls for new models and new sets of informative summary statistics. I will approach this challenge by integrating models established to infer either selection or demography alone and through current techniques to explore a large space of summary statistics, such as PLS or machine learning algorithms. The proposed innovations will allow me to work towards answering some of the most controversial questions in evolutionary biology, namely the importance of adaptation in shaping genomic variation. I will approach these questions by inferring genome-wide selection coefficients from unique data sets of four organisms representing various selective and demographic histories: Deer mice (Peromyscus maniculatus), HCM viruses, Drosophila melanogaster and humans. These estimates will not only have broad implications for the management of pandemics or the development of new drugs, but will also greatly improve our understanding of the mode and tempo of the process of adaptation.	Swiss National Science Foundation	Ambizione	214250.0	CHF
163	Daniel Reker	Langer lab Department of Chemical Engineering Massachusetts Institute of Technology	Langer lab Department of Chemical Engineering Massachusetts Institute of Technology	2016-07-01	2017-12-31	Active learning for late-stage drug design	Challenges in solubility, stability, and absorption require formulation development that can significantly delay the introduction of promising drugs to patients. Active machine learning allows for rapid model development by implementing a feedback-driven artificial intelligence that puts the machine in charge of requesting additional data for iteratively improving predictive accuracy. Coupled to novel organ-on-a-chip assay systems, active learning workflows have the potential to transform formulation development and generate in silico models that help streamlining translational drug design. This proposal aims to establish active learning workflows for rapidly generating models for various objectives relevant to formulation development using intestine-on-a-chip systems. In addition to predictive models, such workflows will generate vast amounts of biological data to deepen our understanding of organ-on-a-chip systems as well as provide theoretical insights into the learning patterns of artificial intelligence.	Swiss National Science Foundation	Early Postdoc.Mobility	None	None
164	Emanuela Keller	University of Zurich	Neurochirurgische Intensivstation Neurochirurgische Klinik Universitätsspital Zürich	2017-02-01	2019-01-31	ICU-Cockpit: IT platform for multimodal patient monitoring and therapy support in intensive care and emergency medicine	In neurocritical care, patient monitoring is based not only on standard intensive care monitoring, but also on numerous data obtained from very complex pathophysiological changes in the human brain. The medical staff often cannot integrate the huge amount of clinical data continuously generated by different devices. The amount of available data per patient is enormous (petabyte), and the data are multimodal. Examples are recordings from electrocardiography, artificial ventilation, electroencephalography, hemodynamics, metabolism and video monitoring. The lack of data integration and usability is one of the major reasons why only a small part of the knowledge that physicians use in this field is evidence based. The growth of knowledge in medicine, as well as personalized medicine including genotype data is no longer manageable for physicians alone in daily clinical practice.Machine learning and artificial intelligence, which enable for semi-automatic analysis of these complex and big data, are fundamental tools. Started in 2014, ICU-Cockpit is a joint research project between the University, ETH and IBM Research Zurich, in order to create an integrated platform for patient monitoring and therapy support. A framework based on data analysis, machine learning and modeling will allow for therapy support resulting in a better outcome for patients. ICU Cockpit can trigger a fundamental change in safety culture and standard operating procedures in daily emergency and intensive care medicine as well as telemedicine, and opens up enormous potential for clinical studies and scientific evidence.	Swiss National Science Foundation	NRP 75 Big Data	573853.0	CHF
165	Dr Pedro Ballester Aristin	EMBL - European Bioinformatics Institute	Thornton Group	2010-07-01	2014-06-30	New computational methods for protein function prediction using structural, binding and sequence data	Structural Genomics projects determine a large number of protein structures that have little or no functional information associated with them. Therefore, there is an increasing need for tools to analyse and characterise the possible functional attributes of such structures. The main objective of the proposed research is to investigate, implement and validate new methods for protein function prediction exploiting the fast growing volume of publicly available structural, binding and sequence data. A full suite of protein function prediction tools (ProFunc) based on principles such as having similar sequence, fold or binding sites has been recently developed at the European Bioinformatics Institute (EBI). Experience shows that no single method, either sequence-based or structure-based, provides a high proportion of correct predictions in all cases. Furthermore, methods exploiting binding data are not currently incorporated to this holistic effort. This is in contrast with the imminent availability of StARLite, a medicinal chemistry database containing vast bioactivity data, which constitutes an extremely valuable resource for the development of such methods. In order to fill this gap, a new method for protein function prediction exploiting StARLite binding data will be investigated and ultimately integrated with ProFunc using an automatic consensus protocol. This class of methods are based on the principle that protein binding similar sets of molecules are likely to have similar biochemical function, which means that their effectiveness is limited by our ability to predict protein-ligand binding via docking techniques. The candidate has recently developed a very promising machine learning based improvement to docking. The massive volume of structural and binding data that will be used for machine learning training, allied with the availability CREDO?s detailed characterisation of inter-molecular interactions, means that the methodology will be made even more accurate in the course of the fellowship. The successful outcome of the proposed research will represent a major advance in our ability to predict the biochemical function of new structures from Structural Genomics projects. Also, this investigation is expected to increase our understanding of what combination of structural, binding and sequence features confer biochemical function. Furthermore, the proposed chemogenomics studies will improve drug target validation and polypharmacological drug lead profiling. In addition, improved docking will permit more effective identification of biologically active molecules as a way to reduce expensive and slow empirical High-Throughput Screening. Overall, the widespread application of these methodologies would strongly contribute to the understanding and exploitation of biological systems (e.g. pharmaceutical discovery).	Medical Research Council	Fellowship	400905.0	GBP
166	Nicolas Salamin	University of Lausanne	Département d'Ecologie et d'Evolution Faculté de Biologie et de Médecine Université de Lausanne	2017-04-01	2020-03-31	Efficient and accurate comparative genomics to make sense of high volume low quality data in biology	The amount of biological data that is used to study biological and medical questions is increasing drastically. The advances of genomic technologies enable now many research groups to assemble large scale genomic data for a large spectrum of organisms, and the challenge has now shifted from producing to analysing these large amounts of genomic data.Making sense of all that data relies on comparative genomics to identify the conserved or divergent elements, and elucidate the ones that are associated with essential housekeeping functions and those associated with innovation or adaptation. For instance, an important question is whether a gene has the same function in a model organism such as fly or mouse and in humans. However, this simple question leads to complex methodological issues. Finding the corresponding (“orthologous”) genes in different species is not trivial computationally and is dependent on the quality of the data. Characterizing differences between orthologous genes as functionally relevant or inconsequential is also computationally intensive and dependent on data quality.Because of this complexity, typical comparative genomics approaches tend to focus on few high-quality genomes and to analyse each gene family independently. These analyses, however, fail to capitalize on the increase in available data and ignore interaction (co-evolution) among genes.By contrast, in this project, we aim to develop a comparative genomics approach that leverages the abundant but noisy and heterogeneous data generated, and models coevolution of multiple genes in functional modules such as metabolic pathways. To achieve this, we will: 1) combine high- and low-quality genomic data available, with an emphasis on robustness to data incompleteness and inaccuracies, and scalability to tens of thousands of genomes.2) implement stringent quality controls-via statistical tests, empirical benchmarks, and filters;3) develop efficient machine learning algorithms that can cope with orders of magnitude more data.This approach tackles head-on the “variety”, “veracity”, and “volume” aspects of IBM’s framework of Big Data. Our project also has implications outside biological research. Data curation and homology assessment (WP1) are essential in free text and language analyses, while machine learning approaches for hypothesis prioritization (WP2) is a key element in computer science.	Swiss National Science Foundation	NRP 75 Big Data	573911.0	CHF
167	Professor Ronan Lyons	Swansea University	Institute of Life Science Medical School	2019-10-01	2022-03-31	Application of machine learning to discover new multimorbidity phenotypes associated with poorer outcomes	We will exploit the most deeply phenotyped population e-cohort in the UK, created by HDRUK investment, containing detailed multi-sourced data on a 2.5M population with GP records in Wales from 2000-2020, augmented with demographic, multiple disease registry, hospital inpatient, outpatient data and laboratory results from 2007. No other part of the UK has this depth of records in a stable population with low levels of migration and loss to follow up. Useful algorithms will be adopted by the NHS with tracking of intervention and subsequent impact. Objectives A. complete the most deeply phenotyped population e-cohort in the UK using existing data from the Secure Anonymised Information Linkage (SAIL) system augmented with Census data B. apply innovative machine learning approaches to validate and refine clusters of conditions detected across the adult life course C. use cohort data to identify mechanistic pathways underlying disease combinations D. report on prevalence, social patterning and health inequalities using small area, census, taxation, and household composition data E. identify potential biomarkers predicting individual and multiple morbidities through longitudinal trajectories of values in routinely collected laboratory data F. undertake a comprehensive analysis of variables used in established morbidity/comorbidity indices with multiple correspondence analysis and factor analysis of mixed data to identify clusters G. provide new variables for linkage to the 20,000 Welsh participants in UK Biobank, 7,000 in Airwave and 15,000+ in Healthwise Wales and use algorithms for 40+ cohorts in DPUK for further studies into the genetics of shared mechanistic pathways H. contribute data on incidence, prevalence and burden to the Global Burden of Diseases I. contribute validated algorithms into NHS systems to allow for early NHS adoption, supporting precision medicine and impact measurement	Medical Research Council	Research Grant	563132.0	GBP
168	Philipp Bucher	EPF Lausanne	Institut Suisse de Recherche Expérimentale sur le Cancer EPFL - SV - ISREC	2009-04-01	2013-06-30	Chromatin structure-driven computational analysis of gene regulatory regions	The genetic code for gene regulatory information and the molecular mechanisms of transcriptional control are still poorly understood. The advent of high-throughput technologies to map in vivo DNA-protein complexes, in particular chromatin immunoprecipitation combined with ultrahigh-throughput sequencing (ChIP-Seq) raises new hope for a breakthrough. For the first time it is possible to obtain a comprehensive and detailed view of the chromatin structure of an entire genome in a particular cell type. In addition, we are now able to identify the complete repertoire of in vivo binding sites for a given transcription factor under given conditions. In other words, the molecular events that control gene expression in proximity to the DNA suddenly have become visible. The genome-wide ChIP-Seq datasets that have become available over the last year, already led to numerous new insights about gene regulation. We anticipate that very large volumes of similar data will be released during the course of the proposed project. Computational analysis of ChIP-Seq data is in its infancy. For computational biology, the next few years will probably be remembered as a learning phase during which the community has acquired experience how to make best use of this new type of molecular data. Standard protocols for quality-control and low level data processing will arise. The type of biological questions that can be answered will be better defined and stated in terms amenable to computational approaches. Appropriate data structures for higher level analysis will arise and methodological principles and algorithm will consolidate over time. This proposal is meant to be a contribution to this learning process. The focus is on higher level analysis and interpretation, not on primary data processing. Specifically we are interested in questions concerning the relationship between DNA sequence, chromatin structure, transcriptional activation and repression. A key question in gene regulation, especially with regard to large higher eukaryotic genomes, is why a given transcription factor binds only to a subset of potential target sites in the genome. Much of the proposed work is devoted directly or indirectly to this problem. Histone modification maps based on ChIP-Seq provide clues about DNA accessibility, transcriptional status, and other physiological processes acting on a gene regulatory region. Classification and categorization will help to define subsets of genomic regions that offer similar conditions for transcription factor binding. Information on evolutionary conservation may further direct our analyses to functionally relevant chromatin regions. Comprehensive maps of in vivo transcription factor binding sites provide ideal training and test sets for machine learning approaches that may help to answer the key question of what directs gene regulatory proteins to their physiological target sites. Our research will be mostly biological question-driven in this sense. In addition to methodological advances, we hope that the proposed work will lead to a number of specific and experimentally testable hypotheses regarding chromatin-modulated gene regulatory mechanisms.	Swiss National Science Foundation	Project funding (Div. I-III)	199116.1	CHF
169	Richard Hahnloser	University of Zurich	Institut für Neuroinformatik Universität Zürich Irchel und ETH Zürich	2010-10-01	2014-09-30	The roles of social context and sleep replay for vocal learning in a songbird	Many complex learning behaviors such as speech learning are strongly influenced by factors including social context and sleep. Although many influences are known today, they have mostly been studied in artificial rather than natural settings and are currently supported only by correlative but not by causal evidence. Our work aims at bridging this gap by studying vocal development in the songbird and its dependence on social interactions with conspecific birds and on neural replay of behavioral sequences during sleep. The songbird is a vocal learner in which the brain mechanisms involved in sleep replay are well known. During sleep, premotor neurons of the vocal apparatus in zebra finches engage in bursting patterns that are reminiscent of their patterns generated during song production. In the past, we have performed extensive studies on the generation of such sleep-burst sequences in large song-control networks. We now want to make use of his knowledge and test for a causal relationship between sleep sequences and vocal development. Such a causal relationship has been widely hypothesized but has never been tested experimentally. We plan to implant stimu-lation electrodes into the brain area that generates sleep sequences and perturb downstream sleep bursts to study their effects on vocal changes. Comparisons will be made with birds that are similarly stimulated, but at daytime rather than during sleep. We hope this research will provide one of the first demonstrations that off-line neural activity during sleep has key roles for procedural learning.The social interactions during vocal learning and their influences have not been studied exten-sively yet. In a different set of experiments we will study the social factors that are beneficial or detrimental to vocal learning. It is known that birds with siblings produce less accurate copies of tutor song than birds without siblings, an effect known as a fraternal inhibition. However, the precise factors of this inhibition and the role of the parents in mediating this inhibition are currently not known. To study such effects of social context and many more, we will design and build a bird monitoring system in which several microphones and a video camera jointly operate to record all songs, the locations of the singers, and the locations of the other birds of a family living inside the same cage. This bird-monitoring system is a difficult instrumentation task because jointly tutored birds sing similar songs and often they sing at the same time. Hence, we will apply sophisticated machine-learning techniques to solve this blind-source separation problem. Our bird monitoring system will be fully automated and minimally rely on human input, thus facilitating behavioral experiments and high-throughput data acquisition. We are convinced that this tool will be useful to a large community of birdsong and neuroethology researchers worldwide, because one of the most successful strategies for understanding brain mechanisms is to study them in natural settings rather than in artificial ones. In future experiments beyond this grant application, we will make use of this bird-monitoring system also in electrophysiological experiments, to study brain mechanisms in a natural social context.The broader relevance of our work extends from songbirds to human social sciences and physi-ology, because effects of sibling number and parental interactions influence speech learning also in children. And, the functions of sleep and dreams remain deeply mysterious and any new insights even in animal models will be highly valuable.	Swiss National Science Foundation	Project funding (Div. I-III)	463572.0	CHF
170	Susan Kamal	Institute for Prediction Technology (UCIPT) Department of Family Medicine University of California	Institute for Prediction Technology (UCIPT) Department of Family Medicine University of California	2017-04-01	2017-09-30	Predictive Modeling of cART Medication Adherence and Immuno-virologic outcomes among HIV infected Adults in Lausanne, Switzerland	Advancements in human immunodeficiency tritherapy have allowed patients on treatment to achieve a life expectancy similar to those without the disease. To achieve therapeutic goals, it is important to adhere to treatment regimen. The monitoring of adherence can be done using several methods such as patient reports, pill count and electronic monitoring. Electronic monitoring allows daily monitoring of medication taking through the use of electronic pill boxes (Medication event monitoring systems, MEMS) that store the time and day of opening. This method is used routinely in care at the pharmacy of the Policlinique Medicale Universitaire since 2004. Currently there is medication adherence data for about 500 patients followed at the adherence programme. Few studies have described the erosion of medication adherence over time, but more research is needed to identify the early critical indicators of initial nonadherence signs in HIV. To be able to investigate the effect of medication nonadherence on immune-virologic outcomes, we would like to conduct a predictive modeling analysis of the adherence and clinical data collected retrospectively at our institute in Lausanne. The medication adherence data in Lausanne is very unique as it comprises daily medication intake and interview transcripts with patients about the barriers and facilitators to adherence collected routinely in care of a long period of time (12 years). This predictive modeling will be done using state of the art prediction algorithms combining Big Data Science, statistical modeling, behavioral psychology, clinical and adherence sciences. The the University of California Institute for Prediction Technology (UCIPT) has developed a lot of novel methods for big data science analysis and this joint project will combine unique patient data from the adherence clinic in Lausanne with state of the art predictive machine learning methodology at UCIPT.The analysis of this data can provide unprecedented insights into patient behavior regarding dealing with chronic medication in general, and their struggle to deal with HIV. Consequently, tailored interventions can be developed to prevent nonadherence that can lead to viral failure, and mortality.	Swiss National Science Foundation	Doc.Mobility	None	None
171	Professor Sophia Ananiadou	The University of Manchester	Computer Science	2014-03-31	2017-09-30	Supporting Evidence-based Public Health Interventions using Text Mining	This project will address current limitations in Evidence-based public health (EBPH) interventions by exploring new research methods, beyond the PICO framework, which combine text mining and machine learning to produce novel search while screening tools for public health. The PICO framework is conventionally used to structure pre-defined research questions matching clinical needs, helping to identify the Population, the Intervention, the Comparator and the Outcome. However, it is not well suited to the needs of EBPH reviews such as those conducted by the National Institute for Health and Care Excellence (NICE). PH questions are always complex involving behaviour, culture and organizations and often need to be described using abstract, fuzzy terminology in ways that make defining all the parameters in PICO a priori extremely problematic We will investigate novel approaches to EBPH reviewing based on text mining-based unsupervised methods for the discovery of direct and indirect associations to support a dynamic and multi-dimensional relevance required for public health reviews. In particular, it will build on distributional semantics methods to improve term and document similarity measures by including contextual information in a novel way. Novel descriptive clustering algorithms will be developed that will use these measures to group documents, to analyse their topics to yield meaningful cluster labels and to simultaneously yield high quality document and label clusters. The project will also produce new ranking algorithms to order and visualise meaningful associations in an interactive manner, suitable for EBPH reviewing. A pilot Web-based system providing a quick, interactive way of screening while searching, and visualisation, based on terms, their associations, descriptive clusters, labels and their ranking will form the basis for quantitative and qualitative evaluation for public health reviews related with alcohol misuse and consumption.	Medical Research Council	Research Grant	655668.0	GBP
172	Prof Mark Jenkinson	University of Oxford	None	2019-06-01	2024-05-31	Integrative imaging of brain structure and function in populations and individuals	Neuroimaging enables the mapping of many aspects of the brain’s anatomy, connections, and function. New landmark studies including UK Biobank and the Human Connectome Projects are taking neuroimaging to the scale of populations. Such studies deploy multiple imaging modalities with the aim of learning more about the brain, and identifying imaging markers relevant to neurological disease. However, we cannot currently take full advantage of the richness of these new resources, including: major advances in the quality of data; complementarity of multi-modal imaging; large subject numbers; and linked information about health outcomes, genetics and risk factors. Our vision is to extend the reach of imaging neuroscience. This requires new research across multiple domains: from integrated cross-modal analysis, to more detailed and biologically-interpretable markers, to machine learning. We aim to enable neuroimaging to achieve its full potential, from the modelling of variation in populations to the characterisation of individual subjects. We will deliver powerful modelling approaches and research platforms, continuing our long track record of disseminating software for use by basic and clinical neuroscientists. Further, we will leverage our leadership in big data projects to demonstrate how these approaches and computational tools can advance our understanding of the brain and its diseases.	Wellcome Trust	Collaborative Award in Science	4106203.0	GBP
173	Prof Christian Beckmann	Radboud Universiteit Nijmegen	None	2019-06-01	2024-05-31	Integrative imaging of brain structure and function in populations and individuals	Neuroimaging enables the mapping of many aspects of the brain’s anatomy, connections, and function. New landmark studies including UK Biobank and the Human Connectome Projects are taking neuroimaging to the scale of populations. Such studies deploy multiple imaging modalities with the aim of learning more about the brain, and identifying imaging markers relevant to neurological disease. However, we cannot currently take full advantage of the richness of these new resources, including: major advances in the quality of data; complementarity of multi-modal imaging; large subject numbers; and linked information about health outcomes, genetics and risk factors. Our vision is to extend the reach of imaging neuroscience. This requires new research across multiple domains: from integrated cross-modal analysis, to more detailed and biologically-interpretable markers, to machine learning. We aim to enable neuroimaging to achieve its full potential, from the modelling of variation in populations to the characterisation of individual subjects. We will deliver powerful modelling approaches and research platforms, continuing our long track record of disseminating software for use by basic and clinical neuroscientists. Further, we will leverage our leadership in big data projects to demonstrate how these approaches and computational tools can advance our understanding of the brain and its diseases.	Wellcome Trust	Collaborative Award in Science	4106203.0	GBP
174	Prof Karla Miller	University of Oxford	None	2019-06-01	2024-05-31	Integrative imaging of brain structure and function in populations and individuals	Neuroimaging enables the mapping of many aspects of the brain’s anatomy, connections, and function. New landmark studies including UK Biobank and the Human Connectome Projects are taking neuroimaging to the scale of populations. Such studies deploy multiple imaging modalities with the aim of learning more about the brain, and identifying imaging markers relevant to neurological disease. However, we cannot currently take full advantage of the richness of these new resources, including: major advances in the quality of data; complementarity of multi-modal imaging; large subject numbers; and linked information about health outcomes, genetics and risk factors. Our vision is to extend the reach of imaging neuroscience. This requires new research across multiple domains: from integrated cross-modal analysis, to more detailed and biologically-interpretable markers, to machine learning. We aim to enable neuroimaging to achieve its full potential, from the modelling of variation in populations to the characterisation of individual subjects. We will deliver powerful modelling approaches and research platforms, continuing our long track record of disseminating software for use by basic and clinical neuroscientists. Further, we will leverage our leadership in big data projects to demonstrate how these approaches and computational tools can advance our understanding of the brain and its diseases.	Wellcome Trust	Collaborative Award in Science	4106203.0	GBP
175	Dr. Poirazi	Foundation For Research And Technology - Hellas	None	2012-10-01	2017-10-01	Dissecting the Role of Dendrites in Memory	Understanding the rules and mechanisms underlying memory formation, storage and retrieval is a grand challenge in neuroscience. In light of cumulating evidence regarding non-linear dendritic events (dendritic-spikes, branch strength potentiation, temporal sequence detection etc) together with activity-dependent rewiring of the connection matrix, the classical notion of information storage via Hebbian-like changes in synaptic connections is inadequate. While more recent plasticity theories consider non-linear dendritic properties, a unifying theory of how dendrites are utilized to achieve memory coding, storing and/or retrieval is cruelly missing. Using computational models, we will simulate memory processes in three key brain regions: the hippocampus, the amygdala and the prefrontal cortex. Models will incorporate biologically constrained dendrites and state-of-the-art plasticity rules and will span different levels of abstraction, ranging from detailed biophysical single neurons and circuits to integrate-and-fire networks and abstract theoretical models. Our main goal is to dissect the role of dendrites in information processing and storage across the three different regions by systematically altering their anatomical, biophysical and plasticity properties. Findings will further our understanding of the fundamental computations supported by these structures and how these computations, reinforced by plasticity mechanisms, sub-serve memory formation and associated dysfunctions, thus opening new avenues for hypothesis driven experimentation and development of novel treatments for memory-related diseases. Identification of dendrites as the key processing units across brain regions and complexity levels will lay the foundations for a new era in computational and experimental neuroscience and serve as the basis for groundbreaking advances in the robotics and artificial intelligence fields while also having a large impact on the machine learning community.	European Research Council	Starting Grant	1398000.0	EUR
176	Dr Alex Bottle	Imperial College London	Primary Care And Public Health	2010-09-01	2014-02-28	Can valid and practical risk-prediction or casemix adjustment models, including adjustment for co-morbidity, be generated from English hospital administrative data (Hospital Episode Statistics)?	Using routine NHS hospital admissions data (Hospital Episode Statistics, HES) we aim to derive a series of predictive models for in-hospital mortality, unplanned readmission, unplanned reoperation and non-attendance in outpatients departments. For the last three of these, there is a need to define them in terms of ICD/OPCS codes and time lags so that they will be of most use to the NHS. There will be a focus on the measurement of and adjustment for comorbidity, including an update of the popular Charlson index which we will calibrate for use in the NHS. We will use not just traditional logistic regression but machine learning methods such as artificial neural networks, which have shown promising results with other datasets and are particularly suited to looking for hidden relations between variables. The outcome measures will be specified empirically from the data but with input from clinical and coding experts. These models will be based on national data and will therefore allow us to observe the variation between hospitals in mortality and each of the other outcome measures. This benchmarking will help the NHS and its hospitals drive quality improvement in accordance with the NHS Next Stage Review. At an individual patient level, knowledge of their risk of adverse outcomes such as these aids clinical decision making and informs clinical discussion. The models from this project could be used for both purposes. HES now captures some 60 million OPD appointments each year since 2003/4. The quality of this interesting new resource is uncertain, however. As well as answering the questions concerning optimal time lag and outcomes in non-attenders, this project will afford valuable experience in the use of these data in prediction of non-attendance and health services research in general.	National Institute for Health Research (Department of Health)	Full Grant	400921.33	GBP
177	Dr Richard Edmondson	University of Manchester	None	2016-04-01	2018-03-31	Artificial Intelligence and surgical decision making: an oxymoron or the way ahead	Some patients with ovarian cancer have surgery before chemotherapy whilst others have surgery after chemotherapy. For some, it may be best not to have an operation at all. Deciding the role and timing of surgery for individual patients remains a key clinical question with enormous ramifications for patients and also for the health service. The situation is almost exactly the same for oligometastatic colorectal cancer where the key question remains whether patients should have simultaneous resection of visceral metastases at the time of their initial surgery. It is no surprise that MDT decision making and subsequent practice is non uniform across the UK. Whilst predictive tools are clearly needed, previous attempts to generate these have failed, principally because they have used limited numbers of factors. A successful predictive algorithm is likely to need a combination of patient factors, tumour biology factors and importantly surgeon factors. We believe that the answer lies in using a big data and machine learning approach. Machine learning algorithms underpin many areas of commerce, banking and other areas of daily life but have not yet been utilised in clinical decision making. We propose to extract data that already exist, but are ?hidden? in NHS data silos, into a usable format. We will then use them to develop, train and validate machine learning algorithms, including neural networks that are ideally suited for this purpose, to predict surgical outcome. This project will provide important tools to answer highly relevant clinical questions but perhaps even more importantly will serve as an exemplar and develop the infrastructure to use big data to improve outcomes for patients with cancer.	Cancer Research UK	Pioneer Award Committee - Pioneer Award	None	None
178	Dr. Alexander LEX	Graz University of Technology	None	2013-05-01	2015-08-31	Visual Analysis of Heterogeneous Data using Semantic Subsets	Analyzing and understanding very large and heterogeneous datasets is a fundamental challenge researchers face in many scientific domains. Disciplines such as astronomy, physics and biology have to deal with datasets of an unprecedented scale and complexity. While analyzing these datasets is challenging, they also have the potential to revolutionize our understanding of the underlying processes. To realize this potential, novel analysis approaches have to be developed in all fields of the data sciences. In this proposal for an Erwin Schrödinger fellowship I introduce semantic subsets as a novel method for the visual analysis of large, heterogeneous, and multiple datasets. I propose to leverage machine learning, statistical and other methods to first partition datasets into meaningful subsets, and then use a tight integration of computational and visualization methods to support experts in choosing subsets relevant to a task. These subsets and their relationships are then visualized, facilitating an open, exploratory analysis of the data. The core research challenges addressed in this proposal are how to efficiently and effectively find suitable subsets, manage multiple subsets, and visualize the relationships between them. I argue that this approach is suitable to address the problems posed by the analysis of multiple large and heterogeneous datasets, as it scales well, is highly flexible, and naturally integrates multiple datasets. I intend to develop prototypes realizing the semantic subsets concept for the analysis of biomolecular data in design studies. These applications will be the product of a user-centered design process involving close collaboration with domain experts. The applications will address the domain expert's data analysis problems and aid them in their scientific discovery process. The formal evaluation of the utility of the approach will be conducted using case studies based on longitudinal observations of the deployed applications in addition to controlled user studies. I plan to conduct this research at the Visual Computing Group at Harvard University, lead by Professor Hanspeter Pfister. Professor Pfister and his group have considerable expertise in developing visualization methods for molecular biology. In addition, the greater Boston area is home to many top-tier molecular biology research labs, including the Harvard Medical School and the Broad Institute of MIT and Harvard, to which Professor Pfister and myself have established ties. This environment is therefore uniquely suited to the proposed kind of research. During the planned return phase at the Institute for Computer Graphics and Vision at Graz University of Technology I will not only be able to pass on my gained knowledge to my peers and to students, but will also be able to support Professor Schmalstieg in his agenda of building a strong data visualization group in Graz and thereby strengthen the already sizable Austrian visualization research community.	Austrian Science Fund FWF	Erwin Schrödinger Programme	145130.0	EUR
179	Prof. Ramsey	UNIVERSITAIR MEDISCH CENTRUM UTRECHT	None	2013-08-01	2018-08-01	Intracranial COnnection with Neural Networks for Enabling Communication in Total paralysis	iCONNECT aims to give severely paralyzed people the means to communicate by merely imagining to talk or make hand gestures. Imagining specific movements generates spatiotemporal patterns of neuronal activity in the brain which I intend to record and decode with an intracranial Brain-Computer Interface (BCI) system. Many people suffer from partial or full loss of control over their body due to stroke, disease or trauma, and this will increase with population ageing. With both duration and quality of life beyond 60 increasing in the western world, more and more people will suffer from the consequences of function loss (mostly stroke) with the prospect of living for decades with the handicap, and will stand to benefit from restorative technology that has yet to be developed. I believe that functionality can be restored with brain implants. My goal is to develop a BCI that can interpret activity patterns on the surface of the brain in real-time. For this we need to discover how the brain codes for (imagined) actions, how codes can be captured and decoded and how an intracranial BCI system impacts on a user. I will use state of the art techniques (7 Tesla MRI and electrocorticography, ECoG) to explore brain codes and develop decoding strategies. Interactions between user and implanted device will be studied in paralyzed people. I will directly link decoded movements to animated visual feedback of the same body part, expecting to induce a feeling of ownership of the animation, and thereby a sense of actual movement. This research is only possible because of the latest developments in imaging of human brain activity, machine learning techniques, and micro systems technology. My lab is unique in bringing together all these techniques. Success of the project will lead to deeper understanding of how sensorimotor functions are represented in the human brain. The ability to ?read' the brain will add a new dimension to the field of neural prosthetics.	European Research Council	Advanced Grant	2498829.0	EUR
180	Professor Nicola Minling Low	University of Berne	Institut für Sozial- und Präventivmedizin Universität Bern	2017-11-01	2021-10-31	Zika virus: causality, open science and risks of emerging infectious diseases	BackgroundZika virus infection was established as a cause of congenital abnormalities, including microcephaly, and of Guillain-Barré syndrome during a Public Health Emergency of International Concern that the World Health Organization (WHO) announced in February 2016. The Public Health Emergency ended in November 2016 but substantial gaps remain in the causality framework of Zika complications, knowledge about population level susceptibility to Zika virus infection and the risks of the newly recognised route of sexual transmission of Zika virus. Objectives1. To produce a web platform that will allow the production and updating of living systematic reviews of evidence about Zika virus infection; 2. To estimate key parameters that will allow refined inferences about the sexual transmissibility of Zika virus in endemic and non-endemic settings; 3. To investigate the seroprevalence of antibodies to Zika virus in different geographic settings and to use seroprevalence data to allow estimation of the duration of immunity after Zika virus infection. Methods1. We will produce an open access web application to produce living systematic reviews that allow continual updating of evidence about causal associations between Zika virus and its complications, and emerging research questions. The application will automate searching and deduplication, use text mining and machine learning to assist screening and allow automated updates of review output for rapid publication. 2. We have developed a sexual transmission framework to identify key parameters needed to understand the potential for ongoing spread of Zika virus through sexual transmission. We will analyse data to determine the duration of persistence of Zika virus in semen, vaginal fluid, urine, breast milk and other bodily fluids. We will then use a transmission model to estimate the per sex act probability of Zika virus transmission. 3. We will use data from ongoing longitudinal studies and repeated cross-sectional studies in Nicaragua that will determine antibody levels to Zika virus using new diagnostic tests (taking into account exposure to dengue and chikungunya). We will apply “back-calculation” methods to determine the duration of immunity of Zika virus infection. We will also pilot a method for the collection and assessment of seroprevalence data collected in a range of settings that have experienced new Zika transmission since 2013 and where Zika is presumed to be endemic to improve understanding of population level susceptibility to Zika virus infection.Timeline: The project will last four yearsImportance and impactThis project has considerable importance for research on Zika virus infection and transmission. Whilst vaccine development is advancing rapidly, there are still important gaps in our knowledge about vulnerability to Zika virus in large proportion of the world’s population that lives in areas where Aedes mosquito vectors are distributed. The project objectives are aligned with the research agenda of the WHO and with international initiatives to increase capacity for preparedness for infectious disease pandemics. The outputs are therefore relevant to current research priorities. By working within a culture of open science and with the living systematic review network, our research outputs, including publications and software will be publicly available as quickly as possible.	Swiss National Science Foundation	Project funding (Div. I-III)	700000.0	CHF
181	Dr. Sarel-Jacob FLEISHMAN	WEIZMANN INSTITUTE OF SCIENCE LTD	None	2019-01-01	2023-12-31	Automated computational design of site-targeted repertoires of camelid antibodies	We propose to develop the first high-throughput strategy to design, synthesize, and screen repertoires comprising millions of single-domain camelid antibodies (VHH) that target desired protein surfaces. Each VHH will be individually designed for high stability and target-site affinity. We will leverage recent methods developed by our lab for designing stable, specific, and accurate backbones at interfaces, the advent of massive and affordable custom-DNA oligo synthesis, and machine learning methods to accomplish the following aims: Aim 1: Establish a completely automated computational pipeline that uses Rosetta to design millions of VHHs targeting desired protein surfaces. The variable regions in each design will be encoded in DNA oligo pools, which will be assembled to generate the entire site-targeted repertoire. We will then use high-throughput binding screens followed by deep sequencing to characterize the designs’ target-site affinity and isolate high-affinity binders. Aim 2: Develop an epitope-focusing strategy that designs several variants of a target antigen, each of which encodes dozens of radical surface mutations outside the target site to disrupt potential off-target site binding. The designs will be used to isolate site-targeting binders from repertoires of Aim 1. Each high-throughput screen will provide unprecedented experimental data on target-site affinity in millions of individually designed VHHs. Aim 3: Use machine learning methods to infer combinations of molecular features that distinguish high-affinity binders from non binders. These will be encoded in subsequent designed repertoires, leading to a continuous “learning loop” of methods for high-affinity, site-targeted binding. AutoCAb’s interdisciplinary strategy will thus lead to deeper understanding of and new general methods for designing stable, high-affinity, site-targeted antibodies, potentially revolutionizing binder and inhibitor discovery in basic and applied biomedical research.	European Research Council	Consolidator Grant	2337500.0	EUR
182	Dr. Alexander PETUTSCHNIGG	University of Applied Sciences Salzburg	None	2018-02-01	2021-01-31	TreeTrace - Biometric fingerprints of trees: log tracing from forest to sawmill and early esti	With the increasing amount of imaging devices installed at sawmills, the importance of using these data for improving workflow and for increasing revenues in the wood processing industries is growing. In this context, challenging questions with respect to imaging and image processing technology arise, several of which will be tackled in this joint project. The project considers two application cases as follows: The first application case is the question of tracing tree logs from the forest harvesting site to the sawmill by using biometrics related tree log recognition techniques based on image processing of cross-section data only. This approach of course assumes the additional availability of imaging sensors in the forest. Since there is a trend for installing CT imaging devices at sawmills, which are of course not available in the forest, the challenging issue of cross modality matching arises. The second application case is the determination of wood quality from cross-section imagery, applicable already in the forest, and/or at the sawmill. Obviously, these two application cases share many aspects. (1) They can be combined at application level, i.e. wood quality may be determined already in the forest due to imaging devices available for the tracing application, and further refined using the sensors available at the sawmill. Conversely, CT data from the sawmill, acquired to analyse the wood quality, can be used for the tracing application; (2) data preprocessing and many features extracted are required for both, matching cross section images as well as automated wood quality analysis; (3) the questions which imaging sensors should be employed and how the resulting data can be combined effectively have to be answered. Thus, synergies arise between these two application cases which will be efficiently exploited in the project. A common data set for experimental validation can be used (which implies also sharing employed sensors), ground truth data established wrt. annotating images can be shared, many software components implementing preprocessing (e.g. pith detection, cross section texture segmentation, contrast optimisation) as well as feature extraction techniques (e.g. annual ring detection, spiral growth detection) can be developed jointly and shared subsequently. The project will break new grounds in the area of wood imaging and processing of corresponding data with advanced algorithms in vision and machine learning with particular focus on cross modality processing. While those techniques are being developed for two specific application cases, the developed algorithms will be applicable to a wide range of applications in wood imagery processing and analysis as well as for other domains where similar settings arise.	Austrian Science Fund FWF	None	328573.89	EUR
183	Dr Oliver Zeldin	Diamond Light Source Ltd	None	2015-02-01	2019-01-31	Serial crystallographic studies of radiation sensitive macromolecules.	This proposal outlines a graph-based approach to dealing with the heterogeneous datasets present in serial femtosecond crystallography (SFX). By describing the hundreds to tens of thousands of images in an SFX dataset as the vertices of a graph, and the agreement between pairs of images that share reflections as the edge weights (with no edge between images that have few or zero Miller indices in common), it is possible to refine partialities and merge observations without first averaging all th e images. This opens up exciting new opportunities for sub-population clustering, outlier rejection, and time-resolved methods. Preliminary work where a graph has been created, and the individual image parameters optimized through a graph synchronization procedure has demonstrated the promise of this approach. Many powerful algorithms and machine learning techniques exist for analyzing graphs, and these will be leveraged through close collaboration with members of the Stanford Computer Science D epartment. Biological relevance of the methodology will be kept as a priority throughout by being initially hosted by Dr. Axel Brunger (Molecular and Cellular Physiology), and through collaboration with biology groups and my sponsor, Dr. Dave Stuart.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	250000.0	GBP
184	Prof Wiebke Arlt	University of Birmingham	Clinical and Experimental Medicine	2009-03-01	2012-02-29	Steroid profiling as a biomarker tool in the diagnosis and monitoring of adrenal tumours	Adrenal tumours are common, with a prevalence of 1-2% in the general population. Prevalence increases with age, with 3% of 40-year-olds and 10% of 70-year-olds harbouring an adrenal tumour. In an ageing society and with the increasingly widespread use of abdominal imaging the number of incidentally discovered adrenal tumours is rapidly increasing and represents a huge burden for the health system. Diagnostic work-up of adrenal incidentalomas aims to exclude malignancy and steroid excess, but is currently compromised by a lack of sensitive diagnostic tools. This shortcoming is addressed by this proposal that aims to establish steroid profiling as a biomarker tool in the differential diagnosis of adrenal incidentaloma. Feasibility studies analysing urinary steroid metabolite excretion in 83 benign and 35 malignant adrenal tumours by gas chromatography/mass spectrometry indicate significant differences in steroid excretion, with high androgen and glucocorticoid precursors in malignant tumours. Preliminary analysis indicates a high diagnostic sensitivity and specificity of a distinct subset of steroid metabolites. Based on these data we plan to analyse 24-h urinary steroid excretion in a large cohort of adrenal incidentaloma patients (n=1000) to prospectively evaluate the diagnostic value of this novel biomarker tool. In an important transfer step to implementation of the biomarker tool in routine clinical practice, we will establish liquid chromatography/tandem mass spectrometry (LC/MS/MS) for rapid high throughput measurement of steroid markers identified as most differentiating by biocomputational analysis. The latter will apply machine learning techniques, taking two different but complementary approaches, prototype-based relevance learning and probabilistic Bayesian kernel models. These methods will be utilised to identify discriminative steroids, determine their prognostic and predictive value and develop generative models that could also give mechanistic insights. Recruitment to the study will be facilitated by local, national and international networks including the European Network for the Study of Adrenal Tumours (ENS@T), which already contributed 500 urine samples in 12 months, facilitating preliminary analysis. Clinical data will be stored in a common database format that has been developed, agreed and implemented by ENS@T and that will be made available to all participating centres of the UK Adrenocortical Tumour Network (UK ACT). This proposal links an extensive team of researchers and research facilities across the UK and Europe, generating a unique, interdisciplinary expertise that will ensure the success of this project; results will improve the diagnostic management of a common condition.	Medical Research Council	Research Grant	727149.0	GBP
185	Dr Peter Uhlhaas	University of Glasgow	School of Psychology	2014-07-31	2019-02-28	Using Magnetoencephalography to Investigate Aberrant Neural Synchrony in Prodromal Schizophrenia: A Translational Biomarker Approach	In this project, we will apply state-of-the-art magnetoencephalography (MEG) towards examining neural synchrony in participants at ultra-high-risk (UHR) for the development of schizophrenia (ScZ) with the aim of establishing a diagnostic index. Specifically, we will recruit 100 participants meeting UHR-criteria over a two year period from psychiatric services in Glasgow and Edinburgh as well as from the data base of the Edinburgh High Risk study. Following the initial assessment of UHR-status, monthly mental-state monitoring for the first six-months will be implemented to detect transition to psychosis. After this period, UHR-subjects will receive monitoring assessments every 3 months up to a total of 2 years. MEG-activity will be obtained during a visuo-spatial WM-paradigm as well as during a perceptual task which requires participants to detect a sine-wave grating. In addition, resting-state activity will be measured. Time-frequency representations will be estimated at the sensor and source-level. Moreover, time course of oscillatory activity within a specified frequency band will be investigated for source-connectivity based on a Partial Directed Coherence (PDC) approach and cross-frequency coupling. In addition to MEG-data, we will obtain estimates of GABA and Glutamate levels through proton magnetic resonance spectroscopy (MRS) to examine relationship between neural synchrony and excitatory-inhibition (E/I) balance parameters. MEG, MRS and MRI-measurements will be complimented by detailed psychopathological (CAARMS, SPI-A) and neuropsychological testing. To develop a diagnostic index, we will employ a multivariate machine learning technique towards the development of a biomarker which compares controls, converted and non-converted UHR-participants. This will be informed by our Information theoretic analysis of the different MEG-parameters as well as the complimentary information from neuropsychology, psychopathology and MRS-data.	Medical Research Council	Research Grant	816353.0	GBP
186	Dr William Cawthorn	University of Edinburgh	Centre for Cardiovascular Science	2019-06-30	2022-06-29	Population-level imaging, genomic and phenotypic analyses to determine how bone marrow adiposity impacts human health	Bone marrow adipose tissue (BMAT) accounts for up to 70% of total bone marrow volume and 10% of total fat mass in healthy humans. BMAT further increases with ageing and in diverse clinical conditions, such as osteoporosis, obesity, type 2 diabetes and radiotherapy. Unlike other adipose depots, BMAT also increases in states of caloric restriction, including anorexia nervosa. Thus, BMAT is a major feature of normal anatomy; is distinct to other types of adipose tissue; and is altered in many clinical contexts. However, study of BMAT has been extremely limited, and therefore how BMAT impacts human health and disease remains to be established. This proposal will fill in this critical gap in knowledge by leveraging the power of the UK Biobank (UKBB). Magnetic resonance imaging (MRI) is emerging as a key tool to measure BMAT, but this has never been done on a population level. UKBB is now MRI scanning 100,000 of its participants; hence, using this data, Objective 1 is to measure BMAT of each participant by developing machine learning-based algorithms for automated MRI analysis. Establishing these new automated MRI analysis tools will yield extensive academic, clinical and commercial benefits. Objective 2 is to use GWAS and PheWAS to identify genetic and phenotypic factors associated with altered BMAT. No previous MRI study has analysed BMAT in more than 600 subjects; hence, our population-level BMAT analysis will provide unprecedented power to identify these associations. Finally, Objective 3 is to use Mendelian randomisation in UKBB and other large-scale cohorts to determine if SNPs associated with altered BMAT are causally linked to physiological and pathological outcomes. This will reveal if BMAT directly influences physiological traits and/or the aetiology of diverse diseases. In summary, this work will yield cutting-edge approaches for automated MRI analysis while revealing fundamental new knowledge about the impact of BMAT on human health and disease.	Medical Research Council	Research Grant	550452.0	GBP
187	Dr. Ernö Robert CSETNEK	University of Vienna	None	2017-03-01	2021-02-28	Nonsmooth optimization problems: splitting and dynamics	Many real-life problems can be modeled as structured optimization problems involving both nonsmooth and smooth data. The aim of this project with principal investigator Ernö Robert Csetnek is to deal with nonsmooth convex and nonconvex optimization problems having complex structures, by making use of splitting algorithms. The main feature of these algorithms is that they fully decompose all the objects from the model, which is a very useful aspect from the point of view of providing numerical implementations. The research project follows three objectives. The main focus of the first objective is to investigate the impact of inertial and memory effects on the convergence performances of the primal-dual algorithms designed for solving highly structured convex optimization problems. We intend to analyze the speed of convergence for both, the sequence of iterates generated by the iterative schemes, and the objective function values. In this context the parallelism with monotone inclusions and especially the Attouch-Théra duality will play a significant role. Further, we aim to make use of acceleration techniques in the sense of Nesterov, with the main focus on optimization problems involving compositions with linear operators, going beyond the classical FISTA method designed for minimizing the sum of a (simple) nonsmooth function with a smooth one. The second objective considers nonconvex structured optimization problems for which we aim to formulate suitable splitting methods. In this context, the classical proximal-point and proximal-gradient methods are known to have good convergence properties for minimization problems involving functions with analytic features, namely those which satisfy the Kurdyka-Lojasiewicz inequality. Our main focus will be on nonconvex optimization problems involving composition with linear operators. Further, we aim to make use of inertial and memory effects and to investigate the speed of convergence of the resulting numerical schemes. The third main objective is to investigate optimization problems and monotone inclusions from the continuous perspective. The main focus will be on dynamical systems where time dependent operators/functions are involved. This class of differential inclusions/equations plays a fundamental role, for example, when dealing with sweeping processes. Beyond that, time discretizations of continuous systems serve as a model for numerical schemes. We mention here the generalized Nash equilibrium problem, which can be formulated as a quasi-variational inequality problem and solved by projected-gradient-type algorithms, in the formulation of which moving sets are involved in order to handle the problem properly. The applications we expect range from image processing, with a particular emphasis on the solving of real-life problems dealing with image denoising, image deblurring, image inpainting and image segmentation, to machine learning in connection with support vector classification and support vector regression. Other fields that we have in mind for numerical experiments are optimal portfolio selection, decomposition of video streams, clustering and network communication.	Austrian Science Fund FWF	Stand-Alone Project	313362.0	EUR
188	Mr Chris Barnes	University College London	None	2013-05-01	2018-04-30	A statistical approach to the understanding of mutational processes in the human genome and their impact on evolution, health and disease.	Germline genomic instability is the hypothesis that the architecture of the genome can increase the local mutation rate mostly through homologous regions promoting structural variation (SV) through errors in double strand break (DSB) repair and replication processes. Genomic instability has important consequences for genomic disorders, neuro-degenerative disease and primate evolution. There are three main aims of this research. 1) Develop stochastic models for the different mechanisms of SV for mation and use Approximate Bayesian Computation (ABC) methods to estimate parameters such as relative contributions and length-dependent mutation rates from published datasets. 2) Test the hypothesis that local genome architecture contributes to genomic instability by using a combination of the developed ABC framework and machine-learning methods to relate variant position and mechanism to genomic features. Use this to predict interesting regions of the genome for further study. 3) Examine the effect of genome instability in complex disease (metabolic, cardiovascular and autoimmune), neurodegenerative disease, population differentiation and evolution through collaborative efforts with geneticists and clinicians using both human and great ape sequencing.	Wellcome Trust	Research Career Development Fellowship	774472.0	GBP
189	Dr Grzegorz Kudla	University of Edinburgh	None	2018-04-01	2023-03-31	RNA synthetic biology	As large-scale sequencing projects uncover new variation in the human genome, understanding the consequences of this variation becomes increasingly important. In the next five years, we will use synthetic biology, next-generation sequencing, and computational modelling to study the relationships between gene sequence, expression, structure, and function. We will focus on studies of noncoding RNAs and synonymous mutations in protein-coding genes. We believe that a detailed understanding of genotype-phenotype relations for selected model transcripts will uncover principles applicable to many RNA and protein molecules. Specifically, we aim: 1) To understand the molecular mechanisms underlying an RNA fitness landscape. 2) To understand the effects of codon usage on various stages of gene expression. 3) To develop new applications of genotype-phenotype mapping. In aim 1, we will use yeast U3 snoRNA as a model system to study genotype-phenotype relations. We previously constructed a library of 60,000 mutants of U3 to study the effects of mutations on fitness in wild-type yeast. To study the role of gene-gene interactions, we will express the library in a collection of strains depleted of U3-interacting proteins, and to study gene-environment interactions, we will express the mutants in a range of environmental conditions. We will also develop high-throughput assays to measure the effects of mutations on U3 RNA abundance and RNA-protein interactions. In aim 2, we will use human cell culture models to measure the effects of synonymous mutations on transcription, RNA stability, RNA export and translation. We will then use machine learning to uncover the sequence determinants of expression, and to understand which stages of expression are most strongly influenced by mutations. In collaboration with partners in industry (ThermoFisher) and academia (Laurence Hurst, University of Bath), we will then use our data to develop new strategies for codon optimization. In aim 3, we will collaborate with University of Edinburgh researchers to apply our genotype-phenotype mapping methods to understand human disease mutations. We will focus on mutations in genes relevant to the local research community, encoding a range of transcription factors, hormone receptors, and metabolic enzymes.	Medical Research Council	Unit	1205000.0	GBP
190	Ms. Laura Linnea Maria Elo-Uhlgren	University of Turku	None	2016-06-01	2021-05-31	From longitudinal proteomics to dynamic individualized diagnostics	Longitudinal omics data hold great promise to improve biomarker detection and enable dynamic individualized predictions. Recent technological advances have made proteomics an increasingly attractive option but clinical longitudinal proteomic datasets are still rare and computational tools for their analysis underdeveloped. The objective of this proposal is to create a roadmap to detect clinically feasible protein markers using longitudinal data and effective computational tools. A biomedical focus is on early detection of Type 1 diabetes (T1D). Specific objectives are: 1) Novel biomarker detector using longitudinal data. DynaOmics introduces novel types of multi-level dynamic markers that are undetectable in conventional single-time cross-sectional studies (e.g. within-individual changes in abundance or associations), develops optimization methods for their robust and reproducible detection within and across individuals, and validates their utility in well-defined samples. 2) Individualized disease risk prediction dynamically. DynaOmics develops dynamic individualized predictive models using the multi-level longitudinal proteome features and novel statistical and machine learning methods that have previously not been used in this context, including joint models of longitudinal and time-to-event data, and one-class classification type techniques. 3) Dynamic prediction of T1D. DynaOmics builds a predictive model of dynamic T1D risk to assist early detection of the disease, which is crucial for developing future therapeutic and preventive strategies. T1D typically involves a relatively long symptom-free period before clinical diagnosis but current tools to predict early T1D risk have restricted power. The objectives involve innovative and unconventional approaches and address major unmet challenges in the field, having high potential to open new avenues for diagnosis and treatment of complex diseases and fundamentally novel insights towards precision medicine.	European Research Council	Starting Grant	1499869.0	EUR
191	Ao. Prof. Dr. Peter LACKNER	University of Salzburg	None	2017-07-01	2020-06-30	Structure based prediction of MHC II binding peptides	A key event in immune reactions is the binding of a pathogen derived antigen peptide to a MHC class II molecule. Only the resulting complex binds to the T-Cell receptor and triggers responses against the pathogen. These processes also play a role in allergies and they are associated with different autoimmune diseases such as diabetes or multiple sclerosis. In this respect, the identification of MHC-II binding peptides is a central task in biomedical research. Potential wet lab experiments are time consuming and costly. This constraint has driven the development of computational prediction methods for MHC-II binding peptides. However, to date their accuracy and/or range of applicability is still limited. Sequence-based approaches normally apply machine learning, utilizing sequence data of known binders and non-binders for certain MHC-II allotypes. The accuracy can be rather good, but in general these approaches can only be reliably applied to MHC-II allotypes where sufficient experimental data are available. In contrast, structure based methods operate on known 3D structures of MHC-II molecules and usually employ physical force fields. In general, they do not build on experimental binding data. However, they are yet limited by the number experimentally determined MHC-II structures and lack in prediction accuracy. We here propose a new structure based approach. We hypothesize that the application of statistical scoring functions (SSFs) in combination with information about intrinsic features of the binding peptides such as flexibility or preference for a certain local conformation can considerably improves the prediction accuracy. SSFs have been successfully used in protein structure bioinformatics for many years. Several parameters such as the compilation data set composition, the reference state, and the method for significance estimate calculation restrains the utilization of SSFs for a certain problem. We will investigate the influence of the different parameters on the prediction accuracy. In order to achieve a practical solution, two further points are important. First, the calculation of high-quality structural models for all presently known MHC-II allotypes applying comparative modeling accompanied by exhaustive model assessment. And second, the subsequent reduction of the molecular representation to the main chain, such that a fast threading approach can be applied for binding prediction. This simplified model has the prime advantage that the potential errors in side chain modeling will not obstruct the binder prediction. The final software will be released as standalone program for high throughput predictions and as a web-service for small scale experiments. We further will provide the set of MHC-II models annotated with quality scores and allotype information as a separate database. Finally we intend to use the method in In-house collaborations to design hypo-allergens.	Austrian Science Fund FWF	Stand-Alone Project	203710.5	EUR
192	Dr Danielle Belgrave	Imperial College London	National Heart and Lung Institute	2015-10-01	2018-09-30	Unified probabilistic latent variable modelling strategies to accelerate endotype discovery in longitudinal studies	Aim: To determine a unified probabilistic latent variable modelling strategy for integrating immunological, molecular, biological and clinical phenotypes for endotype discovery in longitudinal studies. Objectives: 1. To build a unified graphical model that represents a broad range of important variables associated with asthma and allergic disease. 2. To use innovative computational statistical latent variable modelling methods to discover novel subtypes of childhood asthma and allergy across multiple cohorts. 3. To extend these graphical models to generate novel insights into a systems modelling framework that is able to upscale in order to integrate clinical data, immunological data, genetic data and epigenetic data. 5. To extend this unified graphical modelling framework to explore principled methods for using probabilistic latent variable models to deal with missing variables in the context where not all variables are available at every time-point. 6. To formally assess the strengths and weakness of Bayesian and Frequentist methods within a longitudinal birth cohort setting. Methods: The proposal will use data from the STELAR consortium for clinical endotype discovery and data from MAAS for extending graphical models to a systems biology framework. Current Bayesian machine learning and classical-statistical probabilistic modelling approaches will be extended to identify latent disease subtypes. Dimensionality reduction techniques will be developed and explored to understand the latent space which best describes high-dimensional clinical and immunological data - considering viral and bacterial stimuli-cytokine responses separately. Scientific and Medical Opportunities: It is hoped that more refined endotype discovery will lead to understanding their underlying biological mechanisms and therefore lead to more targeted treatment and management strategies. This is applicable not just to asthma and allergy, but is generalizable to other diseases.	Medical Research Council	Fellowship	260595.0	GBP
193	Dr Paul Bentley	Imperial College London	None	2015-11-01	2019-04-30	Decision-assist software for management of acute ischaemic stroke using brain-imaging machine-learning	1. We shall acquire a retrospective dataset of clinical and CT data (n~10,000; of which ~1000 SICHs). This step is facilitated by ethical approval being in place; adoption by the NIHR network; collaborations with 11 UK centres to date; and relevant clinical parameters already collected by centres for audit. We have currently acquired 1700 subjects&rsquo; data from 2 centres (Supporting Information 1). We shall additionally acquire ~4000 non-stroke, and follow-up stroke, images, to facilitate automated anomaly detection (of which we have already acquired 1750). Finally, we have agreed in principle to acquire data from the IST-3 thrombolysis trial9 (n=3000), this being comprised exclusively of cases where there was treatment-decision uncertainty, and includes patients not thrombolysed. 2. Images will be pre-processed using an automated, in-house pipe-line of joining, normalization, smoothing, and segmentation, that we have already partly developed (Supporting Information 2). 3. We shall optimize our existing model by exploring CT image features most relevant to SICH/outcome prediction, using a range of machine-learning methods our group are experienced with11. This will involve purely data-driven approaches (e.g. support-vector machines), and hypothesis-assisted methods (e.g. delineation of acute ischaemia extent - this being the strongest currently-recognised imaging predictor of SICH13, yet poorly quantified). Our group have, to date, demonstrated that whole-brain high-dimensional information can be one useful predictor10; used feature-reduction to identify novel imaging patterns that predict SICH; and begun development of an automated anomaly detector (Supporting Information 3,4). Current SICH-predictive methods have validation accuracies of ~65%5,6, whereas our provisional model achieved accuracy of 74%. 4. The optimized model will be validated, and compared with current prognostic scores, e.g. SEDAN, HAT5,6. For this we shall take a cohort of 1000 subjects, from several centres that did not contribute data for model optimization. This step will entail review of scans by three neuroradiologists, since many prognostic scores utilise radiology measures related to size of infarction (ASPECTS score) and middle cerebral artery density. Inter-rater reliability will be ascertained. 5. The model will be incorporated into a user-friendly, clinically-relevant decision-assist tool by a software engineer. The tool will be designed for doctors to input patient data, and combine automatically with CT data on existing CT viewing platforms (PACS). The software will output probability of SICH risk, and good functional outcome, with confidence intervals (Supporting Information 5); and will be compared to those of stroke patients, not receiving tPA, calculated from models based upon thrombolysis trials8,9. This will be displayed in a relevant way for doctors making treatment decisions, and will be transferred schematically to show patients on a tablet. A patient representative will help with the design of these aspects. 6. We shall conduct a prospective feasibility study of the software. We shall install our software in 4-5 collaborating centres, and encourage its use by stroke-clinicians and radiologists to assist thrombolysis-decisions over 10 months. The primary outcome will be rate of thrombolysis. We hypothesise that the software will increase, or at least maintain, thrombolysis rates compared to previous rates in the same centres. Secondary outcomes will be: 1) SICH rate; 2) SICH and outcome predictive accuracy compared to existing scores; 3) speed of thrombolysis decision-making; 4) clinician and patient/family feedback. 7. A sub-study will explore whether incorporation of hyperacute CT-perfusion data, using multimodal machine-learning methods, can enhance SICH and function prediction. We expect to acquire ~1000 CT-perfusion data from our current collaborating centres. Increasing evidence suggests that advanced imaging can enhance prediction of outcomes after thrombolysis14, and estimate time of onset when this is unknown2. Methods developed in the earlier part of the study will be transferred to develop novel, assumption-free analyses of CT-perfusion images.	National Institute for Health Research (Department of Health)	Full Award	525360.0	GBP
194	Univ.Prof. Dr. Immanuel BOMZE	University of Vienna	None	2014-05-01	2019-04-30	Network Optimization in Bioinformatics and Systems Biology	Mathematical models and algorithmic approaches for solving combinatorial optimization problems from the field of network optimization are known to be essential in telecommunications and the design of transportation and supply chain networks. More recently, it has been discovered that network optimization algorithms are also crucial in the context of bioinformatics and systems biology. Numerous publications in systems biology point out that studying functions, structures and interactions of proteins in combination with networks can provide new insights regarding robust biomarkers, can allow new discoveries regarding protein functions, or testing of new hypothesis regarding their interactions. Network optimization algorithms have also been applied in the analysis of functional modules in protein-protein interaction networks, the discovery of regulatory subnetworks, in revealing hidden components in biological processes, or in detecting transcription factor modules. Motivated by these recent developments, we aim to study several network optimization problems that are among the most challenging ones in these fields and that were not sufficiently studied or understood so far. One of them is essential for the analysis of protein-protein interaction networks, and the other one is an innovative way of combining machine learning and network optimization techniques for extracting signaling pathways or building network-driven classifiers. Existing approaches for these benchmark problems in particular are not able to tackle the supernetworks of very large-scale arising in real world. Thus, in this project we aim at developing the first supernetwork-driven approach in combinatorial optimization that will seamlessly integrate various methodologies from operations research (exact and metaheuristic approaches for network optimization) and computer science (machine learning) into a single mathematical framework. To capture important real world characteristics of the problems to be studied, we will thereby combine techniques of combinatorial, robust optimization and bi-objective optimization. In order to ensure that our algorithms will be able to cope with the enormous size of supernetworks, the tools we will develop will rely on decomposition approaches for mixed integer programming, metaheuristics and parallelization techniques. The obtained results will be important contributions to the fields of combinatorial optimization and bioinformatics.	Austrian Science Fund FWF	Stand-Alone Project	347760.0	EUR
195	Dr Romy Lorenz	University of Cambridge	None	2018-09-01	2022-09-01	Fractionating the human frontoparietal cortex: combining meta-analytic and real-time optimization approaches	Disruptions in the same set of frontal and parietal brain regions are seen across a striking range of psychiatric and neurological conditions. This network of regions has been referred to as multiple-demand (MD) system and can be divided into at least two closely coupled subnetworks. However, despite extensive research efforts, the specific functional mechanism each subnetwork supports remains poorly understood using available neuroimaging technology. To overcome these limitations, I have recently developed a novel technique based on real-time neuroimaging and machine learning: Neuroadaptive Bayesian Optimization (NaBO). The key goal of this fellowship is to develop a complementary approach that leverages the strength of large-scale, automated meta-analyses and NaBO to obtain a fine-grained functional mapping between MD subnetworks and the cognitive processes they support. This approach will exploit the wealth of data generated by neuroimaging to date (meta-analysis) for defining a prior model of how cognitive functions relate to MD subnetworks and then refine this model in unprecedented detail (NaBO). The resulting model will be validated using behavioural assessment. Advancing our understanding of these subnetworks in normal brain function is an important first step for developing targeted clinical interventions and informing the design of sensitive diagnostic test batteries.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	250000.0	GBP
196	Dr Bender	University of Cambridge	None	2018-10-01	2021-09-30	Moving the Adverse Outcome Pathways Framework towards Practical Utility by Integrating Compound Profiling Data and Using Deep Learning	Despite a significant investment in in vitro and in vivo screening, clinical safety concerns are still a major cause of compounds being withdrawn from the development process. A lack of mechanistic understanding of safety findings, combined with sparse data sets, restricts the development of approaches capable of predicting earlier potential safety concerns for new chemical entities. It is often unclear whether these are truly surprise events or, with hindsight, could actually have been predicted based on the available data at the time. This failure to detect early signals of safety issues may arise due to problems at the interface between three main components of predictive analysis: observer, data and technology. In this work we propose to employ novel mathematical approaches to data representation and modelling, such as deep learning, of the processes that lead to an adverse outcome in order to reduce or eliminate events of this type. Data will be compiled from within AZ and GSK and shared via Lhasa Limited Ltd, with the student having access to both data sources for model generation. Depending on the adverse event considered, we will either compile AOP frameworks for adverse events, and/or use deep learning approaches for cases where only observational data is available, and hence extend current AOP frameworks where indicated. In particular, nodes in deep networks can be interpreted with respect to their contribution to output toxicity, and hence information for AOPs can be derived from them. The current project will involve GSK and AstraZeneca as industrial partners, with the charity Lhasa Ltd. as an 'honest broker', to exchange and pool compound profiling data for model generation. This framework is currently already being established in the context of the Cambridge Alliance on Medicines Safety (CAMS), and it hence improves significantly upon previous analyses which were based either on public data, or data from only a single source. A pilot study on Structural Cardiotoxicity has already been completed and it is currently being written up for publication, proving the viability and benefit of exchanging data for safety prediction in this framework. We now would like to broaden the approach to other adverse events where data is available. This proposal directly puts into practice recommendations published recently, and it represents an advancement over previous approaches (such as eTox) in being able to have broader access to internal safety data from two major pharmaceutical companies in the UK, AstraZeneca and GSK, shared under confidentiality agreements via a Trusted Broker, Lhasa. This means that all biological data will be made available in the context of the project, including experimental protocols, quantitative data on exposure of compounds, and additional target-based and biological profiling information of compounds can be used in this project. Hence, we expect that the combination of access to data, and the utilization of state-of-the-art machine learning methods, will enhance our ability to predict drug safety and toxicity events considerably. Increasing our understanding of the molecular mechanisms by which compounds can cause adverse events will lead to the implementation of much improved in silico and in vitro screens to detect safety risks will avoid unnecessary investments in preclinical and clinical studies.	National Centre for the Replacement, Refinement and Reduction of Animals in Research	Studentship	90000.0	GBP
197	Professor Fergus Gleeson	Oxford University Hospitals NHS Foundation Trust	None	2017-10-01	2021-09-30	IDEAL: Artificial Intelligence and Big Data for Early Lung Cancer Diagnosis	IDEAL comprises 6 work packages (WP) over 36 months. Each WP has a leader, with Milestones, Tasks (T) and Deliverables (D). See Appendix A for a GANTT chart. WP1: Project Management (M1-M36)(Lead: FG, Involved: VP-DB-MC-SMB, FTE:1.35) The project will be led by FG supported by a Project Manager (PM), who will ensure that the project meets the required quality, time & cost, identify risks, manage spend & provide reports. D1.1. Risk assessment (M1) D1.2. Regular progress reports WP2: Planning for a Big Dataset (M1-M9)(Lead: FG, Involved: LP-MC-DB, FTE:3.75) T2.1. Database Definition (M1) We will define the database architecture to enable selection of data subsets to adaptively re-train a best classifier for the patient demographic/scanner/pathway. Project partners will test the baseline system and decide what annotations will be included, including making the database multi-use (e.g. including COPD annotations). We will define thresholds for minimum acceptable performance. T2.2. Big Data Acquisition and Testing (M2-M9) We will collect >500 patients containing pulmonary nodules (PN) with ground-truth per site (total: 1500). The PN Clinics at three sites see 90 patients per month and have a database of over 1000 patients. The new database will be used to augment pre-existing datasets. The database creation will require an innovative data science approach, so that the thousands of images represent the millions of possible patient, scanner, and protocol combinations. The clinical research fellow and radiographers will collect, annotate and anonymize data. They will iteratively re-train and test the algorithms in collaboration with Optellum, in order to identify nodule types (e.g. sizes, characteristics, clinical pathways) and scan types (scanner model, protocol, kernel, resolution) to be added in order to create a balanced and unbiased set. Milestone 1: Database defined (M1) Milestone 2: Database ready (M9) D2.1. New PN database with 1500 patients WP3: Product Development (M1-M15)(Lead: VP, Involved: LP-SMB, FTE:4.625) T3.1. Machine Learning on Multi-Center Data (M1-M9, FTE:1.5) The evolving database from WP2 will be integrated into a “lean product development” to improve machine learning and guide data acquisition, so that the DIB handles heterogeneous data. Optellum will productize the LVB prototype so that it can be robustly deployed in a hospital setting. T3.2. Front-end Prototype (M1-M3)(FTE:0.5) User interface prototype defined and developed, with frequent Usability Tests with the end users. T3.3. Back-end Prototype(M3-M9)(FTE:0.5) Back-end server ready for PACS integration developed and tested. T3.4. Final Product Development (M10-M15)(FTE:1.5) T3.5. CE-marking (M1-M15)(FTE:0.625) We determine regulatory classification according to CE-MDD. Quality Management System (QMS) will be introduced and user testing conducted with help of consultant from ScreenPoint Medical. We expect to apply for CE-marking in M12. Milestone 3: Prototype ready for clinical study (M9) Milestone 4: CE-marking (M15) D3.1. Full software D3.2. CE-mark WP4: Texture Risk-model (M1-M12)(Lead: FG, Involved: LP-MC-DB-SMB, FTE:1.0) T4.1. Risk-model development. We will develop a risk model for small pulmonary nodules that incorporates texture using retrospective data. Milestone 5: Texture included in risk model (M9) D4.1. Risk model report (M12) WP5: Clinical Study (M9-M33)(Lead FG, Involved: MC-DB, FTE:10.0) T5.1. Prospective clinical study (M9-M33) Research radiographers at the three sites, under the guidance of the clinical research fellow, will assess patients with PN and enter them into the clinical trial and follow them for up to 12 months with established methods (volumetry, PET) compared against the initial DIB score. Milestone 6: Final patient follow up (M33) D5.1. Study results report (M36) WP6: Analysis & Dissemination (M21-M36)(Lead FG, Involved: MC-DB-VP, FTE:1.25) T6.1. NHS dissemination: Results presented at BTS and BSTI meetings. T6.2. International dissemination LVB launched at the 2018 European Congress of Radiology. Milestone 7: Project finished (M36)	National Institute for Health Research (Department of Health)	Full Grant	1425634.0	GBP
198	Dr. Demian WASSERMANN	National Institute for Research in Computer Science and Automatic Control (INRIA)	None	2018-03-01	2023-02-28	Accelerating Neuroscience Research by Unifying Knowledge Representation and Analysis Through a Domain Specific Language	Neuroscience is at an inflection point. The 150-year old cortical specialization paradigm, in which cortical brain areas have a distinct set of functions, is experiencing an unprecedented momentum with over 1000 articles being published every year. However, this paradigm is reaching its limits. Recent studies show that current approaches to atlas brain areas, like relative location, cellular population type, or connectivity, are not enough on their own to characterize a cortical area and its function unequivocally. This hinders the reproducibility and advancement of neuroscience. Neuroscience is thus in dire need of a universal standard to specify neuroanatomy and function: a novel formal language allowing neuroscientists to simultaneously specify tissue characteristics, relative location, known function and connectional topology for the unequivocal identification of a given brain region. The vision of NeuroLang is that a unified formal language for neuroanatomy will boost our understanding of the brain. By defining brain regions, networks, and cognitive tasks through a set of formal criteria, researchers will be able to synthesize and integrate data within and across diverse studies. NeuroLang will accelerate the development of neuroscience by providing a way to evaluate anatomical specificity, test current theories, and develop new hypotheses. NeuroLang will lead to a new generation of computational tools for neuroscience research. In doing so, we will be shedding a novel light onto neurological research and possibly disease treatment and palliative care. Our project complements current developments in large multimodal studies across different databases. This project will bring the power of Domain Specific Languages to neuroscience research, driving the field towards a new paradigm articulating classical neuroanatomy with current statistical and machine learning-based approaches.	European Research Council	Starting Grant	1497045.0	EUR
199	Peter Achermann	University of Zurich	Institut für Pharmakologie und Toxikologie Universität Zürich	2017-11-01	2019-01-31	EEG based microsleep episode detection in the maintenance of wakefulness test and the driving simulator using a machine learning approach	Road traffic injuries are the leading cause of death for those aged 15-29 years. Excessive daytime sleepiness (EDS) is estimated to be the underlying cause in up to 15-20% of motor vehicle accidents (MVA), and is most often caused by socially induced sleep deprivation or poor sleep hygiene in otherwise healthy individuals, followed by medical disorders, or the intake of drugs. Methods for reliably objectifying sleepiness are urgently sought, primarily for sleepiness detection while driving but also for predicting the risk of sleepiness induced accidents during laboratory assessments of patients. The EEG is widely recognized as the gold standard for determining sleep-wake stages and their sudden, as well as gradual, changes. In the clinical and scientific context, standard EEG scoring criteria are generally applied, in which sleep is scored based on 30-s epochs. These sleep criteria consider neither the occurrence of microsleep episodes (MSE) nor the local aspects of sleep demonstrated in both animals and humans. Falling asleep is a gradual, not a sudden, process and shows fluctuations between waking and sleep. Particularly when assessing objective sleepiness in the context of driving ability, MSE of short duration originating in any brain area become an important criterion.We aim to characterize and identify MSE by defining visual scoring rules for MSE as short as 1 s, extracting relevant features based on quantitative EEG analyses, and by developing machine learning algorithms to detect MSE. First, we will only consider occipital EEG leads but will extend our analyses to central EEG leads in a second step. Our algorithms will be trained and verified on MWT data of patients and subsequently applied to MWT data of sleep deprived healthy individuals, and simulated driving conditions. In the driving simulator, we will investigate the association of MSE with impaired driving performance and spontaneously perceived sleepiness (SPS). In the context of fitness to drive assessments, one generally assumes that the perception of sleepiness precedes the occurrence of MSE. Our approach should allow to validate or disprove such an assumption. Previous studies mainly assessed relationships based on mean values or pooled data. Our aim is to take inter-individual variations into account and relate single events (i.e. MSE) with quantitative EEG measures. Therefore, we intend to track the sleep-wake transition zone (e.g. occurrence of MSE, vigilance fluctuations) with high temporal resolution on a second-by-second basis. In summary, we intend to develop and formulate the first standardized MSE scoring rules worldwide and to establish reliable automatic detection algorithms. This will have a major impact in sleep medicine and research and open new areas of research and diagnostic procedures. Since sleepiness is among the most frequent causes of car accidents, and an important risk factor for train and truck drivers and in many surveillance tasks such as air traffic or nuclear power plant control, reliable diagnostic tools to judge fitness to drive or fitness on the job become essential for reducing car and work accidents, catastrophic incidents, and the immense costs related to excessive daytime sleepiness.	Swiss National Science Foundation	Project funding (Div. I-III)	217848.0	CHF
200	Professor Emad Rakha	University of Nottingham	None	2018-10-15	2021-10-14	Intraoperative spectroscopic evaluation of sentinel lymph nodes in breast cancer	The status of the sentinel lymph node (SLN) in invasive breast cancer (BC) influences subsequent management of the axilla. Current modalities for intraoperative detection of SLN either show low sensitivity, consume whole tissue or are time consuming and laborious. Aims This study aims to develop a novel tool for fast intra-operative assessment of SLN using cutting-edge biophotonics (Raman spectroscopy and auto-fluorescence imaging) combined with advanced statistical modelling and machine learning techniques to develop a medical device that can be used in the surgical theatres to assess SLN status. Techniques and Methodology Develop and validate a diagnostic model based on integrated Raman spectroscopy, guided by auto-fluorescence imaging, and machine learning techniques for diagnosis of SLN (target accuracy >95% sensitivity/specificity). Develop an integrated framework for semi-supervised learning to improve the performance of diagnosis in real-time by including data from new patients. Establish the design of a prototype device which will classify a sample within speed and accuracy levels compatible with clinical use: initial target is 10 minutes at 95% diagnosis sensitivity/specificity. Impact on breast cancer research This novel multimodal spectral imaging technique will provide a cost-effective and accurate intraoperative platform for assessment of SLN.	Breast Cancer Now	Project	None	None
201	Ingo Scholtes	University of Zurich	Institut für Informatik Universität Zürich	2018-08-01	2022-07-31	Next-Generation Network Analytics for Time Series Data	Network-based data mining techniques are an important foundation for data science applications in computer science, computational social science, economics and life sciences. They help us to extract knowledge from vast corpora of relational data that capture links or interactions between documents, humans, financial institutions, or genes. However, advances in data sensing and collection increasingly provide us with data that not only tell us who is linked to whom, but also when and in which order these links occur. The analysis of such time series data on networks is still a major challenge. A naive application of network analytic methods discards information on the timing and ordering of links, which however determine the causal topology of dynamic networks. Empirical studies show that this leads to wrong results about the importance of nodes, cluster structures, and dynamical processes. It invalidates applications of current network analytic methods in time series data and limits our understanding of networked systems with dynamic topologies.Filling this gap, my goal as an SNSF professor is to develop a new generation of network analytic methods for time series data on networks. We will take an interdisciplinary perspective that combines stochastic models of time series data with graph analytic, algebraic and information-theoretic methods. It enables us to reach three objectives, namely to (i) develop network analytic techniques for sequential relational data capturing pathways in networks, (ii) extend these techniques to time-stamped data on dynamic networks with high temporal resolution, and (iii) implement a software package for the analysis of time series data on networks.A novelty of our approach is the use of multi-order graphical models, i.e. compact static summarisations of time series data that capture the causal topology of dynamic networks. This will help us to advance the theoretical foundation of data science and network analysis. It will lead to scalable, time-aware methods to find important nodes and detect cluster structures in massive streams of relational data. We validate and test them in time series data on software development teams made available by an industry partner. The final deliverable of our project is an Open Source software implementation of our methods. A collaboration with the Swiss Data Science Center will help us to disseminate it in the Swiss data science community. An international network of experts in network science, bioinformatics, computational epidemiology, computational social science, and machine learning will ensure the interdisciplinary impact of our project.	Swiss National Science Foundation	SNSF Professorships	1516939.0	CHF
202	Dr Mehrdad Alizadeh Mizani	Middle East Technical University	None	2017-11-01	2019-11-01	Developing Novel Approaches To Enhance Privacy Protection In Research Databases	The confidential nature of health data is the main reason for restrictions in access to health data for research. Technical methods are available to de-identify, pseudonymise, anonymise and synthesise health data. The challenge of these techniques is to balance the trade-off between confidentiality and the amount of useful information for research. Additionally, the temporal nature of health data, the sophisticated machine learning methods and the inclusion of unstructured in health information systems, complicate the protection of privacy. In this project, two platforms of the Asthma UK Centre for Applied Research (AUKCAR) will be used for research, namely the UK Asthma Observatory and database of Asthma Research Volunteers in the UK. The aim of this research is to develop methods and approaches to enhance privacy protection, while maximising information content in the application of machine learning algorithms on temporal datasets of structured and unstructured health data.	The Academy of Medical Sciences	Newton International Fellowship	99000.0	GBP
203	Dr. Christian Wagner	Juelich Research Centre	None	2018-01-01	2022-12-31	Controlled Mechanical Manipulation of Molecules	The idea to freely control the atomic-scale structure of matter has intrigued scientists for many decades. The low-temperature scanning probe microscope (LT SPM) has become the instrument of choice for this task since it allows the rearrangement of atoms and molecules on a surface. There is, however, no generic SPM-based method for the manipulation of molecules beyond lateral rearrangement. The goal of this project is to develop controlled mechanical manipulation of molecules (CM3) in which a LT SPM is used to handle large organic molecules in three dimensions with optimal control over position, orientation and shape. CM3 will become a game-changing technique for research on molecular properties and molecular-scale engineering, because it combines fully deterministic manipulation with broad access to molecular degrees of freedom for the first time. In CM3 the tip is attached to a single reactive atom within a molecule. Tip displacement guides the molecule into a desired conformation while the surface provides a second (weaker) fixation. The fundamental challenge addressed by this project is the identification of precise molecular conformations at any time during manipulation. The solution is a big data approach where large batches of automatically recorded SPM manipulation data are structured using machine learning and interpreted by comparison to atomistic simulations. The key idea is a comparison of entire conformation spaces at once, which is robust, even if the theory is not fully quantitative. The obtained map of the conformation space is used to determine molecular conformations during manipulation by methods of control theory. The effectiveness of this approach will be demonstrated in experiments that unambiguously reveal the structure-conductance relation for a series of molecules and that realize the engineering paradigm of piecewise assembly on the molecular scale by constructing a direct current rotor / motor from individual components.	European Research Council	Starting Grant	1465944.0	EUR
204	Dr Caroline Roney	King's College London	Imaging & Biomedical Engineering	2018-10-01	2021-09-30	Predicting Atrial Fibrillation Mechanisms Through Deep Learning	Persistent atrial fibrillation (AF) patients are a heterogeneous population: some patients require multiple procedures, with more extensive ablation strategies; while for others, isolation of the pulmonary veins using ablation (PVI) is sufficient. Identifying persistent AF patients where PVI will be a sufficient treatment remains a clinical challenge, which if solved could lead to improved safety, better patient selection, as well as decreased time and cost for procedures. Biophysical simulations personalised to cardiac imaging and electrical data may offer substantial insights into the mechanisms underlying AF, but run too slowly to be used during clinical procedures. My objective is to develop a combined biophysical simulation and deep learning network pipeline that accurately quantifies the likelihood of success of PVI for an individual patient quickly enough for use during a clinical procedure, to guide ablation therapy. Methodology: We will simulate a virtual patient cohort covering the range of observed electrical and anatomical properties. These biophysical simulations will use the cardiac monodomain equation and the Courtemanche-Ramirez-Nattel atrial cell model, solved on meshes constructed from MRI images, with different fibrosis distributions, and repolarisation and conduction properties. The deep learning convolutional neural network will be trained to large quantities of post-processed data from biophysical simulations to ensure that the network captures the physics and physiology of the system. The training will then be augmented with the complexity and reality of clinical data. Finally, the deep learning pipeline will be tested in a retrospective study. We hope this study will provide insights into the mechanisms sustaining AF. We hope that different research and clinical centres will contribute to and make use of the trained network to predict patient-specific AF mechanisms and PVI ablation outcomes.	Medical Research Council	Fellowship	311169.0	GBP
205	Dr Mikhail Spivakov	MRC London Institute of Medical Sciences	None	2018-07-01	2021-03-31	Functional Gene Control	We are interested in how genomic and epigenetic information is integrated with extrinsic signals to establish functional patterns of gene expression. Our emphasis is on biological phenomena involving concerted changes in phenotype, such as cell differentiation and activation, and on the role of DNA regulatory elements such as enhancers in these processes. We combine experimental approaches (including genome-wide assays of chromatin state, enhancer-promoter contacts and gene expression) with advanced statistical and machine learning techniques to study these questions, focusing on human cells and taking advantage of genetic and epigenetic variation as ‘natural perturbations’ in this system. Our research builds on the foundations of our previous work on promoter-enhancer relationships, organisation of DNA regulatory elements and population genomics. Our goal is to delineate the ‘ground rules’ of gene regulation and, on their basis, generate functional models of gene control networks underlying transcriptional decisions. Interrogation and validation of these models will pinpoint key individual players (genes, DNA regulatory elements, extrinsic signals) and their regulatory relationships, as well as shed light on how they are affected in disease.	Medical Research Council	Unit	None	None
206	Prof. Dr. Heidi NEUBAUER	University of Veterinary Medicine, Vienna	None	2019-06-01	2022-05-31	Novel therapies in JAK/STAT driven T-cell malignancies (JAKSTAT-TARGET)	Mature T-cell leukemias/lymphomas (MaTCL) are hematologic malignancies of mostly incurable prospects in light of limited efficient therapies. As a heterogeneous group of tumors, single MaTCL types are rare, which impedes large-volume biomaterial and data collections and clinical studies. Hyperactivating somatic mutations in JAK/STAT genes stand out as high-incidence aberrations across MaTCL entities. Particularly the model diseases investigated here, T-cell prolymphocytic leukemia (T-PLL) and T-cell large granular lymphocyte leukemia (T-LGLL), carry those in 50-70% of cases. This interdisciplinary JAKSTAT-TARGET consortium of immunologists, hematologists, structural chemists, and systems biologists capitalizes on unique resources such as clinical registry linked sample repositories, new high-fidelity mouse models, pipelines of structure-based target design, and in-silico machine learning tools. We propose that targeting the JAK/STAT signalling network in synergistic combinations with drugs inhibiting inter-connected other key driver pathways will improve individualized anti-leukemic efficacy. We will achieve this by three objectives: O1 will address the causal T-cell-receptor and cytokine mediated impact on genome integrity and on the occurrence of JAK/STAT mutations. It interrogates the biochemical and functional consequences of the mutated and unmutated clones, and derives actionable differential vulnerabilities. O2 will study the performance of identified synergistic drug combinations using in-house developed optimized STAT-inhibitors in novel animal models and primary samples. O3 will implement drug-screen data from patient material into an ongoing clinical trial. Ultimately, with machine learning algorithms we will integrate the harmonized data of genomic profiles, drug-sensitivity patterns, and clinical outcomes from all objectives toward multi-omics guided predictions of optimal choices for trial designs and individual-patient based therapy selection.	Austrian Science Fund FWF	02 International programmes	274900.5	EUR
207	Dr Olesya Ajnakina	King's College London	None	2019-01-01	2023-12-31	Predicting a) risk of onset and of b) psychosis outcomes based on individual genetic and environmental profiles	Introduction: No tools currently exist to reliably predict (a) an individual's risk of developing first episode psychosis (FEP), and (b) psychosis outcomes in the next 5 years. Such tools could improve effectiveness of prevention and treatment strategies by allowing early and timely intervention that is tailored to the appropriate risk level for psychotic conversion as well as prognosis. They will also be of a special interest for school and university counselling services as they will highlight which students are more likely to develop psychosis based on pieces of information about their lives.Aims: To develop appropriate, reliable and accurate predictive models by analysing easily obtainable data about patients' lives using statistical and machine learning methods.Methods: I will utilise for the first-time data that collate data from >20 research sites across Europe and the UK capturing the data from a total of 14,826 patients diagnosed with psychosis, N=13,377 of these have been followed up for 5 years, and N=2,245 controls.Although a number of risk factors have been linked to onset of psychosis and psychosis outcomes (such as childhood adversity, migration, illicit drug use), the magnitude of their effects on an individual person is unknown. To establish this level of individual outcomes, I will utilise robust statistical and machine learning methods, such as Least Absolute Shrinkage and Selection Operator and Elastic Net, which are optimal methods for clinical prediction, personalised medicine and for an understanding of the process. Their significant advantages over the standard method of data analyses are 1) they handle a large number of predictors in relation to sample size; and 2) they address collinearity and overfitting problems (poor prediction of new cases).The performance of my models will be assessed by internal validation methods (calibration and discrimination) using cross-validation and bootstrapping methods. It will be possible to externally validate their prediction in independent samples from a completely different study. I will further estimate the clinical usefulness, the ability to make better decision with a model than without, by conducting utility-based loss of function analyses, such as decision-curves analyses and net-benefit analyses.The risk factors for both developing psychosis and outcomes to be included in my analyses were selected on the basis of (1) patients' perspectives; and (2) current literature.By the end of the project I will have developed simple and validated models for assessing (a), and (b) psychosis outcomes in the next 5 years based on 5 to 10 questions/pieces of information about a person.Implications: These results will be of interest to General Practitioners with expertise in psychosis, school and university counselling services, and specialists in early intervention services. These results should enable better focus of care, and reduce costs associated with treating patients with psychosis. This knowledge of specific risk factors for psychosis onset and poor prognosis will be useful for Public Education as they will enable clearer and better tailored public health campaigns.	National Institute for Health Research (Department of Health)	Full Grant	323879.0	GBP
208	Dr Tobias Goehring	University of Cambridge	MRC Cognition and Brain Sciences Unit	2020-06-12	2025-06-11	Restoring the sense of sound: deep-learning based compensation strategies for the electro-neural transmission of sound by cochlear implants	Over 800,000 severe-to-profound hearing-impaired individuals use a cochlear implant (CI) worldwide. Compromised speech perception in noisy environments is a major problem for CI users and can have a negative impact on their quality of life and mental health. Noise-reduction algorithms, that process the corrupted speech signal before being presented, have produced some benefits for CI users but they still struggle in even moderate levels of noise and there remains considerable variability in the benefits across CI users. I will develop a compensation strategy to overcome the limitations of previous approaches by taking into account CI-specific and user-specific effects. The compensation strategy consists of a computational model to simulate the electro-neural transmission of CIs and a machine-learning algorithm trained to reduce the noise component of a speech-in-noise signal. I will develop the strategy in three stages: (I) by incorporating a computational model of the CI processing, (II) by incorporating a computational model of the electrode-nerve interface and (III) by adjusting these models with user-specific parameters measured with electro-physiological and psycho-physical tests. Each stage will be used to generate training data for a noise-reduction algorithm based on deep recurrent neural networks. Hereby, real-world speech and noise recordings will be processed by the computational model to generate labels for the supervised training of the neural networks. Listening experiments will be performed with CI users to evaluate the strategy and its effect on the perception of speech in noise by measuring speech reception thresholds and quality ratings. If successful, the strategy could be integrated into the external speech processor of a cochlear implant without the need for surgical re-implantation. This CI-specific approach has the potential to overcome the current limitations and to provide benefits for CI users.	Medical Research Council	Fellowship	1025336.0	GBP
209	Dr Isabelle Mareschal	Queen Mary University of London	Sch of Biological and Chemical Sciences	2019-07-01	2022-12-31	Understanding individual differences in facial emotion perception and their association with psychiatric risk indicators	The aim of this project is to understand why atypical processing of emotional facial expressions is associated with many clinical disorders. Although it is well established that atypical processing is associated with increased psychiatric risk, the cognitive basis of atypical processing is not known, and this has prevented progress in diagnosis and treatment. Knowing why some people show atypical processing requires knowing what emotional expressions look like to different people, but technical limitations have previously made it impossible to establish what an emotional expression looks like to an individual. We have now overcome this limitation by combining ground breaking computer graphics techniques and state-of-the-art behavioural methods. The new tools use genetic algorithms that allow individuals to create the facial expressions that they associate with particular emotions. In each iteration of the algorithm, selected characteristics are bred to create a new 'generation' of facial expressions. The process is repeated until convergent on an expression associated with a particular emotion ('happy', 'sad', 'angry'). We propose to use these 'evolved' faces to gain knowledge about emotion expression recognition in typical and high trait populations, thereby improving clinical and pre-clinical studies of emotional processing. We will use the new tools to allow participants to create their own facial expressions. We will then use machine-learning techniques to quantify and characterise the facial configurations created by typical and by individuals with high trait anxiety or psychopathy. We will use these evolved expressions to establish the role of perceptual differences in atypical emotional processing in high trait groups, by using them in conventional clinical and pre-clinical emotional tests instead of standard faces. We will ensure maximum uptake of our toolkit by making it open access, and easy to use.	Medical Research Council	Research Grant	722846.0	GBP
210	Dr Peter Wijeratne	University College London	Computer Science	2019-09-01	2022-08-31	Computational models for clinical trial design in Huntington's disease	A major barrier to successful disease modifying therapy (DMT) development in Huntington's disease (HD) is its biological and phenotypic heterogeneity, which makes it difficult to define suitable biomarkers and inclusion criteria for clinical trials. Recent advances in the fields of machine learning and computational modelling have made it possible to infer patient-specific information from large and varied datasets. Such information has the potential to improve clinical trial design, and hence accelerate the development of a DMT for HD. This project will use a large multi-modal imaging and clinical patient dataset, to: i) construct a baseline array of computational models for patient stratification, using standard statistical and machine learning methods; ii) use more advanced machine learning methods to identify potential disease subtypes and model patient-specific trajectories of key macro-scale biomarkers for early-stage clinical trial design; iii) define subtype-specific models of micro-scale protein dynamics in HD for DMT design. Specifically, this project will develop methods in subtyping, deep probabilistic modelling, and trajectory modelling that have been successfully used in Alzheimer's disease. This project will use the largest combined multi-modal HD dataset - comprised of three separate cohort studies - to evaluate the potential of machine learning techniques in multi-centre studies, which are essential for DMT verification in a rare disease like HD. The proposed framework will naturally extend to Phase 3 trials, and different types of disease, making it a model for next-generation clinical trial design.	Medical Research Council	Fellowship	273137.0	GBP
211	Dr Alexander Oldroyd	University of Manchester	None	2018-08-20	2020-08-19	The Development of a Continuous and Remote Disease Activity Monitoring System in Inflammatory Myopathies to Improve Management and Treatment	Purpose The idiopathic inflammatory myopathies (IIMs) are a group of diseases characterised by muscle inflammation. Clinical decision making is limited by the inability to remotely and continuously measure disease activity. Previous studies have developed smartphone-based apps for patient reported outcome measurement (PROM) entry ("PROM apps"). The muscles of the thighs that allow hip flexion are particularly affected in the IIMs, resulting in predictable changes of gait. Accelerometers incorporated into user-friendly devices can remotely measure gait patterns. Changes of PROMs and gait patterns follow IIM disease activity. Aim This study aims to develop, test and evaluate a novel system that can continuously and remotely measure a patient’s IIM disease activity through daily submission of PROMs and continuous assessment of gait pattern. Study design Stage 1: An IIM patient participant group will inform changes to the initial design and capability of an already designed PROM app template and the proposed use of an accelerometer "patch" system. Stage 2: The system will be trialled in 30-40 participants with an IIM over a 90 day period. Each day participants will be requested to complete a panel of PROMs through the developed PROM app. Participants will also continuously wear an accelerometer patch on the lateral aspect of their thigh for continuous collection of gait data. Stage 3: Analysis will employ machine learning techniques to identify PROM and gait variables associated with changes in disease activity. A novel “disease activity score” algorithm will be developed, which will allow IIM disease activity to be measured (through daily PROM submission and gait pattern analysis) for clinical purposes. Stage 4: The clinical utility of the novel system will be explored through focus groups with IIM-specialist clinicians. Application Patient care will be improved through the ability to remotely identify worsening IIM disease activity, thus preventing irreversible muscle damage and disability.	Versus Arthritis	Clinical Research Fellowship	134818.2	GBP
212	Mihaela Zavolan	University of Basel	Biozentrum der Universität Basel Systembiologie	2009-10-01	2013-03-31	Inference of post-transcriptional regulatory codes involving miRNAs and RNA binding proteins	Although for many years transcription factors held the center stage inthe regulation of gene expression, a very complex post-transcriptionalregulatory layer implemented by miRNAs and RNA-binding proteins andfrequently acting precisely on the mRNAs encoding transcriptionfactors, has been uncovered. Far from passively carrying the geneticinformation to the ribosomal translation machines, messenger RNAs havea life of their own and this can be extended or shortened depending oninteractions with various protein and ribonucleoprotein complexes inthe cell. Although the miRNAs have initially been described asregulators of the mRNA translation rate, it is now clear that animportant mechanism behind the miRNA-based regulation is target mRNAdegradation. The activity of miRNA-containing ribonucleoproteincomplexes can itself be modulated for example by RNA-binding proteins(RBPs) that recognize sites in the vicinity of miRNA-binding sites andact as competitors for miRNA binding.Much effort in the past years has been devoted to identifying newplayers in post-transcriptional control. Many groups, including ourown, contributed to the catalog of miRNA genes in species ranging fromviruses to human. Similarly, many groups, ours included, contributedthrough computational or experimental approaches to the list ofputative miRNA-target interactions. Yet although it is clear that onaverage a miRNA targets hundreds of genes, much remains to be done tounderstand the determinants of miRNA targeting specificity. Based onthe observation that miRNAs destabilize their mRNA targets manyexperimental studies aimed to identify miRNA targets by miRNAtransfection and microarray profiling. In spite of the fact thathundreds to thousands of transcripts respond in a typical experiment,only a fraction of the predicted miRNA targets do. Moreover, forreasons that are so far unclear, the magnitude of the response varieswidely. In a recent analysis of over seventy experimental data sets ofmRNA or protein level changes that occurred upon perturbation of miRNAexpression, we found that functional miRNA target sites reside inaccessible regions, and that the degree of mRNA degradation is relatedto the U (and to some extent A) nucleotide content of the miRNA targetsite environment. This suggests that the fate of miRNA targets dependsnot only on their interaction with the RNA-induced silencing complex(RISC), but also on the presence of modulatory protein co-factors. Incollaboration with the group of Tom Tuschl (The RockefellerUniversity) we have recently identified a number of RBPs that interactwith the RISC complex and we characterized their cognate mRNAs byimmunoprecipitation and microarray expression profiling. We havefurther developed a novel cross-linking and immunoprecipitation methodto identify RBP targets at the resolution of individual bindingsites. Building on this work, we here propose to carry out the following projects:1. Computational modeling of miRNA-target interactions.The starting point of this study will be the set of sequences that we found, with the CLIP method mentioned above, to be bound by Argonaute protein-containing complexes. We will attempt to use machine learning approaches to identify the location of miRNA binding sites in these data and to characterize the mode of binding of miRNAs to their targets. We will also thoroughly characterize the properties of these binding sites and we will use the results to develop improved methods for miRNA target prediction.2. Experimental identification of the targets of U-rich element binding proteins.This project will build on one hand on the experimental method that we developed in collaboration with the group of Tom Tuschl (The Rockefeller University), and on the other hand on our computational results that indicate that U-rich elements are associated with the degradation of miRNA targets. We have selected a set of U-rich element binding proteins whose targets we would like to identify by CLIP, and then study in relationship with the miRNA targets that we already obtained.3. Development of computational models of RBP-mRNA interactions.This projects aims to again use the CLIP data that we have and will obtain in the near future to start developing models to specifically describe RBP-mRNA interactions, taking into account the particularities of this class of proteins. These projects will make an important contribution to a quantitativeunderstanding of miRNA-based post-transcriptional regulation and tothe inference of the elusive 'RNA code'.	Swiss National Science Foundation	Project funding (Div. I-III)	600000.0	CHF
213	Professor Caroline Relton	University of Bristol	None	2018-04-01	2023-03-31	Epigenetic Epidemiology	Background: To maximally exploit the rapid pace of change, including the accrual of large-scale data, in the field of epigenetic epidemiology, we will develop innovative methods for the robust scientific interrogation of population-based epigenetic data and apply them to research questions of scientific and medical importance, structured around four domains: Aim 1: We will explore the genetic architecture of epigenetic traits and use this information to understand the role that DNA methylation variation plays in health and disease. Aim 2: We will develop and make readily accessible the causal analysis methods and tools and apply Mendelian randomization (MR) to epigenetic questions. Aim 3: We will use DNA methylation as an index of past exposures to improve our prediction of disease risk and prognosis. Aim 4: From neurodevelopment to cancer, there are a multitude of settings in which we can apply epigenetic epidemiology to understand disease mechanisms and predict disease. Methods: We will utilize multiple data sources; from in-house studies, via collaborations and consortia, and through publicly accessible repositories. Our primary focus will be on the analysis of DNA methylation, as this continues to be the most readily available source of epigenetic data in population-based studies. However, we will integrate these data with newly generated and publicly available epigenomic and transcriptomic data, tissue-specific data and histone modification data. A wide range of methods will be applied. These include mQTL analysis, functional annotation and machine learning approaches, such as penalized regression, support vector machines, and neural networks. We will test for mediation using MR and apply our prediction methods in disease relevant datasets. Translation: The output arising from this programme will be used to develop biomarkers of disease risk and disease prognosis. It will also shed light on the genetic architecture of DNA methylation and the causal role this molecular phenotype plays in development and disease, which will in turn inform future interventions.	Medical Research Council	Unit	1254000.0	GBP
214	Dr David Howard	University of Edinburgh	None	2019-01-03	2023-01-02	Using multiple data sources to stratify depression and identify more targeted drug treatments	Depression is a heritable disorder with a highly polygenic architecture. Progress in obtaining genome-wide significant findings has been slow, but over the last few years large cohorts have become available and have started to yield valuable insights. I will combine information from these cohorts to uncover the genetic underpinnings of the disorder and develop individual-level risk prediction of depression using polygenic risk scoring. The inclusion of non-genetic risk factors for depression is also likely to further increase accuracy of prediction using multifactorial risk scores. This will also allow me to investigate novel methods for identifying modifiable risk factors for depression. Depression is clinically heterogeneous and comorbid with a range of other health conditions. The derived multifactorial risk scores offer the opportunity to stratify depression into subtypes using machine learning methods. I will analyse the genetic and non-genetic risk factors involved in each depression subtype which will improve our understanding of the underlying biology of each subtype. Gene-set analysis will reveal potential drug repositioning opportunities offering more targeted treatments for patients in each subtype. The efficacy of anti-depressant treatment response for specific subtypes will be estimated using currently available electronic health record linked data.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	300000.0	GBP
215	Mr Emmanuel Mwanga	Ifakara Health Institute	None	2019-07-01	2022-01-01	Using machine-learning and mid-infrared spectroscopy for rapid assessment of blood-feeding histories and parasite infection rates in field-collected malaria mosquitoes	Effective surveillance and control of malaria-transmitting mosquitoes require quantitative understanding of key biological attributes, namely: preferred blood-hosts of the mosquitoes1,2, proportions infected with parasites3, survivorship4,5, indoor/outdoor-biting behaviour5,6 and insecticide susceptibility7. Currently, identifying mosquito blood-meals and Plasmodium infections involve enzyme-linked immunosorbent assays(ELISA)8,9, or polymerase chain reactions(PCR)10,11, which are time-consuming, laborious and require expensive reagents. However, advances in near-infrared spectroscopy (NIR) suggest potential for cheaper, quicker and non-invasive alternatives for predicting age and species of mosquitoes12–15, and detecting pathogens e.g. Wolbachia16 and Zika virus17 in laboratory-infected Aedes. Promisingly, Mid-infrared (MIR) can provide even better accuracies since structural identities of bio-molecules are delineated at finer resolutions than in NIR bands18,19. However, the spectroscopy-based methods have not been field-validated because entomologists lack comparative field samples of known attributes, and advanced computational methods to process large spectral datasets. I propose to couple MIR-spectroscopy with machine-learning algorithms and validate them for rapid-assessment of blood-feeding histories and infectiousness of field-collected Anopheles arabiensis and Anopheles funestus, which dominate malaria transmission in Tanzania3,20. I will calibrate the systems to identify different vertebrate blood-meals in mosquito abdomen, and Plasmodium sporozoite in heads and thoraces. This field-validation will enable scale-up of MIR-based approaches, thereby significantly improving surveillance-responses and intervention monitoring.	Wellcome Trust	International Masters Fellowship	120000.0	GBP
216	CYTOCHROMA LIMITED	CYTOCHROMA LIMITED	None	None	2022-01-01	RAPID: a new test to identify the safety of new drugs and vaccines	Access to medicines and anti-viral vaccines would have significant societal, environmental and economic impacts, both in the short and long term. The current Covid-19 pandemic has highlighted the inefficiency in how novel therapeutics are made and tested. New drug and vaccine development takes on average  >10 years, with costs in excess of 2 and 0.5 billion USD respectively. Latter stage therapeutics failures amount to over 90% in clinical trials, because predicting reactions in humans cannot be determined with current models and tests. Global pandemics are predicted to become more common, and subsequently, there is an increased and immediate need for 1) more accurate preclinical models, and 2) better, predictive tests to identify safety of drugs and vaccines. Cytochroma addresses the first need; by providing physiologically relevant, stem-cell-derived, human models for preclinical testing. We specialise in liver cell manufacture, a tissue that is often damaged and in which testing is required. We propose to address the second need and develop a more efficient method of testing the safety of new drugs and vaccines. This Robust Automated Phenotypic Identification of cell Damage or 'RAPID' test would use observational-based screening. By tagging cells with fluorescent dyes and viewing via a powerful microscope we can visualise how tissues react to drugs and vaccines at a single-cell level. This provides vastly more information than traditional tests and can be combined with machine learning to understand, modify and feedback to directly improve the development of new therapeutics. Cytochroma manufacturers liver models from a unique stem cell bank. These stem cells reflect a diverse genetic background that allows testing of a global population in vitro -- enabling identification of a _universal_ treatment for diseases. Our state-of-the-art technology and robotic based cell production can be easily adapted to tag cells and screen for toxicity on a high- content microscope. This automated approach enhances our capacity and enables us to provide cells at a scale and quality required for testing. These cells and the RAPID test will enable more accurate identification of toxicity, reduce late-stage attrition and accelerate development to make essential drugs and vaccines available faster. Cytochroma is based in Scotland, where over half of all Europe's biosafety is undertaken. The Company is well connected at all levels within the sector and it has strong relationships with several leading Contract Research Organisations and pharmaceutical giants, both of which offer an attractive route to market.	UK Research and Innovation	Research Grant	50000.0	GBP
217	Dr Christan de Goede	Lancashire Teaching Hospitals NHS Foundation Trust	None	2017-12-01	2021-01-31	MyPad – Intelligent Bladder Pre-void Alerting System	Project Description: Iterative development of a comfortable, miniaturised, highly customisable, US-based device which is mounted ergonomically on a child s abdomen wall, to measure the distension of urinary bladder and consequently decides smartly whether to issue an alert to wake the patient (pre-void) during the night. Particularly, this project relates to methods and apparatuses for treating urinary incontinence, suitably by providing pre-void alerts. A patent has been published on our techniques, innovative US processing software and the design of the device [8]. Methodology: Several non-invasive low powered sensors detect changes in the pattern of ultrasound pulses reflected from multiple points of the bladder and related tissue around the bladder in intermittent manner using a skin-interfacing pad, and the acquired information in a data storage unit is transmitted into a processing/computing unit using wireless Bluetooth technology. The discriminant features (detailed in our patent [8]) extracted from this information based on the specific characteristics of urine in the bladder and the bladder itself are then processed by the smartphone computer-implemented Machine Learning (ML) techniques in a parallel software processing to determine the relative fluid level (to at least 50ml) in the bladder. Other sensors such as movement, temperature and moisture measurements are employed to enhance warning performance and self-customising features. Data Collection, Storage & Analysis: i) Acquiring and extracting information from bladder data: Upon collecting A-mode reflected signals obtained via a plurality of transducers interchangeably through skin-interfacing device, the echoes are stored and time stamped in memory and sent to a wireless computing device on real-time for further processing using Bluetooth technology. ii) Acquiring and extracting information from real-time event data: Our intelligent smartphone application where several ML algorithms are working in parallel processing extracts discriminant features from acquired data. iii) Correlating bladder data or information with a status: These features are mapped onto multiple classifiers that have previously been observed, and modulated using different levels of liquid encapsulated within the bladder. The mapping classifiers depicting level of liquid are obtained by applying several ML techniques on detected features, status data and similarities. iv) Triggering alerts: Final bladder status is determined by the weighted average/weighted majority of the plurality of classifiers, and accordingly an alarm type customised for the user is triggered if the level is depicting a trigger point. Design & Safety: The geometry, wearability, and usability and optimisation of the device will be iterated through a reference group comprising children with their families, by taking both sex and different morphology types into consideration throughout the project. For the prototype, software has been designed to decrease the intensity and ultrasound signal exposure time to the minimum. The sonar energy penetrated through the body in intermittent manner will cause no heating risk for the body in line with international guidelines and regulations of related international organisations [7]. Necessary permissions will be obtained from organisations such as NHS National Research Ethics Service (NRES) and National Patient Safety Agency (NPSA). Device Assessment: i) Trial assessments will be performed to verify the basic functionality of the device. When a first functional version of My-PAD is worn by healthy child volunteers over a 12h monitoring period and then, ii) a trial with healthy child volunteers will be performed to assess sensor performance and comfort at night. After obtaining successful results from previous phases, the device iii) will be tested on children with NE. Throughout there will be focused engagement with the trial participants in group sessions and through individual interviews to gain qualitative and quantitative data and iterate the device design and functionality through an EBCD process.	National Institute for Health Research (Department of Health)	Full Grant	477200.0	GBP
218	Dr Marco Caminati	University of St Andrews	Computer Science	2018-02-14	2021-02-13	Stochastic models to enable tailoring of medications to patients with multiple morbidities	We propose to study three common chronic conditions: diabetes, cardiovascular disease and COPD, and their clinical guidelines. In order to find a combination of medications which result in the best outcomes for patients, we need to consider the patient's clinical history, current values and preferences, as well as have a model and treatment information for other patients with similar conditions. For the later, we propose to use Scottish EHRs, specialist disease registry data (e.g., diabetes registry), the national prescribing dataset PIS, and primary and secondary care data in Scotland. This fellowship opportunity will explore combinations of machine learning, formal modelling techniques and automated reasoning approaches commonly used respectively in Theoretical Computer Science and in Artificial Intelligence, to construct (stochastic) models from guidelines and EHRs. This will enable us to compute the optimal medication choices for a patient with one or more chronic conditions, given his/her recorded data and comparisons with similar patients. We will further investigate solutions in the presence of uncertainties and incomplete information. To evaluate the approach, we will develop and test predictive models iteratively using Scottish EHRs and replicate the processes on data from other centres involved in HDR UK, Canada and Brazil.	Medical Research Council	Fellowship	289274.0	GBP
219	Dr Sylvane Desrivieres	King's College London	Social Genetic and Dev Psychiatry Centre	2017-09-01	2019-08-31	Neurobiological underpinning of eating disorders: integrative biopsychosocial longitudinal analyses in adolescents	This project aims to identify early biomarkers of eating disorders (EDs) by applying Big Data methods to the rich database derived from a representative population of adolescents and a clinical sample of emerging adults with an ED diagnosis. First, we will characterise trajectories of ED symptoms in IMAGEN, the largest and most comprehensively characterised longitudinal gene x neuroimaging cohort n=2000 male and female adolescents followed-up at ages 14, 16, 19 and 23 years. We will classify individuals based on their ED symptoms trajectories, using growth mixture models or generalised estimating equations to model the longitudinal course of disordered eating behaviours, including core ED symptoms, a continuous global index of eating pathology and BMI changes. Next, we will use machine learning procedures based on cross-validated regularised logistic regression combining neuroimaging, genomic and psychometric data modalities to identify correlates of EDs and select the features that best classify individuals who endorse ED symptoms along with those who endorse no ED symptoms at any time point. To identify predictors of ED symptoms, we will use age 14 data to compare individuals who developed ED symptoms over time (symptoms absent at age 14 but present at later ages), or those who recovered (symptoms present at age 14, not at later ages) to those who never developed symptoms. Finally, we will select the most predictive and easily applicable components of our comprehensive profile for validation in a clinical sample. This will be patients, aged 18-25 with a 1st episode of DSM-5 AN or BN (n = 50 /diagnosis), assessed through standardised protocols in a way identical to IMAGEN. This paradigmatic multimodal approach, in which neuroimaging may provide added value compared with the existing standard assessments, may yield potential application for early and differential ED diagnoses.	Medical Research Council	Research Grant	230792.0	GBP
220	Professor Aras Kadioglu	University of Liverpool	Institute of Infection and Global Health	2017-07-10	2020-12-31	Mechanisms for acquisition and transmission of successful antibiotic resistant pneumococcal clones pre- and post-vaccination	To understand the molecular mechanisms of emergence, persistence and transmission of antibiotic resistant pneumococci arising before and after the introduction of conjugated polysaccharide vaccines (PCV). To this end, mouse models will be used to study the transmission, colonization and disease capability of antimicrobial resistant pneumococcal lineages. The overall aim being to identify the specific drivers of antibiotic resistant clones and their role in invasive pneumococcal disease and the host immune response in selection and transmission of antibiotic resistant pneumococci.	Medical Research Council	Research Grant	273163.0	GBP
221	Dr Nicholas Meyer	King's College London	Psychosis Studies	2016-10-01	2020-10-31	Detecting early signs of relapse in psychosis using remote monitoring technology	AIM: To investigate the association between disturbances in sleep and circadian rhythm, motor activity, and heart rate variability (predictor variables), and symptomatic deterioration and relapse (outcome variables) in psychosis, using remote monitoring technology (RMT). OBJECTIVES 1) To use RMT to collect predictor and outcome variables in 50 patients with psychosis for up to a year. 2) To evaluate the predictive value and temporal relationship of the bio-signatures for relapse, individually and in combination. 3) To identify evidence for sleep and circadian rhythm disturbance playing a causal role in the development of psychopathology. 4) To gain specific skills in the use and development of RMT in psychiatry, that will allow me to play a role in the future development and evaluation of clinical prediction tools. METHODOLOGY Objective 1: A sample of 50 individuals with psychosis will use the RMT for 12 months. Predictor variables will be gathered using a wrist-worn device and smartphone sensors. Outcome variables are obtained from a twice-weekly, validated smartphone symptom questionnaire, and from fortnightly review of the electronic patient record. Objectives 2 and 3: The strength and temporal association between predictors and outcomes will be modelled using multilevel modelling (continuous symptom fluctuation outcomes) and penalised functional regression (binary relapse outcomes). Additionally, predictive modelling (machine learning) approaches will be used to explore these associations. Objective 4: I will fulfil this training objective through the running of this study, and in visits to project supervisors and collaborators at this and other centres of expertise. SCIENTIFIC AND MEDICAL OPPORTUNITIES Results may have far-reaching implications for the development of a relapse prediction tool for psychosis, and for understanding the relationship between sleep disruption and psychopathology.	Medical Research Council	Fellowship	243384.0	GBP
222	Dr Sach Mukherjee	MRC Biostatistics Unit	None	2014-03-01	2016-11-30	Statistics and machine learning for precision medicine	Our work focuses on the development and application of statistical and machine learning approaches that can exploit molecular and genomic data to assist in directing therapies to patients likely to benefit. Our efforts encompass both (i) direct prediction of therapeutic response and (ii) scalable estimation of molecular networks and dynamics that can shed light on disease mechanisms and heterogeneity, inform prediction of response and help in identifying promising therapeutic opportunities. We work on specific biomedical questions, addressed in collaboration with experimental groups, as well as methodological research in statistics and machine learning motivated by such questions. The potential of computational approaches in medicine is increasingly clear, but the challenges posed by noisy and incomplete data, biological and clinical heterogeneity and complex underlying processes and dynamics remain substantial. Our work is aimed at developing and exploiting statistical methods that can help to surmount some of these challenges. High-dimensional approaches, networks and graphical models and inference for dynamical systems are key methodological themes in much of our work. Two key ongoing projects are: Data-driven characterization of biological networks in cancer. How is the genomic heterogeneity of cancer manifested at the level of biological networks, such as those involved in cell signalling? Do cancers show altered “wiring” due to genomic aberrations? And if so, how? In close collaboration with experimental partners, we are working on both theoretical and applied aspects of these questions. We are also investigating whether protein signalling networks differ by cancer type and how networks can be used to help discover and define cancer subtypes. Finally, we are developing scalable methodologies by which to systematically assess causal network estimation approaches using interventional data. Statistical methods for personalized medicine. We are addressing statistical challenges that arise in the prediction of drug response from multiple high-throughput data types. These challenges include the large number of potential predictors (high-dimensionality), heterogeneity arising from known and unknown disease subtypes, limited number of samples and the need to integrate multiple data types.	Medical Research Council	Unit	None	None
223	Dr Dominic Waithe	University of Oxford	Weatherall Inst of Molecular Medicine	2018-04-01	2021-03-31	Quantitative and Real-Time Image Analysis for Advanced Light Microscopy.	In terms of microscopy analysis, great inroads have been made in terms of impartial and systematic analysis but little has been done to ensure that cells under the microscope are selected impartially. For this project DW will develop algorithms that can statistically quantify and describe cellular appearances utilizing the latest machine learning, computer vision (CV) and signal processing techniques and technologies. DW has in ongoing work investigated the use of CV algorithms in microscopy and has shown very promising results can be achieved by utilizing object detection convolutional neural networks for cellular detection. DW will extend on his use of neural networks for localizing cells (objectives 1-2) and will also develop methods to statistically describe cellular appearance using networks derived from auto-encoders (objective 3), a type of compression network. Neural networks are implemented in several ways, a popular method is to use Tensorflow and DW is an expert in this language. To effectively train neural networks, powerful GPUs are required. Fortunately the WIMM has various computational facilities and DW has access to two powerful GPU equipped servers. For developing CV and real-time analysis approaches to work with camera and detector hardware, DW will work toward developing algorithms that can be embedded in miniaturized electronics (objective 4). The Nvidia Jetson TX2 Developer kit is a resource which allows you to create and develop neural networks and distribute them onto small hardware boards. DW will develop and test this hardware technique with microscopy based hardware and algorithms. For objectives 5 and 6 GPU code will be systematically produced in CUDA and will be made as compatible and distributable as possible. Oxford University has several microscopy software development projects (e.g. in Micron) and it is intended that the software and libraries produced by this project will be made compatible with these other projects.	Medical Research Council	Fellowship	345783.0	GBP
224	Professor Steven Williams	King's College London	Neuroimaging	2012-08-06	2014-07-05	Cerebral Blood Flow Imaging - Towards an Efficient, Automated Assay of Ongoing Pain and its Treatment	Despite our in depth knowledge of the basic mechanisms underlying pain, we still struggle to develop effective new analgesics. This is largely because the development of novel therapies and a clearer understanding of how we process pain are almost wholly reliant on self-reported measures that are inherently subjective. We will address these existing limitations, building upon a neuroimaging protocol recently developed in this laboratory that has demonstrated the central representation of ongoing pain, in both acute and persistent pain states, independently of patient self-report. First, we will validate the robustness of this quantitative, cerebral blood flow (CBF) assay in a new patient cohort, using these new, independent data to train our recently developed, automated machine learning algorithms. These algorithms will discriminate between individuals in pain-free, pre-surgical states, compared to the ongoing pain experienced following third molar surgery. In a second study, we will test this 'pain discrimination' algorithm in the presence and absence of a widely used, generic analgesic, to provide probabilistic discrimination between post-surgical pain response and treatment with analgesia. These methods will enable us to visualise the central effects of both pain and drug uptake as well as their interaction (i.e. analgesia). While focussed here on examining analgesic response in acute post-surgical pain, these methods should translate into the study and treatment of persistent pain. We envisage the development of shorter duration, reduced cost, analgesic trials requiring fewer patients, facilitating more rapid "go/no-go" decision-making.	Medical Research Council	Research Grant	394246.0	GBP
225	Dr David Wright	Queen's University of Belfast	Centre for Public Health	2018-02-14	2021-02-13	Data driven public health approaches for diabetic retinopathy and age-related macular degeneration	This fellowship will focus on the use of EHR and retinal imaging to improve population eye health. Developing novel outcome measures for chronic eye disease: Management of age-related macular degeneration (AMD) requires regular monitoring and rapid treatment if the wet form of the disease develops. Changes in either ocular structures or visual function can signal progression to wet AMD. 3D retinal imaging based on Optical Coherence Tomography can resolve ocular structures in unprecedented detail and QUB researchers have expertise using the latest modalities. However, analytical methods are sub-optimal, especially when attempting to link structural and functional changes. In this project, novel statistical methods will be developed to integrate a large retinal imaging dataset of AMD patients with EHRs of visual function. The aim is to develop meaningful outcome measures of AMD progression for use in clinical trials. Optimising diabetic retinopathy screening: Diabetic retinopathy (DR) is one of the most common causes of sight loss among working-age people in the UK. Those at risk of DR are screened; retinal photographs are taken at regular intervals and images are manually graded for specific pathologies. The aim of this project is to explore the potential of integrating automated image analysis into the Northern Ireland DR screening programme to both target treatment more effectively and reduce costs. A key challenge is predicting DR progression. There may be subtle patterns of retinal changes predicting DR progression that can be detected only by integrating data from many thousands of patients. Using screening images drawn from the NI diabetic eye screening programme (c. 87,000 patients), the fellow will apply the latest deep learning techniques (convolutional neural networks) to detect novel features predictive of DR progression. Performance of the automated methods will be assessed along with the potential for improvements to the screening programme.	Medical Research Council	Fellowship	279158.0	GBP
226	Professor Attila Lorincz	University of London	None	2016-06-01	2019-05-31	Development of a highly accurate DNA methylation classifier for prevalent and incident cervical pre-cancer	Background:Cervical cancer, caused by persistent infection with high risk (hr) HPV affects ~500,000 women globally and causes ~260,000 deaths annually. Although HPV immunisation has been successfully implemented the level of protection expected from current vaccines will be quite substantially incomplete and it will take several decades to see an effect of the new and improved nonavalent vaccine. A pressing need to combat cervical cancer through improved screening remains far into the future. Highly sensitive hrHPV testing is likely to become the dominant primary screen. However, hrHPV infection is common and only a fraction of women are at risk of developing cervical cancer. 40% of hrHPV+ women are cytology negative and triage by proposed adjunctive immunostaining tests such as p16 (often in conjunction with ki67) are insufficient. A molecular test is needed to more accurately identify clinically significant HPV infection. Aims:We aim to develop a DNA methylation (DNAm) biomarker panel that has the potential to be an excellent triage tool for hrHPV+ women and may become an integral part of the primary screening test for preventing cervical cancer.Methods:We propose to measure genome-scale human DNAm as well as DNAm of predefined sites in HPV16, 18, 31 and 33 in a set of 350 hrHPV+ women with normal cytology. This will be the largest such study to date. First, we will measure DNAm with reduced representation bisulfite sequencing followed by machine learning using MS-SPCA to identify ~100 sites which consistently appear in the best ranking models. Then, the best sites will be further sifted by additional multivariate data modelling to provide us with a minimum number of required classifier sites. Finally, these selected sites, presumably 10-20 sites, will be validated in a second set of 200 well characterised cervical samples.How the results of this research will be used:We will develop a significantly improved risk classification tool to triage hrHPV+ women to colposcopy. The new classifier must come close to the high sensitivity of current hrHPV tests (90-95%) but deliver a substantially higher specificity and PPV (both ~70%) than current molecular reflex tests (30-40% and 40-50% respectively). This new algorithm would allow more efficient utilization of colposcopy services while hrHPV+ women negative for the triage classifier could be followed up at suitably frequent intervals to safely catch most, if not all, triage false negatives.	Cancer Research UK	CRC - Biomarker Project Award	None	None
227	Professor Robert Leech	King's College London	Neuroimaging	2018-04-01	2020-09-30	A novel adaptive sampling technique for mapping brain function	Patients with a range of neurological and psychiatric disorders have cognitive impairments associated with abnormal activity and connectivity within fronto-parietal brain networks. Cognitive tasks (performed either behaviourally or in the scanner) that can sub-classify patients based on different types of brain network dysfunction have great potential value in clinical research and assessment. However, achieving this aim is non-trivial. The proposed project will develop and apply a novel neuroadaptive approach for identifying the optimal tasks that differentially engage two important frontoparietal brain networks, with the aim of developing more sensitive cognitive tasks. There are four work packages. WP1, we will use meta-analytic approaches based on the large existing literature of FMRI studies to identify cognitive tasks that form an ordered experimental parameter space. This will be the starting point for optimisation. For demonstration purposes, we will seek to find tasks that differentiate between two important functional networks involved in cognitive control. WP2 will use closed-loop neuroadaptive Bayesian optimisation with real-time functional MRI to find the tasks that maximally dissociate between these two functional brain networks. WP3 will involve a further fine-tuning round of Bayesian optimisation to refine the task parameters of the best candidate cognitive tasks from WP2. WP4 will validate the cognitive tasks behaviourally, using internet-delivered cognitive testing on a large number of participants followed by factor-analysis. The neuroadaptive tools developed in the project and the optimised cognitive tasks will be shared with the research community and form the basis for subsequent clinical translational grant applications.	Medical Research Council	Research Grant	456799.0	GBP
228	Dipl.Ing. Dr. Gerhard KRANNER	Viscovery Software GmbH	None	2018-07-01	2021-06-30	SystemMedicine clinical decision support for COPD patients	Chronic obstructive pulmonary disease (COPD) claimed 3.2 million lives in 2015, making it the third cause of death worldwide. It is predicted to increase in coming years due to aging populations and thus constitutes an enormous socio-economic burden. Existing assessment strategies neglect the complex, multi-component, and heterogeneous pathophysiology, as well as manifold comorbidities (cardiovascular, metabolic etc.). Therefore, improved COPD diagnosis and classification constitutes an urgent medical need for improved and personalized prevention measures and treatments strategies. The main aim of our proposal is to develop a tool that will enable effective preventive measures and personalize treatment strategies for COPD. This transnational and interdisciplinary project combines clinical scientists, experimentalists, computational and systems biology researchers, as well as a medium sized company. We will develop a systems medicine model of COPD constructed on (i) machine learning clustering of two comprehensive patient cohorts (COSYCONET, CIRO) providing long-term clinical observations, systematic outcome evaluation, biomaterial collections, multiple laboratory measurements, and extensive imaging data of more than 6,000 patients, complemented by (ii) an iterative systems biology framework of modeling and experimental analysis. Based on this multi-scale systems medicine model, we will generate a novel Clinical Decision Support (CDS) software that can be implemented in the existing IT infrastructure of hospitals and private practices for routine application. As a prototypic demonstrator of applied systems medicine, our tool will enable i) individual and comprehensive treatment and prevention measures for COPD patients ii) significant reductions of socio-economic costs due to less mortality and disability. iii) novel insights in the dysregulation of metabolism, immunology and aging in COPD from the underlying model.	Austrian Science Fund FWF	None	246692.36	EUR
229	Professor Tony Pridmore	University of Nottingham	School of Computer Science	2018-09-01	2022-08-31	PhenomUK - Crop Phenotyping: from Sensors to Knowledge	PhenomUK is a Technology Touching Life network proposal centred on plant phenotypic technologies. Its primary aim is to foster interdisciplinary research into innovative, and potentially disruptive, technological capabilities that will drive world-leading discovery research in plant and agricultural science. It will do this by bringing together the engineering and physical and life science communities to consider novel technologies and their integration to a degree not achieved by previous projects driven by specific biological hypotheses and objectives. Attention will centre on the combination and integration of existing and emerging phenotyping technologies in three directions: 1. Across phenotyping contexts, to maximise the benefit obtained from the different types of knowledge created by phenotyping 2. Across biological and temporal scales, to produce much richer data streams than are currently available 3. Over time, creating robust phenotyping systems incorporating sensor selection and placement, data acquisition, fusion, analysis and management. This will position the UK to play a leading role in the rapidly developing international phenotyping community and obtain maximum benefit from emerging technologies and the many stand-alone phenotyping tools and data sets developed to date.	Medical Research Council	Research Grant	528567.0	GBP
230	Dr Rune Nyrup	University of Cambridge	None	2018-10-01	2020-03-31	Understanding Medical Black Boxes: A Philosophical Analysis of AI Explainability	I plan during the next two years to develop a major, multi-year project into AI explainability in medical contexts. This project will connect existing literatures in philosophy of science, philosophy of medicine and medical ethics, where problems of understanding and explanation have been extensively studied, to the emerging literature on explainability in machine learning and the ethics of AI. The aim will be (i) to enhance our understanding of the problems AI systems raise for explainability in medical contexts and (ii) to collaborate with machine learning researchers to develop technical research apt to address these problems. The existing literatures on explainability and understanding in medicine are vast and have not previously been systematically connected to the ethics of AI. To lay the groundworks for a later grant proposal, this application proposes to conduct three pilot-studies, focusing on potential challenges from AI to: (1) mechanistic understanding, (2) clinical judgement and diagnostic reasoning and (3) informed consent. A part-time research assistant will assist in scoping the relevant literatures. Travel to groups at other universities and a workshop in Cambridge will furthermore help establish contacts with a network of researchers interested in the ethics of AI and AI explainability in medical contexts.	Wellcome Trust	Seed Award in H&SS	86561.0	GBP
231	Mr Abhishek Mishra	University of Oxford	None	2018-10-01	2021-10-01	Delivering Care Through AI Systems	For this project, I aim to examine 4 issues. First, I will consider whether introducing machine learning (ML) systems requires a revision of the ‘standard of care’ for clinicians, by understanding the moral permissibility of using second-hand information (from ‘black box’ systems) and whether practitioners’ medical expertise justifies judgments about such systems. Second, given the possibility of ML systems systematically underserving groups that are underrepresented in the training data, I will consider accounts of distributive justice to operationalize ‘equal access to care’. Third, to address the disagreements between clinicians on how to trade-off risks in clinical choices, I will catalogue the factual, rational, and moral sources of this disagreement to yield a principled method of evaluating these trade-offs. Finally, I will weigh the potential harms and gains from deploying AI systems in healthcare so that certain ethical and legal arguments don’t deprive society of the good such systems can provide. Key goals: • To represent the ethical concerns in deploying AI systems over the appropriate standard of care, ensuring equal access to care, and representing reasoning about risk trade-offs. • To balance these concerns against the benefits of such a deployment. • To deliver practical ethical guidance to healthcare policy-makers and AI system-builders.	Wellcome Trust	PhD Studentship in H&SS	140538.0	GBP
232	MSc BSc Rafael REISENHOFER	University of Vienna	None	2018-10-15	2020-10-14	Depth and Discriminability in Deep Learning Architectures	Deep neural networks have recently provided astounding results in a wide range of classification and regression tasks. This has sparked a renewed interest in the rigorous mathematical analysis of deep neural network architectures with the goal of uncovering the underlying principles that facilitate their groundbreaking success. Recent fundamental results already provide a better understanding of the relationship between depth and expressive power as well as a detailed analysis of the approximation properties of deep neural networks. It was also shown that certain types of convolutional neural networks exhibit desirable invariance properties such as stability with respect to small deformations. The present proposal aims at a mathematical investigation of another important property of a deep learning architecture, namely its discriminatory behavior. In most classification tasks, different classes are intertwined in a complex manner in the input space. In order to succeed, the realization of a deep neural network needs to disentangle those classes such that they can be separated in the corresponding feature space. Our goal is to better understand how the depth and other characteristics of a neural network influence its discriminatory power in the sense that they facilitate a clear separation of signal classes. Eventually, we aim to prove statements that quantify the discriminative power of a deep learning architecture with respect to distinct classes of signals as a function of depth and properties of the corresponding signals. The classification behavior of a neural network is mostly determined by its invariance properties on one side and its discriminatory properties on the other side. We will thus focus our investigation on a special class of convolutional neural networks, so-called scattering networks, for which substantial results regarding invariance and stability have already been established. We furthermore aim to utilize that when considering the modulus squared as a non-linearity, the output of each layer in a scattering network can be explicitly written as a cascade of autocorrelations in the frequency domain. In the initial phase of the project, we will investigate the discriminatory properties of scattering architectures with respect to simple template signal classes, such as signals that are sparse in the time or frequency domain. We then aim to extend our analysis to signal classes that resemble the structure of practical machine learning tasks in the sense that they are defined by shifts and time-frequency deformations of single prototype signals. Eventually, we aim to translate our theoretical findings into applicable guidelines regarding the optimal design of deep learning architectures for specific classification tasks. The research will primarily be conducted by the applicant (Rafael Reisenhofer) on a full-time basis. The work of the applicant will be supported by the invaluable expertise of the co-applicant (Philipp Grohs).	Austrian Science Fund FWF	None	156140.0	EUR
233	Assoz. Prof. Dr. Klaus SCHÖFFMANN	University of Klagenfurt	None	2018-10-01	2021-09-30	Relevance Detection of Ophthalmic Surgery Videos	In this project, we want to investigate fundamental research questions in the field of postoperative analysis of ophthalmic surgery videos (OSVs). More precisely, three research objectives are covered: (1) Classification of OSV segments - is it possible to improve upon the state-of-the-art in automatic content classification and content segmentation of OSVs, focusing on regular and irregular operation phases? (2) Relevance prediction and relevance-driven compression - how accurately can the relevance of OSV segments be determined automatically for educational, scientific, and documentary purposes (as medical experts would do), and what compression efficiency can be achieved for OSVs when considering relevance as an additional modality? (3) Analysis of common irregularities in OSVs for medical research - we address three quantitative medical research questions related to cataract surgeries, such as: is there a statistically significant difference in duration or complication rate between cataract surgeries showing intraoperative pupil reactions and those showing no such pupil reactions? We plan to perform these investigations using data acquisition, data modelling, video content analysis, statistical analysis, and state-of-the-art machine learning methods - such as content classifiers based on deep learning. The proposed methods will be evaluated on annotated video datasets ("ground truth") created by medical field experts during the project. Beyond developing novel methods for solving the abovementioned research problems, project results are expected to have innovative effects in the emerging interdisciplinary field of automatic video-based analysis of ophthalmic surgeries. In particular, research results of this project will enable efficient permanent video documentation of ophthalmic surgeries, allowing to create OSV datasets relevant for medical education, training, and research. Moreover, archives of relevant OSVs will enable novel postoperative analysis methods for medical research questions - such as causes for irregular operation phases, for example. The research project will be a cooperation between computer scientists of AAU Klagenfurt (conducted by Prof. Klaus Schöffmann, supported and advised by Dr. Mario Taschwer and Prof. Laszlo Böszörmenyi) and ophthalmic surgeons and researchers at Klinikum Klagenfurt (Dr. Doris Putzgruber-Adamitsch, Dr. Stephanie Sarny, Prof. Yosuf El-Shabrawi).	Austrian Science Fund FWF	None	379635.38	EUR
234	Prof Jan Herman VELDINK	UNIVERSITAIR MEDISCH CENTRUM UTRECHT	None	2018-07-01	2023-06-30	Emerging Simplex ORigins In ALS	My aim is to understand the exact genetic contribution in every patient with Amyotrophic Lateral Sclerosis (ALS), a lethal disease with a life time risk of 0.3% and an urgent unmet therapeutic need. I have recently shown a disproportionate large contribution from low-frequency genetic variants in ALS. ALS is not simply a collection of unique rare diseases with a monogenetic cause nor is it a diagnostic continuum with a complex contribution of thousands of small effect factors. ALS is in-between, which I call “simplex”, where in each patient a few, considerably strong genetic factors with or without environmental factors are at play. ALS mutations are characterized by reduced penetrance, variable clinical expressivity, have specific pleiotropic clinical features and interact with environmental factors. These phenomena are unexplained, but provide me with important and new opportunities in order to unravel the clinical, genetic and biological heterogeneity in ALS. I have created new research fields to go an important step beyond the state of the art: Splitting by lumping uses novel machine learning algorithms to reclassify patients using clinical pleiotropic features, environmental factors and blood epigenetic profiles to identify novel ALS mutations. Imaging genomics overlays patterns in ALS-associated brain morphology on MRI with brain gene-expression patterns to find ALS mutations. ALS risk in 3D integrates data on three-dimensional folding of DNA with genetic data to identify causal mutations and mutation-to-mutation interaction. ALS genomic modifiers in 3D identifies modifiers of C9orf72 mutations through the development of cellular reporter assays and CRISPR-Cas9 based screens. Genomic findings are translated using cellular models which can be used for targeted and unbiased drug screens. If successful, my approaches can be applied beyond the scope of this ERC and will have a clear impact on clinical trial design and genetic counselling in ALS in particular.	European Research Council	Consolidator Grant	1980434.0	EUR
235	Professor Daoqiang Zhang	Nanjing University of Aeronautics and Astronautics	None	2018-03-31	2021-02-28	Big-Data Driven Intelligent Analysis of High Dimensional Multimodal Neuroimaging Data and its Application to Brain Disease Diagnosis	Neuroimaging methods based on high dimensional multimodal structural and functional imaging data have been recently proposed for objective diagnosis of brain diseases such as Alzheimer’s disease and autism. However, it is challenging to deal with multimodal data, since 1) multimodal data are typically massive in dimensionality,2) the complete set of Training Programme multimodal data is often unavailable for each subject due to data loss during canning or storage, or due to different study designs in different institutes, and 3) the number of subjects is often much smaller than the dimensionality of the multimodal data. The goal of this project is to develop advanced machine learning methods to address all these challenges in intelligent analysis of multimodal neuroimaging data. Specifically, we will develop a robust ensemble learning method for hierarchical decision fusion from multiple multi-level classifiers, through a layer-by-layer and localˇto-global fashion, to address the first challenge of high dimensionality. Moreover, we will develop a unified framework for novel multi-task semi-supervised (or transfer) learning with multimodal imaging data, to jointly address the second and third challenges of missing data and insufficient training samples, respectively. To our knowledge, the existing neuroimaging analysis methods are not able to deal effectively with these two challenges. Finally, all these proposed methods will be tested and evaluated on real neuroimaging datasets. The overarching aim of this project is to develop, train and transfer news skills to China-PI (Zhang) and his group on 1) efficient analysis of high-dimensional neuroimaging data using current advances and new knowledge in big data analytics and data science, especially in the areas of parallel and distributed computing, data analytics/image pattern recognition; 2) and transferable skills such communication, leadership and project management skills.	The Academy of Medical Sciences	Newton Advanced Fellowship	108000.0	GBP
236	Prof David Murphy	University of Bristol	None	2009-03-09	2012-05-08	Gene networks involved in hypothalamic plasticity in response to dehydration; assessing the in vivo functions of candidate nodal genes.	We have used array technology to comprehensively describe the pattern of gene expression in the hypothalamus, and how this changes following the physiological challenge of dehydration. We now wish to study the functions of key differentially expressed genes in vivo. We have employed a rational and unbiased approach to gene selection. We have utilised machine-learning algorithms to describe a gene network that, we hypothesise, might be involved in regulating and mediating hypothalamic plasticity. Of particular interest are those genes with many connections. Such genes may represent crucial functional hubs, or nodes. We will now test this hypothesis in vivo, focusing on 4 genes with 4 or more connections. We will now determine the functional and regulatory roles of these four key signalling nodes within a hypothetical gene network activated in the SON as a consequence of dehydration. To test this hypothesis we will: - validate the transcriptome data by determining the expression patterns of our candidate genes in the brain, hypothalamus and HNS at both the RNA and protein levels in terms of both specific brain cell-types and responses to dehydration - assess the functions of these genes in basal hypothalamic activity and stress-induced remodelling using in vivo gene manipulation techniques. Three systems will be exploited - knockout transgenic mice, transgenic rats and somatic gene delivery using viral vectors. Gene activity will be manipulated by over-expression of wild-type proteins, or inhibition using RNAi. This will be followed by expression analysis of putative interacting genes, and by robust, but wherever possible, non-invasive, quantification of water balance, vasopressin release, the electrical activity of hypothalamic neurons, and hypothalamic morphology.	Biotechnology and Biological Sciences Research Council	Standard grant	970501.0	GBP
237	Professor Stephen McKenna	University of Dundee	School of Computing	2010-05-01	2011-04-30	Microscopic Image Analysis for Cell Biology	Researchers from Computing will ?hop? discipline to the Life Sciences to initiate collaboration on automated image analysis for cell biology. Requirements for microscopy image analysis have shifted dramatically in recent years as technology developments have enabled higher throughput and higher resolution multi-dimensional, multi-spectral data sets to be routinely acquired, often at multiple scales. Algorithms that automate analysis of cell biology images are crucial as manual annotation of such data is often the rate-limiting step in microscopy workflow. The large data sets generated by high-throughput techniques enable modern machine learning methods to be leveraged: algorithms that scale well to large image data sets in which only relatively small numbers of images are partially annotated. Initial activity will focus on analysis of phenotypes from fluorescence microscopy images of in vivo cell-based assays. Software developed will be integrated and disseminated via the open OMERO project.	Medical Research Council	Research Grant	92895.0	GBP
238	Dr Rodrigo Braga	Imperial College London	None	2014-11-01	2018-10-31	Local functional architecture and individual differences in cognitive and clinical states.	Functional connectivity within and between large-scale brain networks is disrupted in a range of mental disorders. Current network-based explanations of mental disorders have led to ambiguous conclusions, with different clinical conditions being associated with disruption of the same functional networks. My recent work has shown that heteromodal regions of the cortex can be decomposed to reveal a 'local functional architecture' (LFA) of separable subregions with distinct activation timecourses. Exploring this deeper LFA-level could disambiguate the neural basis of a range of mental illnesses. I will develop a novel analysis technique for the study of individual differences in brain activity at the LFA-level. My first goal will be to optimise a group-wise analysis technique I have developed (2,3) for use within individual subjects. I will apply the technique to large fMRI databases to explore to what extent LFA-level features such as subregion size and functional connectivity with ot her brain structures are conserved across the population. I will then use machine-learning techniques to test which LFA features relate to individual variability in a range of cognitive and personality inventories. Having identified candidate LFA features, I will test for group-wise differences in LFA properties in two psychiatric populations, schizophrenia and unipolar depression.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	250000.0	GBP
239	Prof Alison Noble	University of Oxford	None	2016-11-01	2021-10-31	Perception Ultrasound by Learning Sonographic Experience	PULSE will develop a new generation of ultrasound imaging capabilities to revolutionize the use of this low-cost and portable imaging technology across clinical medicine worldwide. The greatest barrier to the universal implementation of ultrasound (US) in clinical medicine today is the need to train sonographers to the highest level to ensure diagnostic images are of consistently high quality and fit for purpose. Unfortunately, the non-expert finds US images very difficult to interpret by eye alone. Perception Ultrasound by Learning Sonographic Experience (PULSE) is an innovative inter-disciplinary project designed to eliminate the need for highly skilled operators of the technology. It is motivated by the observation that sonographers find it easier to interpret their own scans than review those taken by others. The innovation in PULSE is to apply the latest ideas from machine learning and computer vision to build, from real world training video data, computational models that describe how an expert sonographer performs a diagnostic study of a subject from multiple perceptual cues. Novel machine-learning based computational models will be derived based on probe and eye motion tracking, image processing, and knowledge of how to interpret real-world clinical images and videos acquired to a standardised protocol. By building models that more closely mimic how a human makes decisions from US images we believe we will build considerably more powerful assistive interpretation methods than have previously been possible from still US images and videos alone. Software demonstrators will be developed and evaluated on real world obstetric US data in collaboration with clinical experts and novices to demonstrate the new approach and its potential to move routine US scanning services from hospitals into the community which would have clear economic, healthcare and social benefits across Europe and beyond.	European Research Council	Advanced Grant	2462015.0	EUR
240	Thomas Lemmin	ETH Zurich	Departement of Computer Science Systems Group ETH Zürich	2018-02-01	2019-01-31	Spectral analysis of fluorescently labeled amyloids	The self-assembly of prion precursors into oligomers and fibers has been linked to several neurodegenerative and systemic disorders. In particular, the aggregation of Amyloid-ß (Aß), tau and a-synuclein in brain tissue have been associated with the neuropathological process of Alzheimer’s (AD) and Parkinson’s disease (PD). Numerous studies have shown that not only these aggregates can propagate from cell-to-cell in a prion-like manner, but their toxicity and linked pathology strongly depends on their conformations, defining different strains of amyloid. The characterization of the biologically relevant strains remains hard to determine experimentally.To overcome this problem, I propose to implement a computational multicomponent spectral analysis pipeline that will allow to efficiently discriminate amyloid strains. Several fluorescent dyes, such as Congo red and thioflavin, are known to specifically bind to fibrils. Furthermore, their emission spectrum is modulated by the conformation of the fibril. In this project, I will use machine learning to analyze the spectral information of fluorescent microscope image and determine the strains of amyloid. The pipeline developed in this project will allow to characterize the composition of brain aggregates in vitro, in vivo and in brain tissue. Such a method could also greatly aid biophysical studies of amyloids by quickly assessing the quality and composition of samples, as well as give molecular insights linked to the different phenotypes. This understanding should lay the groundwork for the development of effective treatments for AD, PD and other neurodegenerative diseases linked to prions.	Swiss National Science Foundation	Return CH Advanced Postdoc.Mobility	110200.0	CHF
241	Yok-Ai Que	University of Berne	Klinik für Intensivmedizin Departement Klinische Forschung Inselspital	2016-07-01	2019-06-30	In silico prediction of phage-bacteria infection networks as a tool to implement personalized phage therapy	The emergence and rapid dissemination of antibiotic resistance worldwide threatens medical progress. As a consequence, medicine might face a return to the pre-antibiotic era in a very soon future. The paucity of potential new anti-infectives in the pipeline of pharmaceutical industries urges the need for alternatives to fight this public health problem. Phage therapy might represent such an alternative. This re-emerging therapy uses viruses that specifically infect and kill bacteria during their life cycle to reduce/eliminate bacterial load and cure infections. These viruses, called bacteriophages or phages, have been co-evolving with bacteria for billions years, controlling bacterial populations and epidemics, and contributing to their genetic exchanges. With the advantage of having low impact on the commensal flora, as they are highly strain specific, some phages might, nevertheless, harbor virulence factors and drive horizontal gene transfer mediating dissemination of pathogenic traits including antibiotic resistance, calling for their careful selection before their therapeutic use (see below “Phage lifestyle inside the bacteria”). The success of phage therapy mainly relies on the exact matching between both the target pathogenic bacteria and the therapeutic phage. Therefore, having access to a fully characterized phage library is necessary, although not sufficient, to start with phage therapy. An essential and obligate second step to conceive personalized phage therapy treatments is the capacity to predict the interactions between the target pathogen and its potential phage. The long term goal of the proposed research is, therefore, to develop quantitative and predictive in silico models of phage-bacteria infection networks. These models will describe the interactions between phage and bacteria and will serve to fasten the selection of effective phages to propose phage therapy in a personalized fashion.To efficiently predict successful phage-bacteria interactions suitable for phage therapy, we will develop a novel in silico methodology that will, ultimately, enable the selection of phage candidates from an existing phage library to target a given pathogenic bacteria. To achieve this, we will combine genomic information with state-of-the-art bioinformatic and machine learning techniques, taking advantage of the growing amount of interaction data already available as well as of our own data to keep uncovering new phage families. We will ensure that our methodology brings explanatory power along, thereby shedding light on the relevant genomic features underscoring the interactions. To challenge our approach, we will eventually prospectively validate our methodology using paradigmatic pathogens (Pendleton et al. 2013). For this, we will construct the phage-bacterium infection networks around those pathogens, to identify single phages and/or phage cocktails with extended bactericidal activities, as assessed in different models of infections, including a Galleria melonnella model of infection and a rat endocarditis model. We expect our methodology to drive a paradigm shift in phage therapy, by offering a time-sparing and easy-to-use way to accurately select phages for each individual patient. The methodology will be made available online and several future developments of this project are already envisioned.	Swiss National Science Foundation	Interdisciplinary projects	915766.0	CHF
242	Dr Raymond Carragher	University of Strathclyde	Inst of Pharmacy and Biomedical Sci	2018-02-14	2021-02-13	Precision Drug Theraputics: Risk Prediction in Pharmacoepidemiology	The project will develop statistical and machine learning algorithms to analyse NHS datasets to build predictive models to support precision therapeutics focusing on the following two areas: 1) Cancer chemotherapy 2) Cardiovascular therapies HDR UK will provide the data repositories for linkage of established patient cohorts to further phenotypic resources. This will provide deeper phenotyping and should allow more precise prediction algorithms to be developed. Advanced statistical modelling (logistic regression, least absolute shrinkage and selection operator (LASSO) regression, Bayesian modelling) and machine learning approaches (neural nets, deep learning algorithms) will be used as part of this approach. The precision and incremental value of additional datasets will be assessed as will automated approaches to optimising algorithms. Existing research in the use of Bayesian hierarchical point-mass models, based around body-systems, to detect safety signals in clinical trials may be extended for use in observational studies. This approach is designed to use the additional information given by the relationships within and between body-systems in a statistical analysis. The outcomes of the project, in this case the prediction models, will be translated into Clinical Decision Support (CDS) tools which will promote learning health systems. User and usability experience data will be captured during CDS design and development. The output will be a prototype intervention suitable for evaluation through the MRC Complex Intervention Framework to support clinicians in making informed choices and highlighting the risks in the different possible prescribing choices.	Medical Research Council	Fellowship	300445.0	GBP
243	Dr Deepti Gurdasani	Queen Mary University of London	William Harvey Research Institute	2019-08-05	2021-03-25	Predictive analytics of integrated genomic and clinical data using machine learning and complex statistical approaches	Although the utility of complex statistical, machine and deep learning (ML and DL) approaches in the context of multi-dimensional data has been clearly demonstrated, these methods have not been widely utilised to improve novel drug discovery and clinical risk prediction. This proposal aims to harness the potential of large-scale integrated genetic and health data to spur innovation, and develop predictive algorithms to improve clinical decision making and patient health. Specifically, this will focus on the development and evaluation of ML and DL frameworks for GWAS, and clinical risk prediction using publicly available large-scale EHR and genomics biodata resources, including UK Biobank, Genomics England and INTERVAL studies. Transcriptomic and functional data will be integrated into these using predictive approaches, where this has not been directly measured. This will be implemented in three stages: 1) assessment of complex time-dependent statistical approaches for modelling of hazard; 2) optimisation and assessment of existing ML and DL approaches for modelling of clinical risk; 3) development of novel approaches, specifically using recurrent neural networks (RNNs) to incorporate temporality and missingness in clinical data, including time varying covariates to accurately model complex hazard functions; the objective of this project will be to develop approaches that appropriately leverage the rich longitudinal and time-dependent data on individuals shown by us and others to substantially improve clinical risk prediction. In addition to risk prediction, this proposal will also focus on improving our understanding of genetic aetiology of disease. In addition to standard GWAS approaches, hybrid ML and GWAS approaches for prioritisation of candidate genes, and genetic variants associated with disease will also be applied, potentially improving the power to identify novel associations, with important implications for prioritisation of therapeutic targets.	Medical Research Council	Fellowship	177596.0	GBP
244	Dr Yolanda Hill	University of Exeter	Mathematics	2017-11-15	2021-02-17	Cardiac Positioning System (CPS) - An automated navigation system to guide catheter ablation therapy	Background Reentrant waves can form around myocardial infarction scars, potentially resulting in VT. The reentrant pathway can be interrupted by radiofrequency ablation lesions, terminating and preventing VT. Pace mapping is performed to locate the exit site for ablation. Prediction of scar location is guided by an ECG of the clinical VT. Pacing is performed within the scar, and template and paced ECGs are compared. Good correlation indicates pacing from the exit site. The procedure is lengthy, difficult and VT recurrence rates are high. Objectives Regions of scar will be more accurately identified and human error mitigated, in guiding the catheter to the initial pacing site. Coordinates of scar location will be specified with an error boundary extending to cover 12% of the heart (average scar size). Pace mapping accuracy will be increased; given 40 is the average number of pace maps generated per patient, I aim to locate the target by sampling less than 10 maps: an improvement of 75%. Methods A machine learning algorithm will use clinical ECG, patient geometry and medication data for input, with corresponding location of successful ablation, derived from an MRI patient model, as output data. Given input data from newly presenting patients, the algorithm will predict the scar location by tagging the model and registering it with the electroanatomical map. Difference graphs calculated by comparing template and paced ECGs will provide input data for a machine learning algorithm, with corresponding location of successful ablation as output data. Given input data from new patients, the machine learning algorithm will indicate the ablation target. Research Outputs A software product will be produced and integrated into the CARTO mapping system for clinical use to improve ablation therapy success rates. IPR will be obtained and product information disseminated to clinicians via journals and conferences such as the European Heart Rhythm Association.	Medical Research Council	Fellowship	264230.0	GBP
245	Dr Laura Johnson	University of Bristol	Sch for Policy Studies	2019-12-31	2021-12-30	Innovating behaviour and health surveillance for cardiovascular disease prevention in Malaysia	We propose a combination of new data collection, secondary analysis of SEACO cohort data, metabolic analysis of blood and urine samples, methodological innovation using urinary biomarkers and wearable sensors to measure diet and physical activity. We will generate detailed data on diet, physical activity and intermediate cardiometabolic risk factors from 1500 children aged 7-17 years. We will collect objective physical activity data using a wrist-worn accelerometer worn for 7 days. Newly collected blood samples will be analysed using an automated high-throughput serum nuclear magnetic resonance (NMR) to estimate quantitative molecular information >150 metabolites. A targeted assay designed to measure selected putative food biomarkers relevant to Malaysian diets will be applied to n=750 urine samples. Machine learning will be applied to labelled motion sensor data (n=150) to identify eating events and if robust the model will be applied to wrist-worn accelerometer data (n=1500). We will then explore associations of objective measures of physical activity and diet with metabolic health using linear and logistic regression.	Medical Research Council	Research Grant	284830.0	GBP
246	Dr Claudia Lindner	The University of Manchester	School of Health Sciences	2018-02-14	2021-02-13	Fully automated system for the analysis of the efficacy of knee replacement surgery	This project aims to develop a computer-aided system to analyse radiographic signs of early joint failure in knee replacement surgery (KRS). The software system to be developed will be based on the BoneFinderTM-technology (www.bone-finder.com) which uses machine-learning methods to automatically locate skeletal structures in radiographs. Based on a set of training data consisting of radiographs and feature point annotations, BoneFinderTM uses Random Forest-based shape model matching methods to locate the corresponding feature points in unseen images. BoneFinderTM has been applied to automatically outline knee joints in radiographs but further methodological development is required to account for disease and to incorporate implant detection. For a given image, the automatically identified feature points will be used to quantify the knee bones and implant fitting. This will include conventional geometric measurements of lengths and angles but these only give a sparse representation of the structures. Statistical Shape and Appearance Models will be used to capture and quantify their overall shape and texture. Using retrospective data, machine-learning methods will be applied to combine the derived radiographic shape and appearance information of the knee joint with collected clinical data to analyse signs of early joint failure. This will lead to a computer-aided system that will have learned to identify radiographic indications of early joint failure based on radiographs and clinical data for any new subject, informing the KRS decision-making process. A feasibility study will be conducted to identify the clinical requirements for usability and acceptability, and for the integration of the system into the clinical workflow. This will also include the identification of a suitable implementation strategy of the system into the existing digital healthcare infrastructure. The system will be validated during a pilot trial.	Medical Research Council	Fellowship	236193.0	GBP
247	Dr Iain Marshall	King's College London	Health and Social Care Research	2016-07-01	2021-06-30	RobotReviewer: development and evaluation of a machine learning tool to speed up evidence synthesis in cardiovascular diseases	Background Systematic reviews (SRs) are the bedrock of evidence-based practice. However, due to the exponential increase in available research, it is becoming increasingly difficult to keep SRs up-to-date, and keep pace with the primary literature. This problem is compounded in the rapidly moving area of cardiovascular diseases (CVDs), where most reviews are out of date within 2 years of publication. Aims and objectives To extend and evaluate RobotReviewer, a machine learning (ML) system to semi-automate the extraction of data from PDFs reporting clinical trials in CVDs. The system should extract information on the population, interventions, outcomes, statistics, and risks of bias. The accuracy of the system for each variable will be evaluated via a comparison with published systematic reviews. This will allow the user to determine when the system is accurate enough for use, and to what extent. Methodology The system will use an emerging method, distant supervision, in which a text-mining algorithm extracts pertinent text having learned to do so from existing published systematic reviews. A corpus will be developed which links the full text of clinical trials in PDF format with structured data from the Cochrane Database of Systematic Reviews (CDSR), and ClinicalTrials.gov. Methods will be developed to label the target data elements in the PDFs using data from the CDSR and clinicaltrials.gov. ML algorithms will be developed and trained using this data. The system performance will be evaluated against accuracy standards to enable a judgment about whether the system is ready for use, and in what capacity. Scientific and medical opportunities For those conducting systematic reviews, an accurate automation system could reduce the huge time and cost burden in conducting SRs. For clinicians and patients, increased coverage of SRs and quicker production time would ensure that health decision-making is based on the highest quality and up-to-date evidence.	Medical Research Council	Fellowship	330011.0	GBP
248	Dr Claire Niedzwiedz	University of Glasgow	College of Medical, Veterinary, Life Sci	2017-11-15	2021-01-13	A machine learning approach to understanding comorbidity between mental and physical health conditions	The key aim of the research is to enhance our understanding of the comorbidity between mental and physical health conditions by combining the disciplines of public health, computer science and psychiatry. The objectives of the research are to improve the prediction of the onset of co-morbidities between mental and physical health conditions (such as major depressive disorder and diabetes) and related adverse outcomes (e.g. hospitalisation and mortality). A range of data sources will be used to test the utility of implementing a machine learning approach to prediction. For example, using the UK Biobank and Generation Scotland cohorts will allow the exploration of a range of biological, environmental and lifestyle factors. Linked administrative health data (including the Scottish Morbidity Records, disease registers, Prescribing Information System, mortality records and the census) will facilitate the exploration of patients' complex medical histories and social characteristics (e.g. occupations). Machine learning algorithms (e.g. deep neural networks and random forest) will be used to learn from patterns in a range of big data by splitting the data into training and test datasets, assessing the algorithm performance and comparing the results with other methodological approaches. By identifying factors that are highly predictive of physical and mental health comorbidities and adverse outcomes, there is great potential to develop new approaches to patient stratification and novel precision medicine interventions. Collecting these data within medical settings may facilitate the development of improved diagnostic, treatment and preventative measures in clinical and public health practice.	Medical Research Council	Fellowship	290658.0	GBP
249	Dr Bartlomiej Papiez	University of Oxford	Population Health	2018-02-14	2021-02-13	Towards quantitative image analysis of respiratory imaging data for pulmonary disease assessment.	This research project goes substantially beyond the state-of-the-art in medical image analysis in term of: - a methodology by a novel paradigm extending current local or global formulation to a unified non-local counterpart considering all components of image registration (similarity measure, motion/deformation model, optimisation method) jointly with quantitative imaging; - a hypothesis that this unified image analysis framework will be physiologically explicitly grounded in the analysed data (potential to link with advances in machine learning, and opening up to future opportunities for collaboration on big data), and be consequently more relevant to biomedical applications. - challenge on improving the performance of motion estimation, the author believes that the presented methodological advances will eventually lead to the development of real-time (close to real-time) motion estimation for highly dimensional biomedical data. Such an advance will have immediate impact beyond personalised precise radiotherapy planning and delivery.	Medical Research Council	Fellowship	266536.0	GBP
250	Dr Killington	University of Leeds	None	None	None	BBSRC Research Development Fellowship: Dr D R Westhead. From gene functional association to biomolecular networks in parasites and plants	1) To create databases of gene functional associations based on a variety of data sources for Arabidopsis and for the Apicomplexan parasites, and make these accessible to the associated research communities as web services. 2) To develop, compare and optimise machine learning-based methods to combine evidence from the sources above in prediction problems related to biomolecular networks, including missing enzymes in metabolic networks. 3) To make the results methods and predicted biomolecular networks available to the research community as web services.	Biotechnology and Biological Sciences Research Council	Fellowship - RD	93700.0	GBP
251	Professor Popelier	The University of Manchester	None	None	None	Novel force fields devised using machine learning	The potential energy functions used in biomoelcular modelling must be improved in order to secure its future predictive power and trust of the experimental community. In our previous work we replaced point charges by atomic multipole moments in order to improve the accuracy of the (short-range) electrostatic interaction. Quantum Chemical Topology (aka atoms in Molecules") uses molecular electron density to define atoms as finite volumes shaped by the molecular enviroment they occur in. In this proposal we focus on atomic polarisation, i.e. how the electron density of a topological atom fluctuates upon a change in nuclear positions of its neighbouring atoms. We do not follow an existing method (such as the Drude/shell model, electronegativity equalisation, effective polarisation, polarisable point dipoles, etc.). Instead we adopt a modern machine learning method called Genetic Programming to directly establish the link between an atom's electron density reponsing to a geometrical change in immediate environment. Summarising the proposed method, focus on a given atom in a molecule. Normal modes generate hundreds of molecular geometries, representing the ever changing environment of an atom, including bond length and angle variations, and conformational flexibility. Quantum Chemical Topology cuts this given atom out of each of the distorted molecular charge density and calculates the corresponding atomic multipole moments. The latter fluctuate in response to a change in molecular geometry and it is these data that the Genetic Programming algorithm is trained on. Our proposed method is totally new, which is why we need this feasible study."	Biotechnology and Biological Sciences Research Council	Standard grant	105463.0	GBP
252	Professor Caroline Relton	University of Bristol	None	2013-06-01	2018-03-31	Epigenetic Epidemiology	Scientific abstract Background: To maximally exploit the rapid pace of change, including the accrual of large-scale data, in the field of epigenetic epidemiology, we will develop innovative methods for the robust scientific interrogation of population-based epigenetic data and apply them to research questions of scientific and medical importance, structured around four domains: Aim 1: We will explore the genetic architecture of epigenetic traits and use this information to understand the role that DNA methylation variation plays in health and disease. Aim 2: We will develop and make readily accessible the causal analysis methods and tools and apply Mendelian randomization (MR) to epigenetic questions. Aim 3: We will use DNA methylation as an index of past exposures to improve our prediction of disease risk and prognosis. Aim 4: From neurodevelopment to cancer, there are a multitude of settings in which we can apply epigenetic epidemiology to understand disease mechanisms and predict disease. Methods: We will utilize multiple data sources; from in-house studies, via collaborations and consortia, and through publicly accessible repositories. Our primary focus will be on the analysis of DNA methylation, as this continues to be the most readily available source of epigenetic data in population-based studies. However, we will integrate these data with newly generated and publicly available epigenomic and transcriptomic data, tissue-specific data and histone modification data. A wide range of methods will be applied. These include mQTL analysis, functional annotation and machine learning approaches, such as penalized regression, support vector machines, and neural networks. We will test for mediation using MR and apply our prediction methods in disease relevant datasets. Translation: The output arising from this programme will be used to develop biomarkers of disease risk and disease prognosis. It will also shed light on the genetic architecture of DNA methylation and the causal role this molecular phenotype plays in development and disease, which will in turn inform future interventions.	Medical Research Council	Unit	None	None
253	Dr Saqi	Rothamsted Research	None	None	2018-03-31	A systems approach to candidate gene and pathway identification	This project will develop integrated bioinformatics approaches for identifying new genes and pathways implicated in a range of biological processes relevant to plant pathology and crop science. This work will in part build on earlier research into data integration and graph-based analysis methods that have been used in the development of the ONDEX data integration framework for systems biology applications. Research efforts will be directed in the following areas: 1. Methods and software for integrating new sources of biological information including gene function, biochemical pathway, protein structure, gene network and other information (including that extracted from biological literature through text mining) will be developed in response to requirements derived from the biological applications to be studied. 2. Comparative genome analysis and visualisation methods will be developed to exploit the information from model organisms that have more complete genome and pathway information. These methods will be applied to the prediction of new candidate gene and pathway functions from partially or newly sequenced crop, pest and pathogen genomes. 3. Machine learning approaches (including graphical data analysis, data mining and visualisation) will be developed to extract new biological insights from integrated datasets with the aim of identifying novel interactions at the gene and pathway level for the purpose of predicting new gene function, annotation of emerging genomes and other 'omics resources. 4. Specialist databases of gene function (e.g. PHI-base) will be further developed in collaboration with biologists as resources for the research community and to underpin research in the above areas.	Biotechnology and Biological Sciences Research Council	Institute CSG	761116.0	GBP
254	UNIVERSITY OF MASSACHUSETTS AMHERST	UNIVERSITY OF MASSACHUSETTS AMHERST	None	2016-09-01	2021-08-31	Statistical methods for real-time forecasts of infectious disease: expanding dynamic time-series and machine learning approaches for pandemic scenarios	The emergence and global expansion of SARS-CoV-2 as a human pathogen over the last four monthsrepresents a nearly unprecedented challenge for the infectious disease modelling community. This pandemichas benefitted from huge volumes of data being generated, but the rate of dissemination of these data hasoften outpaced existing data pipelines. While the last decade has seen significant advances in real-timeinfectious disease forecasting — spurred by rapid growth in data and computational methods — thesemethods have primarily focused on seasonal endemic diseases based, are based on historical data, and sodo not apply easily to this novel pathogen, or to pandemic scenarios. New methods are needed to leveragethe wealth of surveillance data at fine spatial granularity, together with associated information about policyinterventions and environmental conditions over space and time, to reason directly about the mechanisms toforecast and understand the transmission dynamics of SARS-CoV-2 transmission. These methods must usesound statistical and epidemiological principles and be flexible and computationally efficient to provide real-time forecasts to guide public health decision-making and respond to changing aspects of this global crisis.The central research activities of this project are (1) to develop scalable, computationally efficient Bayesianhierarchical compartmental models to flexibly respond to state-level public health forecasting needs, and (2)to design models and conduct analyses to draw robust inference about the effectiveness of interventions inimpacting the reproductive rate of SARS-CoV-2 infections within the US to build an evidence-base forcontinued responses to COVID-19 and future pandemics.	National Institutes of Health	Research Grant	78507.0	USD
255	Dr. Sarel-Jacob FLEISHMAN	WEIZMANN INSTITUTE OF SCIENCE LTD	None	2019-01-01	2023-12-31	Automated computational design of site-targeted repertoires of camelid antibodies	We propose to develop the first high-throughput strategy to design, synthesize, and screen repertoires comprising millions of single-domain camelid antibodies (VHH) that target desired protein surfaces. Each VHH will be individually designed for high stability and target-site affinity. We will leverage recent methods developed by our lab for designing stable, specific, and accurate backbones at interfaces, the advent of massive and affordable custom-DNA oligo synthesis, and machine learning methods to accomplish the following aims: Aim 1: Establish a completely automated computational pipeline that uses Rosetta to design millions of VHHs targeting desired protein surfaces. The variable regions in each design will be encoded in DNA oligo pools, which will be assembled to generate the entire site-targeted repertoire. We will then use high-throughput binding screens followed by deep sequencing to characterize the designs’ target-site affinity and isolate high-affinity binders. Aim 2: Develop an epitope-focusing strategy that designs several variants of a target antigen, each of which encodes dozens of radical surface mutations outside the target site to disrupt potential off-target site binding. The designs will be used to isolate site-targeting binders from repertoires of Aim 1. Each high-throughput screen will provide unprecedented experimental data on target-site affinity in millions of individually designed VHHs. Aim 3: Use machine learning methods to infer combinations of molecular features that distinguish high-affinity binders from non binders. These will be encoded in subsequent designed repertoires, leading to a continuous “learning loop” of methods for high-affinity, site-targeted binding. AutoCAb’s interdisciplinary strategy will thus lead to deeper understanding of and new general methods for designing stable, high-affinity, site-targeted antibodies, potentially revolutionizing binder and inhibitor discovery in basic and applied biomedical research.	European Research Council	Consolidator Grant	2337500.0	EUR
256	Professor Alison Murray	University of Aberdeen	None	2018-03-01	2019-02-28	Early-life origins of brain resilience to mental illness and cognitive impairment across the life-course	Cortical surface area on Magnetic Resonance Imaging (MRI) from the Paediatric Imaging and NeuroGenetic dataset in North America varies with family income and this relationship is steepest at poorest incomes. This result was not found in Norway, where there is greater equality of socioeconomic circumstance (SEC). Our own research has shown that poorer childhood SEC predicts smaller hippocampi and more brain lesions in late life, which are linked to depressive symptoms and poorer cognition. Here we will extend research to cohorts in Mysore, India, with different SEC and culture, in whom rich life-course and risk factor data exist. We propose pilot work, public engagement and workshops to inform a large-scale future application to investigate hypotheses that early life factors influence risk of subsequent mental illness and cognitive decline. Concentrating on the Mysore groups here, we plan four activities that will inform design of a future project to include cohorts in Mysore and Mumbai. These are deliberately designed around data science, to enable work to be scaledup and to create a resource for future research: Imaging - we will invite subsamples of young and older Mysore cohorts for brain MRI to assess feasibility, acceptability and to measure effect size to inform future power calculation. Health informatics - using public engagement with participants we will determine their views on data linkage of pre-existing data, data to be collected and creation of a bio-resource. Bioinformatics - we will collect new cognitive data, using a game that tests navigational ability, repeat previous cognitive and depression data, blood samples and buccal smears to obtain DNA and RNA for future analysis. Computing science - we will host a workshop at the University of Aberdeen to which Indian and UK co-investigators will be invited to brainstorm "big data' management, analysis and machine learning methods to test in pilot data and apply to future large-scale work.	Medical Research Council	P&Cs	192240.0	GBP
257	Dr Chris Bakal	Institute of Cancer Research	None	2011-12-01	2014-11-30	Quantifying the relationship between cancer cell genotype and phenotype. Determination and validation of the gene expression changes that drive the specific morphological changes essential for breast cancer metastasis.	Background Despite the vast amount of data that have been generated in recent years on cancer cell genotypes, a significant challenge in the post-genomic era will be to understand how genomic alterations drive cellular phenotypes, such as the dramatic changes in morphogenesis that occur during metastasis. We have previously developed technologies to quantify the morphology of single cells and cell populations to precisely investigate changes in cell shape (Bakal et al., Science 2007). We are currently using these methods to quantify the morphology of a panel of breast cancer lines in 2D and 3D culture. Using these methods, we can also quantify hetereogeneity and identify morphologically distinct subpoluations within in isogenic cell lines. Genome-wide mRNA expression levels and genomic copy number variations have been determined for all the lines we are investigating by the Reis-Filho laboratory at the ICR/Breakthrough Breast Cancer Center. This allows us to perform statistical analysis to find patterns of gene expression that relate to quantifiable differences in cell shape. In addition, we are working in collaboration with The Cancer Genome Atlas Project to profile the genotypes and morphological phenotypes parallel following treatment with different small molecules. In this project, we aim to determine how genotypic alterations are linked to specific changes in morphological in cancer cells. Aims (1) To classify a panel of 20-40 breast cancer cell lines based on morphology and identify patterns of gene expression that are correlated with and/or control cell shape. (2) To perform quantitative morphometric analysis of cell invasion in 3D matrices. (3) To determine the whether highly invasive cells represent stable subpopulations within tumour cell lines. Methods In order to complete these studies we will use: - Automated high-throughput image acquisition and feature analysis of single cells in both 2D and 3D. The Bakal laboratory is equipped with two Opera microscopes, each capable of capturing over 100,000 unique images per day. - High-throughput analysis of 3D morphology. - Machine-learning methods to quantify and classify independent phenotypes. The ICR has recently acquired an Altix UV computer in order to facilitate this work. - Statistical analysis to determine correlations between gene expression, copy number and morphological features. - RNAi and small-molecule perturbation. The results of this work will be primarily used to identify and validate genes whose changes in expression are causal to the morphogenesis of metastatic cells.	Cancer Research UK	Biological Sciences Committee - Project Award	None	None
258	HEALTHY KIDZ CIC	HEALTHY KIDZ CIC	None	None	2014-11-30	Healthy Kidz Virtual Buddy	Healthy Kidz is a unique and innovative physical education and data analytics business. Founded in 2018, the company began by providing a four strand physical education programme in Northern Ireland primary schools that sought to get every child active, fit and healthy. In the wake of COVID-19, lack of routine, structure, motivation and / or nudges to exercise, coupled with increased calorie intakes mean that children in low income households are at significant risk of obesity and associated metabolic diseases. In response to the public health crisis, Healthy Kidz has already expedited the development of its mobile application and initiated a 'Global Challenge' which has been widely promoted by Healthy Kidz ambassadors (local sporting heroes including Ireland Rugby's Stephen Ferris) [https://healthy-kidz.com/healthy-kidz-global-challenge/][0]. More than 2,000 children have signed up to the Challenge across Ireland, the UK and internationally. However, given the significant risks posed to vulnerable children and their families, Healthy Kidz is now seeking investment to engage expertise in technology integration and machine learning to scale its offer, increase the breadth of metrics it captures, and develop tailored, automated motivation and physical activity advice via virtual reality to vulnerable children at home. [0]: https://healthy-kidz.com/healthy-kidz-global-challenge/	UK Research and Innovation	Research Grant	48716.0	GBP
259	Dr. David Labonte	IMPERIAL COLLEGE OF SCIENCE TECHNOLOGY AND MEDICINE	None	2020-01-01	2024-12-31	Behavioural biomechanics of insect herbivory - a case study on leaf-cutter ants	Insect herbivores are a dominant element in terrestrial ecosystems, and pose a continuing threat to global food security. However, little is known about a key determinant of insect herbivore success: the mechanics of plant-feeding. MechAnt proposes to transform our understanding of insect-plant relations by providing a rigorous biomechanical investigation into how insects cut leaves, using the major ecosystem engineers and principal insect pest of the New World, the leaf-cutter ants, as a model system. Specifically, MechAnt will combine the traditionally separate fields of behavioural ecology, mechanical engineering, materials science, computer vision and machine learning to investigate: (1) the mechanical and energetic constraints determining the cutting ability, and ontogeny of task choice of differently-sized workers, and hence the adaptive value of physical castes in eusocial insects; (2) the relationship between plant material properties, ease of cutting, and mandibular wear, which will reveal the key mechanical determinants of plant-herbivore species interactions; (3) the division of labour, ontogeny and demography of leaf-cutter colonies foraging on leaves of different “toughness”, testing the hypothesis that leaf-cutter colonies are organised according to ergonomic criteria. By integrating insights ranging from nano-scale mechanics up to whole-colony ecology, MechAnt will quantitatively link the mechanical properties of plants with the performance of individual foragers, the organisation of foraging parties, and the demography and social organisation of leaf-cutter ant colonies. The resulting understanding of the biomechanical innovations underpinning the success of the leaf-cutter ants will yield insights into the behavioural ecology of advanced plant-feeders, highlight the role of biomechanical constraints in the behaviour and evolution of herbivorous insects, and pave the way for the development of novel crop protection strategies.	European Research Council	Starting Grant	1998764.0	EUR
260	Prof. Flavio Donato	UNIVERSITAT BASEL	None	2020-01-01	2024-12-31	Dissecting hippocampal circuits for the encoding of early-life memories	The infant brain is a formidable learning machine. But is it able to encode memories of early-life experiences? Since most of us don’t remember what happened during the first years of our lives, for a long time this question has been open to debate. Recent evidence suggests that, even if we cannot recall them, early-life memories are encoded in the developing hippocampus, persist in a silent state into adulthood, and can affect the acquisition of new information later in life. We know very little about how the infant brain encodes early-life memories, despite the fact that our earliest experiences can stick with us and influence our behaviour as adults. How can the infant hippocampus produce long-lasting memory traces when its circuits are not yet mature? Why can’t we remember early-life memories? And how can infant memories have long-lasting effects if we can’t recall them? To answer these questions, in the following project I propose to study memory processes in the developing brain using the mouse as a model organism. I will implement a combination of genetics, viral tagging, calcium imaging, and opto- and chemogenetic methodologies, in association with behavioural paradigms, to track in vivo the activity of a large number of neurons as the brain matures, and to gain fundamental insights into the early functions of the mammalian memory system. The aims of my proposal are: 1. to understand how the infant hippocampus produces neuronal ensembles to represent early-life experiences; 2. to identify and dissect the neural circuits encoding infant memories; and 3. to unravel how neurons supporting silent memories created during infancy influence learning processes in adults. By bridging developmental, systems, and behavioural neuroscience, my ambition is to understand how the developing brain encodes memories of early-life experiences, and how infant memories influence the operations of higher-order cognitive functions later in life.	European Research Council	Starting Grant	1499055.0	EUR
261	Dr Sofia Villar Moreschi	MRC Biostatistics Unit	None	2020-09-01	2024-12-31	Innovative designs for trials: methods and implementation	Randomised experiments are the gold standard for developing new medical interventions but they are expensive and face multiple other challenges. Novel analysis techniques can lead to efficiency gains. However, there are additional challenges which pose important barriers to the chances of success of a trial and that call for a new approach to the design of experiments. For example, developing patient-centric clinical trials for rare and fatal diseases imposes hard trade-offs between efficiency and outcome objectives My proposed research is an interdisciplinary approach motivated by improving clinical trial design through the development and application of methods that lie in the intersection between optimisation, machine learning and statistics (with links to adaptive and sequential decision making). Most of these methods have much broader applicability. My proposed future work includes four main objectives: 1. Deriving computationally tractable, optimal and nearly optimal, algorithms for designing clinical trials; 2. Improving analysis methods of optimal adaptive trials (estimation and testing); 3. Designing innovative trial designs for emerging challenges 4. Promoting update of novel designs in practice	Medical Research Council	Unit	None	None
262	Dr Danielle Belgrave	Imperial College London	National Heart and Lung Institute	2015-10-01	2018-09-30	Unified probabilistic latent variable modelling strategies to accelerate endotype discovery in longitudinal studies	Aim: To determine a unified probabilistic latent variable modelling strategy for integrating immunological, molecular, biological and clinical phenotypes for endotype discovery in longitudinal studies. Objectives: 1. To build a unified graphical model that represents a broad range of important variables associated with asthma and allergic disease. 2. To use innovative computational statistical latent variable modelling methods to discover novel subtypes of childhood asthma and allergy across multiple cohorts. 3. To extend these graphical models to generate novel insights into a systems modelling framework that is able to upscale in order to integrate clinical data, immunological data, genetic data and epigenetic data. 5. To extend this unified graphical modelling framework to explore principled methods for using probabilistic latent variable models to deal with missing variables in the context where not all variables are available at every time-point. 6. To formally assess the strengths and weakness of Bayesian and Frequentist methods within a longitudinal birth cohort setting. Methods: The proposal will use data from the STELAR consortium for clinical endotype discovery and data from MAAS for extending graphical models to a systems biology framework. Current Bayesian machine learning and classical-statistical probabilistic modelling approaches will be extended to identify latent disease subtypes. Dimensionality reduction techniques will be developed and explored to understand the latent space which best describes high-dimensional clinical and immunological data - considering viral and bacterial stimuli-cytokine responses separately. Scientific and Medical Opportunities: It is hoped that more refined endotype discovery will lead to understanding their underlying biological mechanisms and therefore lead to more targeted treatment and management strategies. This is applicable not just to asthma and allergy, but is generalizable to other diseases.	Medical Research Council	Fellowship	260595.0	GBP
263	Dr Paul Bentley	Imperial College London	None	2015-11-01	2019-04-30	Decision-assist software for management of acute ischaemic stroke using brain-imaging machine-learning	1. We shall acquire a retrospective dataset of clinical and CT data (n~10,000; of which ~1000 SICHs). This step is facilitated by ethical approval being in place; adoption by the NIHR network; collaborations with 11 UK centres to date; and relevant clinical parameters already collected by centres for audit. We have currently acquired 1700 subjects&rsquo; data from 2 centres (Supporting Information 1). We shall additionally acquire ~4000 non-stroke, and follow-up stroke, images, to facilitate automated anomaly detection (of which we have already acquired 1750). Finally, we have agreed in principle to acquire data from the IST-3 thrombolysis trial9 (n=3000), this being comprised exclusively of cases where there was treatment-decision uncertainty, and includes patients not thrombolysed. 2. Images will be pre-processed using an automated, in-house pipe-line of joining, normalization, smoothing, and segmentation, that we have already partly developed (Supporting Information 2). 3. We shall optimize our existing model by exploring CT image features most relevant to SICH/outcome prediction, using a range of machine-learning methods our group are experienced with11. This will involve purely data-driven approaches (e.g. support-vector machines), and hypothesis-assisted methods (e.g. delineation of acute ischaemia extent - this being the strongest currently-recognised imaging predictor of SICH13, yet poorly quantified). Our group have, to date, demonstrated that whole-brain high-dimensional information can be one useful predictor10; used feature-reduction to identify novel imaging patterns that predict SICH; and begun development of an automated anomaly detector (Supporting Information 3,4). Current SICH-predictive methods have validation accuracies of ~65%5,6, whereas our provisional model achieved accuracy of 74%. 4. The optimized model will be validated, and compared with current prognostic scores, e.g. SEDAN, HAT5,6. For this we shall take a cohort of 1000 subjects, from several centres that did not contribute data for model optimization. This step will entail review of scans by three neuroradiologists, since many prognostic scores utilise radiology measures related to size of infarction (ASPECTS score) and middle cerebral artery density. Inter-rater reliability will be ascertained. 5. The model will be incorporated into a user-friendly, clinically-relevant decision-assist tool by a software engineer. The tool will be designed for doctors to input patient data, and combine automatically with CT data on existing CT viewing platforms (PACS). The software will output probability of SICH risk, and good functional outcome, with confidence intervals (Supporting Information 5); and will be compared to those of stroke patients, not receiving tPA, calculated from models based upon thrombolysis trials8,9. This will be displayed in a relevant way for doctors making treatment decisions, and will be transferred schematically to show patients on a tablet. A patient representative will help with the design of these aspects. 6. We shall conduct a prospective feasibility study of the software. We shall install our software in 4-5 collaborating centres, and encourage its use by stroke-clinicians and radiologists to assist thrombolysis-decisions over 10 months. The primary outcome will be rate of thrombolysis. We hypothesise that the software will increase, or at least maintain, thrombolysis rates compared to previous rates in the same centres. Secondary outcomes will be: 1) SICH rate; 2) SICH and outcome predictive accuracy compared to existing scores; 3) speed of thrombolysis decision-making; 4) clinician and patient/family feedback. 7. A sub-study will explore whether incorporation of hyperacute CT-perfusion data, using multimodal machine-learning methods, can enhance SICH and function prediction. We expect to acquire ~1000 CT-perfusion data from our current collaborating centres. Increasing evidence suggests that advanced imaging can enhance prediction of outcomes after thrombolysis14, and estimate time of onset when this is unknown2. Methods developed in the earlier part of the study will be transferred to develop novel, assumption-free analyses of CT-perfusion images.	National Institute for Health Research (Department of Health)	Full Award	525360.0	GBP
264	Dr Christoffer Nellaker	University of Oxford	Physiology Anatomy and Genetics	2015-07-01	2019-07-30	Developing diagnostic methods for clinical genetics - phenotyping from faces in photos.	Aim 1. Enable complete phenotype descriptions from photos for clinicians. I will adapt existing computer vision and machine learning methods for the specific purpose of obtaining phenotype descriptions. CFPS already performs exceptionally well given the limited information that it exploits thus far. Developing the accuracy of craniofacial point annotations and feature descriptors for capturing phenotype characteristics, inferring 3D orientation from 2D images, and applying machine learning approaches will ensure that CFPS reaches its full potential. Aim 2. Robustly predict causative mutations from DNA variants and CFPS. I will lead research that will aid genetic diagnoses with CFPS. The collective body of work to bring CFPS and DNA variant data together is essential for CFPS to become ready for clinical genetic data. To do this I will create family representations to differentiate between de novo and inherited phenotype. With a vector representation of a face during development CFPS will be able to capture and predict disease progression. I will also put in place a robust statistical framework to infer causative DNA variants in rare de novo mutation diseases to empower the search for ultra-rare syndromes. Aim 3. Develop the big data framework for implementing CFPS in global healthcare. Current ethical, law and data security concerns are a major hurdle in the path of bringing CFPS to patients. Within the scope of this Fellowship I will address each of these challenges. Patient images through collaborations and patient contributions will involve applying for REC approval to ask for consent and for people to contribute photos from their family albums. This will be both an exercise in public engagement but also en masse data collection. I will be working with ethics, law and eHealth data management questions to enable CFPS to develop into a form which will be not only powerful, but also usable in clinical settings.	Medical Research Council	Fellowship	457586.0	GBP
265	Dr Steven Kiddle	King's College London	Social Genetic and Dev Psychiatry Centre	2014-04-01	2017-03-31	Early identification of Alzheimer's disease: dynamic biomarkers for enrichment of trials	Aim: To use integrated biostatistics and bioinformatics to relate genetic, peripheral and cognitive biomarkers to central Alzhiemer's disease (AD) pathology, in order to reduce barriers to clinical trials in the prodromal phase of the disease. Objectives 1. Characterise genetic and environmental influences on candidate protein markers. 2. Identify tasks from cognitive tests that reflect amyloid pathology. 3. Relate markers to central pathology using a systems biology approach applied to post-mortem brains. 4. Build a causal model of genetic factors, brain Abeta, cognitive test items and candidate protein markers. Methods Objective 1 Sample: 106 twin pairs (for main analysis) Analyses: An established quantitative-genetic model to test for genetic and environmental control of plasma protein levels and cognitive ability. Analysis of association of protein levels with other AD-related phenotypes, and with genetic data. Objective 2 Sample: 144 + 273 + 56 = 473 subjects combined (across cohorts) Analyses: Meta-analysis of association of cognitive task scores with brain amyloid beta levels. Multivariate regression and machine learning to find optimal combination of cognitive task scores. Objective 3 Sample: ~200 case and ~200 control brains (for main analysis) Analyses: Candidate markers will be assessed for differential expression in AD brains, taking into account genetic differences that affect their levels. Common genetic control of these traits will be further explored using 'co-localisation' analysis. Finally, genome-wide analyses on multiple genomic levels will be performed in an integrated fashion. Objective 4 Sample: 116 + 273 + 170 = 559 combined subjects (across cohorts) Analyses: The most promising markers from Objectives 1-3 will be studied further, with the causal relationship between genetics, brain amyloid levels and these markers investigated using Structural Equation Modelling.	Medical Research Council	Fellowship	253519.0	GBP
266	Dr Matthew Kempton	King's College London	Neuroimaging	2012-10-01	2018-06-30	Trajectory of Brain Structure and Function before and after the Onset of Psychosis: a Longitudinal Multicentre Study	The aim of this study is to characterise the trajectory of brain structure and function before and after the onset of psychosis. Specifically I will examine changes in the volume of the insula, hippocampus and lateral ventricles and test the hypothesis associated with the theory of Tony Grace that functional connectivity between these regions increases prior to psychosis. A secondary aim is to predict who will develop psychosis by applying machine learning techniques to the longitudinal data. The fellowship is to fund longitudinal MRI scans of subjects with an at risk mental state (ARMS), 25-30% of whom are expected to develop psychosis within 2 years of contacting medical services. The baseline MRI scans are already being collected as part of the EU-GEI project. However there were no plans in the original study to do subsequent scanning. My proposal aims to capitalise on this ARMS sample, which is an order of magnitude larger than any examined in previous studies. Scanning will be completed at 7 centres which each have ARMS clinics and a 3T MRI scanner. ARMS subjects will be scanned at the point of transition and 12 and 24 months after transition; those who do not transition to psychosis and healthy controls will be scanned 3, 12 and 24 months after the baseline scan. Analysis of the structural MRI data will be conducted with FreeSurfer and software developed by my collaborator Paul Thompson and resting state fMRI data will be analysed with FSL MELODIC. I will use support vector machines to predict psychosis transition from the imaging and clinical data which would have immediate translational benefits. Changes in brain structure and function before psychosis raises the intriguing possibility that future therapies may be able to arrest these changes. Charactering the trajectory of these changes would indicate which regions of the brain are first affected, and establish a reference point to compare the effects of preventative treatment strategies.	Medical Research Council	Fellowship	1227953.0	GBP
267	Professor Adnan Custovic	Imperial College London	Dept of Medicine	2015-09-15	2017-07-14	MICA: STELAR (Study Team for Early Life Asthma Research) consortium - Asthma e-lab and identification of novel endotypes of childhood asthma	Asthma epidemiology is reaching the limit of what can be achieved through conventional hypothesis-driven research. We hypothesise that asthma is not a single disease, but a condition comprising multiple distinct disease entities (asthma endotypes), each with characteristic pathophysiology and risk factors, and that unbiased novel endotypes of asthma can be identified using complex, rich and expanding datasets from existing UK birth cohort studies by applying a combination of biostatistical and machine learning methods. We propose to form a major Alliance between MRC-funded network of all UK-based birth cohorts designed to study asthma (STELAR consortium), expertise in epidemiologically oriented health informatics research (NW Institute for Bio-Health Informatics) and experts in statistical machine learning (Microsoft Research Cambridge). We will capitalise on the unique collection of well characterised birth cohorts with harmonised clinical outcomes (ALSPAC, SEATON, MAAS, Ashford, Isle of Wight). We will create a secure web-based research environment (Asthma e-Lab) to support consistent recording, description and sharing of data and emerging findings across all partners, thus enabling collaborative epidemiology in near-real-time. The activities of data managers and researchers from the 5 STELAR sites will be made visible to one another, supporting team coordination and peer support and creating a scientific social network to enrich the ongoing modelling and interpretation. We will create and maintain across the consortium annotated dependency graphs of the problem space around the organising principles underlying asthma, and use a machine learning approach interactively over the combined datasets via Asthma e-Lab to discover the unbiased endotypes of asthma. Our findings may underpin new trials of asthma prevention and treatment, personalised for specific endotypes and may help identify novel targets for the discovery of endotypes-specific stratified treatments.	Medical Research Council	Research Grant	568951.0	GBP
268	Dr Rashmi Patel	King's College London	Psychosis Studies	2013-01-14	2016-01-13	Predicting clinical and functional outcomes in psychosis using machine learning	Background Psychotic disorders are responsible for an enormous burden of illness upon individuals and society as a whole (Perala 2007). Structural, functional and DTI MRI studies have shown that the onset of psychosis is associated with changes in brain structure and function (Smieskova 2010 and Pettersson-Yeo 2011). However, it has been difficult to apply such group level findings to a clinical population at the level of the affected individual. This may reflect the overlapping genetic, neurobiological and clinical features of current diagnostic classification systems, which cannot reliably predict the course and outcome of psychotic disorders (Van Os 1997). Aims My project aims to analyse clinical and neuroimaging data of patients with psychotic disorders using Support Vector Machine learning (SVM) and Machine Kernel Learning (MKL) in order to generate more robust systems for classifying illness and predicting outcomes at the level of the affected individual. Methods (i) SVM analysis of data of patients with psychosis from a large, prospective case register (CRIS) to characterise clinical and functional outcomes and predict these with baseline clinical data at first episode. (ii) Individual SVM analysis of clinical data, structural MRI, DTI and fMRI of patients with first episode psychosis to predict the same outcomes. (iii) Analysis of clinical and neuroimaging data using MKL to investigate if combining modalities increases predictive power. Implications Prediction algorithms generated from this project will be further validated using a prospective dataset with the aim of subsequently evaluating successful algorithms in clinical studies. Generating reliable algorithms for predicting outcomes in psychosis may help to develop more effective and personalised treatments.	Medical Research Council	Fellowship	174832.0	GBP
269	Dr Oliver Zeldin	Diamond Light Source Ltd	None	2015-02-01	2019-01-31	Serial crystallographic studies of radiation sensitive macromolecules.	This proposal outlines a graph-based approach to dealing with the heterogeneous datasets present in serial femtosecond crystallography (SFX). By describing the hundreds to tens of thousands of images in an SFX dataset as the vertices of a graph, and the agreement between pairs of images that share reflections as the edge weights (with no edge between images that have few or zero Miller indices in common), it is possible to refine partialities and merge observations without first averaging all th e images. This opens up exciting new opportunities for sub-population clustering, outlier rejection, and time-resolved methods. Preliminary work where a graph has been created, and the individual image parameters optimized through a graph synchronization procedure has demonstrated the promise of this approach. Many powerful algorithms and machine learning techniques exist for analyzing graphs, and these will be leveraged through close collaboration with members of the Stanford Computer Science D epartment. Biological relevance of the methodology will be kept as a priority throughout by being initially hosted by Dr. Axel Brunger (Molecular and Cellular Physiology), and through collaboration with biology groups and my sponsor, Dr. Dave Stuart.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	250000.0	GBP
270	Univ.Prof. Dr. Ulrich STRASSER	University of Innsbruck	None	2016-02-01	2019-01-31	Cryosphere Monitoring in the EUREGIO Region (CRYOMON-SciPro)	The cryosphere (here: snow, ice and glaciers) is the most important inter-seasonal water storage component in the Alps. Climate variability and climate change directly affects cryospheric parameters and processes related to the energy and water cycle, such as snow water equivalent, glacier mass balance or runoff. Accurate monitoring as well as understanding of such processes is still a field of scientific challenge and of utmost importance for hydropower production, agriculture, winter tourism and flood protection. Apart from direct observations, hydrological models are the most common approach to study cryospheric processes. However, particularly at larger scales (>10’000 km²), critical processes such as radiative transfer, snow albedo and the energy balance remain underdetermined due to missing spatially explicit data. Satellite remote sensing is a promising technology for generating spatially explicit information on snow for larger areas, but operational products are mostly limited to the detection of snow cover only. In view of this, the central idea of CRYOMON-SciPro is to exploit the complementary character of physically based hydrological modelling and improved satellite remote sensing products for monitoring key processes within the cryosphere by integrating both methods in an innovative approach (multi-level data fusion). The innovations expected to result from this project include: - An improved representation and understanding of the spatial and temporal dimension of key processes within the cryosphere at larger scales (> 10’00 km²) with a focus on the energy exchange (radiation, snow and ice albedo) and water cycle (mass balance, snow water equivalent, runoff) - A flexible data integration concept based on machine learning and pattern recognition techniques for a multi-level data fusion on the level of input, intermediate and output variables - The first-time application of latest ESA Sentinel 1 (radar) and 2 (optical) satellites for studying the cryosphere - The integration of data from new and innovative field measurement techniques (permanent terrestrial laser scanning, field spectrometry) CRYOMON-SciPro makes use of the EUREGIO region as a field laboratory for cryosphere research with well-instrumented test-sites, high data availability, good contact to authorities and climatological conditions representative of different Alpine zones. The results of the project will thus have a scientific value that is well beyond the EUREGIO region. CRYOMON-SciPro will form the nucleus of an Interregional Project Network (IPN) on cryosphere science with a complementary expertise of three key research institutions within the EUREGO region: - Hydroclimatological modelling and analysis of Cryosphere (Innsbruck University), - Applied Remote Sensing of Cryosphere (EURAC Bolzano), - Data driven modelling and machine learning approaches (Trento University). CRYOMON-SciPro is designed as a three year project, with three PhD-students and young postdoctoral researchers as funded stuff. A scheduled exchange program supports knowledge transfer and education of the young staff researchers.	Austrian Science Fund FWF	International Project Network Tyrol-Trentino	101682.0	EUR
271	Mr Ed Holdsworth	Practical Control Limited	None	2016-01-01	2018-09-30	Speech Rehabilitation from Articulator Movement (SRAM)	Activities are grouped into three areas: technical, clinical and commercial, with the following work packages. The timescale is indicated along with the lead organisation(s): Practical Control Limited (PCL), University of Hull (UoH), University of Sheffield (UoS) and Hull and East Yorkshire NHS Trust (HEY). See Gantt chart in supporting document. 1. Technical Development 1.1. Hardware development and validation 1.1.1. Miniaturisation of external sensor frame (months 1-9, PCL/UoH), to make the system more discreet and acceptable. 1.1.2. Implant instrumentation development (months 1-9, UoH/HEY). Bespoke instrumentation for magnetic implant placement will be developed, evaluated and submitted for regulatory approval. 1.1.3. Intraoral sensor system development (months 1-18, UoH/PCL) for the optimal discreet and accurate technical solution (because of the proximity of implants and sensors). Power and space budget calculations indicate that this is viable (see supporting document for mock up), but this requires significant work on design and manufacturing processes. (Milestone: month 18 &ndash; Intraoral system laboratory evaluation). 1.2. Speech processing 1.2.1. Implementation and evaluation of real time Direct Synthesis (months 1-9, UoS/UoH/PCL). Real time audio feedback is important for improving speech quality by allowing the user to learn to &lsquo;speak&rsquo; (like learning to play a musical instrument). We have demonstrated near real time Direct Synthesis for a restricted vocabulary but improvements to hardware and software are required. 1.2.2. Adaptation to different training regimes (months 1-18, UoS). Patients will follow different treatment and training pathways depending on their particular circumstances. The ideal situation is synchronous recording of audio and PMA data prior to laryngectomy but this is not always possible. Those who have already had a laryngectomy may not have a voice recording. &lsquo;Karaoke&rsquo; techniques will be developed and evaluated for voice reconstruction under these circumstances. (Deliverable: month 18 &ndash; Evaluation of training regimes). 1.2.3. Extension of vocabulary and speaking styles (months 1-24, UoS). Direct Synthesis based on PMA data has demonstrated speech reconstruction, in a &lsquo;voice&rsquo; similar to the user&rsquo;s, for certain vocabularies. Extension of machine learning techniques will address a wider range of vocabulary and speaking styles. 2. Clinical Development 2.1. Update stakeholder requirements (months 1-6, UoH/HEY) in the light of the enhanced system performance. This will guide further development and commercialisation priorities. (Deliverable: month 6 &ndash; Updated stakeholder priority report). 2.2. Evaluation of alternative treatment pathways (months 1-12, HEY), to assess the preferred approaches in terms of stress on the patient, ultimate system performance and treatment costs. (Deliverable: month 12 &ndash; Draft treatment guidelines). 2.3. Regulatory approval (months 9-12, 18-21, UoH/PCL). MHRA &ldquo;Notice of No Objection&rdquo;, NHS R&D and NRES REC approval of the Clinical Investigation Plan. (Milestones: month 12, 24 &ndash; Approvals in place) 2.4. Clinical Study (months 12-21 & 21-27, HEY/UoH). Studies will assess system performance using 1) external sensor frame, 2) intraoral sensor system. Initial laboratory trials will be followed by extended studies in the users&rsquo; home and workplace. (Deliverables: month 21 & 27 &ndash; Clinical study evaluation) 3. Commercial Development 3.1. Market Analysis (months 1-9, PCL/UoH). The size and structure of UK and international markets will be assessed and segmented on the basis of numbers of laryngectomees, current treatment practices, healthcare system characteristics, ability to pay and language characteristics. (Deliverable: month 9 &ndash; Market Analysis report) 3.2. Business Model Evaluation (months 9-18, PCL/UoH), e.g. NHS vs. Private, one-off purchase vs. rental etc, for different market segments. 3.3. Commercialisation Business Case Development (months 16-24, PCL) .This will include the costs and risks of further technical and manufacturing system development, approvals, marketing and support. (Milestone: month 24 &ndash; Preferred commercialisation plan established).	National Institute for Health Research (Department of Health)	Full Award	655678.0	GBP
272	Dr Peter Uhlhaas	University of Glasgow	School of Psychology	2014-07-31	2019-02-28	Using Magnetoencephalography to Investigate Aberrant Neural Synchrony in Prodromal Schizophrenia: A Translational Biomarker Approach	In this project, we will apply state-of-the-art magnetoencephalography (MEG) towards examining neural synchrony in participants at ultra-high-risk (UHR) for the development of schizophrenia (ScZ) with the aim of establishing a diagnostic index. Specifically, we will recruit 100 participants meeting UHR-criteria over a two year period from psychiatric services in Glasgow and Edinburgh as well as from the data base of the Edinburgh High Risk study. Following the initial assessment of UHR-status, monthly mental-state monitoring for the first six-months will be implemented to detect transition to psychosis. After this period, UHR-subjects will receive monitoring assessments every 3 months up to a total of 2 years. MEG-activity will be obtained during a visuo-spatial WM-paradigm as well as during a perceptual task which requires participants to detect a sine-wave grating. In addition, resting-state activity will be measured. Time-frequency representations will be estimated at the sensor and source-level. Moreover, time course of oscillatory activity within a specified frequency band will be investigated for source-connectivity based on a Partial Directed Coherence (PDC) approach and cross-frequency coupling. In addition to MEG-data, we will obtain estimates of GABA and Glutamate levels through proton magnetic resonance spectroscopy (MRS) to examine relationship between neural synchrony and excitatory-inhibition (E/I) balance parameters. MEG, MRS and MRI-measurements will be complimented by detailed psychopathological (CAARMS, SPI-A) and neuropsychological testing. To develop a diagnostic index, we will employ a multivariate machine learning technique towards the development of a biomarker which compares controls, converted and non-converted UHR-participants. This will be informed by our Information theoretic analysis of the different MEG-parameters as well as the complimentary information from neuropsychology, psychopathology and MRS-data.	Medical Research Council	Research Grant	816353.0	GBP
273	Dr William Cawthorn	University of Edinburgh	Centre for Cardiovascular Science	2019-06-30	2022-06-29	Population-level imaging, genomic and phenotypic analyses to determine how bone marrow adiposity impacts human health	Bone marrow adipose tissue (BMAT) accounts for up to 70% of total bone marrow volume and 10% of total fat mass in healthy humans. BMAT further increases with ageing and in diverse clinical conditions, such as osteoporosis, obesity, type 2 diabetes and radiotherapy. Unlike other adipose depots, BMAT also increases in states of caloric restriction, including anorexia nervosa. Thus, BMAT is a major feature of normal anatomy; is distinct to other types of adipose tissue; and is altered in many clinical contexts. However, study of BMAT has been extremely limited, and therefore how BMAT impacts human health and disease remains to be established. This proposal will fill in this critical gap in knowledge by leveraging the power of the UK Biobank (UKBB). Magnetic resonance imaging (MRI) is emerging as a key tool to measure BMAT, but this has never been done on a population level. UKBB is now MRI scanning 100,000 of its participants; hence, using this data, Objective 1 is to measure BMAT of each participant by developing machine learning-based algorithms for automated MRI analysis. Establishing these new automated MRI analysis tools will yield extensive academic, clinical and commercial benefits. Objective 2 is to use GWAS and PheWAS to identify genetic and phenotypic factors associated with altered BMAT. No previous MRI study has analysed BMAT in more than 600 subjects; hence, our population-level BMAT analysis will provide unprecedented power to identify these associations. Finally, Objective 3 is to use Mendelian randomisation in UKBB and other large-scale cohorts to determine if SNPs associated with altered BMAT are causally linked to physiological and pathological outcomes. This will reveal if BMAT directly influences physiological traits and/or the aetiology of diverse diseases. In summary, this work will yield cutting-edge approaches for automated MRI analysis while revealing fundamental new knowledge about the impact of BMAT on human health and disease.	Medical Research Council	Research Grant	550452.0	GBP
274	Dr Guillaume Hennequin	Department of Electrical Engineering University of Cambridge	Department of Electrical Engineering University of Cambridge	2013-02-01	2014-07-31	Fast but not furious: rapid Bayesian inference in balanced cortical circuits	Sensory perception is fast in human, and nonetheless almost Bayes-optimal. I propose a theoretical approach to this puzzle in which circuit mechanisms for fast dynamics (which I have explored as part of my PhD thesis) will be related to the speed of perception, for wich the computational aspects will be cast in the framework of probabilistic Bayesian inference. The working hypothesis will be that the brain represents posterior uncertainty via sampling, for which the host laboratory has found experimental evidence recently. We will thus combine methods from machine learning and statistical physics to understand how inference via sampling can be performed in the cortex. The project has expected outcomes both in the field of machine learning and in neuroscience.	Swiss National Science Foundation	Fellowships for prospective researchers	None	None
275	Dr Christan de Goede	Lancashire Teaching Hospitals NHS Foundation Trust	None	2017-12-01	2021-01-31	MyPad – Intelligent Bladder Pre-void Alerting System	Project Description: Iterative development of a comfortable, miniaturised, highly customisable, US-based device which is mounted ergonomically on a child s abdomen wall, to measure the distension of urinary bladder and consequently decides smartly whether to issue an alert to wake the patient (pre-void) during the night. Particularly, this project relates to methods and apparatuses for treating urinary incontinence, suitably by providing pre-void alerts. A patent has been published on our techniques, innovative US processing software and the design of the device [8]. Methodology: Several non-invasive low powered sensors detect changes in the pattern of ultrasound pulses reflected from multiple points of the bladder and related tissue around the bladder in intermittent manner using a skin-interfacing pad, and the acquired information in a data storage unit is transmitted into a processing/computing unit using wireless Bluetooth technology. The discriminant features (detailed in our patent [8]) extracted from this information based on the specific characteristics of urine in the bladder and the bladder itself are then processed by the smartphone computer-implemented Machine Learning (ML) techniques in a parallel software processing to determine the relative fluid level (to at least 50ml) in the bladder. Other sensors such as movement, temperature and moisture measurements are employed to enhance warning performance and self-customising features. Data Collection, Storage & Analysis: i) Acquiring and extracting information from bladder data: Upon collecting A-mode reflected signals obtained via a plurality of transducers interchangeably through skin-interfacing device, the echoes are stored and time stamped in memory and sent to a wireless computing device on real-time for further processing using Bluetooth technology. ii) Acquiring and extracting information from real-time event data: Our intelligent smartphone application where several ML algorithms are working in parallel processing extracts discriminant features from acquired data. iii) Correlating bladder data or information with a status: These features are mapped onto multiple classifiers that have previously been observed, and modulated using different levels of liquid encapsulated within the bladder. The mapping classifiers depicting level of liquid are obtained by applying several ML techniques on detected features, status data and similarities. iv) Triggering alerts: Final bladder status is determined by the weighted average/weighted majority of the plurality of classifiers, and accordingly an alarm type customised for the user is triggered if the level is depicting a trigger point. Design & Safety: The geometry, wearability, and usability and optimisation of the device will be iterated through a reference group comprising children with their families, by taking both sex and different morphology types into consideration throughout the project. For the prototype, software has been designed to decrease the intensity and ultrasound signal exposure time to the minimum. The sonar energy penetrated through the body in intermittent manner will cause no heating risk for the body in line with international guidelines and regulations of related international organisations [7]. Necessary permissions will be obtained from organisations such as NHS National Research Ethics Service (NRES) and National Patient Safety Agency (NPSA). Device Assessment: i) Trial assessments will be performed to verify the basic functionality of the device. When a first functional version of My-PAD is worn by healthy child volunteers over a 12h monitoring period and then, ii) a trial with healthy child volunteers will be performed to assess sensor performance and comfort at night. After obtaining successful results from previous phases, the device iii) will be tested on children with NE. Throughout there will be focused engagement with the trial participants in group sessions and through individual interviews to gain qualitative and quantitative data and iterate the device design and functionality through an EBCD process.	National Institute for Health Research (Department of Health)	Full Grant	477200.0	GBP
276	Dr Emily Clarke	University of Leeds	School of Medicine	2019-11-01	2023-07-31	Enhanced phenotyping of melanoma whole slide images with artificial intelligence	Background The pathology of melanocytic lesions is one of the most difficult diagnostic areas, resulting in high levels of diagnostic discordance. This project involves the use of convolutional neural networks and random-forest algorithms to afford a reproducible, objective and quantitative assessment of the melanoma phenotype. Aim In this proposed research, we aim to: (1) develop and configure algorithms for the extraction of morphological features at a cellular level to assist the histopathologist in their assessment by providing an automated, reproducible and objective second opinion and (2) explore the use of these morphological features to generate new prognostic biomarkers and better understand melanoma growth patterns. Objectives and Methodology We will employ machine learning methods to generate quantitative cellular data by using a large dataset of whole slide images including atypical melanocytic tumours and melanomas. 3D reconstruction will be performed on a subset of cases to enable improved visualisation and analysis of morphological data as well as comparison to computer-generated models of tumour growth. Data will be correlated with survival and somatic mutation status. Opportunities This novel research will enable the derivation of previously uncaptured phenotypic metrics, which may improve the existing subjective histopathological assessment byproviding an automated second "opinion". It is hoped that this approach will increase diagnostic accuracy in this notoriously difficult area to ensure patients are treated appropriately. These new data may also enable the discovery of new prognostic biomarkers through improved tumour subtyping and through comparing this morphological data to the genomic parameters, we may be able to detect subtle morphological distinctions that indicate the underlying mutation, resulting in improved understanding of the interaction between genotype and phenotype.	Medical Research Council	Fellowship	245899.0	GBP
277	Prof Enkelejda Miho	FHNW University of Applied Sciences and Arts Northwestern	None	2019-10-01	2022-01-01	Discovery of anti-DENV Antibodies Using Artificial Intelligence	<p>Dengue virus (DENV) is a viral pathogen of global health significance: in 390 million<br> cases worldwide, 96 million exhibited clinical symptoms and resulted in 21 thousand<br> deaths. Currently, there are no therapeutic treatments against DENV. DENV is<br> composed of four similar but serologically different viruses (DENV 1-4). Cross-reactive,<br> neutralizing antibodies to all four DENV serotypes may provide an effective passive<br> treatment against severe DENV disease.<br> A large number of potentially successful antibody candidates remain undiscovered due<br> to the complexity of the natural immune response (theoretical antibody repertoire of<br> 10140 potential antibodies). We aim to apply network analyses and machine learning to<br> investigate large amounts of raw high-throughput sequence data from antibody<br> repertoires, resulting in detection of rare, under-represented DENV-specific antibodies.<br> This project aims to discover and develop new neutralizing antibodies for therapeutic<br> treatment of dengue infection and inform vaccine design.</p>	Wellcome Trust	Innovator Award: Digital Technologies	658569.8	GBP
278	Dr Jonathan Clarke	Imperial College London	None	2019-10-01	2023-09-30	Care as a Complex System: Understanding the Network Dynamics of Healthcare Delivery	Health systems are a product of the interactions between healthcare professionals and their patients. These interactions may be understood as networks connecting all actors within the health system to one another through their clinical interactions. In doing so, the provision of healthcare becomes a complex system which may be interrogated and understood using methods of network analysis not previously used in population health research. In the fellowship I will address critical questions facing health systems today, using the latest techniques in machine learning, econometrics and network analysis. I will derive patient-sharing networks to understand how clinical data may be safely, and efficiently shared between patients and clinicians. Through the application of random forest and alternative-specific conditional logit models I will develop new ways to understand how clinical demand is redistributed following sudden or planned changes to hospital services. Using Markov Multiscale Community Detection, I will identify how current primary and secondary care services may be integrated to enhance continuity of care between clinicians while ensuring accountability for the entire population served by the National Health Service. Collectively, the techniques developed during this fellowship will empower patients, clinicians and policymakers to make informed decisions to improve how healthcare is delivered.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	300000.0	GBP
279	Ao. Prof. Dr. Andreas HOLZINGER	Medical University of Graz	None	2019-11-04	2022-11-03	A Reference Model of Explainable AI for the Medical Domain	Towards A Reference Model of Explainable AI for the Medical Domain Andreas Holzinger December, 27, 2018 The progress of statistical machine learning methods has made AI increasingly successful. Deep learning exceeds human performance even in the medical domain. However, their full potential is limited by the difficulty to generate the underlying explanatory structures. The central problem is that they are regarded as "black-boxes" and even if we understand the mathematical principles, they lack an explicit declarative knowledge representation. A motivation for this project are rising legal and privacy issues. This does not imply a ban on automatic learning approaches or an obligation to explain everything all the time, however, there must be a possibility to make results re-traceable on demand - understandable by a human domain expert. We learned of a variety of technical solutions which are currently in development, which could help explain AI/ML systems and their decisions. Transparent algorithms could appropriately enhance trust of medical professionals, thereby raising acceptance of machine learning. Recently, the Google AI team emphasized the significance of research in explainable AI, the importance of Human-Computer Interaction (HCI) research for Knowledge Discovery from Data (KDD), and the urgent need for a research framework around the field of interpretability. In our ongoing research collaboration "Machine learning for diagnosis of colorectal cancer" with the Google AI group and the Institute of Pathology (Ethics Vote Medical University Graz 30-184 ex17/18) a training data set for AI/ML in digital pathology has been generated. As agreed with our colleagues at the Google AI group, we have now the chance to use machine learning algorithms developed in this context for our test environment; in return we will research towards making their algorithms explainable for our domain experts, who have the benefits of using the results for their medical teaching. This project will focus on but is not limited to digital pathological data and context. The advantage of this project is working with real-world data (under full ethics/data protection regulations) together with medical experts. This project will provide important contributions to the international research community in the following ways: evidence in various methods of explainability and novel methods and urgently needed tools for benchmarking and evaluation; Moreover, the contributions gained in this project can be used generally for reverse-engineering human learning and cognitive development and specifically to engineer more human like machine learning systems. All outcomes of this project will be made openly available to the international research community.	Austrian Science Fund FWF	Stand-Alone Projects	392773.5	EUR
280	Dr James Howard	Imperial College London	None	2017-10-04	2020-10-03	Applications of machine learning in clinical cardiovascular imaging	Echocardiography (echo) remains the primary tool through which we assess the function of patients’ hearts. It is cheap, quick and safe. However, interpretation of the pictures can be very difficult and requires years of experience for doctors to accurately identify whether a scan is normal or abnormal. Recently, people have used computer programs to try and help in analysing medical images, and they have shown promise in the field of MRI scanning the heart. In echocardiography, however, training a computer to look at scans has been significantly more difficult. I believe I can overcome these issues by (1) developing a system which can identify exactly what heart structures are being scanned at any moment, and (2) building up a new library of echo scans from which to train a computer so it can analyse these structures. This technique of using neural networks to analyse medical images has many other applications and I am working with co-supervisors to employ my skills in different areas. These include creating a smart phone application which can identify a pacemaker’s model, speeding up the treatment of patients in emergency situations.	Wellcome Trust	PhD Training Fellowship for Clinicians	None	None
281	Dr Marco Caminati	University of St Andrews	Computer Science	2018-02-14	2021-02-13	Stochastic models to enable tailoring of medications to patients with multiple morbidities	We propose to study three common chronic conditions: diabetes, cardiovascular disease and COPD, and their clinical guidelines. In order to find a combination of medications which result in the best outcomes for patients, we need to consider the patient's clinical history, current values and preferences, as well as have a model and treatment information for other patients with similar conditions. For the later, we propose to use Scottish EHRs, specialist disease registry data (e.g., diabetes registry), the national prescribing dataset PIS, and primary and secondary care data in Scotland. This fellowship opportunity will explore combinations of machine learning, formal modelling techniques and automated reasoning approaches commonly used respectively in Theoretical Computer Science and in Artificial Intelligence, to construct (stochastic) models from guidelines and EHRs. This will enable us to compute the optimal medication choices for a patient with one or more chronic conditions, given his/her recorded data and comparisons with similar patients. We will further investigate solutions in the presence of uncertainties and incomplete information. To evaluate the approach, we will develop and test predictive models iteratively using Scottish EHRs and replicate the processes on data from other centres involved in HDR UK, Canada and Brazil.	Medical Research Council	Fellowship	289274.0	GBP
282	Dr Sylvane Desrivieres	King's College London	Social Genetic and Dev Psychiatry Centre	2017-09-01	2019-08-31	Neurobiological underpinning of eating disorders: integrative biopsychosocial longitudinal analyses in adolescents	This project aims to identify early biomarkers of eating disorders (EDs) by applying Big Data methods to the rich database derived from a representative population of adolescents and a clinical sample of emerging adults with an ED diagnosis. First, we will characterise trajectories of ED symptoms in IMAGEN, the largest and most comprehensively characterised longitudinal gene x neuroimaging cohort n=2000 male and female adolescents followed-up at ages 14, 16, 19 and 23 years. We will classify individuals based on their ED symptoms trajectories, using growth mixture models or generalised estimating equations to model the longitudinal course of disordered eating behaviours, including core ED symptoms, a continuous global index of eating pathology and BMI changes. Next, we will use machine learning procedures based on cross-validated regularised logistic regression combining neuroimaging, genomic and psychometric data modalities to identify correlates of EDs and select the features that best classify individuals who endorse ED symptoms along with those who endorse no ED symptoms at any time point. To identify predictors of ED symptoms, we will use age 14 data to compare individuals who developed ED symptoms over time (symptoms absent at age 14 but present at later ages), or those who recovered (symptoms present at age 14, not at later ages) to those who never developed symptoms. Finally, we will select the most predictive and easily applicable components of our comprehensive profile for validation in a clinical sample. This will be patients, aged 18-25 with a 1st episode of DSM-5 AN or BN (n = 50 /diagnosis), assessed through standardised protocols in a way identical to IMAGEN. This paradigmatic multimodal approach, in which neuroimaging may provide added value compared with the existing standard assessments, may yield potential application for early and differential ED diagnoses.	Medical Research Council	Research Grant	230792.0	GBP
283	Professor Aras Kadioglu	University of Liverpool	Institute of Infection and Global Health	2017-07-10	2020-12-31	Mechanisms for acquisition and transmission of successful antibiotic resistant pneumococcal clones pre- and post-vaccination	To understand the molecular mechanisms of emergence, persistence and transmission of antibiotic resistant pneumococci arising before and after the introduction of conjugated polysaccharide vaccines (PCV). To this end, mouse models will be used to study the transmission, colonization and disease capability of antimicrobial resistant pneumococcal lineages. The overall aim being to identify the specific drivers of antibiotic resistant clones and their role in invasive pneumococcal disease and the host immune response in selection and transmission of antibiotic resistant pneumococci.	Medical Research Council	Research Grant	273163.0	GBP
284	Dr Nicholas Meyer	King's College London	Psychosis Studies	2016-10-01	2020-10-31	Detecting early signs of relapse in psychosis using remote monitoring technology	AIM: To investigate the association between disturbances in sleep and circadian rhythm, motor activity, and heart rate variability (predictor variables), and symptomatic deterioration and relapse (outcome variables) in psychosis, using remote monitoring technology (RMT). OBJECTIVES 1) To use RMT to collect predictor and outcome variables in 50 patients with psychosis for up to a year. 2) To evaluate the predictive value and temporal relationship of the bio-signatures for relapse, individually and in combination. 3) To identify evidence for sleep and circadian rhythm disturbance playing a causal role in the development of psychopathology. 4) To gain specific skills in the use and development of RMT in psychiatry, that will allow me to play a role in the future development and evaluation of clinical prediction tools. METHODOLOGY Objective 1: A sample of 50 individuals with psychosis will use the RMT for 12 months. Predictor variables will be gathered using a wrist-worn device and smartphone sensors. Outcome variables are obtained from a twice-weekly, validated smartphone symptom questionnaire, and from fortnightly review of the electronic patient record. Objectives 2 and 3: The strength and temporal association between predictors and outcomes will be modelled using multilevel modelling (continuous symptom fluctuation outcomes) and penalised functional regression (binary relapse outcomes). Additionally, predictive modelling (machine learning) approaches will be used to explore these associations. Objective 4: I will fulfil this training objective through the running of this study, and in visits to project supervisors and collaborators at this and other centres of expertise. SCIENTIFIC AND MEDICAL OPPORTUNITIES Results may have far-reaching implications for the development of a relapse prediction tool for psychosis, and for understanding the relationship between sleep disruption and psychopathology.	Medical Research Council	Fellowship	243384.0	GBP
285	Dr Sach Mukherjee	MRC Biostatistics Unit	None	2014-03-01	2016-11-30	Statistics and machine learning for precision medicine	Our work focuses on the development and application of statistical and machine learning approaches that can exploit molecular and genomic data to assist in directing therapies to patients likely to benefit. Our efforts encompass both (i) direct prediction of therapeutic response and (ii) scalable estimation of molecular networks and dynamics that can shed light on disease mechanisms and heterogeneity, inform prediction of response and help in identifying promising therapeutic opportunities. We work on specific biomedical questions, addressed in collaboration with experimental groups, as well as methodological research in statistics and machine learning motivated by such questions. The potential of computational approaches in medicine is increasingly clear, but the challenges posed by noisy and incomplete data, biological and clinical heterogeneity and complex underlying processes and dynamics remain substantial. Our work is aimed at developing and exploiting statistical methods that can help to surmount some of these challenges. High-dimensional approaches, networks and graphical models and inference for dynamical systems are key methodological themes in much of our work. Two key ongoing projects are: Data-driven characterization of biological networks in cancer. How is the genomic heterogeneity of cancer manifested at the level of biological networks, such as those involved in cell signalling? Do cancers show altered “wiring” due to genomic aberrations? And if so, how? In close collaboration with experimental partners, we are working on both theoretical and applied aspects of these questions. We are also investigating whether protein signalling networks differ by cancer type and how networks can be used to help discover and define cancer subtypes. Finally, we are developing scalable methodologies by which to systematically assess causal network estimation approaches using interventional data. Statistical methods for personalized medicine. We are addressing statistical challenges that arise in the prediction of drug response from multiple high-throughput data types. These challenges include the large number of potential predictors (high-dimensionality), heterogeneity arising from known and unknown disease subtypes, limited number of samples and the need to integrate multiple data types.	Medical Research Council	Unit	None	None
286	Dr Dominic Waithe	University of Oxford	Weatherall Inst of Molecular Medicine	2018-04-01	2021-03-31	Quantitative and Real-Time Image Analysis for Advanced Light Microscopy.	In terms of microscopy analysis, great inroads have been made in terms of impartial and systematic analysis but little has been done to ensure that cells under the microscope are selected impartially. For this project DW will develop algorithms that can statistically quantify and describe cellular appearances utilizing the latest machine learning, computer vision (CV) and signal processing techniques and technologies. DW has in ongoing work investigated the use of CV algorithms in microscopy and has shown very promising results can be achieved by utilizing object detection convolutional neural networks for cellular detection. DW will extend on his use of neural networks for localizing cells (objectives 1-2) and will also develop methods to statistically describe cellular appearance using networks derived from auto-encoders (objective 3), a type of compression network. Neural networks are implemented in several ways, a popular method is to use Tensorflow and DW is an expert in this language. To effectively train neural networks, powerful GPUs are required. Fortunately the WIMM has various computational facilities and DW has access to two powerful GPU equipped servers. For developing CV and real-time analysis approaches to work with camera and detector hardware, DW will work toward developing algorithms that can be embedded in miniaturized electronics (objective 4). The Nvidia Jetson TX2 Developer kit is a resource which allows you to create and develop neural networks and distribute them onto small hardware boards. DW will develop and test this hardware technique with microscopy based hardware and algorithms. For objectives 5 and 6 GPU code will be systematically produced in CUDA and will be made as compatible and distributable as possible. Oxford University has several microscopy software development projects (e.g. in Micron) and it is intended that the software and libraries produced by this project will be made compatible with these other projects.	Medical Research Council	Fellowship	345783.0	GBP
287	Dr Yasemin Hirst	University College London	None	2016-05-01	2017-12-31	CRUK Guardian Angels	Background: Most patients with cancer present with symptoms / via symptomatic routes (including emergency, urgent two week GP referrals or other – non-urgent- referrals). One year survival following the cancer diagnosis relies on early detection.Helping doctors to suspect cancer after patients have presented with symptoms is obviously crucial – but at the same time it is also crucial to support patients to seek help soon after symptoms have developed. Delays in patients' symptom appraisal and help-seeking have usually been studied retrospectively in surveys and interviews. However, there is vast amount of existing data available in the digital and commercial platforms to be used in prospective and complex study designs. To some extent, individual (e.g. google searches, symptom checkers), consumer (e.g. loyalty card) and clinical data (GP visits, referral etc) have previously been a focus of research but have not yet been investigated collectively to understand delays in symptom appraisal and help-seeking in cancer alarm symptoms. Aims: The proposed research aims to investigate delays in symptom appraisal and subsequent help-seeking behaviour using 'Big Data'. The future aim is to link individual, consumer and clinical datasets via a secure mobile phone application, and assess whether it is possible to identify signs of cancer looking at behaviour change and self-assessment using machine learning algorithms. Methods: The project includes three multidisciplinary (Health Psychology, Computing, Advanced Statistics and Cancer Epidemiology) studies that will (a) explore the lay language that is being used to articulate cancer symptoms in order to generate a dictionary of possible online search terms, (b) investigate the associations between symptom perception and behaviour change using consumer data, e.g. continuous purchase of cough medicine etc., and (c) explore public perceptions on data linkage to monitor cancer risk/warning signs. The first two studies will be using data-mining techniques, and the last study will conduct focus groups using inductive thematic analysis to assess the acceptability of using data linkage to monitor indicators of cancer symptoms. How the results of this research will be used; Beyond our future ambition, this project aims to produce a glossary based on lay expressions of cancer symptoms in order to better understand online information-seeking behaviours. We also aim to provide a detailed report on the availability of data from different resources, and evaluate the feasibility of the prospective studies. The results of this project will initiate further cancer research into understanding the ever increasing volumes of data across disciplines.	Cancer Research UK	PRC - Early Diagnosis - Innovation Grant	None	None
288	Dr Elizabeth Baranowski	University of Birmingham	Inst of Metabolism & Systems Research	2018-09-11	2020-12-10	Steroid Metabolomics for Diagnosis and Monitoring of Inborn Steroidogenesis Disorders	Aims: Improve the life-long health of patients with inborn steroidogenic disorders, including congenital adrenal hyperplasia (CAH) and disordered sex development (DSD), through improved tools for diagnosis and monitoring. Objectives: 1. Machine learning analysis of urinary steroid metabolite data. 2. Statistical comparison this metabolomics approach to the conventional biochemical approach. 3. Incorporation of neonatal-specific steroid metabolites to enhance the diagnostic performance in young children. 4. Development of a high-throughput urinary steroid profiling method. 5. Investigating the use of a machine learning-based "adrenal age" to monitor treatment quality in CAH. Methodology: We have developed a machine learning method, Angle Learning Vector Quantization (ALVQ), to discriminate healthy controls and patients with CAH and DSD. Further work will be done to extend this approach to very rare enzyme defects. Examining untargeted GC-MS spectra of urine from healthy babies under 6 months, I will identify important neonatal metabolites, inclusion of which will enhance diagnostic performance in newborns. I will develop a rapid high-throughput method for steroid profiling and use it to measure samples from CAH patients on two different glucocorticoid preparations. Using machine learning, I can determine an age-specific steroid metabolome prototype, an "adrenal age", and will examine whether the two treatments result in different distances from the adrenal age prototype and whether those relate to currently used biochemical and clinical markers of treatment quality. Scientific/Medical Opportunity: An interpretable machine learning method, utilising the entire steroid metabolomics fingerprint, informed by steroid biology, on a sensitive high-throughput platform represents an excellent novel test for diagnosis and treatment monitoring. This will enable clinicians to personalise treatment, and improve control and outcomes for these patients.	Medical Research Council	Fellowship	167889.0	GBP
289	Dr Andre Fujita	University of Sao Paulo	None	2018-03-31	2020-03-20	A model-based graph clustering approach for autism stratification	Autism spectrum disorder (ASD) is usually diagnosed by behavioral analyses and currently there is no objective test. Even the latest computational methods (e.g. support vector machine and deep learning) based on analyses of bloodoxygen-level dependent (BOLD) signal yield classification accuracies of about 60 to 70%, which are unsatisfactory for clinical use. However, if we focus on a group of individuals sharing a specific phenotype, we obtain better results, probably because there is more than one “type” of ASD. Thus, our main goal is to stratify the ASD into subgroups, not by the direct analysis of the BOLD signal as it is usually done, but by the functional brain network (FBN) based on the BOLD signal. The rationale is that ASD can be explained by the differences in how neurons interact. However, there are at least three technical drawbacks with this approach: (i) to the best of our knowledge, there is no method to cluster FBNs (note that this problem is different of the clustering of the vertices of the network as done by the spectral clustering algorithm); (ii) even individuals belonging to the same group present different FBNs (intrinsic fluctuation), which makes the analysis using standard computational methods unfruitful; and (iii) confounders such as age, gender, and other clinical parameters may affect the clustering structure. To overcome these problems, we will represent the FBNs as random graphs and assume that probabilistic models (e.g. Watts-Strogatz and Barabási-Albert models) generate the FBNs. Then, we will define that FBNs generated by the same model belong to the same group while FBNs generated by different models belong to different groups (similar to the Gaussian mixture model). Confounders’ effects will be removed by covarying the probabilistic distributions. We hope this stratification contribute for a better understanding of the mechanisms underlying ASD. To develop this method, Dr. Fujita of USP contacted Dr. Mourao-Miranda of UCL to complement his expertise in classification methods. Dr. Fujita works on statistical methods on graphs while Dr. Mourao-Miranda is specialist in machine learning with applications in psychiatric disorders. To train Dr. Fujita’s group in the field of machine learning, the partners will organize two courses, one at UCL and another at USP. Moreover, two Ph.D. candidates from USP will be sent for six months each one to UCL to study cutting-edge classification techniques. This project is essential to obtain novel insights, solidify this cooperation, and improve the quality of this research.	The Academy of Medical Sciences	Newton Advanced Fellowship	61814.0	GBP
290	Professor Alexey Zaikin	University College London	Women's Cancer	2019-01-15	2022-01-14	HSM: Construction of graph-based network longitudinal algorithms to identify screening and prognostic biomarkers and therapeutic targets (GBNLA)	The methodology developed will be based on the previously proposed idea of parenclitic network analysis. This method will enable the representation of parameters corresponding to individual patients and controls in graph form without a priori knowledge of the interactions between them. The strength of the links will be estimated based on how different they are from those in healthy control subjects. In addition to the original estimation based on linear regression, we will use estimates based on two-dimensional kernel density estimation. The generated graphs or networks will be analysed using topological indices, widely used for characterising complex networks, e.g. mean, variance, and maximal values of edge weights, vertex degree, shortest path lengths, Kleinberg,, diameter of the graph, the degree centrality, network efficiency, betweenness centrality, Google maximal page rank index, number of communities and so on. The obtained metrics corresponding to one moment in time will be obtained for all available serial measurements and then linked to the serial algorithms such as change-point detection methods, parametric empirical Bayes and methods of mean trends. All these methods have already been successfully applied by us for data analysis. In order to combine and compare our methodology with other machine learning network algorithms, we will link it to community detection analysis and various types of shallow and deep artificial neural networks. We will also compare our methods with basic algorithms and models such as Bayesian networks, decision trees and forests, and advanced SVM methods. In order to identify data-specific features of the methodology we will test all newly developed algorithms on very different datasets, testing their potential for different tasks in clinical and biotechnological practice.	Medical Research Council	Research Grant	469754.0	GBP
291	Ms Claudia Wehrspaun	University of Oxford	None	2011-10-01	2015-09-30	Development of novel meta-machine learning algorithms for the integration of genomic and neuroimaging data for genetic pathway discovery: application to Parkinson's disease and schizophrenia.	No Data Entered	Wellcome Trust	WT/NIH Four Year PhD Studentship	70000.0	GBP
292	Dr Matthew Kempton	King's College London	Neuroimaging	2012-10-01	2018-06-30	Trajectory of Brain Structure and Function before and after the Onset of Psychosis: a Longitudinal Multicentre Study	The aim of this study is to characterise the trajectory of brain structure and function before and after the onset of psychosis. Specifically I will examine changes in the volume of the insula, hippocampus and lateral ventricles and test the hypothesis associated with the theory of Tony Grace that functional connectivity between these regions increases prior to psychosis. A secondary aim is to predict who will develop psychosis by applying machine learning techniques to the longitudinal data. The fellowship is to fund longitudinal MRI scans of subjects with an at risk mental state (ARMS), 25-30% of whom are expected to develop psychosis within 2 years of contacting medical services. The baseline MRI scans are already being collected as part of the EU-GEI project. However there were no plans in the original study to do subsequent scanning. My proposal aims to capitalise on this ARMS sample, which is an order of magnitude larger than any examined in previous studies. Scanning will be completed at 7 centres which each have ARMS clinics and a 3T MRI scanner. ARMS subjects will be scanned at the point of transition and 12 and 24 months after transition; those who do not transition to psychosis and healthy controls will be scanned 3, 12 and 24 months after the baseline scan. Analysis of the structural MRI data will be conducted with FreeSurfer and software developed by my collaborator Paul Thompson and resting state fMRI data will be analysed with FSL MELODIC. I will use support vector machines to predict psychosis transition from the imaging and clinical data which would have immediate translational benefits. Changes in brain structure and function before psychosis raises the intriguing possibility that future therapies may be able to arrest these changes. Charactering the trajectory of these changes would indicate which regions of the brain are first affected, and establish a reference point to compare the effects of preventative treatment strategies.	Medical Research Council	Fellowship	1227953.0	GBP
293	Professor Adnan Custovic	Imperial College London	Dept of Medicine	2015-09-15	2017-07-14	MICA: STELAR (Study Team for Early Life Asthma Research) consortium - Asthma e-lab and identification of novel endotypes of childhood asthma	Asthma epidemiology is reaching the limit of what can be achieved through conventional hypothesis-driven research. We hypothesise that asthma is not a single disease, but a condition comprising multiple distinct disease entities (asthma endotypes), each with characteristic pathophysiology and risk factors, and that unbiased novel endotypes of asthma can be identified using complex, rich and expanding datasets from existing UK birth cohort studies by applying a combination of biostatistical and machine learning methods. We propose to form a major Alliance between MRC-funded network of all UK-based birth cohorts designed to study asthma (STELAR consortium), expertise in epidemiologically oriented health informatics research (NW Institute for Bio-Health Informatics) and experts in statistical machine learning (Microsoft Research Cambridge). We will capitalise on the unique collection of well characterised birth cohorts with harmonised clinical outcomes (ALSPAC, SEATON, MAAS, Ashford, Isle of Wight). We will create a secure web-based research environment (Asthma e-Lab) to support consistent recording, description and sharing of data and emerging findings across all partners, thus enabling collaborative epidemiology in near-real-time. The activities of data managers and researchers from the 5 STELAR sites will be made visible to one another, supporting team coordination and peer support and creating a scientific social network to enrich the ongoing modelling and interpretation. We will create and maintain across the consortium annotated dependency graphs of the problem space around the organising principles underlying asthma, and use a machine learning approach interactively over the combined datasets via Asthma e-Lab to discover the unbiased endotypes of asthma. Our findings may underpin new trials of asthma prevention and treatment, personalised for specific endotypes and may help identify novel targets for the discovery of endotypes-specific stratified treatments.	Medical Research Council	Research Grant	568951.0	GBP
294	Dr Rashmi Patel	King's College London	Psychosis Studies	2013-01-14	2016-01-13	Predicting clinical and functional outcomes in psychosis using machine learning	Background Psychotic disorders are responsible for an enormous burden of illness upon individuals and society as a whole (Perala 2007). Structural, functional and DTI MRI studies have shown that the onset of psychosis is associated with changes in brain structure and function (Smieskova 2010 and Pettersson-Yeo 2011). However, it has been difficult to apply such group level findings to a clinical population at the level of the affected individual. This may reflect the overlapping genetic, neurobiological and clinical features of current diagnostic classification systems, which cannot reliably predict the course and outcome of psychotic disorders (Van Os 1997). Aims My project aims to analyse clinical and neuroimaging data of patients with psychotic disorders using Support Vector Machine learning (SVM) and Machine Kernel Learning (MKL) in order to generate more robust systems for classifying illness and predicting outcomes at the level of the affected individual. Methods (i) SVM analysis of data of patients with psychosis from a large, prospective case register (CRIS) to characterise clinical and functional outcomes and predict these with baseline clinical data at first episode. (ii) Individual SVM analysis of clinical data, structural MRI, DTI and fMRI of patients with first episode psychosis to predict the same outcomes. (iii) Analysis of clinical and neuroimaging data using MKL to investigate if combining modalities increases predictive power. Implications Prediction algorithms generated from this project will be further validated using a prospective dataset with the aim of subsequently evaluating successful algorithms in clinical studies. Generating reliable algorithms for predicting outcomes in psychosis may help to develop more effective and personalised treatments.	Medical Research Council	Fellowship	174832.0	GBP
295	Professor Diana Baralle	University of Southampton	None	2017-12-01	2022-11-30	Translational genomics- maximising potential for NHS patient care.	Genomics is the foundation of modern personalised medicine with the acknowledged potential to improve diagnostic accuracy, stratify disease and personalise treatment for immediate patient benefit. Projects to develop genomics in clinical practice are the epitome of the NIHR vision to improve the health and wealth of the nation through research and translation to patient care.Genomics England have kick-started a genomics industry with the 100,000 genomes project which targets patients with rare disease and cancer. One in seventeen people are born with or develop a rare disease during their lifetime and at least 80% of rare diseases have an identified genetic component; 50% of new cases are identified in children. Accurate diagnosis is fundamental in medicine enabling discussion of prognosis, screening, prenatal testing, family cascade testing and possible treatments. 1 in 3 people will get cancer and genomics transforms pathology to enhance the right treatment to the right patient.As implementation of high throughput sequencing into medicine escalates, the challenge remains to effectively translate these findings into diagnostic tests and future treatments. It is estimated that genomes will generate >10 million sequence variants between one individual and another. Each sequence variant must undergo functional verification, herein lies the bottleneck. l aim to use RNA to find missing mutations and provide a legacy for the interpretation of genetic variation in human disease, transforming clinical care.Many mutations in coding regions or introns may appear not to affect protein function but are still potentially causing disease through affecting pre-mRNA splicing. Between 15-50% of unclassified sequence variants (UVs) found at genomic analysis could influence RNA splicing.? Other forms of RNA have also been shown to be important in disease, e.g. non-codingRNA.Aim Development of a diagnostic RNA pipeline, maximising the impact of genome tests for patient benefit and provide a national resource for the NHS.DeliverablesShort term-i) Construct RNA pipeline for testing. Medium term-i) Diagnostic uplift through variant verification in a known disease gene for clinical care (not possible without RNA pathway output). ii) Diagnostic uplift through discovery of new genomic causes of disease.iii) RNA based disease signatures.Long Term-Understand disease processes, for personalised medicine and therapies.The Southampton comprehensive RNA analysis diagnostic pipelinePipeline overview- Figure 6 will have 3 componentsDesign and Methods?Strategic Patient cohortsi) 50 Primary ciliary dyskinesia patients; exome sequencing of key PCD genes completedii) 50 Clinical immunology patients. RNA samples storediii) 200 patients selected from the 100,000 genomes project where RNA is available and genome testing has identified variants of unknown significance [Genomics England supported]Optimisation of RNA tests to establish the pathway In silico/bioinformatic prediction of effect of sequence variants on both genome and transcriptome. In collaboration, research and development of bioinformatics computer software tools for genetic diagnostic testing with regards to splicing and RNA, including, machine learning and RNA Seq.?RNA analyses through patient RNA samples and minigene assays -measurement of RNA levels by RT-PCR or minigene analyses. Develop standard operating procedures for progress through bioinformatics to wet lab.Transcriptome analysis (blood, tissue, single cell (immunology cohort); messenger RNA and non-coding RNA). Each sample will be sequenced at sufficient depth to be able to perform an accurate and exhaustive analysis of RNA splicing patterns as well as identification of long non-coding RNAs and fusion transcripts.Gene function hub. Ultimately this technology will be an integral arm to a functional genomics hub- in collaboration, to prove gene pathogenicity. Including cell assays, biochemical assay, in vivo studies, RNA or methylation assays.Figure 5 for network of facilities and support.	National Institute for Health Research (Department of Health)	Full award	1870764.0	GBP
296	Ao. Univ. Prof.Dr. Alexandra KAUTZKY-WILLER	Medical University of Vienna	None	2019-01-21	2022-01-20	Gender Outcomes and Well-being Development Group (GOING-FWD GNP78)	Gender Outcomes INternational Group: to Further Well-being Development (GOING-FWD) Background: Beyond biological sex, gender is increasingly recognized as a pivotal determinant of health. However, there are no standardized gender measurements. We hypothesize that gender-related factors and their effect will vary substantially between countries and diseases. Aims: The overarching aims of this large Consortium are to integrate sex and gender dimensions in applied health research, to evaluate their impact on clinical cost-sensitive outcomes and patients reported outcomes related to quality of life in noncommunicable diseases including cardiovascular disease, metabolic disease, chronic kidney disease and neurological disease. We also aim to construct innovative ways to disseminate the application of gender measurement towards personalized approaches to chronic disease prevention, diagnosis and treatment. Methods: With a five-country transatlantic network comprised of 30 investigators, we will benchmark innovative solutions to measure gender in retrospective cohorts. Based on consensus, we will develop a framework to identify gender-related factors, as well as cost-sensitive and patients reported outcomes and measure their associations in 32 accessible cohorts of patients affected by cardiovascular, chronic kidney and neurological diseases and metabolic syndrome. Large database analysis and when appropriate machine learning approaches will allow the derivation of pan and within country disease specific gender scores which will be validated through e-Health and m-Health applications in prospective disease groups. Educational modules will be developed to promote awareness, implementation and dissemination. Innovation: As a five-country multidisciplinary Consortium with access to granular large databases, we are uniquely positioned to harness an innovative methodology that will provide a framework to close gender gaps in chronic disease management and promote knowledge transfer in the scientific community and clinical practice.	Austrian Science Fund FWF	02 International programmes	298552.8	EUR
297	Univ.Prof. Dr. Matthias SCHMUTH	Medical University of Innsbruck	None	2019-05-01	2022-04-30	Biomolecular Analyses for Tailored Medicine in AcneiNversa (BATMAN)	Acne Inversa (AI) is a chronic inflammatory disease involving hair follicles that imposes a major physical and psychological burden on patients with significant costs for health systems. Genetic variants affecting different pathways result in wide spectrum of AI phenotypes and tracking gene variants is essential to design personalized treatments. The proposal aims to bring together medical, genetic, experimental and lifestyle data to create holistic health records (HHR), which will allow us to build a personalized model of each patient and to tailor specific treatments based on their personal characteristics. Research on animal or cellular models will be harnessed to validate hypotheses on genetic variants, generating useful information with immediate translational impact on patient stratification and therapeutic options, and also providing a wide-scale overview of previously identified and novel risk markers. DNA will be obtained from AI cases from 3 different locations in Europe. Data will be compiled from whole exome sequencing, whole genome genotyping SNPs arrays and transcriptomic signatures of hair follicle cells and novel mouse models. Genomic information will be merged with clinical evaluations and lifestyle data by advanced machine-learning and data mining algorithms. By the end of the project, our consortium intends to: • identify genetic variants associated with AI susceptibility, severity and response to treatment • design in vivo and in vitro models for investigations on the main biological pathways affected by AI and testing the impact of genetic variants on immune and cutaneous cell biology • produce an HHR to complement medical record by developing a smartphone application to remotely monitor the physical and psychological wellbeing of patients and advise them on physical activity and dietary and smoking habits • propose novel stratification methods that clinicians can use to assess severity, choose the therapy and follow the outcome	Austrian Science Fund FWF	02 International programmes	91230.13	EUR
298	Professor Stephen Wood	University of Birmingham	School of Psychology	2013-06-10	2018-12-31	Linear and non-linear brain changes over the transition to psychosis	The course of schizophrenia is associated with significant brain changes. Exactly when these changes occur is a matter of debate, with significant evidence now available for progressive volumetric declines early in the illness (the first 12 to 24 months post-onset). However, there is additional evidence for the decline beginning before that, during the prodromal period. In this study we seek to replicate findings of progressive structural brain changes across the transition to psychosis in a group identified as at ultra high risk for psychosis. Furthermore we will extend these findings to establish the precise trajectory of these changes, whether measures of functional connectivity also show such change, and to what extent they can be used in pattern classification algorithms to improve predictions of who will or will not develop a psychotic illness. We propose to recruit 120 young people meeting criteria for the at-risk mental state, based on the presence of attenuated psychotic symptoms and/or a family history of schizophrenia or personal history of schizotypal personality disorder. Those with the greatest risk of transition to psychosis, along with 24 healthy controls, will be scanned repeatedly over the subsequent year to establish the longitudinal trajectories of brain structural and functional changes over the onset of psychosis. Specifically, we will use a linear mixed model regression approach to capture the dynamics of the pathological processes before and just after transition in both cortical thickness and measures of global network topology. We will use a machine learning approach to analyse longitudinal brain changes associated with different clinical courses. This will allow us to model transition probabilities and improve prediction of outcome. We hypothesise that the most rapid brain changes will be seen either side of transition, and that longitudinal brain changes will provide better prediction of later transition than baseline images.	Medical Research Council	Research Grant	808010.0	GBP
299	Professor Martin Landray	University of Oxford	None	2016-07-01	2019-03-31	Methodological innovation in large-scale epidemiology	Advances in biomedical and healthcare data science offer the potential of dramatic changes in the scale (size, breadth, depth and duration) and efficiency (data accumulation, storage, processing and dissemination) of clinical trials and observational studies. However, in order to maximise the scientific and public health returns from these new opportunities, it will be important to design systems and approaches that are focused on the key drivers of study quality and essential to ensure that their appropriate use is unencumbered by disproportionate regulatory or bureaucratic obstacles. Our programme comprises three, overlapping elements: Streamlining the design, conduct and analysis of population-based studies: We are developing and evaluating new methods for efficient recruitment (including use of routine clinical data), data collection (e.g. electronic case report forms, scalable approaches to assessment of cognitive function and physical activity), trial management (e.g. to maximise adherence to treatment, completeness of follow-up), quality assurance and trial oversight (including central statistical monitoring and rational pharmacovigilance), adjudication and clinical phenotyping (including theoretical and empirical research on the impact of different approaches on study results), data analysis (e.g. modular tools, test suites, ontological tools, and use of CDISC standards), and data sharing (e.g. clinical trial adverse events, controlled approaches for observational studies). Big Data for Population Health Research: This work centres on the collection, analysis and interpretation of population scale biomedical data. In conjunction with the University of Oxford Big Data Institute (www.bdi.ox.ac.uk) and using the streamlined approaches to building and managing large cohorts outlined above, this work focuses on new approaches to the measurement of health and disease. Examples include the use of genomics and immune profiling, imaging (e.g. morphology, digital pathology, radiology), mobile sensors and cameras (e.g. to assess activity and behavioural factors), and patient-oriented applications (e.g. to assess cognitive function, mood, quality of life, diet). Where appropriate, machine learning and other novel statistical approaches are used to analyse these complex, heterogeneous datasets and draw inferences about the causes and consequences, prevention and treatment of disease. Proportionate regulation of large-scale clinical trials and observational studies: This work seeks to promote the development and adoption of regulatory approaches that facilitate high quality clinical research. This work is founded on the key principles of protecting the rights, safety and well-being of study participants and ensuring the reliability of the study results (which influence the clinical care of future patients). For example, most clinical trial regulations and guidelines were written many years before the widespread use of information technology and the internet, and are no longer fit for purpose. We work with regulators, industry, academia and patient advocates to identify issues, develop recommendations, make the case for change, and encourage the adoption of more appropriate regulatory approaches in areas such as clinical trials, access to clinical data, and sharing of research data.	Medical Research Council	Unit	None	None
300	Professor Tony Pridmore	University of Nottingham	School of Computer Science	2018-09-01	2022-08-31	PhenomUK - Crop Phenotyping: from Sensors to Knowledge	PhenomUK is a Technology Touching Life network proposal centred on plant phenotypic technologies. Its primary aim is to foster interdisciplinary research into innovative, and potentially disruptive, technological capabilities that will drive world-leading discovery research in plant and agricultural science. It will do this by bringing together the engineering and physical and life science communities to consider novel technologies and their integration to a degree not achieved by previous projects driven by specific biological hypotheses and objectives. Attention will centre on the combination and integration of existing and emerging phenotyping technologies in three directions: 1. Across phenotyping contexts, to maximise the benefit obtained from the different types of knowledge created by phenotyping 2. Across biological and temporal scales, to produce much richer data streams than are currently available 3. Over time, creating robust phenotyping systems incorporating sensor selection and placement, data acquisition, fusion, analysis and management. This will position the UK to play a leading role in the rapidly developing international phenotyping community and obtain maximum benefit from emerging technologies and the many stand-alone phenotyping tools and data sets developed to date.	Medical Research Council	Research Grant	528567.0	GBP
301	Dr Rune Nyrup	University of Cambridge	None	2018-10-01	2020-03-31	Understanding Medical Black Boxes: A Philosophical Analysis of AI Explainability	I plan during the next two years to develop a major, multi-year project into AI explainability in medical contexts. This project will connect existing literatures in philosophy of science, philosophy of medicine and medical ethics, where problems of understanding and explanation have been extensively studied, to the emerging literature on explainability in machine learning and the ethics of AI. The aim will be (i) to enhance our understanding of the problems AI systems raise for explainability in medical contexts and (ii) to collaborate with machine learning researchers to develop technical research apt to address these problems. The existing literatures on explainability and understanding in medicine are vast and have not previously been systematically connected to the ethics of AI. To lay the groundworks for a later grant proposal, this application proposes to conduct three pilot-studies, focusing on potential challenges from AI to: (1) mechanistic understanding, (2) clinical judgement and diagnostic reasoning and (3) informed consent. A part-time research assistant will assist in scoping the relevant literatures. Travel to groups at other universities and a workshop in Cambridge will furthermore help establish contacts with a network of researchers interested in the ethics of AI and AI explainability in medical contexts.	Wellcome Trust	Seed Award in H&SS	86561.0	GBP
302	Mr Abhishek Mishra	University of Oxford	None	2018-10-01	2021-10-01	Delivering Care Through AI Systems	For this project, I aim to examine 4 issues. First, I will consider whether introducing machine learning (ML) systems requires a revision of the ‘standard of care’ for clinicians, by understanding the moral permissibility of using second-hand information (from ‘black box’ systems) and whether practitioners’ medical expertise justifies judgments about such systems. Second, given the possibility of ML systems systematically underserving groups that are underrepresented in the training data, I will consider accounts of distributive justice to operationalize ‘equal access to care’. Third, to address the disagreements between clinicians on how to trade-off risks in clinical choices, I will catalogue the factual, rational, and moral sources of this disagreement to yield a principled method of evaluating these trade-offs. Finally, I will weigh the potential harms and gains from deploying AI systems in healthcare so that certain ethical and legal arguments don’t deprive society of the good such systems can provide. Key goals: • To represent the ethical concerns in deploying AI systems over the appropriate standard of care, ensuring equal access to care, and representing reasoning about risk trade-offs. • To balance these concerns against the benefits of such a deployment. • To deliver practical ethical guidance to healthcare policy-makers and AI system-builders.	Wellcome Trust	PhD Studentship in H&SS	140538.0	GBP
303	MSc BSc Rafael REISENHOFER	University of Vienna	None	2018-10-15	2020-10-14	Depth and Discriminability in Deep Learning Architectures	Deep neural networks have recently provided astounding results in a wide range of classification and regression tasks. This has sparked a renewed interest in the rigorous mathematical analysis of deep neural network architectures with the goal of uncovering the underlying principles that facilitate their groundbreaking success. Recent fundamental results already provide a better understanding of the relationship between depth and expressive power as well as a detailed analysis of the approximation properties of deep neural networks. It was also shown that certain types of convolutional neural networks exhibit desirable invariance properties such as stability with respect to small deformations. The present proposal aims at a mathematical investigation of another important property of a deep learning architecture, namely its discriminatory behavior. In most classification tasks, different classes are intertwined in a complex manner in the input space. In order to succeed, the realization of a deep neural network needs to disentangle those classes such that they can be separated in the corresponding feature space. Our goal is to better understand how the depth and other characteristics of a neural network influence its discriminatory power in the sense that they facilitate a clear separation of signal classes. Eventually, we aim to prove statements that quantify the discriminative power of a deep learning architecture with respect to distinct classes of signals as a function of depth and properties of the corresponding signals. The classification behavior of a neural network is mostly determined by its invariance properties on one side and its discriminatory properties on the other side. We will thus focus our investigation on a special class of convolutional neural networks, so-called scattering networks, for which substantial results regarding invariance and stability have already been established. We furthermore aim to utilize that when considering the modulus squared as a non-linearity, the output of each layer in a scattering network can be explicitly written as a cascade of autocorrelations in the frequency domain. In the initial phase of the project, we will investigate the discriminatory properties of scattering architectures with respect to simple template signal classes, such as signals that are sparse in the time or frequency domain. We then aim to extend our analysis to signal classes that resemble the structure of practical machine learning tasks in the sense that they are defined by shifts and time-frequency deformations of single prototype signals. Eventually, we aim to translate our theoretical findings into applicable guidelines regarding the optimal design of deep learning architectures for specific classification tasks. The research will primarily be conducted by the applicant (Rafael Reisenhofer) on a full-time basis. The work of the applicant will be supported by the invaluable expertise of the co-applicant (Philipp Grohs).	Austrian Science Fund FWF	None	156140.0	EUR
304	Assoz. Prof. Dr. Klaus SCHÖFFMANN	University of Klagenfurt	None	2018-10-01	2021-09-30	Relevance Detection of Ophthalmic Surgery Videos	In this project, we want to investigate fundamental research questions in the field of postoperative analysis of ophthalmic surgery videos (OSVs). More precisely, three research objectives are covered: (1) Classification of OSV segments - is it possible to improve upon the state-of-the-art in automatic content classification and content segmentation of OSVs, focusing on regular and irregular operation phases? (2) Relevance prediction and relevance-driven compression - how accurately can the relevance of OSV segments be determined automatically for educational, scientific, and documentary purposes (as medical experts would do), and what compression efficiency can be achieved for OSVs when considering relevance as an additional modality? (3) Analysis of common irregularities in OSVs for medical research - we address three quantitative medical research questions related to cataract surgeries, such as: is there a statistically significant difference in duration or complication rate between cataract surgeries showing intraoperative pupil reactions and those showing no such pupil reactions? We plan to perform these investigations using data acquisition, data modelling, video content analysis, statistical analysis, and state-of-the-art machine learning methods - such as content classifiers based on deep learning. The proposed methods will be evaluated on annotated video datasets ("ground truth") created by medical field experts during the project. Beyond developing novel methods for solving the abovementioned research problems, project results are expected to have innovative effects in the emerging interdisciplinary field of automatic video-based analysis of ophthalmic surgeries. In particular, research results of this project will enable efficient permanent video documentation of ophthalmic surgeries, allowing to create OSV datasets relevant for medical education, training, and research. Moreover, archives of relevant OSVs will enable novel postoperative analysis methods for medical research questions - such as causes for irregular operation phases, for example. The research project will be a cooperation between computer scientists of AAU Klagenfurt (conducted by Prof. Klaus Schöffmann, supported and advised by Dr. Mario Taschwer and Prof. Laszlo Böszörmenyi) and ophthalmic surgeons and researchers at Klinikum Klagenfurt (Dr. Doris Putzgruber-Adamitsch, Dr. Stephanie Sarny, Prof. Yosuf El-Shabrawi).	Austrian Science Fund FWF	None	379635.38	EUR
305	Prof Jan Herman VELDINK	UNIVERSITAIR MEDISCH CENTRUM UTRECHT	None	2018-07-01	2023-06-30	Emerging Simplex ORigins In ALS	My aim is to understand the exact genetic contribution in every patient with Amyotrophic Lateral Sclerosis (ALS), a lethal disease with a life time risk of 0.3% and an urgent unmet therapeutic need. I have recently shown a disproportionate large contribution from low-frequency genetic variants in ALS. ALS is not simply a collection of unique rare diseases with a monogenetic cause nor is it a diagnostic continuum with a complex contribution of thousands of small effect factors. ALS is in-between, which I call “simplex”, where in each patient a few, considerably strong genetic factors with or without environmental factors are at play. ALS mutations are characterized by reduced penetrance, variable clinical expressivity, have specific pleiotropic clinical features and interact with environmental factors. These phenomena are unexplained, but provide me with important and new opportunities in order to unravel the clinical, genetic and biological heterogeneity in ALS. I have created new research fields to go an important step beyond the state of the art: Splitting by lumping uses novel machine learning algorithms to reclassify patients using clinical pleiotropic features, environmental factors and blood epigenetic profiles to identify novel ALS mutations. Imaging genomics overlays patterns in ALS-associated brain morphology on MRI with brain gene-expression patterns to find ALS mutations. ALS risk in 3D integrates data on three-dimensional folding of DNA with genetic data to identify causal mutations and mutation-to-mutation interaction. ALS genomic modifiers in 3D identifies modifiers of C9orf72 mutations through the development of cellular reporter assays and CRISPR-Cas9 based screens. Genomic findings are translated using cellular models which can be used for targeted and unbiased drug screens. If successful, my approaches can be applied beyond the scope of this ERC and will have a clear impact on clinical trial design and genetic counselling in ALS in particular.	European Research Council	Consolidator Grant	1980434.0	EUR
306	Professor Daoqiang Zhang	Nanjing University of Aeronautics and Astronautics	None	2018-03-31	2021-02-28	Big-Data Driven Intelligent Analysis of High Dimensional Multimodal Neuroimaging Data and its Application to Brain Disease Diagnosis	Neuroimaging methods based on high dimensional multimodal structural and functional imaging data have been recently proposed for objective diagnosis of brain diseases such as Alzheimer’s disease and autism. However, it is challenging to deal with multimodal data, since 1) multimodal data are typically massive in dimensionality,2) the complete set of Training Programme multimodal data is often unavailable for each subject due to data loss during canning or storage, or due to different study designs in different institutes, and 3) the number of subjects is often much smaller than the dimensionality of the multimodal data. The goal of this project is to develop advanced machine learning methods to address all these challenges in intelligent analysis of multimodal neuroimaging data. Specifically, we will develop a robust ensemble learning method for hierarchical decision fusion from multiple multi-level classifiers, through a layer-by-layer and localˇto-global fashion, to address the first challenge of high dimensionality. Moreover, we will develop a unified framework for novel multi-task semi-supervised (or transfer) learning with multimodal imaging data, to jointly address the second and third challenges of missing data and insufficient training samples, respectively. To our knowledge, the existing neuroimaging analysis methods are not able to deal effectively with these two challenges. Finally, all these proposed methods will be tested and evaluated on real neuroimaging datasets. The overarching aim of this project is to develop, train and transfer news skills to China-PI (Zhang) and his group on 1) efficient analysis of high-dimensional neuroimaging data using current advances and new knowledge in big data analytics and data science, especially in the areas of parallel and distributed computing, data analytics/image pattern recognition; 2) and transferable skills such communication, leadership and project management skills.	The Academy of Medical Sciences	Newton Advanced Fellowship	108000.0	GBP
307	Professor Diana Baralle	University of Southampton	None	2017-12-01	2022-11-30	Translational genomics- maximising potential for NHS patient care.	Genomics is the foundation of modern personalised medicine with the acknowledged potential to improve diagnostic accuracy, stratify disease and personalise treatment for immediate patient benefit. Projects to develop genomics in clinical practice are the epitome of the NIHR vision to improve the health and wealth of the nation through research and translation to patient care.Genomics England have kick-started a genomics industry with the 100,000 genomes project which targets patients with rare disease and cancer. One in seventeen people are born with or develop a rare disease during their lifetime and at least 80% of rare diseases have an identified genetic component; 50% of new cases are identified in children. Accurate diagnosis is fundamental in medicine enabling discussion of prognosis, screening, prenatal testing, family cascade testing and possible treatments. 1 in 3 people will get cancer and genomics transforms pathology to enhance the right treatment to the right patient.As implementation of high throughput sequencing into medicine escalates, the challenge remains to effectively translate these findings into diagnostic tests and future treatments. It is estimated that genomes will generate >10 million sequence variants between one individual and another. Each sequence variant must undergo functional verification, herein lies the bottleneck. l aim to use RNA to find missing mutations and provide a legacy for the interpretation of genetic variation in human disease, transforming clinical care.Many mutations in coding regions or introns may appear not to affect protein function but are still potentially causing disease through affecting pre-mRNA splicing. Between 15-50% of unclassified sequence variants (UVs) found at genomic analysis could influence RNA splicing.? Other forms of RNA have also been shown to be important in disease, e.g. non-codingRNA.Aim Development of a diagnostic RNA pipeline, maximising the impact of genome tests for patient benefit and provide a national resource for the NHS.DeliverablesShort term-i) Construct RNA pipeline for testing. Medium term-i) Diagnostic uplift through variant verification in a known disease gene for clinical care (not possible without RNA pathway output). ii) Diagnostic uplift through discovery of new genomic causes of disease.iii) RNA based disease signatures.Long Term-Understand disease processes, for personalised medicine and therapies.The Southampton comprehensive RNA analysis diagnostic pipelinePipeline overview- Figure 6 will have 3 componentsDesign and Methods?Strategic Patient cohortsi) 50 Primary ciliary dyskinesia patients; exome sequencing of key PCD genes completedii) 50 Clinical immunology patients. RNA samples storediii) 200 patients selected from the 100,000 genomes project where RNA is available and genome testing has identified variants of unknown significance [Genomics England supported]Optimisation of RNA tests to establish the pathway In silico/bioinformatic prediction of effect of sequence variants on both genome and transcriptome. In collaboration, research and development of bioinformatics computer software tools for genetic diagnostic testing with regards to splicing and RNA, including, machine learning and RNA Seq.?RNA analyses through patient RNA samples and minigene assays -measurement of RNA levels by RT-PCR or minigene analyses. Develop standard operating procedures for progress through bioinformatics to wet lab.Transcriptome analysis (blood, tissue, single cell (immunology cohort); messenger RNA and non-coding RNA). Each sample will be sequenced at sufficient depth to be able to perform an accurate and exhaustive analysis of RNA splicing patterns as well as identification of long non-coding RNAs and fusion transcripts.Gene function hub. Ultimately this technology will be an integral arm to a functional genomics hub- in collaboration, to prove gene pathogenicity. Including cell assays, biochemical assay, in vivo studies, RNA or methylation assays.Figure 5 for network of facilities and support.	National Institute for Health Research (Department of Health)	Full award	1870764.0	GBP
308	Professor Marcus Kaiser	Newcastle University	Sch of Computing	2019-04-01	2022-03-31	Modelling dementia progression based on machine learning and simulations	Our basic strategy is to 1) develop machine learning and dynamic model with available public datasets (ADNI, DPUK, Newcastle data) and 2) validate them with the against other cohorts (UK Biobank and Korea data). In this project, we will combine neuroimaging dataset including DWI, resting-sate fMRI, and PET data. DEVELOPING MACHINE LEARNING APPROACHES Using structural connectivity as measured with diffusion MRI in prodromal dementia, starting with connectivity in healthy subjects, and using a computer simulation to study the progression over time towards healthy ageing or dementia, we found that pathophysiological alterations associated with dementia become significantly apparent before the onset of symptoms, meeting diagnostic criteria for clinical dementia, indicating a potential biomarker for progression towards dementia. This machine learning approach could be improved further by using deep learning. Indeed, Korea University, in addition to providing further training and test datasets, has already developed a deep learning approach for dementia brain connectivity data. We will extend these approaches to develop a model of disease progression, looking at changes in white matter and gray matter organization, and testing the role of different underlying biological mechanisms through computational modelling. VALIDATING OUR APPROACH IN A CLINICAL SETTING This study utilizes existing datasets for training our approach. We use severable studies to ensure that predicting disease progression is reliable across study sites (UK vs. Korea) and patient cohorts. Note that studies, in addition to neuroimaging data, include the complete set of cognitive and clinical scores (MMSE, CAMCOG, UPDRS-III, NPI-Hall, CAF, Cornell-DS) as well as medication information. In a second step, we will use other datasets (UK Biobank and data from Korea University) as test datasets to see whether our approach can deal with novel datasets.	Medical Research Council	Research Grant	304844.0	GBP
309	Dr. Axel Ulrich LODE	University of Vienna	None	2019-01-01	2021-12-31	Numerics for many-body physics and single-shot images	Numerical models for many-body physics and single-shot images Scientific Abstract: We develop and apply improved simulation tools and numerical techniques for the time-dependent many-body Schrödinger equation for describing dynamical quantum systems used in state-of-the art experiments with ultracold atoms like the ones in the groups at the AtomInstitut, TU Wien. Our key goal is to investigate what one can really know about quantum many-body states of ultracold atoms. We go beyond models with a single Gross-Pitaevskii equation which cannot capture the phenomena in our focus like correlations and squeezing, that are observed in current experiments. A fundamental obstacle is to extract the information about correlations and squeezing from the experiment. In many experimental setups, the observations consist in so-called "single-shot images" of the atomic clouds. Theoretically, single-shot images represent a projective measurement of the many-body wavefunction. The current strategy necessitates a very large number of single-shot images to be produced and analyzed. We plan to use and improve a sophisticated numerical tool, the MCTDH-(B/F), that allows to describe correlations and squeezing. We aim to enable a direct and predictive modeling. We will implement an efficient MCTDH-(B/F) software and apply it for the simulation of also two- and three-dimensional many-body dynamics. To directly compare model predictions with experimental images, the single-shot-imaging process is also simulated. To face the key challenge of what one can really know about quantum many-body states of ultracold atoms, we develop statistical analysis and machine learning algorithms that optimally harness the information about squeezing and correlations in the single-shot images. The project core team consists of the PI, Axel Lode, a specialist on the Schrödinger equation and the MCTDH-(B/F) method, one PostDoc, that will work on the generation and analysis of single-shot images with a focus on correlations and on squeezing, and one PhD student that will apply the developed numerical tools in direct collaboration with the experimental physics project partners at the AtomInstitut, TU Wien. The core team is embedded and supported by the WPI applied math and experimental quantum physics experts N. J. Mauser, J. Schmiedmayer, T. Schumm, all WPI full members via START, Wittgenstein, ERC awards, etc..	Austrian Science Fund FWF	01 Stand-Alone Projects	389174.63	EUR
310	Dr Liam Brierley	University of Liverpool	Biostatistics	2019-10-01	2022-09-30	Ecology or genetics? Adapting machine learning approaches to understand determinants of cross-species transmission and virulence in RNA viruses	Emerging infectious diseases remain a prominent threat to global health, e.g., Ebola virus, Zika virus. In 2015, the WHO designated 'Disease X' to indicate the serious potential of previously unknown emerging pathogens to cause public health crises. Though zoonotic RNA viruses are known to present higher risks of emergence, detailed determinants of cross-species transmission remain unclear. Zoonotic viruses also vary widely in their capability to cause severe disease. To predict public health impacts of 'Disease X', a better understanding of which traits drive this variation in infectivity and virulence is urgently needed. Whilst previous approaches have focused on ecological predictors, these traditional frameworks have been unable to capture the information within increasingly available RNA virus sequences. This research aims to capitalise upon the potential power within large genetic data resources and quantify comparative influences of genetic versus ecological traits of RNA viruses and hosts upon cross-species transmission dynamics. To fully integrate novel, high-dimensional genetic data, new analytical approaches are needed. I will apply machine learning as a state-of-the-art statistical methodology, comparing several advanced approaches, e.g. gradient boosting, a method of gradual model learning which outperforms traditional methods. Models will span all known mammal and avian RNA viruses (22 families) using the exceptional breadth of EID2, a large, host-virus infectivity dataset. This project will additionally develop further text-mining tools to capture and integrate virulence data within EID2. The proposed models will allow tests of evolutionary theory across a range of RNA viruses. Quantified model outputs will contribute to public health risk assessments by informing prioritisation for novel viruses and advancing frameworks for emergence predictions, moving towards a 'smarter', empirically-driven strategy to prevent future disease burden.	Medical Research Council	Fellowship	235657.0	GBP
311	Dr Liam Brierley	University of Liverpool	None	None	2022-09-30	Ecology or genetics? Adapting machine learning approaches to understand determinants of cross-species transmission and virulence in RNA viruses	Emerging infectious diseases remain a prominent threat to global health, e.g., Ebola virus, Zika virus. In 2015, the WHO designated 'Disease X' to indicate the serious potential of previously unknown emerging pathogens to cause public health crises. Though zoonotic RNA viruses are known to present higher risks of emergence, detailed determinants of cross-species transmission remain unclear. Zoonotic viruses also vary widely in their capability to cause severe disease. To predict public health impacts of 'Disease X', a better understanding of which traits drive this variation in infectivity and virulence is urgently needed. Whilst previous approaches have focused on ecological predictors, these traditional frameworks have been unable to capture the information within increasingly available RNA virus sequences. This research aims to capitalise upon the potential power within large genetic data resources and quantify comparative influences of genetic versus ecological traits of RNA viruses and hosts upon cross-species transmission dynamics. To fully integrate novel, high-dimensional genetic data, new analytical approaches are needed. I will apply machine learning as a state-of-the-art statistical methodology, comparing several advanced approaches, e.g. gradient boosting, a method of gradual model learning which outperforms traditional methods. Models will span all known mammal and avian RNA viruses (22 families) using the exceptional breadth of EID2, a large, host-virus infectivity dataset. This project will additionally develop further text-mining tools to capture and integrate virulence data within EID2. The proposed models will allow tests of evolutionary theory across a range of RNA viruses. Quantified model outputs will contribute to public health risk assessments by informing prioritisation for novel viruses and advancing frameworks for emergence predictions, moving towards a 'smarter', empirically-driven strategy to prevent future disease burden.	UK Research and Innovation	Research Grant	235657.0	GBP
312	Professor Stephen Wood	University of Birmingham	School of Psychology	2013-06-10	2018-12-31	Linear and non-linear brain changes over the transition to psychosis	The course of schizophrenia is associated with significant brain changes. Exactly when these changes occur is a matter of debate, with significant evidence now available for progressive volumetric declines early in the illness (the first 12 to 24 months post-onset). However, there is additional evidence for the decline beginning before that, during the prodromal period. In this study we seek to replicate findings of progressive structural brain changes across the transition to psychosis in a group identified as at ultra high risk for psychosis. Furthermore we will extend these findings to establish the precise trajectory of these changes, whether measures of functional connectivity also show such change, and to what extent they can be used in pattern classification algorithms to improve predictions of who will or will not develop a psychotic illness. We propose to recruit 120 young people meeting criteria for the at-risk mental state, based on the presence of attenuated psychotic symptoms and/or a family history of schizophrenia or personal history of schizotypal personality disorder. Those with the greatest risk of transition to psychosis, along with 24 healthy controls, will be scanned repeatedly over the subsequent year to establish the longitudinal trajectories of brain structural and functional changes over the onset of psychosis. Specifically, we will use a linear mixed model regression approach to capture the dynamics of the pathological processes before and just after transition in both cortical thickness and measures of global network topology. We will use a machine learning approach to analyse longitudinal brain changes associated with different clinical courses. This will allow us to model transition probabilities and improve prediction of outcome. We hypothesise that the most rapid brain changes will be seen either side of transition, and that longitudinal brain changes will provide better prediction of later transition than baseline images.	Medical Research Council	Research Grant	808010.0	GBP
313	Dr Emily Clarke	University of Leeds	School of Medicine	2019-11-01	2023-07-31	Enhanced phenotyping of melanoma whole slide images with artificial intelligence	Background The pathology of melanocytic lesions is one of the most difficult diagnostic areas, resulting in high levels of diagnostic discordance. This project involves the use of convolutional neural networks and random-forest algorithms to afford a reproducible, objective and quantitative assessment of the melanoma phenotype. Aim In this proposed research, we aim to: (1) develop and configure algorithms for the extraction of morphological features at a cellular level to assist the histopathologist in their assessment by providing an automated, reproducible and objective second opinion and (2) explore the use of these morphological features to generate new prognostic biomarkers and better understand melanoma growth patterns. Objectives and Methodology We will employ machine learning methods to generate quantitative cellular data by using a large dataset of whole slide images including atypical melanocytic tumours and melanomas. 3D reconstruction will be performed on a subset of cases to enable improved visualisation and analysis of morphological data as well as comparison to computer-generated models of tumour growth. Data will be correlated with survival and somatic mutation status. Opportunities This novel research will enable the derivation of previously uncaptured phenotypic metrics, which may improve the existing subjective histopathological assessment byproviding an automated second "opinion". It is hoped that this approach will increase diagnostic accuracy in this notoriously difficult area to ensure patients are treated appropriately. These new data may also enable the discovery of new prognostic biomarkers through improved tumour subtyping and through comparing this morphological data to the genomic parameters, we may be able to detect subtle morphological distinctions that indicate the underlying mutation, resulting in improved understanding of the interaction between genotype and phenotype.	Medical Research Council	Fellowship	245899.0	GBP
314	Dr Andrew Swift	University of Sheffield	None	2019-10-01	2021-09-30	Developing a machine learning tool to improve prognostic and treatment response assessment on cardiac MRI data	<p>Cardiovascular diseases account for 26% of deaths in the UK. Current clinical imaging assessments rely on manual or semi-automated measurements. Emerging approaches focus on individual parts of the heart. We have developed the first tensorbased machine learning approach that holistically assesses the heart and surrounding structures on cardiovascular magnetic resonance imaging (CMRI) scans. We will develop this approach into a tool that can identify patients who respond to treatment or who will die early. Key advantages are rapid holistic assessment, minimal human error and full transparency with direct visualisation of features for the disease. We will assemble a large cohort of CMRI scans from 5, 000 patients with pulmonary hypertension, a severe condition affecting the heart, and assess the ability to predict treatment response and likelihood of early death. This tool will revolutionise disease<br> assessment, and improve treatment delivery and patient care.</p>	Wellcome Trust	Innovator Award: Digital Technologies	639873.0	GBP
315	Dr Haiping Lu	University of Sheffield	None	2019-10-01	2021-09-30	Developing a machine learning tool to improve prognostic and treatment response assessment on cardiac MRI data	<p>Cardiovascular diseases account for 26% of deaths in the UK. Current clinical imaging assessments rely on manual or semi-automated measurements. Emerging approaches focus on individual parts of the heart. We have developed the first tensorbased machine learning approach that holistically assesses the heart and surrounding structures on cardiovascular magnetic resonance imaging (CMRI) scans. We will develop this approach into a tool that can identify patients who respond to treatment or who will die early. Key advantages are rapid holistic assessment, minimal human error and full transparency with direct visualisation of features for the disease. We will assemble a large cohort of CMRI scans from 5, 000 patients with pulmonary hypertension, a severe condition affecting the heart, and assess the ability to predict treatment response and likelihood of early death. This tool will revolutionise disease<br> assessment, and improve treatment delivery and patient care.</p>	Wellcome Trust	Innovator Award: Digital Technologies	639873.0	GBP
316	Prof Enkelejda Miho	FHNW University of Applied Sciences and Arts Northwestern	None	2019-10-01	2022-01-01	Discovery of anti-DENV Antibodies Using Artificial Intelligence	<p>Dengue virus (DENV) is a viral pathogen of global health significance: in 390 million<br> cases worldwide, 96 million exhibited clinical symptoms and resulted in 21 thousand<br> deaths. Currently, there are no therapeutic treatments against DENV. DENV is<br> composed of four similar but serologically different viruses (DENV 1-4). Cross-reactive,<br> neutralizing antibodies to all four DENV serotypes may provide an effective passive<br> treatment against severe DENV disease.<br> A large number of potentially successful antibody candidates remain undiscovered due<br> to the complexity of the natural immune response (theoretical antibody repertoire of<br> 10140 potential antibodies). We aim to apply network analyses and machine learning to<br> investigate large amounts of raw high-throughput sequence data from antibody<br> repertoires, resulting in detection of rare, under-represented DENV-specific antibodies.<br> This project aims to discover and develop new neutralizing antibodies for therapeutic<br> treatment of dengue infection and inform vaccine design.</p>	Wellcome Trust	Innovator Award: Digital Technologies	658569.8	GBP
317	Dr Jonathan Clarke	Imperial College London	None	2019-10-01	2023-09-30	Care as a Complex System: Understanding the Network Dynamics of Healthcare Delivery	Health systems are a product of the interactions between healthcare professionals and their patients. These interactions may be understood as networks connecting all actors within the health system to one another through their clinical interactions. In doing so, the provision of healthcare becomes a complex system which may be interrogated and understood using methods of network analysis not previously used in population health research. In the fellowship I will address critical questions facing health systems today, using the latest techniques in machine learning, econometrics and network analysis. I will derive patient-sharing networks to understand how clinical data may be safely, and efficiently shared between patients and clinicians. Through the application of random forest and alternative-specific conditional logit models I will develop new ways to understand how clinical demand is redistributed following sudden or planned changes to hospital services. Using Markov Multiscale Community Detection, I will identify how current primary and secondary care services may be integrated to enhance continuity of care between clinicians while ensuring accountability for the entire population served by the National Health Service. Collectively, the techniques developed during this fellowship will empower patients, clinicians and policymakers to make informed decisions to improve how healthcare is delivered.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	300000.0	GBP
318	Ao. Prof. Dr. Andreas HOLZINGER	Medical University of Graz	None	2019-11-04	2022-11-03	A Reference Model of Explainable AI for the Medical Domain	Towards A Reference Model of Explainable AI for the Medical Domain Andreas Holzinger December, 27, 2018 The progress of statistical machine learning methods has made AI increasingly successful. Deep learning exceeds human performance even in the medical domain. However, their full potential is limited by the difficulty to generate the underlying explanatory structures. The central problem is that they are regarded as "black-boxes" and even if we understand the mathematical principles, they lack an explicit declarative knowledge representation. A motivation for this project are rising legal and privacy issues. This does not imply a ban on automatic learning approaches or an obligation to explain everything all the time, however, there must be a possibility to make results re-traceable on demand - understandable by a human domain expert. We learned of a variety of technical solutions which are currently in development, which could help explain AI/ML systems and their decisions. Transparent algorithms could appropriately enhance trust of medical professionals, thereby raising acceptance of machine learning. Recently, the Google AI team emphasized the significance of research in explainable AI, the importance of Human-Computer Interaction (HCI) research for Knowledge Discovery from Data (KDD), and the urgent need for a research framework around the field of interpretability. In our ongoing research collaboration "Machine learning for diagnosis of colorectal cancer" with the Google AI group and the Institute of Pathology (Ethics Vote Medical University Graz 30-184 ex17/18) a training data set for AI/ML in digital pathology has been generated. As agreed with our colleagues at the Google AI group, we have now the chance to use machine learning algorithms developed in this context for our test environment; in return we will research towards making their algorithms explainable for our domain experts, who have the benefits of using the results for their medical teaching. This project will focus on but is not limited to digital pathological data and context. The advantage of this project is working with real-world data (under full ethics/data protection regulations) together with medical experts. This project will provide important contributions to the international research community in the following ways: evidence in various methods of explainability and novel methods and urgently needed tools for benchmarking and evaluation; Moreover, the contributions gained in this project can be used generally for reverse-engineering human learning and cognitive development and specifically to engineer more human like machine learning systems. All outcomes of this project will be made openly available to the international research community.	Austrian Science Fund FWF	Stand-Alone Projects	392773.5	EUR
319	Dr James Howard	Imperial College London	None	2017-10-04	2020-10-03	Applications of machine learning in clinical cardiovascular imaging	Echocardiography (echo) remains the primary tool through which we assess the function of patients’ hearts. It is cheap, quick and safe. However, interpretation of the pictures can be very difficult and requires years of experience for doctors to accurately identify whether a scan is normal or abnormal. Recently, people have used computer programs to try and help in analysing medical images, and they have shown promise in the field of MRI scanning the heart. In echocardiography, however, training a computer to look at scans has been significantly more difficult. I believe I can overcome these issues by (1) developing a system which can identify exactly what heart structures are being scanned at any moment, and (2) building up a new library of echo scans from which to train a computer so it can analyse these structures. This technique of using neural networks to analyse medical images has many other applications and I am working with co-supervisors to employ my skills in different areas. These include creating a smart phone application which can identify a pacemaker’s model, speeding up the treatment of patients in emergency situations.	Wellcome Trust	PhD Training Fellowship for Clinicians	None	None
320	QUALIS FLOW LIMITED	QUALIS FLOW LIMITED	None	None	2020-10-03	Automating compliance for remote construction working	Construction logistics monitoring and compliance is typically paper-based and requires multiple individuals and teams to process, in order to ensure that material movements are handled in a safe and environmentally responsible manner. Qflow is a software tool, using a combination of Internet of Things and machine learning techniques, to digitise the information recovered from paper tickets at a construction site entrance. This ensures that this information is fed directly to the managers who need it most, and without the need for any on-site presence aside from the existing traffic marshals. Information is provided on the material types and waste removals, descriptions, relevant certifications of the supply chain, and listed quantities. This supports several teams to work remotely, including logistics, environmental, QS and data administration. The innovation that Qflow is exploring now is automated compliance screening and anomaly detection, to notify users when there are discrepancies in their data that require investigation, or where there is an illegal waste transfer. The software provides the eyes and ears on site in real-time, and provides access to that information on a cloud-based platform, meaning that those who need the data can access it wherever they are, without having to double handle paperwork and ensuring that the site operations continues smoothly without the need for intervention.	UK Research and Innovation	Research Grant	27374.0	GBP
321	Dr. Jan Clemens	UNIVERSITAETSMEDIZIN GOETTINGEN - GEORG-AUGUST-UNIVERSITAET GOETTINGEN - STIFTUNG OEFFENTLICHEN RECHTS	None	2020-02-01	2025-01-31	Neural Computations Underlying Social Behavior in Complex Sensory Environments	Animals often interact in groups. Animal groups constitute complex sensory environments which challenge the brain and engage complex neural computations. This behavioral context is therefore fruitful for understanding how sophisticated neural computations give rise to behavior. However, it is also technically difficult since many of the relevant sensory cues arise from the members of the group and are therefore hard to quantify or control. Consequently, we only incompletely understand how the brain drives complex social behaviors in naturalistic contexts. To uncover the neural computations underlying social behavior in groups, we are using Drosophila, which provides unprecedented experimental access to the nervous system via genetic tools. Drosophila gathers on rotten fruit to feed and mate. Courtship and aggression dominate social interactions and rely on the recognition of sex-specific chemical cues and the production of context-specific acoustic signals. How are these multi-modal cues integrated to control and switch between courtship and aggression? How is unstable and conflicting sensory information resolved to promote stable behavioral strategies? How does sensory processing adapt to socially crowded environments in order to efficiently target behavior at individual members of the group? These issues will be addressed by combining computational modeling and genetic tools. Using machine learning, we will quantify and model the fine structure of social interactions to identify the social cues that drive behavior. Closed-loop optogenetics and calcium imaging in behaving animals will allow us to test the models and to ultimately reveal how the brain integrates, selects and combines social cues to drive social interactions. This multi-disciplinary approach will uncover the computational principles and mechanisms by which sensory information is processed to drive behavior in the complex sensory environment of animal groups.	European Research Council	Starting Grant	1476920.0	EUR
322	Dr. Ynte Ruigrok	UNIVERSITAIR MEDISCH CENTRUM UTRECHT	None	2020-02-01	2025-01-31	Early recognition of intracranial aneurysms to PRevent aneurYSMal subarachnoid hemorrhage	Intracranial aneurysms usually go undetected until rupture occurs leading to aneurysmal subarachnoid hemorrhage (ASAH), a type of stroke with devastating effects. Early detection and preventive treatment of aneurysms fall short as we do not know who is it at risk and why, as we have insufficient insight in the contribution and interplay of genetic, environmental and intermediate phenotypic risk factors. Given the rarity of the disease, there is a paucity of large and rich cohorts to study risk factors separately with sufficient power. To add to the problem, my preliminary findings suggest disease heterogeneity with subgroup specific risk factors for aneurysms. The sex-related heterogeneity is most eminent in the disease with 2/3 of patients being women. I aim to advance disease understanding to allow early recognition of intracranial aneurysms to prevent ASAH. I have established a new conceptual approach that integrates genetic and environmental risk factors with imaging markers as intermediate phenotypes for genetic factors. With data reduction and machine-learning approaches I will for the first time address disease heterogeneity and aneurysm risk with adequate power. I will develop and validate a tool to automatically detect new imaging markers predicting aneurysm development applying feature-learning models. Next I will elucidate the genetic basis underlying differential imaging risk patterns (imaging genetic factors). I will apply a new hypothesis-free strategy to detect and validate yet unknown environmental risk factors predicting aneurysm presence. I will assess the contribution to disease of all factors detected according to sex. All risk factors will be combined in an aneurysm prediction risk model to understand relative contribution of different risk factors in different subgroups. It will advance disease understanding and individualized risk prediction of aneurysms leading to precision medicine in early aneurysm detection to reduce the burden of ASAH.	European Research Council	Starting Grant	1499108.0	EUR
323	Dr. Marios Philiastides	University of Glasgow	None	2020-09-01	2025-08-31	Dynamic Network Reconstruction of Human Perceptual and Reward Learning via Multimodal Data Fusion	Training and experience can lead to long-lasting improvements in our ability to make decisions based on either ambiguous sensory or probabilistic information (e.g. learning to diagnose a noisy x-ray image or betting on the stock market). These two processes are referred to as perceptual and probabilistic/reward learning, respectively. Despite considerable efforts to uncover the neural systems involved in these processes, perceptual and reward learning have largely been studied in separate lines of research using divergent learning mechanisms. The primary aim of this proposal is to develop a unified framework for integrating these lines of research and understand the extent to which they share a common computational and neurobiological basis. Specifically, we will test the proposition that both the perceptual and reward systems could be understood in a common framework of “reward maximization”, whereby a domain-general reinforcement-guided learning mechanism – based on separate prediction error representations – facilitates future actions and adaptive behavior. To offer a comprehensive spatiotemporal characterization of the relevant networks and their computational principles we will adopt a state-of-the-art multimodal neuroimaging approach to fuse simultaneously-acquired EEG and fMRI data, via machine-learning-inspired multivariate single-trial analysis techniques and computational modelling. The project’s ultimate goal is to empower a level of neuronal and mechanistic understanding that extends beyond what could be inferred with each of these modalities in isolation. We will achieve this goal by exploiting endogenous trial-by-trial electrophysiological variability to build parametric fMRI predictors that can offer additional explanatory power than what can already be achieved by stimulus- or behaviorally-derived predictors, allowing us to go over and beyond what has been reported previously in the literature.	European Research Council	Consolidator Grant	1996043.0	EUR
324	Dr. Marloes EEFTENS	SCHWEIZERISCHES TROPEN- UND PUBLIC HEALTH-INSTITUT	None	2020-05-01	2025-04-30	Beyond seasonal suffering: Effects of Pollen on Cardiorespiratory Health and Allergies	As climate change increases the duration and intensity of the pollen season, allergies to airborne pollen are increasingly common in Europe. Yet, it is not well recognized that high pollen concentrations may increase respiratory and cardiovascular events, leading to mortality and excess hospitalizations. I aim to investigate how short-term exposure to pollen is related to mortality, hospitalization and allergic symptoms, both on its own and synergistically with air pollution and weather. I will develop spatiotemporal exposure models of pollen for the years 2003-2022 based on a network of 14 pollen measurements stations in Switzerland. Taking advantage of large, real-world datasets without selection bias (Swiss National Cohort) and the efficient case-crossover study design, I will investigate the population effects of pollen on daily respiratory and cardiovascular mortality and hospitalization, also accounting for variation in air pollution and weather conditions. To explore individual sensitivity, I will conduct repeated measurements of lung function and airway inflammation in a dedicated panel of 400 allergic patients complemented with opportunistic repeated accounts of self-reported symptoms from the “e-symptoms” app by Swiss Allergy Centre. To provide personalized prevention recommendations and enhance quality of life for the allergic population, I will derive exposure-response relationships based on prevalent pollen, air pollution and weather triggers and individual symptom reports, allowing me to ultimately forecast symptom severity using machine learning techniques. This highly innovative project utilizes available nationwide health datasets and systematic novel data collection methods (in the in-depth panel study), to better understand the role of pollen in respiratory and cardiovascular diseases at both personalized and population levels. The project will prevent and reduce health effects due to pollen, which constitute a large burden on health and economy.	European Research Council	Starting Grant	1381932.0	EUR
325	Dr Jennifer Steeden	University College London	Institute of Cardiovascular Science	2020-02-01	2024-01-31	Towards 10-minute Magnetic Resonance Scanning in Children - Developing Accelerated Imaging Using Machine Learning	Magnetic Resonance Imaging (MRI) scans play a vital role in helping many ill children, by finding out what the problem is and helping plan their treatment. MRI is safe because it does not use radiation. MRI scans produce good-quality pictures or images of many parts of the body, including the brain, heart, spine, joints and other organs. The main problem is they take a long time - often over an hour. During the scan, the child has to keep very still and may even need to hold their breath many times. This is especially hard for children and unwell patients. Hence, younger children under 8 years old need a general anaesthetic, to put them to sleep during the scan. In many childhood diseases, for example in cancer, children may need many MRI scans to follow up disease progression and treatment. Being put to sleep for all of these scans is not pleasant for the child and may occasionally cause problems. It also puts a lot of pressure on hospitals who need to find the doctors, beds, equipment and funds for this. One way of overcoming these problems would be to speed up the MRI scans so the children do not have to keep still or hold their breath. The simplest way of doing this is to collect less data for each image, but this causes so much distortion in the images that they cannot be used. There are some ways of converting these into useful images, but these are complicated and take too long to use in a hospital. Machine Learning is an upcoming way of teaching computers to find complicated patterns in large amounts of information. Recent advances mean that computers are now so powerful that they can learn effectively. Machine Learning has been successfully used for analysing many types of images, for example to perform de-noising, interpolation, image classification and border identification. Despite its popularity, only a few recent studies have shown its potential for reconstruction of MRI images. This is partly due to the greater complexity of the problem and importantly, the large amounts of data required to 'learn' the solution. At Great Ormond Street Hospital, we have MRI images from over 100,000 children and scan an additional 10,000 children each year, all of which we could use to help train and test Machine Learning technologies. I have already shown that basic Machine Learning techniques can remove distortions from MRI scans of the heart, so I am well placed to develop Machine Learning techniques to reconstruct MRI images from other children's diseases, as well as developing more advanced Machine Learning techniques. I showed Machine Learning to be faster than existing reconstruction methods and the images were of better quality than more conventional state-of-the-art techniques. However, much more work is needed to get Machine Learning working reliably in children's scans and to make the most of the possible benefits. If we can use fast scanning with Machine Learning we could shorten scan times from 1 hour to about 10 minutes for children having MRI scans. They would not have to keep completely still for the scan and would not have to hold their breath, therefore reducing the need to put patients to sleep. This would make MRI scanning far less difficult and daunting for children, and would eliminate the cost and side effects from the anaesthetic. Quicker scans would help reduce waiting lists and costs for the NHS. It would also mean that MRI scanning would be used far more often, so it could help many more children. Additionally, these techniques could enable MRI scans to become affordable in some countries for the first time.	Medical Research Council	Fellowship	989996.0	GBP
326	Shuai Li	University of Tennessee Knoxville	None	2020-05-01	2021-04-30	RAPID: Impacts of Design and Operation Attributes of Mass-Gathering Civil Infrastructure Systems on Pathogen Transmission and Exposure	Engineering - This Rapid Response Research (RAPID) grant will support fundamental research to reveal how the design attributes and operation strategies will influence the transmission of and exposure to infectious pathogens within mass-gathering civil infrastructure systems. During the pandemic of 2019 novel coronavirus, the mass-gathering civil infrastructure systems, such as schools, airports, and public transit systems, can become hot spots for spreading the infectious disease. There remains a striking knowledge gap in understanding the impacts of infrastructure design and operation on the occurrence, distribution, transport, and viability of pathogens. It is imperative to address this knowledge gap. Results from this project will lead to bio-informed guidelines for managing critical civil infrastructure systems to prevent exposure of facility users to pathogenic microorganisms, and reduce risks of spreading infectious diseases, and thus alleviating burdens on healthcare systems and citizens. This project will provide much needed insights for infrastructure design reconfigurations and operation practices during the pandemic, in the recovery, and beyond to prevent further disease outbreaks and support healthy, resilient, and smart communities. As a result, this project will help promote public health, national security, and economic prosperity. In addition, this project will raise public science literacy and awareness of infectious diseases, and improve student education and training, as well as K-12 outreach and engagement activities. <br/><br/>The specific objective of this research is to parameterize relevant design attributes and operation strategies of infrastructure systems, and subsequently evaluate their impacts on pathogen transmission and exposure from spatiotemporal microbiome profiles. Three aims will be pursued: 1) identify and quantify the design attributes and operation strategies that may impact pathogen dynamics; 2) audit the types, abundance, and co-occurrence patterns, as well as spatiotemporal dynamics of microorganisms, particularly pathogens, associated with spatially and functionally distributed system components; and 3) characterize the impacts of design and operation on the transmission and exposure pathways of microorganisms in infrastructure systems. The spatial and functional interdependence of system components will be considered to parameterize design attributes based on building information modeling and syntactic analysis. The operation strategies will be modeled using integrated data sensing and simulation techniques. A model-informed sampling approach will be developed with molecular and metagenomics techniques to characterize spatiotemporal microbiome dynamics. The impacts of design and operation on microbial transmission and exposure pathways will be assessed using integrated source tracking and machine learning methods. At the nexus of infrastructure system engineering and environmental microbiology, this convergence research will provide unique insights into design attributes and operation practices impacting pathogen transmission and exposure in mass-gathering civil infrastructure systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	199809.0	USD
327	Arup Chakraborty	Massachusetts Institute of Technology	None	2020-04-01	2021-03-31	RAPID: Immunogenicity of SARS-CoV2 to Human T Cells	Mathematical and Physical Sciences - Pandemics caused by infectious pathogens have plagued humanity since antiquity. The Coronavirus Disease 2019 (COVID-19) caused by the SARS-CoV-2 virus is currently spreading across the world rapidly, including in the United States, with major adverse impact on health and the economy. The SARSCoV-2 outbreak has led to several urgent efforts to develop vaccines that may offer protection against this virus. It is unknown as to whether the current approaches being pursued will elicit protective immune responses in humans. While vaccines have been very effective against many pathogens, the empirical methods for vaccine development pioneered by Pasteur and Jenner over two centuries ago have failed to produce effective vaccines against Human Immune Deficiency Virus, Malaria, Tuberculosis, and many other pathogens. Therefore, rational design of vaccines based on a mechanistic understanding of the pertinent virology and immunology is being pursued, and these efforts include work that is rooted in statistical physics. SARSCoV-2 is phylogenetically most similar to SARS-CoV. This project will use a machine learning approach to understand how the SARS-CoV-2 virus interacts with the immune T cells. This work will directly impact the design of SARS-CoV-2 vaccines and vaccines against future endemic-causing pathogens.<br/><br/>Analyses of patients who have recovered from SARS-CoV shows that antibody responses are not prevalent a few years later, but memory T cell responses are durable and may offer long-term protection. The main questions addressed by this project are 1. Will the SARS-CoV peptides targeted by human T cells that are mutated in SARS-CoV-2 still elicit human T cell responses - i.e. are they immunogenic? 2: Are the 102 peptides identified by host major histocompatibility molecules binding assays alone that are common between SARS-CoV and SARS-CoV-2 immunogenic in humans? If not, they are irrelevant from vaccine design perspective. The goal of the work proposed here is to take a physics-based machine learning approach to determine the immunogenicity of SARS-CoV-2 proteins to human T cell responses.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	124472.0	USD
328	Viktor Prasanna	University of Southern California	None	2020-05-01	2021-04-30	RAPID: ReCOVER: Accurate Predictions and Resource Allocation for COVID-19 Epidemic Response	Computer and Information Science and Engineering - The recent outbreak of COVID-19 and its world-wide impact calls for urgent measures to contain the epidemic. Predicting the speed and severity of infectious diseases like COVID-19 and allocating medical resources appropriately is central to dealing with epidemics. Epidemics like COVID-19 not only affect world-wide health, but also have profound economic and social impact. Containing the epidemic, providing informed predictions and preventing future epidemics is essential for the global population to resume their day-to-day work and travel without fear. Shortage of resources puts undue stress on healthcare system further risking health of the community. Preparedness and better management of available resources would require specific predictions at the level of cities and counties around the world rather than solely at the level of countries. The project will provide a predictive understanding of the spread of the virus by developing machine learning based computational models to study the transmission of the virus and evaluate the impact of various interventions on disease spread. The project will learn infection prediction models for COVID-19 considering the following. (i) Predicting at state/county/city-level rather than country-level as finer granularity is essential in planning and managing resources. (ii) How infectious a person is changes over time. Learning the model through observed data will help in understanding of the temporal nature of the virality. (iii) At such granularity travel is a significant reason for the spread and needs to be accounted for. (iv) Available data needs to be ?corrected? by finding the number of underlying unreported cases that are not observed and yet influence the epidemic dynamics. The project will also solve the resource allocation problem based on the prediction ? for instance if a certain number of masks will be available next week in a certain state, how should they be distributed across different hospitals in the state (which hospitals and how many in each state)?<br/><br/>Proposed project ReCOVER will use a novel fine-grained, heterogeneous infection rate model to perform predictions at various granularities (hospital/airports, city, state, country) while accounting for human mobility. ReCOVER will integrate data from various sources to build highly accurate models for prediction of the epidemic across the world at various granularity. Due to the ability to capture temporal heterogeneity in infection rate, the approach has the potential to provide insights into infectious nature of COVID-19 which are not fully understood yet. The project will address the issue of unreported cases through temporal analysis of historical infections and correct the data. The right granularities of modeling will be automatically identified, e.g., when to model a state over its cities to trade-off precision for higher reliability in predictions. The proposed project also formulates and solves a resource allocation problem that can guide the response to contain the epidemic and prevent future outbreaks. This is provided by optimal solutions to resource allocation over a network where each node (representing a region) has a function that captures probabilistic response. While the project obtains data with COVID-19 in consideration, the model and algorithms developed under the project are applicable to a wide class of contagious diseases. The project will culminate into an interactive customizable tool that can be used to perform predictions and resource management by a qualified user such as a government entity tasked with managing the epidemic response. The data and code will also be shared with research community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	158592.0	USD
329	Indrakshi Ray	Colorado State University	None	2020-05-01	2021-04-30	RAPID: ENSURING INTEGRITY OF COVID-19 DATA AND NEWS ACROSS REGIONS	Computer and Information Science and Engineering - Large amounts of epidemiological data are being generated and collected from a variety of sources to understand the impact and propagation of COVID-19. Similarly, huge amounts of news articles are generated and disseminated about the pandemic to keep the population informed. The appropriateness of the actions taken by individuals, corporations, and governments are often based on the quality of data and news. Thus, ensuring the quality of data and news is important. However, malicious actors can alter the attributes of data records, insert spurious records, or suppress records causing any analysis to be inadequate and misinformation to be propagated. This project addresses the critical problem of defining and identifying spurious data and news concerning COVID-19, and tracking the source of misinformation. The project novelty lies in the development of an approach and associated toolset that adapts and combines Machine Learning technologies to detect spurious data and misinformation and presents the results in a manner that is easy for end users to understand and interpret. The approach detects discrepancies in COVID-19 data and traces the flagged discrepancies back to the data sources. The results obtained from the news sources and those obtained from the medical data analysis are compared to determine correlations between the quality of news and the degree and type of data manipulation performed at any region. The project?s impacts are on significantly enhancing the ability to perform accurate scientific analysis, and detecting and explaining news manipulation with respect to COVID-19. The scientific principles developed in the project are expected to be useful outside the medical domain. The PI and the students identified for this project are minorities. The project will be carried out in the Computer Science Department at Colorado State University which is a BRAID affiliate.<br/><br/>COVID-19 data discrepancies are related to (1) single records, where some field is modified, (2) sequence of records over time forming a temporal dimension, where spurious records have been inserted or records have been suppressed, and (3) sequences of records across regions forming a spatial dimension, where there is a pattern of manipulation or information disclosure across regions. The approach determines the appropriate combination of autoencoders, Long Short-Term Memory (LSTM), Temporal Convolution Network (TCNs), and Convolution Neural Networks (CNNs) that can work with data obtained from medical sources and news containing both spatial and temporal dimensions. The tools help the investigators? collaborators at the University of Colorado Anschutz Medical Center and Center for Disease Control and Prevention to perform data integrity checking of medical records and to provide explanations of integrity violations. The tools also handle different types of data and news alterations pertaining to COVID-19.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	199748.0	USD
330	Thomas Boellstorff	University of California-Irvine	None	2020-05-01	2021-04-30	RAPID: The Role of Emerging Virtual Cultures in the Prevention of COVID-19 Transmission	Social, Behavioral and Economic Sciences - The COVID-19 pandemic has transformed our relationship to the physical world. Social distancing guidelines have led many people to avoid all forms of public life, from concerts and restaurants to everyday interaction in parks, neighborhoods, and the homes of family and friends. In response there has been a massive increase in online interaction: the internet has suddenly become the primary way that many Americans socialize, labor, and learn. It is crucial to gain a better understanding of how the emergence of these changes is related to the pandemic. Even if a vaccine is discovered, preventing catastrophic levels of COVID-19 transmission into the next few years will depend on social distancing that can be sustained and integrated with work, education, and community. This means going online. The starting point for addressing this global challenge is thus the fact that what we call ?social distancing? is really physical distancing. Successful physical distancing will rely on new forms of social closeness online. Yet there is not just one ?online.? A rapid and effective response requires clarifying the impact of virtual worlds as part of different forms of online interaction that comprise a virtual culture: social network sites, streaming websites, and multiplayer platforms. The project will also train graduate student researchers in methodological approaches for studying online cultures. <br/><br/>This research will be conducted in a densely trafficked virtual world. Virtual worlds are places where individuals interact with avatars in online environments. The investigators have conducted research in a virtual world context for over a decade, and thus have detailed baseline data with which to examine what is happening as a large number of individuals enter that virtual world due to the COVID-19 pandemic. What is the sudden move to virtual worlds doing in terms of social closeness and interaction? How does co-presence in virtual place transform intimacy and collaboration? How might this provide innovative strategies for preventing viral transmission, by forging new forms of social closeness in the context of physical distancing? To investigate these questions, the researchers will conduct participant observation, individual interviews, and group interviews. The study will compare individuals who have spent time in the virtual world for years with individuals who have entered the virtual world after COVID-19. Findings from this research will provide insight into the specific possibilities virtual worlds are providing in the circumstances of societies reshaped by COVID-19. In these new circumstances, virtual worlds will be one element of an online ecosystem linking drones, robots, and autonomous vehicles to mobile devices, social network sites, online games and streaming, augmented reality, artificial intelligence, machine learning, and data analytics. The research will thus provide a better understanding of the place of virtual worlds in this emerging online ecosystem.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	195619.0	USD
331	Michael Vahey	WASHINGTON UNIVERSITY	None	2020-05-15	2021-04-30	RAPID: A multiscale approach to dissect SARS-CoV-2 attachment to host cells and detect viruses on surfaces	Biological Sciences - The 2019 novel coronavirus, identified as the cause for the pneumonia pathology reported in Wuhan, spread quickly and became a global pandemic. The project will employ experimental methods to develop sensors for the detection of SARSCoV-2 from environmental samples and develop predictive models for virus attachment to cells by applying computational machine learning methods. The outcome of this project will contribute to the development of proactive measures to identify viruses with pandemic potential before they are able to transmit and spread broadly among humans. The graduate students involved in this research will gain experience in protein biochemistry, fluorescence microscopy, and computational simulations and experience utilizing those skills to problems of societal importance.<br/><br/>This NSF Rapid response Research (RAPID) project will support a project that is aimed to characterize receptor interactions mediated by the Spike protein (S) of SARS-CoV-2. Development of fluorescence-based assays to characterize SARSCoV-2 attachment to Angiotensin converting enzyme (ACE2)-functionalized surfaces with controlled density and mobility, identifying peptide mimics of the ACE2 ectodomain for the development of sensors to detect SARSCoV-2 from environmental samples, and develop and validate predictive models of CoV attachment from primary sequence using machine learning constitute the specific goals of this project.<br/><br/>This RAPID award is made by the Molecular Biophysics Program in the Division of Molecular and Cellular Biosciences, using funds from the Coronavirus Aid, Relief, and Economic Security (CARES) Act.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	200000.0	USD
332	Anastasia Angelopoulou	Columbus State University	None	2020-05-15	2021-04-30	RAPID/Collaborative Research: Quantifying Social Media Data for Improved Modeling of Mitigation Strategies for the COVID-19 Pandemic	Engineering - This Rapid Response Research (RAPID) grant will support research that will contribute new knowledge related to modeling social behavior and community activity during the COVID-19 pandemic, as well as future pandemics with COVID-19 characteristics. The model focuses on compliance with mitigation strategies and public health guidelines, thus enabling the selection of policies that are most effective in promoting both the progress of science and advancing national health and prosperity. Various pandemic models are currently being used to predict the spread of a virus and establish which mitigation strategies are the most effective. These models are heavily based on assumptions and may include an oversimplified reality of how populations react and behave. This research will provide needed knowledge and methods for the development of a model of how individuals in the U.S. react to certain mitigation strategies, such as social-distancing, stay-at-home orders, quarantines, and travel advisories, by mining and analyzing social media data during the COVID-19 crisis. This enhanced modeling approach and its resultant model will be of great value to disaster response managers and policy/decision makers to understand human social behavior. This work allows assessment of the effectiveness of mitigation strategies and public health guidelines during pandemics (and other crises). This project will also form the basis of a publicly available case study suitable for university level students that can be widely incorporated in courses. <br/><br/>Although individual-based and homogeneous mixing pandemic models provide useful insights and predictive capabilities within a range of possibilities, they are highly sensitive to people?s actions. This research aims to provide an enhanced approach to model social behavior and community activity during a pandemic in terms of compliance with mitigation strategies and public health guidelines. Social media data present a brief window of opportunity for research on how, and to what extent, the public does or does not comply with the recommended mitigation strategies and public health guidelines. The research team will collect real-time data from social media related to COVID19-exposed regional populations in the U.S. The data will be analyzed using machine learning techniques to identify non-mutually exclusive clusters of people based on similarity of their demographic, geographic, and time information, and establish relationships among clusters. The analyzed data will form the basis of a data-driven multi-paradigm simulation model that captures changes in public sentiment over time, quantifies the resistance/compliance with mitigation strategies and health guidelines, and gauges overall effectiveness of various mitigation strategies and advice over time.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	13406.0	USD
333	Mary Jo Ondrechen	Northeastern University	None	2020-05-15	2021-04-30	RAPID: D3SC: Identification of Chemical Probes and Inhibitors Targeting Novel Sites on SARS-CoV-2 Proteins for COVID-19 Intervention	Mathematical and Physical Sciences - The life cycle of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) involves a number of viral proteins and enzymes required for infectivity and replication. Inhibitors that target these enzymes serve as potential therapeutic interventions against coronavirus disease 2019 (COVID-19). With this award, the Chemistry of Life Processes program in the Chemistry Division is supporting the research of Drs. Mary Jo Ondrechen and Penny J. Beuning from Northeastern University to apply computational methods to identify sites in SARS-CoV-2 proteins that would be good targets for binding inhibitors. The project uses artificial intelligence methods developed at Northeastern University to identify pockets and crevices in the structures of viral proteins that may serve as new targets for the development of antiviral agents. Large datasets of natural and synthetic compounds are computationally searched for molecules that fit into these alternative sites, and any compounds that fit will be experimentally tested for their ability to inhibit the functions of these viral enzymes. The project provides training in computational chemistry and biochemical analysis to graduate students and postdoctoral associates.<br/><br/>This project uses the unique Partial Order Optimum Likelihood (POOL) machine learning (ML) method developed by Dr. Ondrechen?s group to predict multiple types of binding sites in SARS-CoV-2 proteins, including catalytic sites, allosteric sites, and other interaction sites. The goals of this project are to apply the POOL-ML method to identify the binding sites on viral pathogen SARS-CoV-2 proteins using the three-dimensional protein structures as input. Molecular dynamics simulations are used to generate conformations for ensemble docking. Compounds from the large molecular databases are computationally docked into the predicted sites to identify potentially strong binding ligands. Candidate ligands to selected SARS-CoV-2 proteins, including the main protease and 2?-O-ribose RNA methyltransferase, are experimentally tested in vitro for binding affinity and the effect of the best predicted inhibitors on catalytic activities determined by direct biochemical assays. All the SARS-CoV-2 protein structures in the Protein Data Bank (PDB) are studied. Compound libraries for the study include: a) selected 2600+ compounds from the ZINC and Enamine databases that are already being manufactured; b) a library of 20,000+ compounds found in foods that the team recently gained access to; these potentially hold some special advantages, including ready availability in the public domain and low cost; and c) the March 2020 open access CAS (American Chemical Society) database of 50,000 compounds with known or potential anti-viral activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	165808.0	USD
334	Marinka Zitnik	Harvard University	None	2020-05-01	2021-04-30	RAPID:Collaborative Research: Computational Drug Repurposing for COVID-19	Computer and Information Science and Engineering - With the disruptive nature of the COVID-19 pandemic, effective treatments could save the lives of severely ill patients, protect individuals with a high risk of infection, and reduce the time patients spend in hospital beds. However, there are currently no effective treatments for COVID-19. Traditional methodologies take years to develop and test compounds from scratch. Machine learning provides promising new approaches to repurpose drugs that are safe and already approved for other diseases. This project will develop a machine learning toolset to expedite the development of safe and effective medicines for COVID-19. The toolset will rapidly identify safe repurposing opportunities for approved and experimental drugs. It will predict whether treatments may have therapeutic effects in COVID-19 patients, allowing the identification of drugs and drug cocktails that are safe and plentiful enough to treat a substantial number of patients. By putting tools in the hand of practitioners, the activities in this project will have an immediate impact. They will result in actionable predictions that are accurate and interpretable. <br/><br/>Recently, the principal investigators have developed a series of machine learning tools to identify drug repurposing opportunities. Building on foundational previous work, in this project, the principal investigators will first build a large COVID-19 focused knowledge graph that will capture fundamental and COVID-19-specific biological knowledge. The graph learning methods will be adapted to identify safe drugs and drug cocktails for COVID-19. To predict the safety of cocktails with two or more drugs, the methods will generalize to an exponentially large space of high-order drug combinations. In addition to drug safety, efficacy is a crucial endpoint for drug development. The project will develop a novel graph neural network (GNN) method to identify efficacious drug repurposing opportunities, even for diseases, such as COVID-19, that do not yet have any drug treatments and thereby, no label, supervised information. The method will predict what drugs and drug combinations may have a therapeutic effect on COVID-19. Finally, the principal investigators will integrate the developed tools into a complete, explainable framework that will generate predictions, provide explanations, and incorporate human feedback into the machine learning loop. This project will provide new, open tools for rapid drug repurposing that will be relevant for COVID-19 and other emerging pathogens. Additionally, the project will provide unique opportunities for multi-disciplinary curriculum development, training and advising, and professional activities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	99863.0	USD
335	Meggan Craft	University of Minnesota-Twin Cities	None	2020-05-15	2021-04-30	RAPID: The effect of contact network structure on the spread of COVID-19: balancing disease mitigation and socioeconomic well-being	Biological Sciences - What makes COVID-19 spread rapidly in some places, yet slowly in others? How should society lessen social distancing while limiting an increase in infections? To answer these questions, this Rapid Response Research (RAPID) project seeks to understand how patterns of interpersonal interaction (?structure?) in social contact networks affect disease spread in a population. The researchers will simulate a disease spreading through a variety of social contact networks, and use machine learning to relate each network?s structure to the number and timing of new infections. By limiting structures related to increased disease, societies may be able to reopen other parts of their economies while still curbing overall disease spread. The researchers will produce an interactive web application for the public and decision-makers to visualize trade-offs between reducing disease and maintaining social cohesion. This research will support the professional development of an early career scientist.<br/><br/>This research aims to determine the inherent risk of SARS-CoV-2 spread based on contact network structure. The researchers will use machine learning to 1) identify network structures that influence disease spread and 2) predict disease spread on empirical contact networks. Important network structures will serve as targets for simulated disease mitigation interventions (e.g. reducing structures that increase levels of disease or increasing structures that reduce disease levels). Finally, the researchers will investigate whether future outbreaks of COVID-19 or other diseases could be alleviated through optimizing social contact networks ahead of time. The outcomes of this research will inform and facilitate quick, efficient interventions to reduce the social and economic costs of COVID-19. This research will develop a general framework for relating disease to network structure. Thus, results can be generalized beyond the current pandemic, serving to further our understanding of potential future waves of COVID-19, as well as other directly-transmitted diseases in humans, livestock, and wildlife.<br/><br/>This RAPID award is made by the Ecology and Evolution of Infectious Diseases Program in the Division of Environmental Biology, using funds from the Coronavirus Aid, Relief, and Economic Security (CARES) Act<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	199136.0	USD
336	Gil Gallegos	New Mexico Highlands University	None	2020-05-15	2021-04-30	RAPID: Machine Learning Methods to Understand, Predict and Reduce the Spread of COVID-19 in Small Communities	Mathematical and Physical Sciences - The ongoing COVID-19 outbreak has recently reached pandemic status spreading all around the world. The severity of the pandemic, along with an enormous impact on world?s economy and society, has forced governments to introduce emergency measures. It is essential to utilize the available statistical data from trusted sources in order to model and evaluate the dynamics of the pandemic spread, to not only better understand such complex systems, but to learn and develop possible solutions to prevent further spread of current and/or similar future outbreaks. Thus, this research, devoted to the development of mathematical models of COVID-19 pandemic spread, addresses an urgent national need. Faculty and students in computer science, anthropology, and computational chemistry at New Mexico Highlands University have formed a diverse group for finding a solution to the complicated problems of the description and prediction of COVID-19 spread. This multidisciplinary project is expected to yield a better understanding of the interconnections among many factors that contribute to the spread of COVID-19. Statistical data will be collected in regions of Northern New Mexico, including San Juan and McKinley Counties in the Navajo Nation and Los Alamos county outside of the Navajo Nation. Analysis of the collected statistical data along with socio-cultural assessment from this project will be presented to New Mexico (NM) tribal and health authorities. The project will aim to provide a scientific basis for the prediction of disease spread and will consider scenarios associated with the possibility of another wave of the pandemic. Students from this minority-serving institution involved in the project will obtain valuable experience in the application of advanced machine learning models and methods in providing fast robust reaction to a national health, economic, and societal crisis.<br/><br/>In this study, machine learning methods will be used to analyze pandemic spread scenarios in different regions and to glean the most important features of the data characterizing the spread. The research team will use both traditional machine learning techniques and advanced methods, such as artificial neural networks, allowing development of virus incidence model capturing dependencies in both linear and nonlinear domains. The work will concentrate on understanding disease spread with regard to multiple socioeconomic factors. The problem can be treated as a sequence modeling one; so, recurrent neural networks and more complex models based on their recurrent cells might be one promising direction. The next step will be to assemble datasets for small isolated communities with different socioeconomic backgrounds and ethnicities ? comparing Navajo Indians living on the Navajo reservation to Los Alamos County (NM) ? and to test the applicability of the developed model to these regions. The spatiotemporal data available on the spread is heterogeneous in character. An important goal of this research is to classify the collected data with respect to the similarity in the epidemic curve behavior and then build separate models for different regions according to this classification. The proposed model will be used for prediction of future incidents and to produce the most effective non-medical recommendations for suppression and prevention of future viral outbreaks.<br/><br/>This research is supported by the Partnerships for Research and Education in Materials (PREM) program and the Condensed Matter and Materials Theory (CMMT) program in the Division of Materials Research in the Directorate for Mathematical and Physical Science using supplemental funds made available by the Coronavirus Aid, Relief, and Economic Security (CARES) Act.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	185747.0	USD
337	Richard T Lester	University of British Columbia	None	None	2021-04-30	Digital Virtual Support of Cases and Contacts to Novel Coronavirus (COVID-19): Readiness and Knowledge Sharing for Global Outbreaks (WelTel PHM)	The global outbreak of COVID-19 is the latest example of a rapidly spreading infectious outbreak with global impact. Infected patients with mild symptoms and asymptomatic contacts need to be isolated, ideally without overwhelming health facilities. WelTel, an integrated virtual care and patient engagement solution, emerged as an innovation initially to support the global HIV pandemic through a Canadian-Kenyan partnership over a decade ago. Co-founded by the lead investigator and registered in British Columbia, WelTel has continued to integrate research into a richly featured virtual care platform that can be used on the frontlines of healthcare delivery. The study aims to: 1-Deploy and co-optimize WelTel to assist in home monitoring and support of COVID-19 cases and contacts; 2- Determine essential linkages and technical demands of the digital health ecosystem for data security purposes and integration into other electronic health records (EHR) & health information management systems (HIMS); 3-Evaluate communication and other metadata captured by the system for public health quality improvement to better understand and reduce barriers (such as stigma); 4-Use novel computing approaches such as natural language processing (NLP) and machine learning to harness artificial intelligence (AI) capabilities to model, predict, and provide insights into future precision public health approaches. Collaborators have necessary expert skills in quantitative and qualitative research methods for rigorous assessment, and come from the countries targeted for the research deployment (Canada, UK, US, Kenya, and Rwanda). A rapid digital landscape analysis will also be done as a part of this research. Virtual care may be an efficient, cost-effective way to provide the necessary public health monitoring and support for patients and contacts of COVID-19 and future emerging communicable pathogens, as well as can inform public health quality improvement and precision care.	Canadian Institutes of Health Research	Research Grant	500000.0	CAD
338	Prof. Matthew Cotton	MRC/UVRI & LSHTM Uganda Research Unit	None	None	2021-04-30	African COVID-19 Preparedness (AFRICO19)	Our project, AFRICO19, will enhance capacity to understand SARS-CoV-2/hCoV-19 infection in three regions of Africa and globally. Building on existing infrastructures and collaborations we will create a network to share knowledge on next generation sequencing (NGS), including Oxford Nanopore Technology (MinION), coronavirus biology and COVID-19 disease control. Our consortium links three African sites combined with genomics and informatics support from the University of Glasgow to achieve the following key goals: 1. Support East and West African capacities for rapid diagnosis and sequencing of SARS-CoV-2 to help with contact tracing and quarantine measures. Novel diagnostic tools optimized for this virus will be deployed. An African COVID-19 case definition will be refined using machine learning for identification of SARS-CoV-2 infections. 2. Surveillance of SARS-CoV-2 will be performed in one cohort at each African site. This will use established cohorts to ensure that sampling begins quickly. A sampling plan optimized to detect initial moderate and severe cases followed by household contact tracing will be employed to obtain both mild to severe COVID-19 cases. 3. Provide improved understanding of SARS-CoV-2 biology/evolution using machine learning and novel bioinformatics analyses. Our results will be shared via a real-time analysis platform using the newly developed CoV-GLUE resource.	Wellcome/Department for International Development	Research Grant	2001990.0	GBP
339	Professor Dirk-Peter Herten	University of Birmingham	None	2020-08-01	2023-08-01	AMS Professorship Award for Professor Dirk-Peter Herten, University of Birmingham	I want to establish a world-leading research group in receptor signalling by providing tools and support for quantitative studies with molecular sensitivity for biomedical research. The prestigious award of the AMS fellowship will enable the purchase of cutting-edge microscopy tools and allow further automation of our microscopes to increase throughput and provide the capacity for super-resolved 3D reconstructions of whole cells. My position in COMPARE aligned to the Institute of Cardiovascular Sciences (ICVS) and the School of Chemistry at the University of Birmingham (UoB) adds expertise in methods development to the COMPARE advanced microscopy facility at UoB and will allow me to work on my quantitative microscopy methods. My appointment creates a unique opportunity to support researchers and clinicians in their search for solutions to urgent biomedical questions, like HIV infection or thrombosis, by use of existing techniques and novel approaches. I will involve Jeremy Pike (UoB, Data Analysis Officer) and Iain Styles (Computer Sciences, Turing Institute Fellow and Deputy Director of COMPARE, UoB) in machine learning approaches for the fast processing of 3D microscopy data. Additionally, I will initiate a planned industry collaboration with IRIS Biotech (Germany) to elaborate on the potential commercialisation of fluorescent probes for super-resolution microscopy, chemical multiplexing and metal cation sensing based on my patent (DE 10 2016 012 162.9). A challenge in methods development is to identify suitable targets and questions for the novel approach. The fellowship will enable collaborations with colleagues on campus and within COMPARE to increase the number of biomedical targets and facilitate translational application of my techniques which focus on T cell receptor signalling and more recently on GPCRs. Examples of new collaborations include the platelet immunoglobulin C-type lectin-like receptors GPVI and CLEC-2 (with Steve Watson, Steve Thomas and Natalie Poulter, ICVS) which are novel targets for a variety of thrombosis and thrombo-inflammatory disorders, and in the chemokine GPCR family (with Dimity Veprintsev, University of Nottingham - UoN) that play an important role in diseases like hypertension, hypoxia, or hypoglycaemia. In this context, I envision a key training centre for advanced microscopy at UoB also addressing problems like fluorescence labelling and probe development. This will involve colleagues in the School of Chemistry as well as COMPARE researchers working on fluorophores (Jon Preece, UoB) and bioactive molecules (Liam Cox, UoB; Barrie Kellam, UoN). COMPARE offered me a generous starting budget COMPARE (£ 450K) and the institute is in the process of refurbishing the labs to my needs, to move 3 co-workers together with my equipment by February 2020. Since I am unable to bring any overseas funding, the award will allow me to get accommodated with the UK grant application system and plan projects to strengthen my translational research (MRC) and the development of novel probes and techniques (BBSRC and EPSCR) without losing any momentum in my ongoing research activities. I have already applied for a translational research grant (BBSCR TRDF) in collaboration with Robert Henderson (University of Edinburgh), which involves quantitative imaging microscopy through use of his 256x256 APD camera.	The Academy of Medical Sciences	AMS Professorship Scheme Round 2	470621.92	GBP
340	Professor Xiaolin Huang	Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology	None	2018-02-01	2019-06-30	Low cost robotic orthosis for stroke treatment in rural China	China is the worst affected developing country with 2.5M new stroke cases each year and 11.1M stroke survivors at any given time. In the past decades, due to lower socioeconomic status, less stroke awareness, and inequitable distribution of medical resources to rural areas, the incidence rate and burden of stroke in China has increased disproportionately in rural areas of the northeast and central regions. Rehabilitation programmes have been shown to be extremely effective in reducing the disability and restoring walking ability through early training. However, in most rural areas of China no such medical rehabilitation centres or hospitals exist leaving the rural population without the therapies which will allow them to regain mobility functions after stroke. This leads to disability and has broader negative socioeconomic impacts. This project seeks to gather evidence directly from the key stakeholders in the beneficiary ODA countries (China and Kazakhstan) about what their problems and requirements are. The networking activities will allow us to build a full proposal based around actual rather than assumed need, and therefore maximise the impact achieved. The project aims to establish a multi-disciplinary consortium including experts from rehabilitation robotics, sensing, machine learning, physiotherapy and rehabilitation medicine. We aim to provide low-cost robotic solutions to stroke survivors in remote home and community environments. This would reduce therapists’/stroke carers' demand in rural areas of ODA countries whilst maximizing the stroke survivor’s sense of intention, involvement, interaction and achievement of limb movement, with greater likelihood of successful rehabilitation and improved quality of life.	The Academy of Medical Sciences	None	22000.0	GBP
341	TWO WORLDS CONSULTING LIMITED	TWO WORLDS CONSULTING LIMITED	None	None	2019-06-30	udu: AI Platform for Pandemic Intelligence	The UK, amongst others, lacks a coherent infrastructure to support effective direct and timely collection and analysis of pandemic data, about both the progressIon of Covid-19 itself and the population response to public policy aimed at mitigating and profiling its progress. Refining policy and informing the judgement calls required to navigate the balance between lockdown and economic damage requires both accurate data and the ability to rapidly model multiple, 'What if?' scenarios. Current data intelligence systems are partial, fragmented, incomplete, lag reality and, in most cases can only surface what they have specifically been asked to look for. AI systems used to look for patterns are often constrained by the quality and range of data available to them. Existing models tend to look at single factors in isolation, e.g. not taking into account multiple sources of mortality data or failing to take account factors such as population mobility and behaviour, the impact of events such as Cheltenham races, sunny bank holiday weather or other regional and seasonal variations. This can only be addressed through a more holistic approach to data collection and integration. This project therefore uses an advanced data intelligence platform, udu, which is capable of integrating a wide range of data from multiple sources and of multiple types and of actively discovering new data online. It then uses software that can self-organise itself around a task to discover relationships between and patterns in the collected data to provide an inferential view of pandemic impact, policy effectiveness and population behaviour. udu has been established for several years in niche markets. Here, we are building on previous experience by Two Worlds in using udu to create systems for the predictive analysis of environmental change to public health for the first time. The resulting system is intended to be capable of supporting direct exploration by human users, providing an interface (API) to allow other teams to test their own analytic models against the datascape created by udu and supporting local and external machine learning systems with a wider range of high quality data and analysis.	UK Research and Innovation	Research Grant	49984.0	GBP
342	Dr. Andre HOLZAPFEL	The Austrian Research Institute for Artificial Intelligence (OFAI)	None	2016-04-01	2016-09-30	A deeper understanding of common elements in musical rhythm	When listening to an unfamiliar style of music, we attempt to tap the beat and to synchronise with the rhythm, a process that enables us to interpret the structure of what we hear. This process is made possible by properties of music encountered in cultures throughout the whole world. In this project, we aim to identify such common properties in musical rhythm and their culturally dependent interpretation by applying a novel multidisciplinary methodology that combines the perspectives of music information retrieval (MIR) and ethnomusicology. Our insights into common elements of musical rhythm will be shaped into unitary models for the analysis of temporal structure in the musics of the world. Such models represent an important contribution to temper the existing bias towards Western music in MIR research, and can contribute to systems that can cope with a larger cultural diversity of music. In this very moment, the epoch-making development of deep learning gives us the tool to explore the borders and potentials of machine learning in application to music as a cultural expression. We will approach discovering common elements by answering important research questions from ethnomusicology with the help of innovative unitary models that combine deep learning and Bayesian modelling. Deep learning enables the discovery of low-level common signal properties, and Bayesian models enable for inclusion of expert knowledge and culturally dependent high-level interpretation. Our developed models will offer perspectives for a fair and balanced music recommendation and distribution in digital platforms and offer radically novel scientific perspectives on music analysis within engineering and humanities. Our project will promote a deeper understanding of music that suits the needs of a new digital age and indicates ways to connect musicians and listeners across cultural borders.	Austrian Science Fund FWF	Lise Meitner Programme	159620.0	EUR
343	Dr Amir Enshaei	University of Newcastle	Northern Instittue of Cancer Research	2016-08-01	2020-08-01	Development of machine learning system as a prediction tool in acute lymphoblastic leukaemia	None	Blood Cancer UK	Integrative Biology Fellowship	None	None
344	Doctor Richard Dobson	King's College London	None	2013-10-01	2016-09-30	Creating an early diagnostic blood test for Alzheimer's Disease	In this PhD we aim to validate, refine and extend a panel of biomarkers of early Alzheimer's disease pathology. One of the earliest known markers of Alzheimer's disease pathology is the level of amyloid beta in the brain; another early marker is hippocampal volume. Our previous work has shown that the level of some proteins in plasma associate with brain amyloid burden across independent cohorts and proteomic platforms. In this study these plasma protein markers will be validated, and novel plasma protein markers of brain amyloid burden identified. In addition, inexpensive and non-invasive multi-modal biomarkers of early Alzheimer's disease pathology will be investigated for the first time. Data on the level of plasma proteins, and/or other blood analytes or cognitive measures, will be compared to brain amyloid burden and/or hippocampal volume as derived from brain scans. Regression, classification and machine learning approaches will be used to study the ability of these biomarkers to predict brain amyloid burden or hippocampal atrophy. Cross-validation will be used to test the robustness of these biomarkers over datasets derived from independent cohorts and proteomic platforms. These results will reveal the clinical utility of inexpensive and non-invasive biomarkers of early Alzheimer's disease, a potentially transformative technology.	Alzheimer's Society	PhD Studentship	79457.0	GBP
345	Dr Chris Gibbons	University of Cambridge	None	2017-10-01	2018-09-30	Development and testing of an intelligent system for the personalised reporting and evaluation of patient-reported data (INSPiRED).	Objective To develop an intelligent computerised system (ConcertoHealth) oriented to supporting decision-making by helping patients communicate key aspects of their health and experience of care to healthcare providers.The system will include personalised adaptive questionnaires and automated analysis of written comments relating to experience of care as well as common mental and physical health issues. It will automatically analyse information, communicate results clearly and explain what steps should be taken next. Design The study will consist of four complementary work packages: Work Package One Validation of computer-adaptive tests for depression, anxiety, and physical function. Computer adaptive tests (CATs) can increase the accuracy and reduce the burden of questionnaires by tailoring assessments to the individual patient: thus asking fewer but more relevant questions. Before CATs can be used, item banks from which the CAT can withdraw questions must be validated. I will validate item banks for mental and physical health for use in the UK using a nationally-representative sample including people with long-term conditions. The analysis will be conducted using an internationally-approved analytical procedure which brings together leading psychometric techniques including item response theory. The effect of using different psychometric models (e.g. Rasch or multidimensional item-response theory) on the length and accuracy of CATs will be evaluated. New item banks will be compared with existing legacy questionnaires. Scores from the item banks will be directly comparable with existing legacy questionnaires using the same scale. Work Package Two Develop and test machine learning algorithms to make sense of open-text reports of patient experience and outcome. Machine learning refers to a set of statistical and computational techniques where computers 'learn' to recognise patterns in data. I will use machine learning to develop algorithms to recognise patterns in open-text comments collected from a large representative sample of people in the UK, including patients with long-term conditions. Three types of algorithm will be developed to: a.) identify linguistic markers of clinical states (e.g. depression); b.) rate the emotional tone of comments (e.g. feeling isolated); and c.) identify issues which may not be brought to light using structured questionnaires alone (e.g. side-effects, safety). I will use a range of techniques including support vector machines, nave Bayesian classifiers and topic models to develop the algorithms. Supervised algorithms will be assessed using sensitivity and specificity analyses for correctly performing the tasks which they were trained to complete. Work Package Three Co-creation of guidelines with patients and clinicians to inform the development of effective feedback for patient-reported assessments. I will use participatory design to develop strategies for presenting feedback using qualitative methods. Focus groups and interviews will be conducted with 48 patients with long-term conditions and 32 healthcare professionals from primary and secondary care services. Transcripts will be analysed using iterative two-stage coding to create strategies for presenting information embedded in user experience. The acceptability and comprehensibility of these presentation strategies will be assessed using a web-based survey of 250 patients, 250 clinicians and 250 members of the public to create evidence-based guidelines. Work Package Four - Development of specialist computer system for collecting patient-reported data that includes all the tools validated in the current study. ConcertoHealth will be based on the existing computerised platform and will bring together research evidence from WP1-3 into an open-access computer-based system suitable for use across the NHS. Expected outcomes The system will improve the patient-centeredness of care in the NHS by providing a means to highlight important issues relating to patient health and experience which can be used to improve health service delivery and organisation at the individual, local and national levels.	National Institute for Health Research (Department of Health)	Full award	115285.0	GBP
346	Dr Coricelli	Università degli Studi di Trento	None	2014-08-01	2019-08-01	Transfer Learning within and between brains	The neural bases of adaptive behavior in social environments are far from being understood. We propose to use both computational and neuroscientific methodologies to provide new and more accurate models of learning in interactive settings. The long-term objective is to develop a neural theory of learning: a mathematical framework that describes the computations mediating social learning in terms of neural signals, structures and plasticity. We plan to develop a model of adaptive learning based on three basic principles: (1) the observation of the outcome of un-chosen options improves the decisions taken in the learning process, (2) learning can be transferred from one domain to another, and (3) learning can be transferred from one agent to another (i. e. social learning). In all three cases, humans appear able to construct and transfer knowledge from sources other than their own direct experience, an underappreciated though we believe critical aspect of learning. Our approach will combine neural and behavioral data with computational models of learning. The hypotheses will be formalized into machine learning algorithms and neural networks of "regret" learning, to quantify the evolution of the learning computations on a trial-by-trial basis from the sequence of stimuli, choices and outcomes. The existence and accuracy of the predicted computations will be then tested on neural signals recorded with functional magnetic resonance imaging (fMRI). The potential findings of this project could lead us to suggest general principles of social learning, and we will be able to measure and model neural activation to show those general principles in action. In addition, our results could have important implications into policy-making - by revealing what type of information agents are naturally inclined to better learn from - and clinical practice - by outlining potential diagnostic procedures and behavioral therapies for disorders affecting social behavior.	European Research Council	Consolidator Grant	1999998.0	EUR
347	Gerardo Chowell-Puente	Georgia State University Research Foundation, Inc.	None	2020-04-15	2021-03-31	Collaborative Research: RAPID: RTEM: Rapid Testing as Multi-fidelity Data Collection for Epidemic Modeling	Biological Sciences - The novel coronavirus (COVID-19) epidemic is generating significant social, economic, and health impacts and has highlighted the importance of real-time analysis of the spatio-temporal dynamics of emerging infectious diseases. COVID-19, which emerged out of the city of Wuhan in China in December 2019 is now spreading in multiple countries. It is particularly concerning that the case fatality rate appears to be higher for the novel coronavirus than for seasonal influenza, and especially so for older populations and those with prior health conditions such as cardiovascular disease and diabetes. Any plan for stopping the epidemic must be based on a quantitative understanding of the proportion of the at-risk population that needs to be protected by effective control measures in order for transmission to decline sufficiently and quickly enough for the epidemic to end. Different data collection and testing modalities and strategies available to help calibrate transmission models and predict the spread/severity of a disease, have variable costs, response times, and accuracies. In this Rapid Response Research (RAPID) project, the team will examine the problem of establishing optimal practices for rapid testing for the novel coronavirus. The result will be the Rapid Testing for Epidemic Modeling (RTEM), which will translate into science-based predictions of the COVID-19 epidemic's characteristics, including the duration and overall size, and help the global efforts to combat the disease. The RTEM will fill an important gap in data-driven decision making during the COVID-19 epidemic and, thus, will enable services with significant national economic and health impact. The educational impact of the project will be on mentoring of post-doctoral and PhD researchers and on curricula by incorporating research challenges and outcomes into existing undergraduate and graduate classes. <br/><br/>Computational models for the spatio-temporal dynamics of emerging infectious diseases and data- and model-driven computer simulations for disease spreading are increasingly critical in predicting geo-temporal evolution of epidemics as well as designing, activating, and adapting practices for controlling epidemics. In this project, the researchers tackle a Rapid Testing for Epidemic Modeling (RTEM) problem: Given a partially known target disease model and a set of testing modalities (from surveys to surveillance testing at known disease hotspots), with varying costs, accuracies, and observational delays, what is the best rapid testing strategy that would help recover the underlying disease model? Several scientific questions arise: What is the value of testing? Should only sick people be tested for virus detection? What level of resources should be devoted to the development of highly accurate tests (low false positives, low false negatives)? Is it better to use only one type of test aiming at the best cost/effectiveness trade off, or a non-homogeneous testing policy? Naturally these questions need to be investigated at the interface of epidemiology, computer science, machine learning, mathematical modeling and statistics. As part of the work, the team will develop a model of transmission dynamics and control, tailored to COVID-19 in a way that accommodates diagnostic testing with varying fidelities and delays underlying a rapid testing regimen. The investigators will further integrate the resulting RTEM-SEIR model with EpiDMS and DataStorm for executing continuous coupled simulations. <br/><br/>This project is jointly funded through the Ecology and Evolution of Infectious Diseases program (Division of Environmental Biology) and the Civil, Mechanical and Manufacturing innovation program (Engineering).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	67000.0	USD
348	Michael Pazzani	University of California-San Diego	None	2020-05-01	2021-04-30	RAPID: Explainable Machine Learning for Analysis of COVID-19 Chest CT	Computer and Information Science and Engineering - In December 2019, it was discovered that a widely contagious pneumonia was caused by a new coronavirus infection now named COVID-19. The primary test for detection of the virus is real-time polymerase chain reaction (RT-PCR) with sensitivity of approximately 71% in some studies. However, this test may require several days to provide a result. Perhaps more importantly, imaging with x-ray or computed tomography (CT) are required to confirm pneumonia, which is the principal cause of death, as it leads to acute respiratory distress syndrome (ARDS). Recent studies have shown sensitivity of chest CT for approximately 98% for COVID-19 pneumonia and could provide immediate results but currently require human interpretation. Given the need for rapid, more accurate diagnosis, this project will use, adapt, and evaluate explainable machine learning techniques to diagnosis of COVID-19 pneumonia. This project will improve the understanding of mechanisms of COVID-19 and will help mitigate its impacts.<br/><br/>Viral nucleic acid detection using real-time polymerase chain reaction (RT-PCR) is the primary method for diagnosis of COVID-19 infection, which has rapidly spread worldwide as a global pandemic. Sensitivity of this test for COVID-19 infection has been estimated at approximately 71% in some studies and may require several days for a result. X-ray and CT imaging are complementary technologies that allow diagnosis of COVID-19 pneumonia, which can evolve to acute respiratory distress syndrome (ARDS) -- the principal cause of death in patients with COVID-19 infection. Especially early in the course of the disease, chest CT has multiple advantages over RT-PCR yielding results more quickly and is already widely deployed, but requires expert radiologist interpretation. The number of chest CTs may rapidly exceed the speed and capacity of already strained radiologists. An explainable machine learning algorithm may address this disadvantage to expedite the interpretation of chest CT and assist rapid triage of patients to the ICU, inpatient ward, monitoring unit, or home self-quarantine. Machine learning algorithms, specifically those leveraging deep convolutional neural networks (deep learning), have the potential for facilitating even more rapid diagnosis within minutes. This project seeks to validate the use of explainable deep learning methods to adjust diagnostic operating points for multiple applications, including (a) disease screening, (b) disease staging and prognostication, and (c) evaluation of treatment response.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	101643.0	USD
349	Gregory Voth	University of Chicago	None	2020-05-01	2021-04-30	RAPID: Data-driven Multiscale Integrative Model of the Coronavirus Virion	Mathematical and Physical Sciences - Gregory Voth of the University of Chicago is supported by this RAPID award to develop and deploy multiscale models of the entire SARS-CoV-2 virus, the virus that causes the novel coronavirus infectious disease 2019 (COVID-19). Such multiscale models, at both the atomistic and coarse grain levels, contribute greatly to our understanding of how this virus replicates. Molecular simulations of viral processes in COVID-19 are useful to identify possible weaknesses in the viral life cycle. This research focuses on the dynamics of coronavirus processes, including the conformational transitions that are required for the virus to function. The project has three main foci: 1) all-atom simulations of individual viral proteins that are essential to the viral life cycle; 2) a coarse-grain models to a holistic understanding of entire virion (the virus outside the host cell) and its large scale processes, such as fusion of virions with host cells; and 3) machine-learning-based approaches to link the all-atom and coarse grain models and further refine their accuracy. As part of a larger, international community working on COVID-19, all data, models and analysis code will be made publicly available as soon as they are developed, including through the NSF-funded Molecular Science Software Institute (MolSSI). The complete multiscale picture of virus structure and dynamics will be used to identify potential target sites for drug development and other therapeutic strategies.<br/><br/><br/>The research in this RAPID project is for the development and application of multiscale computer simulation methods to characterize key elements of large-scale viral processes in SARS-CoV-2 replication. To achieve this goal there are three main objectives: (1) to characterize the dynamical behavior of essential viral proteins involved using all-atom molecular dynamics simulations and understand the conformational transitions necessary for their function; (2) to develop and model the complete SARS-CoV-2 virion using coarse-grained simulation methods; and (3) to develop machine learning based approaches that systematically link atomic-level and coarse-grained simulation scales, and facilitate the generation of even more accurate and descriptive coarse-grained models. This research focuses on several biomolecular systems that are urgently needed to understand and characterize the transmission and propagation of the SARS-CoV-2 virus, including the spike protein that mediates entry of the viral particles into host cells, the host cell receptor, angiotensin-converting-enzyme 2, which binds the spike protein, coronavirus protease which catalyzes viral processes, and other viral protein components, especially as structural data and biochemical information are released in the next few months. Coarse-grained simulations will focus on the urgent need to develop a holistic model of the entire SARS-CoV-2 virion as well as its large-scale processes such as the fusion of virions with host cells.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	190595.0	USD
350	Arup Chakraborty	Massachusetts Institute of Technology	None	2020-04-01	2021-03-31	RAPID: Immunogenicity of SARS-CoV2 to Human T Cells	Mathematical and Physical Sciences - Pandemics caused by infectious pathogens have plagued humanity since antiquity. The Coronavirus Disease 2019 (COVID-19) caused by the SARS-CoV-2 virus is currently spreading across the world rapidly, including in the United States, with major adverse impact on health and the economy. The SARSCoV-2 outbreak has led to several urgent efforts to develop vaccines that may offer protection against this virus. It is unknown as to whether the current approaches being pursued will elicit protective immune responses in humans. While vaccines have been very effective against many pathogens, the empirical methods for vaccine development pioneered by Pasteur and Jenner over two centuries ago have failed to produce effective vaccines against Human Immune Deficiency Virus, Malaria, Tuberculosis, and many other pathogens. Therefore, rational design of vaccines based on a mechanistic understanding of the pertinent virology and immunology is being pursued, and these efforts include work that is rooted in statistical physics. SARSCoV-2 is phylogenetically most similar to SARS-CoV. This project will use a machine learning approach to understand how the SARS-CoV-2 virus interacts with the immune T cells. This work will directly impact the design of SARS-CoV-2 vaccines and vaccines against future endemic-causing pathogens.<br/><br/>Analyses of patients who have recovered from SARS-CoV shows that antibody responses are not prevalent a few years later, but memory T cell responses are durable and may offer long-term protection. The main questions addressed by this project are 1. Will the SARS-CoV peptides targeted by human T cells that are mutated in SARS-CoV-2 still elicit human T cell responses - i.e. are they immunogenic? 2: Are the 102 peptides identified by host major histocompatibility molecules binding assays alone that are common between SARS-CoV and SARS-CoV-2 immunogenic in humans? If not, they are irrelevant from vaccine design perspective. The goal of the work proposed here is to take a physics-based machine learning approach to determine the immunogenicity of SARS-CoV-2 proteins to human T cell responses.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	124472.0	USD
351	Viktor Prasanna	University of Southern California	None	2020-05-01	2021-04-30	RAPID: ReCOVER: Accurate Predictions and Resource Allocation for COVID-19 Epidemic Response	Computer and Information Science and Engineering - The recent outbreak of COVID-19 and its world-wide impact calls for urgent measures to contain the epidemic. Predicting the speed and severity of infectious diseases like COVID-19 and allocating medical resources appropriately is central to dealing with epidemics. Epidemics like COVID-19 not only affect world-wide health, but also have profound economic and social impact. Containing the epidemic, providing informed predictions and preventing future epidemics is essential for the global population to resume their day-to-day work and travel without fear. Shortage of resources puts undue stress on healthcare system further risking health of the community. Preparedness and better management of available resources would require specific predictions at the level of cities and counties around the world rather than solely at the level of countries. The project will provide a predictive understanding of the spread of the virus by developing machine learning based computational models to study the transmission of the virus and evaluate the impact of various interventions on disease spread. The project will learn infection prediction models for COVID-19 considering the following. (i) Predicting at state/county/city-level rather than country-level as finer granularity is essential in planning and managing resources. (ii) How infectious a person is changes over time. Learning the model through observed data will help in understanding of the temporal nature of the virality. (iii) At such granularity travel is a significant reason for the spread and needs to be accounted for. (iv) Available data needs to be ?corrected? by finding the number of underlying unreported cases that are not observed and yet influence the epidemic dynamics. The project will also solve the resource allocation problem based on the prediction ? for instance if a certain number of masks will be available next week in a certain state, how should they be distributed across different hospitals in the state (which hospitals and how many in each state)?<br/><br/>Proposed project ReCOVER will use a novel fine-grained, heterogeneous infection rate model to perform predictions at various granularities (hospital/airports, city, state, country) while accounting for human mobility. ReCOVER will integrate data from various sources to build highly accurate models for prediction of the epidemic across the world at various granularity. Due to the ability to capture temporal heterogeneity in infection rate, the approach has the potential to provide insights into infectious nature of COVID-19 which are not fully understood yet. The project will address the issue of unreported cases through temporal analysis of historical infections and correct the data. The right granularities of modeling will be automatically identified, e.g., when to model a state over its cities to trade-off precision for higher reliability in predictions. The proposed project also formulates and solves a resource allocation problem that can guide the response to contain the epidemic and prevent future outbreaks. This is provided by optimal solutions to resource allocation over a network where each node (representing a region) has a function that captures probabilistic response. While the project obtains data with COVID-19 in consideration, the model and algorithms developed under the project are applicable to a wide class of contagious diseases. The project will culminate into an interactive customizable tool that can be used to perform predictions and resource management by a qualified user such as a government entity tasked with managing the epidemic response. The data and code will also be shared with research community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	158592.0	USD
352	Indrakshi Ray	Colorado State University	None	2020-05-01	2021-04-30	RAPID: ENSURING INTEGRITY OF COVID-19 DATA AND NEWS ACROSS REGIONS	Computer and Information Science and Engineering - Large amounts of epidemiological data are being generated and collected from a variety of sources to understand the impact and propagation of COVID-19. Similarly, huge amounts of news articles are generated and disseminated about the pandemic to keep the population informed. The appropriateness of the actions taken by individuals, corporations, and governments are often based on the quality of data and news. Thus, ensuring the quality of data and news is important. However, malicious actors can alter the attributes of data records, insert spurious records, or suppress records causing any analysis to be inadequate and misinformation to be propagated. This project addresses the critical problem of defining and identifying spurious data and news concerning COVID-19, and tracking the source of misinformation. The project novelty lies in the development of an approach and associated toolset that adapts and combines Machine Learning technologies to detect spurious data and misinformation and presents the results in a manner that is easy for end users to understand and interpret. The approach detects discrepancies in COVID-19 data and traces the flagged discrepancies back to the data sources. The results obtained from the news sources and those obtained from the medical data analysis are compared to determine correlations between the quality of news and the degree and type of data manipulation performed at any region. The project?s impacts are on significantly enhancing the ability to perform accurate scientific analysis, and detecting and explaining news manipulation with respect to COVID-19. The scientific principles developed in the project are expected to be useful outside the medical domain. The PI and the students identified for this project are minorities. The project will be carried out in the Computer Science Department at Colorado State University which is a BRAID affiliate.<br/><br/>COVID-19 data discrepancies are related to (1) single records, where some field is modified, (2) sequence of records over time forming a temporal dimension, where spurious records have been inserted or records have been suppressed, and (3) sequences of records across regions forming a spatial dimension, where there is a pattern of manipulation or information disclosure across regions. The approach determines the appropriate combination of autoencoders, Long Short-Term Memory (LSTM), Temporal Convolution Network (TCNs), and Convolution Neural Networks (CNNs) that can work with data obtained from medical sources and news containing both spatial and temporal dimensions. The tools help the investigators? collaborators at the University of Colorado Anschutz Medical Center and Center for Disease Control and Prevention to perform data integrity checking of medical records and to provide explanations of integrity violations. The tools also handle different types of data and news alterations pertaining to COVID-19.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	199748.0	USD
353	Thomas Boellstorff	University of California-Irvine	None	2020-05-01	2021-04-30	RAPID: The Role of Emerging Virtual Cultures in the Prevention of COVID-19 Transmission	Social, Behavioral and Economic Sciences - The COVID-19 pandemic has transformed our relationship to the physical world. Social distancing guidelines have led many people to avoid all forms of public life, from concerts and restaurants to everyday interaction in parks, neighborhoods, and the homes of family and friends. In response there has been a massive increase in online interaction: the internet has suddenly become the primary way that many Americans socialize, labor, and learn. It is crucial to gain a better understanding of how the emergence of these changes is related to the pandemic. Even if a vaccine is discovered, preventing catastrophic levels of COVID-19 transmission into the next few years will depend on social distancing that can be sustained and integrated with work, education, and community. This means going online. The starting point for addressing this global challenge is thus the fact that what we call ?social distancing? is really physical distancing. Successful physical distancing will rely on new forms of social closeness online. Yet there is not just one ?online.? A rapid and effective response requires clarifying the impact of virtual worlds as part of different forms of online interaction that comprise a virtual culture: social network sites, streaming websites, and multiplayer platforms. The project will also train graduate student researchers in methodological approaches for studying online cultures. <br/><br/>This research will be conducted in a densely trafficked virtual world. Virtual worlds are places where individuals interact with avatars in online environments. The investigators have conducted research in a virtual world context for over a decade, and thus have detailed baseline data with which to examine what is happening as a large number of individuals enter that virtual world due to the COVID-19 pandemic. What is the sudden move to virtual worlds doing in terms of social closeness and interaction? How does co-presence in virtual place transform intimacy and collaboration? How might this provide innovative strategies for preventing viral transmission, by forging new forms of social closeness in the context of physical distancing? To investigate these questions, the researchers will conduct participant observation, individual interviews, and group interviews. The study will compare individuals who have spent time in the virtual world for years with individuals who have entered the virtual world after COVID-19. Findings from this research will provide insight into the specific possibilities virtual worlds are providing in the circumstances of societies reshaped by COVID-19. In these new circumstances, virtual worlds will be one element of an online ecosystem linking drones, robots, and autonomous vehicles to mobile devices, social network sites, online games and streaming, augmented reality, artificial intelligence, machine learning, and data analytics. The research will thus provide a better understanding of the place of virtual worlds in this emerging online ecosystem.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	195619.0	USD
354	Michael Vahey	WASHINGTON UNIVERSITY	None	2020-05-15	2021-04-30	RAPID: A multiscale approach to dissect SARS-CoV-2 attachment to host cells and detect viruses on surfaces	Biological Sciences - The 2019 novel coronavirus, identified as the cause for the pneumonia pathology reported in Wuhan, spread quickly and became a global pandemic. The project will employ experimental methods to develop sensors for the detection of SARSCoV-2 from environmental samples and develop predictive models for virus attachment to cells by applying computational machine learning methods. The outcome of this project will contribute to the development of proactive measures to identify viruses with pandemic potential before they are able to transmit and spread broadly among humans. The graduate students involved in this research will gain experience in protein biochemistry, fluorescence microscopy, and computational simulations and experience utilizing those skills to problems of societal importance.<br/><br/>This NSF Rapid response Research (RAPID) project will support a project that is aimed to characterize receptor interactions mediated by the Spike protein (S) of SARS-CoV-2. Development of fluorescence-based assays to characterize SARSCoV-2 attachment to Angiotensin converting enzyme (ACE2)-functionalized surfaces with controlled density and mobility, identifying peptide mimics of the ACE2 ectodomain for the development of sensors to detect SARSCoV-2 from environmental samples, and develop and validate predictive models of CoV attachment from primary sequence using machine learning constitute the specific goals of this project.<br/><br/>This RAPID award is made by the Molecular Biophysics Program in the Division of Molecular and Cellular Biosciences, using funds from the Coronavirus Aid, Relief, and Economic Security (CARES) Act.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	200000.0	USD
355	Anastasia Angelopoulou	Columbus State University	None	2020-05-15	2021-04-30	RAPID/Collaborative Research: Quantifying Social Media Data for Improved Modeling of Mitigation Strategies for the COVID-19 Pandemic	Engineering - This Rapid Response Research (RAPID) grant will support research that will contribute new knowledge related to modeling social behavior and community activity during the COVID-19 pandemic, as well as future pandemics with COVID-19 characteristics. The model focuses on compliance with mitigation strategies and public health guidelines, thus enabling the selection of policies that are most effective in promoting both the progress of science and advancing national health and prosperity. Various pandemic models are currently being used to predict the spread of a virus and establish which mitigation strategies are the most effective. These models are heavily based on assumptions and may include an oversimplified reality of how populations react and behave. This research will provide needed knowledge and methods for the development of a model of how individuals in the U.S. react to certain mitigation strategies, such as social-distancing, stay-at-home orders, quarantines, and travel advisories, by mining and analyzing social media data during the COVID-19 crisis. This enhanced modeling approach and its resultant model will be of great value to disaster response managers and policy/decision makers to understand human social behavior. This work allows assessment of the effectiveness of mitigation strategies and public health guidelines during pandemics (and other crises). This project will also form the basis of a publicly available case study suitable for university level students that can be widely incorporated in courses. <br/><br/>Although individual-based and homogeneous mixing pandemic models provide useful insights and predictive capabilities within a range of possibilities, they are highly sensitive to people?s actions. This research aims to provide an enhanced approach to model social behavior and community activity during a pandemic in terms of compliance with mitigation strategies and public health guidelines. Social media data present a brief window of opportunity for research on how, and to what extent, the public does or does not comply with the recommended mitigation strategies and public health guidelines. The research team will collect real-time data from social media related to COVID19-exposed regional populations in the U.S. The data will be analyzed using machine learning techniques to identify non-mutually exclusive clusters of people based on similarity of their demographic, geographic, and time information, and establish relationships among clusters. The analyzed data will form the basis of a data-driven multi-paradigm simulation model that captures changes in public sentiment over time, quantifies the resistance/compliance with mitigation strategies and health guidelines, and gauges overall effectiveness of various mitigation strategies and advice over time.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	13406.0	USD
356	Mary Jo Ondrechen	Northeastern University	None	2020-05-15	2021-04-30	RAPID: D3SC: Identification of Chemical Probes and Inhibitors Targeting Novel Sites on SARS-CoV-2 Proteins for COVID-19 Intervention	Mathematical and Physical Sciences - The life cycle of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) involves a number of viral proteins and enzymes required for infectivity and replication. Inhibitors that target these enzymes serve as potential therapeutic interventions against coronavirus disease 2019 (COVID-19). With this award, the Chemistry of Life Processes program in the Chemistry Division is supporting the research of Drs. Mary Jo Ondrechen and Penny J. Beuning from Northeastern University to apply computational methods to identify sites in SARS-CoV-2 proteins that would be good targets for binding inhibitors. The project uses artificial intelligence methods developed at Northeastern University to identify pockets and crevices in the structures of viral proteins that may serve as new targets for the development of antiviral agents. Large datasets of natural and synthetic compounds are computationally searched for molecules that fit into these alternative sites, and any compounds that fit will be experimentally tested for their ability to inhibit the functions of these viral enzymes. The project provides training in computational chemistry and biochemical analysis to graduate students and postdoctoral associates.<br/><br/>This project uses the unique Partial Order Optimum Likelihood (POOL) machine learning (ML) method developed by Dr. Ondrechen?s group to predict multiple types of binding sites in SARS-CoV-2 proteins, including catalytic sites, allosteric sites, and other interaction sites. The goals of this project are to apply the POOL-ML method to identify the binding sites on viral pathogen SARS-CoV-2 proteins using the three-dimensional protein structures as input. Molecular dynamics simulations are used to generate conformations for ensemble docking. Compounds from the large molecular databases are computationally docked into the predicted sites to identify potentially strong binding ligands. Candidate ligands to selected SARS-CoV-2 proteins, including the main protease and 2?-O-ribose RNA methyltransferase, are experimentally tested in vitro for binding affinity and the effect of the best predicted inhibitors on catalytic activities determined by direct biochemical assays. All the SARS-CoV-2 protein structures in the Protein Data Bank (PDB) are studied. Compound libraries for the study include: a) selected 2600+ compounds from the ZINC and Enamine databases that are already being manufactured; b) a library of 20,000+ compounds found in foods that the team recently gained access to; these potentially hold some special advantages, including ready availability in the public domain and low cost; and c) the March 2020 open access CAS (American Chemical Society) database of 50,000 compounds with known or potential anti-viral activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	165808.0	USD
357	Marinka Zitnik	Harvard University	None	2020-05-01	2021-04-30	RAPID:Collaborative Research: Computational Drug Repurposing for COVID-19	Computer and Information Science and Engineering - With the disruptive nature of the COVID-19 pandemic, effective treatments could save the lives of severely ill patients, protect individuals with a high risk of infection, and reduce the time patients spend in hospital beds. However, there are currently no effective treatments for COVID-19. Traditional methodologies take years to develop and test compounds from scratch. Machine learning provides promising new approaches to repurpose drugs that are safe and already approved for other diseases. This project will develop a machine learning toolset to expedite the development of safe and effective medicines for COVID-19. The toolset will rapidly identify safe repurposing opportunities for approved and experimental drugs. It will predict whether treatments may have therapeutic effects in COVID-19 patients, allowing the identification of drugs and drug cocktails that are safe and plentiful enough to treat a substantial number of patients. By putting tools in the hand of practitioners, the activities in this project will have an immediate impact. They will result in actionable predictions that are accurate and interpretable. <br/><br/>Recently, the principal investigators have developed a series of machine learning tools to identify drug repurposing opportunities. Building on foundational previous work, in this project, the principal investigators will first build a large COVID-19 focused knowledge graph that will capture fundamental and COVID-19-specific biological knowledge. The graph learning methods will be adapted to identify safe drugs and drug cocktails for COVID-19. To predict the safety of cocktails with two or more drugs, the methods will generalize to an exponentially large space of high-order drug combinations. In addition to drug safety, efficacy is a crucial endpoint for drug development. The project will develop a novel graph neural network (GNN) method to identify efficacious drug repurposing opportunities, even for diseases, such as COVID-19, that do not yet have any drug treatments and thereby, no label, supervised information. The method will predict what drugs and drug combinations may have a therapeutic effect on COVID-19. Finally, the principal investigators will integrate the developed tools into a complete, explainable framework that will generate predictions, provide explanations, and incorporate human feedback into the machine learning loop. This project will provide new, open tools for rapid drug repurposing that will be relevant for COVID-19 and other emerging pathogens. Additionally, the project will provide unique opportunities for multi-disciplinary curriculum development, training and advising, and professional activities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	99863.0	USD
358	Meggan Craft	University of Minnesota-Twin Cities	None	2020-05-15	2021-04-30	RAPID: The effect of contact network structure on the spread of COVID-19: balancing disease mitigation and socioeconomic well-being	Biological Sciences - What makes COVID-19 spread rapidly in some places, yet slowly in others? How should society lessen social distancing while limiting an increase in infections? To answer these questions, this Rapid Response Research (RAPID) project seeks to understand how patterns of interpersonal interaction (?structure?) in social contact networks affect disease spread in a population. The researchers will simulate a disease spreading through a variety of social contact networks, and use machine learning to relate each network?s structure to the number and timing of new infections. By limiting structures related to increased disease, societies may be able to reopen other parts of their economies while still curbing overall disease spread. The researchers will produce an interactive web application for the public and decision-makers to visualize trade-offs between reducing disease and maintaining social cohesion. This research will support the professional development of an early career scientist.<br/><br/>This research aims to determine the inherent risk of SARS-CoV-2 spread based on contact network structure. The researchers will use machine learning to 1) identify network structures that influence disease spread and 2) predict disease spread on empirical contact networks. Important network structures will serve as targets for simulated disease mitigation interventions (e.g. reducing structures that increase levels of disease or increasing structures that reduce disease levels). Finally, the researchers will investigate whether future outbreaks of COVID-19 or other diseases could be alleviated through optimizing social contact networks ahead of time. The outcomes of this research will inform and facilitate quick, efficient interventions to reduce the social and economic costs of COVID-19. This research will develop a general framework for relating disease to network structure. Thus, results can be generalized beyond the current pandemic, serving to further our understanding of potential future waves of COVID-19, as well as other directly-transmitted diseases in humans, livestock, and wildlife.<br/><br/>This RAPID award is made by the Ecology and Evolution of Infectious Diseases Program in the Division of Environmental Biology, using funds from the Coronavirus Aid, Relief, and Economic Security (CARES) Act<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	199136.0	USD
359	Gil Gallegos	New Mexico Highlands University	None	2020-05-15	2021-04-30	RAPID: Machine Learning Methods to Understand, Predict and Reduce the Spread of COVID-19 in Small Communities	Mathematical and Physical Sciences - The ongoing COVID-19 outbreak has recently reached pandemic status spreading all around the world. The severity of the pandemic, along with an enormous impact on world?s economy and society, has forced governments to introduce emergency measures. It is essential to utilize the available statistical data from trusted sources in order to model and evaluate the dynamics of the pandemic spread, to not only better understand such complex systems, but to learn and develop possible solutions to prevent further spread of current and/or similar future outbreaks. Thus, this research, devoted to the development of mathematical models of COVID-19 pandemic spread, addresses an urgent national need. Faculty and students in computer science, anthropology, and computational chemistry at New Mexico Highlands University have formed a diverse group for finding a solution to the complicated problems of the description and prediction of COVID-19 spread. This multidisciplinary project is expected to yield a better understanding of the interconnections among many factors that contribute to the spread of COVID-19. Statistical data will be collected in regions of Northern New Mexico, including San Juan and McKinley Counties in the Navajo Nation and Los Alamos county outside of the Navajo Nation. Analysis of the collected statistical data along with socio-cultural assessment from this project will be presented to New Mexico (NM) tribal and health authorities. The project will aim to provide a scientific basis for the prediction of disease spread and will consider scenarios associated with the possibility of another wave of the pandemic. Students from this minority-serving institution involved in the project will obtain valuable experience in the application of advanced machine learning models and methods in providing fast robust reaction to a national health, economic, and societal crisis.<br/><br/>In this study, machine learning methods will be used to analyze pandemic spread scenarios in different regions and to glean the most important features of the data characterizing the spread. The research team will use both traditional machine learning techniques and advanced methods, such as artificial neural networks, allowing development of virus incidence model capturing dependencies in both linear and nonlinear domains. The work will concentrate on understanding disease spread with regard to multiple socioeconomic factors. The problem can be treated as a sequence modeling one; so, recurrent neural networks and more complex models based on their recurrent cells might be one promising direction. The next step will be to assemble datasets for small isolated communities with different socioeconomic backgrounds and ethnicities ? comparing Navajo Indians living on the Navajo reservation to Los Alamos County (NM) ? and to test the applicability of the developed model to these regions. The spatiotemporal data available on the spread is heterogeneous in character. An important goal of this research is to classify the collected data with respect to the similarity in the epidemic curve behavior and then build separate models for different regions according to this classification. The proposed model will be used for prediction of future incidents and to produce the most effective non-medical recommendations for suppression and prevention of future viral outbreaks.<br/><br/>This research is supported by the Partnerships for Research and Education in Materials (PREM) program and the Condensed Matter and Materials Theory (CMMT) program in the Division of Materials Research in the Directorate for Mathematical and Physical Science using supplemental funds made available by the Coronavirus Aid, Relief, and Economic Security (CARES) Act.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	185747.0	USD
360	Richard T Lester	University of British Columbia	None	None	2021-04-30	Digital Virtual Support of Cases and Contacts to Novel Coronavirus (COVID-19): Readiness and Knowledge Sharing for Global Outbreaks (WelTel PHM)	The global outbreak of COVID-19 is the latest example of a rapidly spreading infectious outbreak with global impact. Infected patients with mild symptoms and asymptomatic contacts need to be isolated, ideally without overwhelming health facilities. WelTel, an integrated virtual care and patient engagement solution, emerged as an innovation initially to support the global HIV pandemic through a Canadian-Kenyan partnership over a decade ago. Co-founded by the lead investigator and registered in British Columbia, WelTel has continued to integrate research into a richly featured virtual care platform that can be used on the frontlines of healthcare delivery. The study aims to: 1-Deploy and co-optimize WelTel to assist in home monitoring and support of COVID-19 cases and contacts; 2- Determine essential linkages and technical demands of the digital health ecosystem for data security purposes and integration into other electronic health records (EHR) & health information management systems (HIMS); 3-Evaluate communication and other metadata captured by the system for public health quality improvement to better understand and reduce barriers (such as stigma); 4-Use novel computing approaches such as natural language processing (NLP) and machine learning to harness artificial intelligence (AI) capabilities to model, predict, and provide insights into future precision public health approaches. Collaborators have necessary expert skills in quantitative and qualitative research methods for rigorous assessment, and come from the countries targeted for the research deployment (Canada, UK, US, Kenya, and Rwanda). A rapid digital landscape analysis will also be done as a part of this research. Virtual care may be an efficient, cost-effective way to provide the necessary public health monitoring and support for patients and contacts of COVID-19 and future emerging communicable pathogens, as well as can inform public health quality improvement and precision care.	Canadian Institutes of Health Research	Research Grant	500000.0	CAD
361	Prof. Matthew Cotton	MRC/UVRI & LSHTM Uganda Research Unit	None	None	2021-04-30	African COVID-19 Preparedness (AFRICO19)	Our project, AFRICO19, will enhance capacity to understand SARS-CoV-2/hCoV-19 infection in three regions of Africa and globally. Building on existing infrastructures and collaborations we will create a network to share knowledge on next generation sequencing (NGS), including Oxford Nanopore Technology (MinION), coronavirus biology and COVID-19 disease control. Our consortium links three African sites combined with genomics and informatics support from the University of Glasgow to achieve the following key goals: 1. Support East and West African capacities for rapid diagnosis and sequencing of SARS-CoV-2 to help with contact tracing and quarantine measures. Novel diagnostic tools optimized for this virus will be deployed. An African COVID-19 case definition will be refined using machine learning for identification of SARS-CoV-2 infections. 2. Surveillance of SARS-CoV-2 will be performed in one cohort at each African site. This will use established cohorts to ensure that sampling begins quickly. A sampling plan optimized to detect initial moderate and severe cases followed by household contact tracing will be employed to obtain both mild to severe COVID-19 cases. 3. Provide improved understanding of SARS-CoV-2 biology/evolution using machine learning and novel bioinformatics analyses. Our results will be shared via a real-time analysis platform using the newly developed CoV-GLUE resource.	Wellcome/Department for International Development	Research Grant	2001990.0	GBP
362	Professor Dirk-Peter Herten	University of Birmingham	None	2020-08-01	2023-08-01	AMS Professorship Award for Professor Dirk-Peter Herten, University of Birmingham	I want to establish a world-leading research group in receptor signalling by providing tools and support for quantitative studies with molecular sensitivity for biomedical research. The prestigious award of the AMS fellowship will enable the purchase of cutting-edge microscopy tools and allow further automation of our microscopes to increase throughput and provide the capacity for super-resolved 3D reconstructions of whole cells. My position in COMPARE aligned to the Institute of Cardiovascular Sciences (ICVS) and the School of Chemistry at the University of Birmingham (UoB) adds expertise in methods development to the COMPARE advanced microscopy facility at UoB and will allow me to work on my quantitative microscopy methods. My appointment creates a unique opportunity to support researchers and clinicians in their search for solutions to urgent biomedical questions, like HIV infection or thrombosis, by use of existing techniques and novel approaches. I will involve Jeremy Pike (UoB, Data Analysis Officer) and Iain Styles (Computer Sciences, Turing Institute Fellow and Deputy Director of COMPARE, UoB) in machine learning approaches for the fast processing of 3D microscopy data. Additionally, I will initiate a planned industry collaboration with IRIS Biotech (Germany) to elaborate on the potential commercialisation of fluorescent probes for super-resolution microscopy, chemical multiplexing and metal cation sensing based on my patent (DE 10 2016 012 162.9). A challenge in methods development is to identify suitable targets and questions for the novel approach. The fellowship will enable collaborations with colleagues on campus and within COMPARE to increase the number of biomedical targets and facilitate translational application of my techniques which focus on T cell receptor signalling and more recently on GPCRs. Examples of new collaborations include the platelet immunoglobulin C-type lectin-like receptors GPVI and CLEC-2 (with Steve Watson, Steve Thomas and Natalie Poulter, ICVS) which are novel targets for a variety of thrombosis and thrombo-inflammatory disorders, and in the chemokine GPCR family (with Dimity Veprintsev, University of Nottingham - UoN) that play an important role in diseases like hypertension, hypoxia, or hypoglycaemia. In this context, I envision a key training centre for advanced microscopy at UoB also addressing problems like fluorescence labelling and probe development. This will involve colleagues in the School of Chemistry as well as COMPARE researchers working on fluorophores (Jon Preece, UoB) and bioactive molecules (Liam Cox, UoB; Barrie Kellam, UoN). COMPARE offered me a generous starting budget COMPARE (£ 450K) and the institute is in the process of refurbishing the labs to my needs, to move 3 co-workers together with my equipment by February 2020. Since I am unable to bring any overseas funding, the award will allow me to get accommodated with the UK grant application system and plan projects to strengthen my translational research (MRC) and the development of novel probes and techniques (BBSRC and EPSCR) without losing any momentum in my ongoing research activities. I have already applied for a translational research grant (BBSCR TRDF) in collaboration with Robert Henderson (University of Edinburgh), which involves quantitative imaging microscopy through use of his 256x256 APD camera.	The Academy of Medical Sciences	AMS Professorship Scheme Round 2	470621.92	GBP
363	Professor Xiaolin Huang	Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology	None	2018-02-01	2019-06-30	Low cost robotic orthosis for stroke treatment in rural China	China is the worst affected developing country with 2.5M new stroke cases each year and 11.1M stroke survivors at any given time. In the past decades, due to lower socioeconomic status, less stroke awareness, and inequitable distribution of medical resources to rural areas, the incidence rate and burden of stroke in China has increased disproportionately in rural areas of the northeast and central regions. Rehabilitation programmes have been shown to be extremely effective in reducing the disability and restoring walking ability through early training. However, in most rural areas of China no such medical rehabilitation centres or hospitals exist leaving the rural population without the therapies which will allow them to regain mobility functions after stroke. This leads to disability and has broader negative socioeconomic impacts. This project seeks to gather evidence directly from the key stakeholders in the beneficiary ODA countries (China and Kazakhstan) about what their problems and requirements are. The networking activities will allow us to build a full proposal based around actual rather than assumed need, and therefore maximise the impact achieved. The project aims to establish a multi-disciplinary consortium including experts from rehabilitation robotics, sensing, machine learning, physiotherapy and rehabilitation medicine. We aim to provide low-cost robotic solutions to stroke survivors in remote home and community environments. This would reduce therapists’/stroke carers' demand in rural areas of ODA countries whilst maximizing the stroke survivor’s sense of intention, involvement, interaction and achievement of limb movement, with greater likelihood of successful rehabilitation and improved quality of life.	The Academy of Medical Sciences	None	22000.0	GBP
364	Dr Tinashe Chikowore	University of the Witwatersrand	None	2019-02-01	2022-02-01	Characterisation of gene-lifestyle interactions associated with obesity-related traits in African populations	Obesity is increasing in Africa and elsewhere, but little is known of how genetic and environmental factors interact.The proposed research has the following components: (i) discovery phase: heterogeneity of variance analysis (HEVA) to determine candidate gene-environment interacting (GEI) variants in the Human Hereditary and Health in Africa (H3Africa) cardiovascular (CVD) working group to replicate the top-ranking signals. Additional variants will be selected from the GWAS trans-ethnic meta-analysis of East Asians, Europeans and Africans based on exhibiting heterogenous effects across the ethnic groups. Gradient Boosted LD adjusted (GraBLD) machine learning algorithms will be used to compute highly predictive genetic risk scores; (ii) cross-sectional and longitudinal analysis phase: single candidate GEI variants and genetic risk scores (of candidate GEI variants and from GraBLD analysis) will be combined with lifestyle factors in generalised linear models (cross-sectional analysis) and linear mixed models (repeated measures analysis) to determine plausible variants responsible for gene-lifestyle interactions in obesity-related traits. Assessments of sensitivity and specificity will be used to determine the predictiveness of these gene-lifestyle interactions and genetic risk scores. The transferability of the identified GEIs across African and European populations will be evaluated. The proposed research may help elucidate relevant risk factors and/or identify obesity intervention targets.	Wellcome Trust	International Training Fellowship - Full	224233.0	GBP
365	Jason Reifler	University of Exeter	None	None	2022-02-01	COVID-19 (Mis)Information Exposure and Messaging Effects in the United Kingdom	Fighting the COVID-19 pandemic requires understanding what information people have about the disease, which misperceptions might be prevalent, and how officials can improve public knowledge and encourage behaviours that will protect public health. First, this study will measure beliefs and attitudes about COVID-19, providing a thorough map of accurate knowledge, but also of misperceptions, particularly those driven by conspiratorial thinking. Second, the study will catalogue the online sources from which our respondents get COVID-19-related information. This will allow us to gauge which accurate information sources reach a wide audience and which sources of online misinformation are systematically distorting people's views. Third, the study will test whether public health messages that seek to correct misinformation are actually effective in changing people's beliefs. Behavioural and survey data will be collected in a multi-wave nationally representative survey that measures both prevalence of false and accurate beliefs about COVID-19 (including beliefs in misperceptions and conspiracy theories) and support for recommendations from public health authorities. To evaluate responses to information from public health officials, the second survey wave will include a randomized experiment evaluating the effects of messaging from health and medical authorities. Finally, the study will measure the quality of the information people consume online about the pandemic by analysing the behavioural data provided by respondents using a combination of human-coded and machine learning approaches. These data will make it possible to identify which groups are most frequently exposed to inaccurate or untrustworthy information about COVID-19, which should aid in the design of effective interventions.	UK Research and Innovation	Research Grant	308109.0	GBP
366	Professor Ian Loram	Manchester Metropolitan University	School of Healthcare Science	2020-01-01	2022-12-31	Quantification of head and trunk control for children with neuromotor and neuromuscular disorders	This imaging analysis tool will be trained to provide detailed, objective information of the segmental trunk control status of children with cerebral palsy (CP), and spinal muscular atrophy (SMA). Two core processes in the identification of trunk control will be automated: i) measurement of alignment of head and trunk segments to the vertical and ii) identification of when the hands and arms are free from contact with the body and any external surface. A cross sectional dataset (400 CP, 20 SMA1, 40 TD) and small exploratory dataset (40 NMD) will be acquired with each child tested using the Segmental Assessment of Trunk Control (SATCo). This subjective test will be recorded using two "RGB-D" cameras each giving 3D information as raw video and depth images. The CP sample (Manchester, Liverpool and Cheshire community services) and SMA sample (Oswestry Hospital and linked centres) would include the range of trunk control problems and body morphology of these populations. Two experienced SATCo clinicians, verified by a third, will label the video identifying i) segmental alignment i.e. when the child loses postural alignment; ii) upper limb support i.e. when the upper limbs contact the trunk or bench; and iii) trunk control status. Using contemporary machine learning methods, the raw RGB-D images and associated labels will train and test our networks through a cross validation process. (For motor function c.f. Case for Support). Exploitation of results includes: a) publication of a substantial public database of (400+20) cases representing trunk control impairment in children with CP and SMA1. This disseminates a public reference and training resource with data, software and instructions enabling inexperienced clinicians to reach the highest standard of clinical assessment of trunk control; b) acquisition of a 6-12-month longitudinal dataset of (20 CP, 5 SMA) children within our clinical network to provide power calculations necessary to plan clinical trials.	Medical Research Council	Research Grant	774510.0	GBP
367	Mr Brook	QUEEN MARY UNIVERSITY OF LONDON	None	2019-07-01	2020-06-30	Implementation of a 3D computational mouse atlas for detection of pancreatic tumours in transgenic mice	High impact cancer research demands the use of clinically relevant disease models. One approach is to use genetically modified mouse models (GEMM's) and this has seen an increase in the number of animals bred for scientific research, a high proportion of which are wasted as they don't have the correct phenotype. Tumour development in GEMMs is difficult to evaluate as their disease develops over long periods of time, usually deep within the body and so tumour detection and measurement of response is challenging unless the animal is sacrificed. The mouse pancreas is an ill-defined organ and in GEMMs of pancreatic cancer, the development of tumour is extremely difficult to assess non-invasively. Magnetic resonance imaging (MRI) and ultrasound (US) are both useful but their potential to reduce animal numbers by providing early detection of tumour and accurate longitudinal imaging data is limited for a number of reasons. MRI is preferred but can be expensive, less widely available and accurate determination of tumour volume via image analysis of the abdominal area is challenging. However, we have developed a 3D computational mouse atlas (3D-CAMMP) that can automatically detect pancreas and pancreatic tumour (with an accuracy of 95%) in MR images of a commonly-used pancreatic GEMM (the KPC mouse). This machine learning model uses imaging data collected on a relatively inexpensive low field MRI instrument. Automatic detection allows a non-expert user to perform MRI imaging and analysis with minimal training. In this project we will transfer use of the 3D-CAMMP mouse atlas to three cancer institutes in the UK, all with high numbers of KPC mice. We are confident that early and accurate identification of tumours will allow optimised evaluation of potential treatments to reduce variability, experiment duration and ultimately have the effect of reducing numbers of required animals used in pancreatic cancer research.	National Centre for the Replacement, Refinement and Reduction of Animals in Research	Skills and Knowledge Transfer	75593.0	GBP
368	Dr Andrea Cangiani	University of Nottingham	Sch of Mathematical Sciences	2019-12-31	2021-12-30	LOng-Term anatomical fluid dynamics for new Univentricular heartS palliation (LOTUS)	This project will take advantage of a unique partnership between USM and Hospital Raja Perempuam Zainab II, in Malaysia, and a world-leading team in the UK, blending together extensive clinical experience from both countries with engineering and mathematical modelling and High-Performance Computing (HPC) research. USM has a well-established research-active Unit of Paediatric and Congenital Cardiac Surgery, with state-of-the-art data acquisition capabilities and a unique and well-maintained data set of patients of all ages. This will be used for the calibration of the mathematical/computational model aimed at explaining the long-term impact of Univentricular Heart (UVH) palliation. The prediction of the morphological changes in the vascular system, as consequences of growth and modifications induced by the surgical procedures, will be achieved by a state-of-the-art artificial intelligence technology based on the generative adversarial neural networks. The project will make use of freely available specialised software, such as CRIMSON, SimVascular, VMTK, for image segmentation and geometry meshing, enhanced by advanced image segmentation software and novel geometric rendering of vascular alterations from surgery based on advanced parametric surface classes. New Computational Fluid Dynamics (CFD) approaches based on polyhedral discretisations will be developed for computational turnaround speedup and reduction of highly skilled time-consuming human intervention at the meshing stage. In particular, three incremental CFD solver will be released, of increasing fidelity, based on novel polytopic 3D meshes of the vessels, pipe-like curvilinear elements designed to reduce the computational costs inherent to standard 3D meshing, inclusion of fluid-structure interaction phenomena modelling compliant vessels.	Medical Research Council	Research Grant	322383.0	GBP
369	TWO WORLDS CONSULTING LIMITED	TWO WORLDS CONSULTING LIMITED	None	None	2021-12-30	udu: AI Platform for Pandemic Intelligence	The UK, amongst others, lacks a coherent infrastructure to support effective direct and timely collection and analysis of pandemic data, about both the progressIon of Covid-19 itself and the population response to public policy aimed at mitigating and profiling its progress. Refining policy and informing the judgement calls required to navigate the balance between lockdown and economic damage requires both accurate data and the ability to rapidly model multiple, 'What if?' scenarios. Current data intelligence systems are partial, fragmented, incomplete, lag reality and, in most cases can only surface what they have specifically been asked to look for. AI systems used to look for patterns are often constrained by the quality and range of data available to them. Existing models tend to look at single factors in isolation, e.g. not taking into account multiple sources of mortality data or failing to take account factors such as population mobility and behaviour, the impact of events such as Cheltenham races, sunny bank holiday weather or other regional and seasonal variations. This can only be addressed through a more holistic approach to data collection and integration. This project therefore uses an advanced data intelligence platform, udu, which is capable of integrating a wide range of data from multiple sources and of multiple types and of actively discovering new data online. It then uses software that can self-organise itself around a task to discover relationships between and patterns in the collected data to provide an inferential view of pandemic impact, policy effectiveness and population behaviour. udu has been established for several years in niche markets. Here, we are building on previous experience by Two Worlds in using udu to create systems for the predictive analysis of environmental change to public health for the first time. The resulting system is intended to be capable of supporting direct exploration by human users, providing an interface (API) to allow other teams to test their own analytic models against the datascape created by udu and supporting local and external machine learning systems with a wider range of high quality data and analysis.	UK Research and Innovation	Research Grant	49984.0	GBP
370	Dr Chrysanthi Papoutsi	University of Oxford	None	2017-09-01	2018-12-01	Digital health for patient safety: a case study in epilepsy care	This project will focus on the potential for machine learning to improve patient safety and will interrogate whether current ethical and regulatory frameworks adequately account for the role of artificial intelligence in healthcare. In contrast to prevailing conceptions of patient safety driven by biomedical and technocratic priorities, I will pursue an understanding of patient safety as an emergent, practical accomplishment between patients, lay carers and service providers. Methods will include a theory-driven review of the literature on patient safety and machine learning, followed by an empirical case study on assisted living technologies for people with epilepsy and their carers. Qualitative methods will be used, such as interviews, ethnographic field notes, multi-modal qualitative data and document analysis. Rich, methodologically-robust empirical data will be analysed by drawing on theoretical frameworks from medical sociology and science and technology studies, to extend previous theorisations of patient safety practices.This award will also contribute to transdisciplinary learning and knowledge exchange. Drawing on the research on assisted living technologies for epilepsy, a number of workshops will be organised between clinicians, computer and data scientists, technology developers, patient and carers, social scientists and health services researchers, charities and commercial organisations. This work will advance the field theoretically and will contribute to tangible changes in digital health technology development and co-production.	The Academy of Medical Sciences	Springboard - Health of the Public 2040 Round 1	49939.53	GBP
371	Dr Peter Keating	University College London	Ear Institute	2017-05-01	2019-05-01	Developmental impact of intermittent hearing loss on spatial hearing in noisy environments	I aim to understand how intermittent unilateral hearing loss affects complex aspects of auditory development, using spatial hearing in noisy environments as a model system. Problem: Otitis media is one of the most common diseases in young children, and can often produce an intermittent unilateral hearing loss. This can disrupt normal development and produce impairments that persist even after normal hearing is restored. Spatial hearing contributes to listening in noisy environments, and this important skill is particularly impaired by developmental hearing loss. However, the neurophysiological changes that produce these impairments are unknown.Research: To address this, I will induce an intermittent unilateral hearing loss in ferrets during development. I will then perform bilateral extracellular recordings in A1 as these animals perform a spatial sound segregation task, and use machine learning to link neural activity with behaviour. I will perform these experiments during periods of both hearing loss and normal hearing, and investigate whether these animals: (i) have adapted to the hearing loss, and (ii) are impaired even when the hearing loss is absent.Impact: By understanding how the brain adapts to hearing loss, we will be able to design better cochlear implants and hearing aids, and better train people to use these devices. By linking impairments with physiological changes in neuronal populations, we will gain insight into pathophysiological markers that could help identify at-risk children. This would facilitate earlier, and better targeted, clinical intervention, and help us prevent, detect, and reverse the underlying pathophysiology.	The Academy of Medical Sciences	Springboard Round 2	99612.0	GBP
372	Prof. Giacomo INDIVERI	University Of Zurich	None	2017-09-01	2022-08-31	Neuromorphic Electronic Agents: from sensory processing to autonomous cognitive behavior	Neural networks and deep learning algorithms are currently achieving impressive state-of-the-art results. In parallel computational neuroscience has made tremendous progress with both theories of neural computation and with hardware implementations of dedicated brain-inspired computing platforms. However, despite this remarkable progress, today’s artificial systems are still not able to compete with biological ones in tasks that involve processing of sensory data acquired in real-time, in complex and uncertain settings. One of the reasons is that neural computation in biological systems is very different from the way today's computers operate: it is tightly linked to the properties of their computational embodiment, to the physics of their computing elements and to their temporal dynamics. Conventional computers on the other hand operate with mainly serial and synchronous logic gates, with functions that are decoupled from their hardware implementation, and with discretized and virtual time. In this project we will combine the recent advancements in machine learning and neural computation with the latest developments in neuromorphic computing technology to design autonomous systems that can express robust cognitive behavior while interacting with the environment, through the physics of their computing substrate. To achieve this we will embed in robotic platforms microelectronic neuromorphic processors and sensors that implement biophysically realistic neural computational primitives and dynamics. We will adopt active-sensing and on-line spike-based learning strategies, context and state-dependent computation, and probabilistic inference methods for "programming" these neuromorphic cognitive agents to solve challenging tasks in real-time. Our results will lead to compact low-power intelligent sensory-motor systems that will have a large impact on service and consumer robotics, Internet of Things, as well as prosthetics and personalized medicine.	European Research Council	Consolidator Grant	1999090.0	EUR
373	Dr Romain Laine	University College London	MRC Laboratory of Molecular Cell Biology	2019-12-28	2022-12-27	How does virus shape relate to infectivity?	The influenza A virus (IAV) is responsible for the seasonal flu as well as the recurring global flu pandemics. The WHO has identified the risk of global influenza pandemic as one of the 10 most serious threats to global health in 2019, placing the study of influenza as a high priority for biomedical research. One particularity of IAV is its heterogeneity in shapes and composition suggesting a highly adaptable phenotype in vivo. The importance of this large variability for the virus however remains poorly understood, in part due to the lack of imaging technologies capable of studying the virus at the nanoscale. My research focusses on exploiting and developing novel imaging technologies, by combining super-resolution microscopy (SRM), high-content screening (HCS) and machine learning, to study the virus from the single molecule, single cell to the population level, essential to understand the role of viral heterogeneity. Initially, I will develop quantitative structural and genetic analysis to inform on the architecture of the virus assembly and genome at the single virus level. Then, by correlating this high-content data with infectivity assay at the nanoscale, I will explore how modulation of this heterogeneity affects the infectivity of the virus in primary respiratory epithelial cells, the virus' host in vivo. This combination of SRM and HCS has large potentials for its drug screening capabilities. Finally, by following the virus' replication in real time at the entry and assembly stages, I will be able to understand the effect of shape and composition heterogeneity on its mechanisms. This research is jointly supported by an industrial partner, developing Live Attenuated Influenza Viruses (LAIV) as a vaccine technology, so not only it has the potential to highlight the importance of the virus variability for its replication mechanisms, it will also inform the design of vaccines, joining the global effort to tackle influenza's health and economic burden.	Medical Research Council	Fellowship	301830.0	GBP
374	Mr Conrad Harrison	University of Oxford	None	None	2022-12-27	Transforming outcome measures in plastic surgery through computer science	Aim The aim of this project is to improve how we measure the outcomes of treatments for cleft lip and/or palate. Background One in 700 babies are born with a gap in their lip and/or the roof of their mouth. This is called cleft lip and/or palate (CL/P). It can cause long-term difficulties with feeding, hearing, speaking, appearance and emotional wellbeing. Clefts are treated in many ways. This typically includes a series of operations as the child grows. Different surgeons recommend different operations, but there is little evidence to tell us which operations are more successful than others. It is important to measure how successful operations are to know which ones work best. So far, this has involved doctors' opinions, which are inconsistent. It can also involve looking at scans and other test results. But this isn't necessarily what matters most to people born with CL/P. Recently, a team of researchers asked people born with CL/P what matters most to them. From this, they made a questionnaire to score these things. It is called CLEFT-Q.Overall, CLEFT-Q has 119 questions. These are arranged into groups, e.g. questions about lips speech mood etc. Some groups of questions are not always suitable. For example, questions about lips are skipped for somebody with only a cleft palate. We discussed this with our research partners (children and adults with CL/P, parents of children with CL/P, and members of the public). They felt CLEFT-Q was still too long. Children under eight are too young to use CLEFT-Q. Instead, their outcomes are often scored by groups of doctors looking at photographs of their face before and after surgery. This is expensive and not always practical. Methods I am making computer programs that shorten CLEFT-Q. These are called computerised adaptive tests (CATs). The programs pick only relevant questions for each person, adjusting based on the answers they've already given. A CAT can predict someone's final CLEFT-Q scores without asking all the questions. This would make CLEFT-Q easier to complete. To make and test the CAT we will study patients' CLEFT-Q answers that were collected around the world by different research teams. I am also making an artificial intelligence' computer program that can measure the outcome of surgery by looking at photographs. I think this will be cheaper, quicker and more consistent than doctors' measurements. To do this I will use 150,000 photos of patients with CL/P before and after they had surgery. The photographs have already been studied by surgeons who rated how well they think the surgery went. My program will learn what a good or bad outcome is by measuring different parts of the face and working out patterns that lead to an outcome being considered good or bad.Patient and public involvement My research partners have already been involved in the project design and helped to write this application. I will invite them to contribute to all further stages of this research. This includes making decisions about what I should work on and how I should do it. They will ensure we make the programs as user-friendly as possible. To make this easier for them, most of our meetings will be done over video-calls or at charity events. We will write up our experience of working together. This will be published on the NIHR INVOLVE website, and I will invite research partners to join me in presenting this at relevant meetings. Dissemination I will keep the CL/P community updated through the CLEFT-Q website, social media and charity newsletters. I will also present our findings at scientific meetings and publish the results in scientific journals.	National Institute for Health Research (Department of Health)	Full Grant	384813.0	GBP
375	Dr Peter Keating	University College London	Ear Institute	2017-05-01	2019-05-01	Developmental impact of intermittent hearing loss on spatial hearing in noisy environments	I aim to understand how intermittent unilateral hearing loss affects complex aspects of auditory development, using spatial hearing in noisy environments as a model system. Problem: Otitis media is one of the most common diseases in young children, and can often produce an intermittent unilateral hearing loss. This can disrupt normal development and produce impairments that persist even after normal hearing is restored. Spatial hearing contributes to listening in noisy environments, and this important skill is particularly impaired by developmental hearing loss. However, the neurophysiological changes that produce these impairments are unknown.Research: To address this, I will induce an intermittent unilateral hearing loss in ferrets during development. I will then perform bilateral extracellular recordings in A1 as these animals perform a spatial sound segregation task, and use machine learning to link neural activity with behaviour. I will perform these experiments during periods of both hearing loss and normal hearing, and investigate whether these animals: (i) have adapted to the hearing loss, and (ii) are impaired even when the hearing loss is absent.Impact: By understanding how the brain adapts to hearing loss, we will be able to design better cochlear implants and hearing aids, and better train people to use these devices. By linking impairments with physiological changes in neuronal populations, we will gain insight into pathophysiological markers that could help identify at-risk children. This would facilitate earlier, and better targeted, clinical intervention, and help us prevent, detect, and reverse the underlying pathophysiology.	The Academy of Medical Sciences	Springboard Round 2	99612.0	GBP
376	Dr Rick Adams	University College London	Computer Science	2018-07-31	2021-07-30	Finding psychosis subtypes using machine learning, clinical, genetic and multimodal imaging data	It has recently been shown that psychotic illnesses cluster into three neurobiologically distinct 'biotypes' that cut across existing diagnostic boundaries (Clementz et al, 2016, Am J Psych). This clustering was performed on eye movement, structural MRI and raw EEG sensor data, yet schizophrenia is best defined as a disorder of functional connectivity between brain regions, i.e. how they interact with each other. One would therefore predict that using functional connectivity data in clustering analysis would yield much clearer and more biologically-interpretable subgroups (as has recently been shown in major depression, by Drysdale et al, 2017, Nat Med). In my previous work I have used computational models of how the brain generates EEG data to infer the underlying connectivity between brain areas, and shown that subjects with schizophrenia have abnormal synaptic connectivity in prefrontal and sensory cortex - the same locations of abnormalities in the three proposed biotypes. I now have access to two much larger datasets (each of n>1000) containing 'resting state' fMRI and both resting state and task-based EEG data in subjects with schizophrenia, bipolar disorder, their relatives and healthy controls. Both also contain many clinical (e.g. cognitive and symptom) measures and GWAS data (imputed to 2x10^7 SNP per person). I will perform connectivity analyses of the fMRI and EEG studies in these large datasets, and then use the connectivity parameters and clinical data to inform clustering analysis. I will use the first dataset to derive the clusters, and then the second dataset to validate these clusters. I will then analyse the clusters' relationships to clinical and genetic data: in particular, testing whether clinical data accentuates or alters the neurobiological cluster boundaries, and whether any cluster has i) an enriched schizophrenic polygenic risk score, and ii) further enrichment of NMDA receptor-related genetic risk variants.	Medical Research Council	Fellowship	292063.0	GBP
377	Dr Nuria Gavara	QUEEN MARY UNIVERSITY OF LONDON	None	2016-10-24	2018-04-23	Effect of cell age on cell migration and cytoskeletal reorganization	Adherent cells contain a network of polymeric proteins, the cytoskeleton (CSK), which provides them with shape and mechanical stability. Redistribution and polarization of the CSK is a crucial event for proper cell migration. Cells from older individuals have diminished ability to remodel their CSK and display reduced migration speeds, suggesting that aging results in impaired cell migration and wound-healing. This proposal will first identify how CSK reorganization is critical for cell migration, and characterise the reorganization undergone by each CSK network when migration starts. Furthermore, we will pinpoint the specific CSK reorganization events that fail to take place on aging cells. Finally, and as a proof-of-concept for future high-throughput low-cost drug discovery, we will develop a framework to identify the CSK phenotypes of young and old migrating cells, and we will use it to test in a quantitative manner whether (and to which extend) specific biochemical compounds help reverting older cells to a young migrating CSK phenotype.	The Dunhill Medical Trust	Research Project & Programme Grants	74930.0	GBP
378	Mr Ferenc Schultesz	City, University of London	None	2016-07-04	2016-09-03	Pattern Classification of attention deficit hyperactivity disorder: Integrating functional magnetic resonance imaging and genetics data	The aim of our study is to investigate integration of genetic data from candidate genes associated with ADHD with functional connectivity alterations observed in fMRI will improve differentiation of ADHD vs control in a classification framework. One of the biggest challenges involved in imaging genetics is high dimensionality of data. We propose machine learning based framework to address this challenge. We intend to apply a recently published clustering algorithm called clustering called “Clustering by fast search and find of density peaks” for estimation if functional connectivity between brain regions. The algorithm has important property that it does not involve random initialization of centroids. Functional connectivity of brain region has high dimensions. We propose to investigate an embedded based feature selection called Elastic Net (EN) that takes advantage of both lasso and ridge regression by combining their penalties in one solution. It enables variable shrinkage, similar to lasso by employing L1 penalty and combining with L2 penalty, it enables to select correlated features. The selected features can be integrated with candidate gene/SNP of ADHD to construct a feature vector. The feature vector can be evaluated by support vector machine classifier. Expected outcome of study may help in understanding of ADHD.	Wellcome Trust	Vacation Scholarships	2000.0	GBP
379	Nicolas Salamin	University of Lausanne	Département d'Ecologie et d'Evolution Faculté de Biologie et de Médecine Université de Lausanne	2017-04-01	2020-03-31	Efficient and accurate comparative genomics to make sense of high volume low quality data in biology	The amount of biological data that is used to study biological and medical questions is increasing drastically. The advances of genomic technologies enable now many research groups to assemble large scale genomic data for a large spectrum of organisms, and the challenge has now shifted from producing to analysing these large amounts of genomic data.Making sense of all that data relies on comparative genomics to identify the conserved or divergent elements, and elucidate the ones that are associated with essential housekeeping functions and those associated with innovation or adaptation. For instance, an important question is whether a gene has the same function in a model organism such as fly or mouse and in humans. However, this simple question leads to complex methodological issues. Finding the corresponding (“orthologous”) genes in different species is not trivial computationally and is dependent on the quality of the data. Characterizing differences between orthologous genes as functionally relevant or inconsequential is also computationally intensive and dependent on data quality.Because of this complexity, typical comparative genomics approaches tend to focus on few high-quality genomes and to analyse each gene family independently. These analyses, however, fail to capitalize on the increase in available data and ignore interaction (co-evolution) among genes.By contrast, in this project, we aim to develop a comparative genomics approach that leverages the abundant but noisy and heterogeneous data generated, and models coevolution of multiple genes in functional modules such as metabolic pathways. To achieve this, we will: 1) combine high- and low-quality genomic data available, with an emphasis on robustness to data incompleteness and inaccuracies, and scalability to tens of thousands of genomes.2) implement stringent quality controls-via statistical tests, empirical benchmarks, and filters;3) develop efficient machine learning algorithms that can cope with orders of magnitude more data.This approach tackles head-on the “variety”, “veracity”, and “volume” aspects of IBM’s framework of Big Data. Our project also has implications outside biological research. Data curation and homology assessment (WP1) are essential in free text and language analyses, while machine learning approaches for hypothesis prioritization (WP2) is a key element in computer science.	Swiss National Science Foundation	NRP 75 Big Data	573911.0	CHF
380	Mihaela Zavolan	University of Basel	Biozentrum der Universität Basel Systembiologie	2009-10-01	2013-03-31	Inference of post-transcriptional regulatory codes involving miRNAs and RNA binding proteins	Although for many years transcription factors held the center stage inthe regulation of gene expression, a very complex post-transcriptionalregulatory layer implemented by miRNAs and RNA-binding proteins andfrequently acting precisely on the mRNAs encoding transcriptionfactors, has been uncovered. Far from passively carrying the geneticinformation to the ribosomal translation machines, messenger RNAs havea life of their own and this can be extended or shortened depending oninteractions with various protein and ribonucleoprotein complexes inthe cell. Although the miRNAs have initially been described asregulators of the mRNA translation rate, it is now clear that animportant mechanism behind the miRNA-based regulation is target mRNAdegradation. The activity of miRNA-containing ribonucleoproteincomplexes can itself be modulated for example by RNA-binding proteins(RBPs) that recognize sites in the vicinity of miRNA-binding sites andact as competitors for miRNA binding.Much effort in the past years has been devoted to identifying newplayers in post-transcriptional control. Many groups, including ourown, contributed to the catalog of miRNA genes in species ranging fromviruses to human. Similarly, many groups, ours included, contributedthrough computational or experimental approaches to the list ofputative miRNA-target interactions. Yet although it is clear that onaverage a miRNA targets hundreds of genes, much remains to be done tounderstand the determinants of miRNA targeting specificity. Based onthe observation that miRNAs destabilize their mRNA targets manyexperimental studies aimed to identify miRNA targets by miRNAtransfection and microarray profiling. In spite of the fact thathundreds to thousands of transcripts respond in a typical experiment,only a fraction of the predicted miRNA targets do. Moreover, forreasons that are so far unclear, the magnitude of the response varieswidely. In a recent analysis of over seventy experimental data sets ofmRNA or protein level changes that occurred upon perturbation of miRNAexpression, we found that functional miRNA target sites reside inaccessible regions, and that the degree of mRNA degradation is relatedto the U (and to some extent A) nucleotide content of the miRNA targetsite environment. This suggests that the fate of miRNA targets dependsnot only on their interaction with the RNA-induced silencing complex(RISC), but also on the presence of modulatory protein co-factors. Incollaboration with the group of Tom Tuschl (The RockefellerUniversity) we have recently identified a number of RBPs that interactwith the RISC complex and we characterized their cognate mRNAs byimmunoprecipitation and microarray expression profiling. We havefurther developed a novel cross-linking and immunoprecipitation methodto identify RBP targets at the resolution of individual bindingsites. Building on this work, we here propose to carry out the following projects:1. Computational modeling of miRNA-target interactions.The starting point of this study will be the set of sequences that we found, with the CLIP method mentioned above, to be bound by Argonaute protein-containing complexes. We will attempt to use machine learning approaches to identify the location of miRNA binding sites in these data and to characterize the mode of binding of miRNAs to their targets. We will also thoroughly characterize the properties of these binding sites and we will use the results to develop improved methods for miRNA target prediction.2. Experimental identification of the targets of U-rich element binding proteins.This project will build on one hand on the experimental method that we developed in collaboration with the group of Tom Tuschl (The Rockefeller University), and on the other hand on our computational results that indicate that U-rich elements are associated with the degradation of miRNA targets. We have selected a set of U-rich element binding proteins whose targets we would like to identify by CLIP, and then study in relationship with the miRNA targets that we already obtained.3. Development of computational models of RBP-mRNA interactions.This projects aims to again use the CLIP data that we have and will obtain in the near future to start developing models to specifically describe RBP-mRNA interactions, taking into account the particularities of this class of proteins. These projects will make an important contribution to a quantitativeunderstanding of miRNA-based post-transcriptional regulation and tothe inference of the elusive 'RNA code'.	Swiss National Science Foundation	Project funding (Div. I-III)	600000.0	CHF
381	Philipp Bucher	EPF Lausanne	Institut Suisse de Recherche Expérimentale sur le Cancer EPFL - SV - ISREC	2009-04-01	2013-06-30	Chromatin structure-driven computational analysis of gene regulatory regions	The genetic code for gene regulatory information and the molecular mechanisms of transcriptional control are still poorly understood. The advent of high-throughput technologies to map in vivo DNA-protein complexes, in particular chromatin immunoprecipitation combined with ultrahigh-throughput sequencing (ChIP-Seq) raises new hope for a breakthrough. For the first time it is possible to obtain a comprehensive and detailed view of the chromatin structure of an entire genome in a particular cell type. In addition, we are now able to identify the complete repertoire of in vivo binding sites for a given transcription factor under given conditions. In other words, the molecular events that control gene expression in proximity to the DNA suddenly have become visible. The genome-wide ChIP-Seq datasets that have become available over the last year, already led to numerous new insights about gene regulation. We anticipate that very large volumes of similar data will be released during the course of the proposed project. Computational analysis of ChIP-Seq data is in its infancy. For computational biology, the next few years will probably be remembered as a learning phase during which the community has acquired experience how to make best use of this new type of molecular data. Standard protocols for quality-control and low level data processing will arise. The type of biological questions that can be answered will be better defined and stated in terms amenable to computational approaches. Appropriate data structures for higher level analysis will arise and methodological principles and algorithm will consolidate over time. This proposal is meant to be a contribution to this learning process. The focus is on higher level analysis and interpretation, not on primary data processing. Specifically we are interested in questions concerning the relationship between DNA sequence, chromatin structure, transcriptional activation and repression. A key question in gene regulation, especially with regard to large higher eukaryotic genomes, is why a given transcription factor binds only to a subset of potential target sites in the genome. Much of the proposed work is devoted directly or indirectly to this problem. Histone modification maps based on ChIP-Seq provide clues about DNA accessibility, transcriptional status, and other physiological processes acting on a gene regulatory region. Classification and categorization will help to define subsets of genomic regions that offer similar conditions for transcription factor binding. Information on evolutionary conservation may further direct our analyses to functionally relevant chromatin regions. Comprehensive maps of in vivo transcription factor binding sites provide ideal training and test sets for machine learning approaches that may help to answer the key question of what directs gene regulatory proteins to their physiological target sites. Our research will be mostly biological question-driven in this sense. In addition to methodological advances, we hope that the proposed work will lead to a number of specific and experimentally testable hypotheses regarding chromatin-modulated gene regulatory mechanisms.	Swiss National Science Foundation	Project funding (Div. I-III)	199116.1	CHF
382	Richard Hahnloser	University of Zurich	Institut für Neuroinformatik Universität Zürich Irchel und ETH Zürich	2010-10-01	2014-09-30	The roles of social context and sleep replay for vocal learning in a songbird	Many complex learning behaviors such as speech learning are strongly influenced by factors including social context and sleep. Although many influences are known today, they have mostly been studied in artificial rather than natural settings and are currently supported only by correlative but not by causal evidence. Our work aims at bridging this gap by studying vocal development in the songbird and its dependence on social interactions with conspecific birds and on neural replay of behavioral sequences during sleep. The songbird is a vocal learner in which the brain mechanisms involved in sleep replay are well known. During sleep, premotor neurons of the vocal apparatus in zebra finches engage in bursting patterns that are reminiscent of their patterns generated during song production. In the past, we have performed extensive studies on the generation of such sleep-burst sequences in large song-control networks. We now want to make use of his knowledge and test for a causal relationship between sleep sequences and vocal development. Such a causal relationship has been widely hypothesized but has never been tested experimentally. We plan to implant stimu-lation electrodes into the brain area that generates sleep sequences and perturb downstream sleep bursts to study their effects on vocal changes. Comparisons will be made with birds that are similarly stimulated, but at daytime rather than during sleep. We hope this research will provide one of the first demonstrations that off-line neural activity during sleep has key roles for procedural learning.The social interactions during vocal learning and their influences have not been studied exten-sively yet. In a different set of experiments we will study the social factors that are beneficial or detrimental to vocal learning. It is known that birds with siblings produce less accurate copies of tutor song than birds without siblings, an effect known as a fraternal inhibition. However, the precise factors of this inhibition and the role of the parents in mediating this inhibition are currently not known. To study such effects of social context and many more, we will design and build a bird monitoring system in which several microphones and a video camera jointly operate to record all songs, the locations of the singers, and the locations of the other birds of a family living inside the same cage. This bird-monitoring system is a difficult instrumentation task because jointly tutored birds sing similar songs and often they sing at the same time. Hence, we will apply sophisticated machine-learning techniques to solve this blind-source separation problem. Our bird monitoring system will be fully automated and minimally rely on human input, thus facilitating behavioral experiments and high-throughput data acquisition. We are convinced that this tool will be useful to a large community of birdsong and neuroethology researchers worldwide, because one of the most successful strategies for understanding brain mechanisms is to study them in natural settings rather than in artificial ones. In future experiments beyond this grant application, we will make use of this bird-monitoring system also in electrophysiological experiments, to study brain mechanisms in a natural social context.The broader relevance of our work extends from songbirds to human social sciences and physi-ology, because effects of sibling number and parental interactions influence speech learning also in children. And, the functions of sleep and dreams remain deeply mysterious and any new insights even in animal models will be highly valuable.	Swiss National Science Foundation	Project funding (Div. I-III)	463572.0	CHF
383	Susan Kamal	Institute for Prediction Technology (UCIPT) Department of Family Medicine University of California	Institute for Prediction Technology (UCIPT) Department of Family Medicine University of California	2017-04-01	2017-09-30	Predictive Modeling of cART Medication Adherence and Immuno-virologic outcomes among HIV infected Adults in Lausanne, Switzerland	Advancements in human immunodeficiency tritherapy have allowed patients on treatment to achieve a life expectancy similar to those without the disease. To achieve therapeutic goals, it is important to adhere to treatment regimen. The monitoring of adherence can be done using several methods such as patient reports, pill count and electronic monitoring. Electronic monitoring allows daily monitoring of medication taking through the use of electronic pill boxes (Medication event monitoring systems, MEMS) that store the time and day of opening. This method is used routinely in care at the pharmacy of the Policlinique Medicale Universitaire since 2004. Currently there is medication adherence data for about 500 patients followed at the adherence programme. Few studies have described the erosion of medication adherence over time, but more research is needed to identify the early critical indicators of initial nonadherence signs in HIV. To be able to investigate the effect of medication nonadherence on immune-virologic outcomes, we would like to conduct a predictive modeling analysis of the adherence and clinical data collected retrospectively at our institute in Lausanne. The medication adherence data in Lausanne is very unique as it comprises daily medication intake and interview transcripts with patients about the barriers and facilitators to adherence collected routinely in care of a long period of time (12 years). This predictive modeling will be done using state of the art prediction algorithms combining Big Data Science, statistical modeling, behavioral psychology, clinical and adherence sciences. The the University of California Institute for Prediction Technology (UCIPT) has developed a lot of novel methods for big data science analysis and this joint project will combine unique patient data from the adherence clinic in Lausanne with state of the art predictive machine learning methodology at UCIPT.The analysis of this data can provide unprecedented insights into patient behavior regarding dealing with chronic medication in general, and their struggle to deal with HIV. Consequently, tailored interventions can be developed to prevent nonadherence that can lead to viral failure, and mortality.	Swiss National Science Foundation	Doc.Mobility	None	None
384	Dr Tinashe Chikowore	University of the Witwatersrand	None	2019-02-01	2022-02-01	Characterisation of gene-lifestyle interactions associated with obesity-related traits in African populations	Obesity is increasing in Africa and elsewhere, but little is known of how genetic and environmental factors interact.The proposed research has the following components: (i) discovery phase: heterogeneity of variance analysis (HEVA) to determine candidate gene-environment interacting (GEI) variants in the Human Hereditary and Health in Africa (H3Africa) cardiovascular (CVD) working group to replicate the top-ranking signals. Additional variants will be selected from the GWAS trans-ethnic meta-analysis of East Asians, Europeans and Africans based on exhibiting heterogenous effects across the ethnic groups. Gradient Boosted LD adjusted (GraBLD) machine learning algorithms will be used to compute highly predictive genetic risk scores; (ii) cross-sectional and longitudinal analysis phase: single candidate GEI variants and genetic risk scores (of candidate GEI variants and from GraBLD analysis) will be combined with lifestyle factors in generalised linear models (cross-sectional analysis) and linear mixed models (repeated measures analysis) to determine plausible variants responsible for gene-lifestyle interactions in obesity-related traits. Assessments of sensitivity and specificity will be used to determine the predictiveness of these gene-lifestyle interactions and genetic risk scores. The transferability of the identified GEIs across African and European populations will be evaluated. The proposed research may help elucidate relevant risk factors and/or identify obesity intervention targets.	Wellcome Trust	International Training Fellowship - Full	224233.0	GBP
385	Jason Reifler	University of Exeter	None	None	2022-02-01	COVID-19 (Mis)Information Exposure and Messaging Effects in the United Kingdom	Fighting the COVID-19 pandemic requires understanding what information people have about the disease, which misperceptions might be prevalent, and how officials can improve public knowledge and encourage behaviours that will protect public health. First, this study will measure beliefs and attitudes about COVID-19, providing a thorough map of accurate knowledge, but also of misperceptions, particularly those driven by conspiratorial thinking. Second, the study will catalogue the online sources from which our respondents get COVID-19-related information. This will allow us to gauge which accurate information sources reach a wide audience and which sources of online misinformation are systematically distorting people's views. Third, the study will test whether public health messages that seek to correct misinformation are actually effective in changing people's beliefs. Behavioural and survey data will be collected in a multi-wave nationally representative survey that measures both prevalence of false and accurate beliefs about COVID-19 (including beliefs in misperceptions and conspiracy theories) and support for recommendations from public health authorities. To evaluate responses to information from public health officials, the second survey wave will include a randomized experiment evaluating the effects of messaging from health and medical authorities. Finally, the study will measure the quality of the information people consume online about the pandemic by analysing the behavioural data provided by respondents using a combination of human-coded and machine learning approaches. These data will make it possible to identify which groups are most frequently exposed to inaccurate or untrustworthy information about COVID-19, which should aid in the design of effective interventions.	UK Research and Innovation	Research Grant	308109.0	GBP
386	Professor Ian Loram	Manchester Metropolitan University	School of Healthcare Science	2020-01-01	2022-12-31	Quantification of head and trunk control for children with neuromotor and neuromuscular disorders	This imaging analysis tool will be trained to provide detailed, objective information of the segmental trunk control status of children with cerebral palsy (CP), and spinal muscular atrophy (SMA). Two core processes in the identification of trunk control will be automated: i) measurement of alignment of head and trunk segments to the vertical and ii) identification of when the hands and arms are free from contact with the body and any external surface. A cross sectional dataset (400 CP, 20 SMA1, 40 TD) and small exploratory dataset (40 NMD) will be acquired with each child tested using the Segmental Assessment of Trunk Control (SATCo). This subjective test will be recorded using two "RGB-D" cameras each giving 3D information as raw video and depth images. The CP sample (Manchester, Liverpool and Cheshire community services) and SMA sample (Oswestry Hospital and linked centres) would include the range of trunk control problems and body morphology of these populations. Two experienced SATCo clinicians, verified by a third, will label the video identifying i) segmental alignment i.e. when the child loses postural alignment; ii) upper limb support i.e. when the upper limbs contact the trunk or bench; and iii) trunk control status. Using contemporary machine learning methods, the raw RGB-D images and associated labels will train and test our networks through a cross validation process. (For motor function c.f. Case for Support). Exploitation of results includes: a) publication of a substantial public database of (400+20) cases representing trunk control impairment in children with CP and SMA1. This disseminates a public reference and training resource with data, software and instructions enabling inexperienced clinicians to reach the highest standard of clinical assessment of trunk control; b) acquisition of a 6-12-month longitudinal dataset of (20 CP, 5 SMA) children within our clinical network to provide power calculations necessary to plan clinical trials.	Medical Research Council	Research Grant	774510.0	GBP
387	Mr Brook	QUEEN MARY UNIVERSITY OF LONDON	None	2019-07-01	2020-06-30	Implementation of a 3D computational mouse atlas for detection of pancreatic tumours in transgenic mice	High impact cancer research demands the use of clinically relevant disease models. One approach is to use genetically modified mouse models (GEMM's) and this has seen an increase in the number of animals bred for scientific research, a high proportion of which are wasted as they don't have the correct phenotype. Tumour development in GEMMs is difficult to evaluate as their disease develops over long periods of time, usually deep within the body and so tumour detection and measurement of response is challenging unless the animal is sacrificed. The mouse pancreas is an ill-defined organ and in GEMMs of pancreatic cancer, the development of tumour is extremely difficult to assess non-invasively. Magnetic resonance imaging (MRI) and ultrasound (US) are both useful but their potential to reduce animal numbers by providing early detection of tumour and accurate longitudinal imaging data is limited for a number of reasons. MRI is preferred but can be expensive, less widely available and accurate determination of tumour volume via image analysis of the abdominal area is challenging. However, we have developed a 3D computational mouse atlas (3D-CAMMP) that can automatically detect pancreas and pancreatic tumour (with an accuracy of 95%) in MR images of a commonly-used pancreatic GEMM (the KPC mouse). This machine learning model uses imaging data collected on a relatively inexpensive low field MRI instrument. Automatic detection allows a non-expert user to perform MRI imaging and analysis with minimal training. In this project we will transfer use of the 3D-CAMMP mouse atlas to three cancer institutes in the UK, all with high numbers of KPC mice. We are confident that early and accurate identification of tumours will allow optimised evaluation of potential treatments to reduce variability, experiment duration and ultimately have the effect of reducing numbers of required animals used in pancreatic cancer research.	National Centre for the Replacement, Refinement and Reduction of Animals in Research	Skills and Knowledge Transfer	75593.0	GBP
388	Dr Andrea Cangiani	University of Nottingham	Sch of Mathematical Sciences	2019-12-31	2021-12-30	LOng-Term anatomical fluid dynamics for new Univentricular heartS palliation (LOTUS)	This project will take advantage of a unique partnership between USM and Hospital Raja Perempuam Zainab II, in Malaysia, and a world-leading team in the UK, blending together extensive clinical experience from both countries with engineering and mathematical modelling and High-Performance Computing (HPC) research. USM has a well-established research-active Unit of Paediatric and Congenital Cardiac Surgery, with state-of-the-art data acquisition capabilities and a unique and well-maintained data set of patients of all ages. This will be used for the calibration of the mathematical/computational model aimed at explaining the long-term impact of Univentricular Heart (UVH) palliation. The prediction of the morphological changes in the vascular system, as consequences of growth and modifications induced by the surgical procedures, will be achieved by a state-of-the-art artificial intelligence technology based on the generative adversarial neural networks. The project will make use of freely available specialised software, such as CRIMSON, SimVascular, VMTK, for image segmentation and geometry meshing, enhanced by advanced image segmentation software and novel geometric rendering of vascular alterations from surgery based on advanced parametric surface classes. New Computational Fluid Dynamics (CFD) approaches based on polyhedral discretisations will be developed for computational turnaround speedup and reduction of highly skilled time-consuming human intervention at the meshing stage. In particular, three incremental CFD solver will be released, of increasing fidelity, based on novel polytopic 3D meshes of the vessels, pipe-like curvilinear elements designed to reduce the computational costs inherent to standard 3D meshing, inclusion of fluid-structure interaction phenomena modelling compliant vessels.	Medical Research Council	Research Grant	322383.0	GBP
389	Dr Romain Laine	University College London	MRC Laboratory of Molecular Cell Biology	2019-12-28	2022-12-27	How does virus shape relate to infectivity?	The influenza A virus (IAV) is responsible for the seasonal flu as well as the recurring global flu pandemics. The WHO has identified the risk of global influenza pandemic as one of the 10 most serious threats to global health in 2019, placing the study of influenza as a high priority for biomedical research. One particularity of IAV is its heterogeneity in shapes and composition suggesting a highly adaptable phenotype in vivo. The importance of this large variability for the virus however remains poorly understood, in part due to the lack of imaging technologies capable of studying the virus at the nanoscale. My research focusses on exploiting and developing novel imaging technologies, by combining super-resolution microscopy (SRM), high-content screening (HCS) and machine learning, to study the virus from the single molecule, single cell to the population level, essential to understand the role of viral heterogeneity. Initially, I will develop quantitative structural and genetic analysis to inform on the architecture of the virus assembly and genome at the single virus level. Then, by correlating this high-content data with infectivity assay at the nanoscale, I will explore how modulation of this heterogeneity affects the infectivity of the virus in primary respiratory epithelial cells, the virus' host in vivo. This combination of SRM and HCS has large potentials for its drug screening capabilities. Finally, by following the virus' replication in real time at the entry and assembly stages, I will be able to understand the effect of shape and composition heterogeneity on its mechanisms. This research is jointly supported by an industrial partner, developing Live Attenuated Influenza Viruses (LAIV) as a vaccine technology, so not only it has the potential to highlight the importance of the virus variability for its replication mechanisms, it will also inform the design of vaccines, joining the global effort to tackle influenza's health and economic burden.	Medical Research Council	Fellowship	301830.0	GBP
390	QUALIS FLOW LIMITED	QUALIS FLOW LIMITED	None	None	2022-12-27	Automating compliance for remote construction working	Construction logistics monitoring and compliance is typically paper-based and requires multiple individuals and teams to process, in order to ensure that material movements are handled in a safe and environmentally responsible manner. Qflow is a software tool, using a combination of Internet of Things and machine learning techniques, to digitise the information recovered from paper tickets at a construction site entrance. This ensures that this information is fed directly to the managers who need it most, and without the need for any on-site presence aside from the existing traffic marshals. Information is provided on the material types and waste removals, descriptions, relevant certifications of the supply chain, and listed quantities. This supports several teams to work remotely, including logistics, environmental, QS and data administration. The innovation that Qflow is exploring now is automated compliance screening and anomaly detection, to notify users when there are discrepancies in their data that require investigation, or where there is an illegal waste transfer. The software provides the eyes and ears on site in real-time, and provides access to that information on a cloud-based platform, meaning that those who need the data can access it wherever they are, without having to double handle paperwork and ensuring that the site operations continues smoothly without the need for intervention.	UK Research and Innovation	Research Grant	27374.0	GBP
391	Dr. Jan Clemens	UNIVERSITAETSMEDIZIN GOETTINGEN - GEORG-AUGUST-UNIVERSITAET GOETTINGEN - STIFTUNG OEFFENTLICHEN RECHTS	None	2020-02-01	2025-01-31	Neural Computations Underlying Social Behavior in Complex Sensory Environments	Animals often interact in groups. Animal groups constitute complex sensory environments which challenge the brain and engage complex neural computations. This behavioral context is therefore fruitful for understanding how sophisticated neural computations give rise to behavior. However, it is also technically difficult since many of the relevant sensory cues arise from the members of the group and are therefore hard to quantify or control. Consequently, we only incompletely understand how the brain drives complex social behaviors in naturalistic contexts. To uncover the neural computations underlying social behavior in groups, we are using Drosophila, which provides unprecedented experimental access to the nervous system via genetic tools. Drosophila gathers on rotten fruit to feed and mate. Courtship and aggression dominate social interactions and rely on the recognition of sex-specific chemical cues and the production of context-specific acoustic signals. How are these multi-modal cues integrated to control and switch between courtship and aggression? How is unstable and conflicting sensory information resolved to promote stable behavioral strategies? How does sensory processing adapt to socially crowded environments in order to efficiently target behavior at individual members of the group? These issues will be addressed by combining computational modeling and genetic tools. Using machine learning, we will quantify and model the fine structure of social interactions to identify the social cues that drive behavior. Closed-loop optogenetics and calcium imaging in behaving animals will allow us to test the models and to ultimately reveal how the brain integrates, selects and combines social cues to drive social interactions. This multi-disciplinary approach will uncover the computational principles and mechanisms by which sensory information is processed to drive behavior in the complex sensory environment of animal groups.	European Research Council	Starting Grant	1476920.0	EUR
392	Dr. Ynte Ruigrok	UNIVERSITAIR MEDISCH CENTRUM UTRECHT	None	2020-02-01	2025-01-31	Early recognition of intracranial aneurysms to PRevent aneurYSMal subarachnoid hemorrhage	Intracranial aneurysms usually go undetected until rupture occurs leading to aneurysmal subarachnoid hemorrhage (ASAH), a type of stroke with devastating effects. Early detection and preventive treatment of aneurysms fall short as we do not know who is it at risk and why, as we have insufficient insight in the contribution and interplay of genetic, environmental and intermediate phenotypic risk factors. Given the rarity of the disease, there is a paucity of large and rich cohorts to study risk factors separately with sufficient power. To add to the problem, my preliminary findings suggest disease heterogeneity with subgroup specific risk factors for aneurysms. The sex-related heterogeneity is most eminent in the disease with 2/3 of patients being women. I aim to advance disease understanding to allow early recognition of intracranial aneurysms to prevent ASAH. I have established a new conceptual approach that integrates genetic and environmental risk factors with imaging markers as intermediate phenotypes for genetic factors. With data reduction and machine-learning approaches I will for the first time address disease heterogeneity and aneurysm risk with adequate power. I will develop and validate a tool to automatically detect new imaging markers predicting aneurysm development applying feature-learning models. Next I will elucidate the genetic basis underlying differential imaging risk patterns (imaging genetic factors). I will apply a new hypothesis-free strategy to detect and validate yet unknown environmental risk factors predicting aneurysm presence. I will assess the contribution to disease of all factors detected according to sex. All risk factors will be combined in an aneurysm prediction risk model to understand relative contribution of different risk factors in different subgroups. It will advance disease understanding and individualized risk prediction of aneurysms leading to precision medicine in early aneurysm detection to reduce the burden of ASAH.	European Research Council	Starting Grant	1499108.0	EUR
393	Dr. Marios Philiastides	University of Glasgow	None	2020-09-01	2025-08-31	Dynamic Network Reconstruction of Human Perceptual and Reward Learning via Multimodal Data Fusion	Training and experience can lead to long-lasting improvements in our ability to make decisions based on either ambiguous sensory or probabilistic information (e.g. learning to diagnose a noisy x-ray image or betting on the stock market). These two processes are referred to as perceptual and probabilistic/reward learning, respectively. Despite considerable efforts to uncover the neural systems involved in these processes, perceptual and reward learning have largely been studied in separate lines of research using divergent learning mechanisms. The primary aim of this proposal is to develop a unified framework for integrating these lines of research and understand the extent to which they share a common computational and neurobiological basis. Specifically, we will test the proposition that both the perceptual and reward systems could be understood in a common framework of “reward maximization”, whereby a domain-general reinforcement-guided learning mechanism – based on separate prediction error representations – facilitates future actions and adaptive behavior. To offer a comprehensive spatiotemporal characterization of the relevant networks and their computational principles we will adopt a state-of-the-art multimodal neuroimaging approach to fuse simultaneously-acquired EEG and fMRI data, via machine-learning-inspired multivariate single-trial analysis techniques and computational modelling. The project’s ultimate goal is to empower a level of neuronal and mechanistic understanding that extends beyond what could be inferred with each of these modalities in isolation. We will achieve this goal by exploiting endogenous trial-by-trial electrophysiological variability to build parametric fMRI predictors that can offer additional explanatory power than what can already be achieved by stimulus- or behaviorally-derived predictors, allowing us to go over and beyond what has been reported previously in the literature.	European Research Council	Consolidator Grant	1996043.0	EUR
394	Dr. Marloes EEFTENS	SCHWEIZERISCHES TROPEN- UND PUBLIC HEALTH-INSTITUT	None	2020-05-01	2025-04-30	Beyond seasonal suffering: Effects of Pollen on Cardiorespiratory Health and Allergies	As climate change increases the duration and intensity of the pollen season, allergies to airborne pollen are increasingly common in Europe. Yet, it is not well recognized that high pollen concentrations may increase respiratory and cardiovascular events, leading to mortality and excess hospitalizations. I aim to investigate how short-term exposure to pollen is related to mortality, hospitalization and allergic symptoms, both on its own and synergistically with air pollution and weather. I will develop spatiotemporal exposure models of pollen for the years 2003-2022 based on a network of 14 pollen measurements stations in Switzerland. Taking advantage of large, real-world datasets without selection bias (Swiss National Cohort) and the efficient case-crossover study design, I will investigate the population effects of pollen on daily respiratory and cardiovascular mortality and hospitalization, also accounting for variation in air pollution and weather conditions. To explore individual sensitivity, I will conduct repeated measurements of lung function and airway inflammation in a dedicated panel of 400 allergic patients complemented with opportunistic repeated accounts of self-reported symptoms from the “e-symptoms” app by Swiss Allergy Centre. To provide personalized prevention recommendations and enhance quality of life for the allergic population, I will derive exposure-response relationships based on prevalent pollen, air pollution and weather triggers and individual symptom reports, allowing me to ultimately forecast symptom severity using machine learning techniques. This highly innovative project utilizes available nationwide health datasets and systematic novel data collection methods (in the in-depth panel study), to better understand the role of pollen in respiratory and cardiovascular diseases at both personalized and population levels. The project will prevent and reduce health effects due to pollen, which constitute a large burden on health and economy.	European Research Council	Starting Grant	1381932.0	EUR
395	Prof. Giacomo INDIVERI	University Of Zurich	None	2017-09-01	2022-08-31	Neuromorphic Electronic Agents: from sensory processing to autonomous cognitive behavior	Neural networks and deep learning algorithms are currently achieving impressive state-of-the-art results. In parallel computational neuroscience has made tremendous progress with both theories of neural computation and with hardware implementations of dedicated brain-inspired computing platforms. However, despite this remarkable progress, today’s artificial systems are still not able to compete with biological ones in tasks that involve processing of sensory data acquired in real-time, in complex and uncertain settings. One of the reasons is that neural computation in biological systems is very different from the way today's computers operate: it is tightly linked to the properties of their computational embodiment, to the physics of their computing elements and to their temporal dynamics. Conventional computers on the other hand operate with mainly serial and synchronous logic gates, with functions that are decoupled from their hardware implementation, and with discretized and virtual time. In this project we will combine the recent advancements in machine learning and neural computation with the latest developments in neuromorphic computing technology to design autonomous systems that can express robust cognitive behavior while interacting with the environment, through the physics of their computing substrate. To achieve this we will embed in robotic platforms microelectronic neuromorphic processors and sensors that implement biophysically realistic neural computational primitives and dynamics. We will adopt active-sensing and on-line spike-based learning strategies, context and state-dependent computation, and probabilistic inference methods for "programming" these neuromorphic cognitive agents to solve challenging tasks in real-time. Our results will lead to compact low-power intelligent sensory-motor systems that will have a large impact on service and consumer robotics, Internet of Things, as well as prosthetics and personalized medicine.	European Research Council	Consolidator Grant	1999090.0	EUR
396	Dr Michael Schmuker	University of Hertfordshire	School of Computer Science	2020-08-14	2023-08-13	2014217 NeuroNex: From Odor to Action - Discovering Principles of Olfactory-Guided Natural Behavior	Fundamental to the work that we propose is a comparative approach to understanding neural representations and behavior in a range of species including mice, flies (adults and larvae), bees and locusts. Each one of these species offers advantages including experimental tractability, behavioral complexity, relevance of the specific ethological niche, etc. Nonetheless we propose to identify common theoretical principles in the ways in which the nervous systems of these organisms represent and transform olfactory stimuli, as well as how their behavioral responses change as a function of odor identity and intensity. Theories at different scales and levels of abstraction will inform and be tested in this project. To exploit the variety of data sources and species we propose to use will require that we identify common principles and test central theoretical ideas. Generally, neuroscience needs to bring experimentalists and theorists together in a more systematic and productive way to maximize the benefit of novel experimental approaches and make investments into complex and expensive experiments more valuable. However, despite widespread agreement on the general importance of theory and modeling in neuroscience, there is no consensus on which kind/level of theory will be most important for making progress. Traditional dynamical systems models of neurons and circuits have provided insights into the nature and limits of single neuron and local circuit computation. Statistical models provide important information about the information available to neurons for making decisions and generating actions. Therefore in this project we bring together computational/theoretical approaches in areas like dynamical systems, information theory, abstract geometry, machine learning/AI, and machine vision.	Medical Research Council	Research Grant	688656.0	GBP
397	Mr Conrad Harrison	University of Oxford	None	None	2023-08-13	Transforming outcome measures in plastic surgery through computer science	Aim The aim of this project is to improve how we measure the outcomes of treatments for cleft lip and/or palate. Background One in 700 babies are born with a gap in their lip and/or the roof of their mouth. This is called cleft lip and/or palate (CL/P). It can cause long-term difficulties with feeding, hearing, speaking, appearance and emotional wellbeing. Clefts are treated in many ways. This typically includes a series of operations as the child grows. Different surgeons recommend different operations, but there is little evidence to tell us which operations are more successful than others. It is important to measure how successful operations are to know which ones work best. So far, this has involved doctors' opinions, which are inconsistent. It can also involve looking at scans and other test results. But this isn't necessarily what matters most to people born with CL/P. Recently, a team of researchers asked people born with CL/P what matters most to them. From this, they made a questionnaire to score these things. It is called CLEFT-Q.Overall, CLEFT-Q has 119 questions. These are arranged into groups, e.g. questions about lips speech mood etc. Some groups of questions are not always suitable. For example, questions about lips are skipped for somebody with only a cleft palate. We discussed this with our research partners (children and adults with CL/P, parents of children with CL/P, and members of the public). They felt CLEFT-Q was still too long. Children under eight are too young to use CLEFT-Q. Instead, their outcomes are often scored by groups of doctors looking at photographs of their face before and after surgery. This is expensive and not always practical. Methods I am making computer programs that shorten CLEFT-Q. These are called computerised adaptive tests (CATs). The programs pick only relevant questions for each person, adjusting based on the answers they've already given. A CAT can predict someone's final CLEFT-Q scores without asking all the questions. This would make CLEFT-Q easier to complete. To make and test the CAT we will study patients' CLEFT-Q answers that were collected around the world by different research teams. I am also making an artificial intelligence' computer program that can measure the outcome of surgery by looking at photographs. I think this will be cheaper, quicker and more consistent than doctors' measurements. To do this I will use 150,000 photos of patients with CL/P before and after they had surgery. The photographs have already been studied by surgeons who rated how well they think the surgery went. My program will learn what a good or bad outcome is by measuring different parts of the face and working out patterns that lead to an outcome being considered good or bad.Patient and public involvement My research partners have already been involved in the project design and helped to write this application. I will invite them to contribute to all further stages of this research. This includes making decisions about what I should work on and how I should do it. They will ensure we make the programs as user-friendly as possible. To make this easier for them, most of our meetings will be done over video-calls or at charity events. We will write up our experience of working together. This will be published on the NIHR INVOLVE website, and I will invite research partners to join me in presenting this at relevant meetings. Dissemination I will keep the CL/P community updated through the CLEFT-Q website, social media and charity newsletters. I will also present our findings at scientific meetings and publish the results in scientific journals.	National Institute for Health Research (Department of Health)	Full Grant	384813.0	GBP
398	Dr. Edwin LUGHOFER	University of Linz	None	2020-03-01	2023-02-28	Interactive Machine Learning with Evolving Fuzzy Systems	None	Austrian Science Fund FWF	Stand-Alone Projects	409109.4	EUR
399	Giulia Pedrielli	Arizona State University	None	2020-04-15	2021-03-31	Collaborative Research: RAPID: RTEM: Rapid Testing as Multi-fidelity Data Collection for Epidemic Modeling	Biological Sciences - The novel coronavirus (COVID-19) epidemic is generating significant social, economic, and health impacts and has highlighted the importance of real-time analysis of the spatio-temporal dynamics of emerging infectious diseases. COVID-19, which emerged out of the city of Wuhan in China in December 2019 is now spreading in multiple countries. It is particularly concerning that the case fatality rate appears to be higher for the novel coronavirus than for seasonal influenza, and especially so for older populations and those with prior health conditions such as cardiovascular disease and diabetes. Any plan for stopping the epidemic must be based on a quantitative understanding of the proportion of the at-risk population that needs to be protected by effective control measures in order for transmission to decline sufficiently and quickly enough for the epidemic to end. Different data collection and testing modalities and strategies available to help calibrate transmission models and predict the spread/severity of a disease, have variable costs, response times, and accuracies. In this Rapid Response Research (RAPID) project, the team will examine the problem of establishing optimal practices for rapid testing for the novel coronavirus. The result will be the Rapid Testing for Epidemic Modeling (RTEM), which will translate into science-based predictions of the COVID-19 epidemic's characteristics, including the duration and overall size, and help the global efforts to combat the disease. The RTEM will fill an important gap in data-driven decision making during the COVID-19 epidemic and, thus, will enable services with significant national economic and health impact. The educational impact of the project will be on mentoring of post-doctoral and PhD researchers and on curricula by incorporating research challenges and outcomes into existing undergraduate and graduate classes. <br/><br/>Computational models for the spatio-temporal dynamics of emerging infectious diseases and data- and model-driven computer simulations for disease spreading are increasingly critical in predicting geo-temporal evolution of epidemics as well as designing, activating, and adapting practices for controlling epidemics. In this project, the researchers tackle a Rapid Testing for Epidemic Modeling (RTEM) problem: Given a partially known target disease model and a set of testing modalities (from surveys to surveillance testing at known disease hotspots), with varying costs, accuracies, and observational delays, what is the best rapid testing strategy that would help recover the underlying disease model? Several scientific questions arise: What is the value of testing? Should only sick people be tested for virus detection? What level of resources should be devoted to the development of highly accurate tests (low false positives, low false negatives)? Is it better to use only one type of test aiming at the best cost/effectiveness trade off, or a non-homogeneous testing policy? Naturally these questions need to be investigated at the interface of epidemiology, computer science, machine learning, mathematical modeling and statistics. As part of the work, the team will develop a model of transmission dynamics and control, tailored to COVID-19 in a way that accommodates diagnostic testing with varying fidelities and delays underlying a rapid testing regimen. The investigators will further integrate the resulting RTEM-SEIR model with EpiDMS and DataStorm for executing continuous coupled simulations.<br/><br/>This project is jointly funded through the Ecology and Evolution of Infectious Diseases program (Division of Environmental Biology) and the Civil, Mechanical and Manufacturing innovation program (Engineering).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	122998.0	USD
400	Michael Pazzani	University of California-San Diego	None	2020-05-01	2021-04-30	RAPID: Explainable Machine Learning for Analysis of COVID-19 Chest CT	Computer and Information Science and Engineering - In December 2019, it was discovered that a widely contagious pneumonia was caused by a new coronavirus infection now named COVID-19. The primary test for detection of the virus is real-time polymerase chain reaction (RT-PCR) with sensitivity of approximately 71% in some studies. However, this test may require several days to provide a result. Perhaps more importantly, imaging with x-ray or computed tomography (CT) are required to confirm pneumonia, which is the principal cause of death, as it leads to acute respiratory distress syndrome (ARDS). Recent studies have shown sensitivity of chest CT for approximately 98% for COVID-19 pneumonia and could provide immediate results but currently require human interpretation. Given the need for rapid, more accurate diagnosis, this project will use, adapt, and evaluate explainable machine learning techniques to diagnosis of COVID-19 pneumonia. This project will improve the understanding of mechanisms of COVID-19 and will help mitigate its impacts.<br/><br/>Viral nucleic acid detection using real-time polymerase chain reaction (RT-PCR) is the primary method for diagnosis of COVID-19 infection, which has rapidly spread worldwide as a global pandemic. Sensitivity of this test for COVID-19 infection has been estimated at approximately 71% in some studies and may require several days for a result. X-ray and CT imaging are complementary technologies that allow diagnosis of COVID-19 pneumonia, which can evolve to acute respiratory distress syndrome (ARDS) -- the principal cause of death in patients with COVID-19 infection. Especially early in the course of the disease, chest CT has multiple advantages over RT-PCR yielding results more quickly and is already widely deployed, but requires expert radiologist interpretation. The number of chest CTs may rapidly exceed the speed and capacity of already strained radiologists. An explainable machine learning algorithm may address this disadvantage to expedite the interpretation of chest CT and assist rapid triage of patients to the ICU, inpatient ward, monitoring unit, or home self-quarantine. Machine learning algorithms, specifically those leveraging deep convolutional neural networks (deep learning), have the potential for facilitating even more rapid diagnosis within minutes. This project seeks to validate the use of explainable deep learning methods to adjust diagnostic operating points for multiple applications, including (a) disease screening, (b) disease staging and prognostication, and (c) evaluation of treatment response.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	101643.0	USD
401	Gregory Voth	University of Chicago	None	2020-05-01	2021-04-30	RAPID: Data-driven Multiscale Integrative Model of the Coronavirus Virion	Mathematical and Physical Sciences - Gregory Voth of the University of Chicago is supported by this RAPID award to develop and deploy multiscale models of the entire SARS-CoV-2 virus, the virus that causes the novel coronavirus infectious disease 2019 (COVID-19). Such multiscale models, at both the atomistic and coarse grain levels, contribute greatly to our understanding of how this virus replicates. Molecular simulations of viral processes in COVID-19 are useful to identify possible weaknesses in the viral life cycle. This research focuses on the dynamics of coronavirus processes, including the conformational transitions that are required for the virus to function. The project has three main foci: 1) all-atom simulations of individual viral proteins that are essential to the viral life cycle; 2) a coarse-grain models to a holistic understanding of entire virion (the virus outside the host cell) and its large scale processes, such as fusion of virions with host cells; and 3) machine-learning-based approaches to link the all-atom and coarse grain models and further refine their accuracy. As part of a larger, international community working on COVID-19, all data, models and analysis code will be made publicly available as soon as they are developed, including through the NSF-funded Molecular Science Software Institute (MolSSI). The complete multiscale picture of virus structure and dynamics will be used to identify potential target sites for drug development and other therapeutic strategies.<br/><br/><br/>The research in this RAPID project is for the development and application of multiscale computer simulation methods to characterize key elements of large-scale viral processes in SARS-CoV-2 replication. To achieve this goal there are three main objectives: (1) to characterize the dynamical behavior of essential viral proteins involved using all-atom molecular dynamics simulations and understand the conformational transitions necessary for their function; (2) to develop and model the complete SARS-CoV-2 virion using coarse-grained simulation methods; and (3) to develop machine learning based approaches that systematically link atomic-level and coarse-grained simulation scales, and facilitate the generation of even more accurate and descriptive coarse-grained models. This research focuses on several biomolecular systems that are urgently needed to understand and characterize the transmission and propagation of the SARS-CoV-2 virus, including the spike protein that mediates entry of the viral particles into host cells, the host cell receptor, angiotensin-converting-enzyme 2, which binds the spike protein, coronavirus protease which catalyzes viral processes, and other viral protein components, especially as structural data and biochemical information are released in the next few months. Coarse-grained simulations will focus on the urgent need to develop a holistic model of the entire SARS-CoV-2 virion as well as its large-scale processes such as the fusion of virions with host cells.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	190595.0	USD
402	Thomas Crawford	Virginia Polytechnic Institute and State University	None	2020-05-01	2021-04-30	RAPID: MolSSI COVID-19 Biomolecular Simulation Data and Algorithm Consortium	Computer and Information Science and Engineering - In response to the growing COVID-19 pandemic, the Molecular Sciences Software Institute (MolSSI) will leverage its position as a neutral commodity resource to help the global computational molecular sciences community quickly provide their scientific data and expertise to address the COVID-19 crisis. The MolSSI is jointly supported by the Office of Advanced Cyberinfrastructure and the Divisions of Chemistry and Materials Research. The centerpieces of this engagement will be (1) a centralized repository for simulation-related data targeting the virus and host proteins and potential pharmaceuticals, and (2) a select set of MolSSI Software Seed Fellowships for Ph.D. students and postdocs targeting COVID-19 related software tools that operate on the data developed in the repository. These two components will enable the biomolecular simulation community to share and utilize key data and other resources to help identify the structural and dynamic characteristics of the host-virus complex to generate potential leads for therapeutics. Although this project is intended to address the acute COVID-19 crisis, in the near term, it also will impact research communities and the next generation of computational molecular scientists in the confrontation and proactive resolution of future world problems.<br/><br/>The MolSSI will create and curate a large-scale repository containing: simulation input files (structures, configurations, scripts, Jupyter notebooks) in an organized structure; MD trajectories, analysis tools, and ready models for drug discovery; pointers to preprint servers such as arXiv, bioRxiv, and ChemRxiv on biomolecular simulation research in regards SARS-CoV-2; and DOI services that create citable data. In addition, it will engage the molecular sciences community through a set of Software Fellowships for graduate student and postdocs to carry out software development, such as large-scale MD simulations, design of drug discovery tools such as docking, machine learning for small molecule toxicity predictions, and methods for determining whether new drugs are bioavailable or can be synthesized. Collectively, these resources will speed the identification and development of leads for antiviral drugs, analyzing structural effects of genetic variation in the SARS-CoV-2 virus, and inhibitors that can disrupt protein-protein interactions to viral entry into cells and adherence to surfaces that cause disease spread.<br/><br/>This award is being funded by the CARES Act supplemental funds allocated to CISE and MPS.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	200000.0	USD
403	Abbas Ourmazd	University of Wisconsin-Milwaukee	None	2020-05-01	2022-04-30	EAGER: Functionally Relevant Structural Heterogeneity in Coronavirus SARS-CoV2 Proteins	Biological Sciences - In order to prevent infections by specific viruses, it is important to understand the molecular details that drive the virus into host cells where they replicate, making more viral particles that spread to other cells in the infected individual. This award will help understand the mechanisms of the SARS-CoV2 infectivity, the virus responsible for the current COVID-19 pandemic, by employing machine learning algorithms to make movies of key proteins involved in driving its infection. There is mounting evidence that viral proteins exist in a range of structures, known as conformations, and that these can play a critical role in their function. In this project, recently developed machine-learning techniques will be used to determine the conformational landscape of key SARS-CoV2 proteins at near-atomic level, with and without antibody involvement. Atomistic insight into the conformational changes in SAR-CoV2 proteins is expected to help clarify the structural basis of virulence in this virus and its successors, ultimately providing a foundation for the development of suitable therapeutic strategies against coronaviruses. <br/><br/>Using experimental cryo-EM snapshots, this project will map the functionally relevant conformational heterogeneities of key SARS-CoV2 proteins to gain a deeper understanding of the role of conformational heterogeneity in this pandemic virus. The specific goals of this project are as follows: (1) Apply advanced machine-learning algorithms to experimental cryo-EM single-particle snapshots in order to determine the energy landscapes of key SARS-CoV2 proteins with and without antibody involvement; (2) Identify the functionally important conformational paths on the relevant energy landscapes; (3) Compare and contrast motions along functional paths with those inferred by discrete clustering methods; (4) Determine the biological implications of conformational motions associated with function; and (5) Make the results widely accessible in order to help facilitate the development of therapeutic strategies.<br/><br/>This RAPID award is made by the Division of Biological Infrastructure (DBI) using funds from the Coronavirus Aid, Relief, and Economic Security (CARES) Act.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	299723.0	USD
404	Judith Klein	Colorado School of Mines	None	2020-05-15	2021-04-30	RAPID: Prediction of coronavirus infections and complications at the individual and the population levels from genomic, proteomic, clinical and behavioral data sources	Computer and Information Science and Engineering - As of mid-April 2020, two million people are infected worldwide with the novel coronavirus that first appeared in Wuhan, China in December of 2019. Now, the USA is at the epicenter of this pandemic, where it has already killed 20,000 people. Approaches to slow the progression are urgently needed. This requires a better fundamental understanding of the factors affecting not only virus spread, but also who develops complications and ultimately dies from the infection. It is becoming clear that many factors are at play, including molecular, physiological, lifestyle, behavioral, demographic and socio-economic ones. In particular, co-morbidities such as diabetes and high blood pressure are known risk factors for COVID-19 complications and death but are likely only the tip of the iceberg. Molecular data indicates that as many as 100 co-morbidities exist. Given this complexity, statistical approaches are needed to integrate and account for all of these factors when predicting and assessing the health risks arising from coronavirus spread and infection. This project will create computational tools that will help individuals and healthcare professionals make decisions related to coronavirus, helping target human and material resources where they are most needed. To decrease the numbers of people suffering from this pandemic, these tools are needed urgently.<br/><br/>Integrating large numbers of risk factors through machine-learning approaches allows the building of statistical models that take all evidence into account. COVID-19 infections will be predicted at the individual and population levels. At the individual level, two binary (yes/no) classifiers will be built, (1) if an individual is likely infected with coronavirus, and if yes, (2) will the patient develop complications. As with all predictions, they cannot replace real data, but they can help prioritize who gets tested, who gets quarantined, who gets more closely monitored for signs of complications, and who gets personalized recommendations. Existing approaches include symptom-tracker apps, such as the coronavirus self-checker apps offered by the CDC, many healthcare providers and local government authorities and the National Early Warning Score (NEWS) and Modified Early Warning Score (MEWS), which determine the degree of illness of a patient. None of these approaches account for co-morbidities, and they lack the use of machine learning for data integration needed to predict individual outcomes. At the population level, possible routes of infection will be analyzed using graph analysis, through analysis of proximity, social interactions, and materials transport, taking the individual-level information into account where available. The project will be highly interdisciplinary, integrating biochemistry and computer science with ongoing input and feedback from healthcare professionals. This will ensure that the work will be relevant to the current crisis and easier to adopt by healthcare providers. Students and postdocs who participate in this research will be trained in interdisciplinary research and will be exposed directly to frontline workers in the pandemic. A publicly available, free app and a web interface will disseminate the predictions made in this project broadly in the hope it will find many users.<br/><br/>In summary, the goal of this research is to understand how SARS-CoV-2 virus and host genomes interact to determine the full spectrum of disease outcomes, with the goals of identifying the cellular basis for host range and pathology, predicting morbidit,; and developing effective medical interventions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	100000.0	USD
405	Keri Stephens	University of Texas at Austin	None	2020-05-15	2021-04-30	RAPID/Collaborative Research: Human-AI Teaming for Big Data Analytics to Enhance Response to the COVID-19 Pandemic	Engineering - Social media data can provide important clues and local knowledge that can help emergency managers and responders better comprehend and capture the evolving nature of many disasters. Yet humans alone cannot grasp the vast data generated by social media, so computers are used to assist. Very little is currently known about how to leverage the skills of humans and machines when they work together (human-machine teaming) to identify meaningful patterns in social media data. Therefore, the fundamental issues this Rapid Response Research (RAPID) project seeks to address are 1) understanding the process of real-time decisions that human digital volunteers make when they rapidly convert social media data into structured codes the machine (Artificial Intelligence algorithms) can understand, and 2) using this knowledge to improve human-machine teaming. This project advances the field by revealing the unique abilities that both humans and machines bring when working together to comprehend social media patterns during an evolving disaster. It supports education and diversity by providing research experiences to diverse students, as well as generating data useful for interdisciplinary courses teaching teamwork, social media analysis, and human-machine teaming. Finally, the findings can help emergency managers better train their volunteers who comb through social media using their understanding of the local knowledge and built environment to help machines see new patterns in data. Hence, this project supports NSF's mission to promote the progress of science and to advance the nation's health, prosperity, and welfare by articulating the unique value that both humans and computers bring that can lead to better decisions during disasters. The goal of this research is to better understand the real-time decisions that human annotators make under different environmental constraints, and how those contribute to the learning of Artificial Intelligence (AI) models. Under time constraints and information overload, human decision-making capabilities are limited; yet, humans still have a unique ability to understand the contextual references to the structures in the built environment that machines cannot recognize. For example, the meaning of the tweet, ?Memorial is overloaded,? -- which means the hospital, called Memorial, is out of beds for patients ?- can be lost on AI systems that lack the knowledge of the built environment. This example demonstrates the value that humans in the loop offer in a human-AI teaming context. <br/><br/>This research focuses on capturing the ephemeral data from a variety of social media sources and our two research thrusts include: 1) online observations of Community Emergency Response Team (CERT) volunteers and a manager (a collaborator on this project) using think-aloud and cognitive interviewing strategies to reveal the real-time mental models used to make coding decisions for annotation tasks; and 2) an empirical analysis of different sampling algorithms for active (machine) learning paradigms to develop a typology of machine errors under diverse contexts that affect the quality of human decision making for annotation. This research will generate design guidelines that bridge the gap between the mechanisms used for real-time data processing with AI models and the understanding of context contributed by a human user teaming with the AI models. Using theories of human decision-making combined with knowledge of how AI functions, this project provides a real-time, mid-disaster examination of 1) how humans understand, process, and interpret social media messages, and 2) how to refine AI algorithms to optimize active learning paradigm. This understanding will provide a theoretical framework enabling future research to develop protocols to optimize human-AI teaming by using concepts such as motivation and information theory. This work can help emergency managers conduct better training of their CERT volunteers and other annotators and provide clearer guidelines for how to communicate the unique value that humans bring to the annotation process for AI systems. Both our protocols and developed understanding of how humans interact with AI systems will be helpful for global health organizations, local and state-level disaster decision-makers, as well as provide direction for the vast CERT network in the United States.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	20262.0	USD
406	Amanda Lee Hughes	Brigham Young University	None	2020-05-15	2021-04-30	RAPID/Collaborative Research: Human-AI Teaming for Big Data Analytics to Enhance Response to the COVID-19 Pandemic	Engineering - Social media data can provide important clues and local knowledge that can help emergency managers and responders better comprehend and capture the evolving nature of many disasters. Yet humans alone cannot grasp the vast data generated by social media, so computers are used to assist. Very little is currently known about how to leverage the skills of humans and machines when they work together (human-machine teaming) to identify meaningful patterns in social media data. Therefore, the fundamental issues this Rapid Response Research (RAPID) project seeks to address are 1) understanding the process of real-time decisions that human digital volunteers make when they rapidly convert social media data into structured codes the machine (Artificial Intelligence algorithms) can understand, and 2) using this knowledge to improve human-machine teaming. This project advances the field by revealing the unique abilities that both humans and machines bring when working together to comprehend social media patterns during an evolving disaster. It supports education and diversity by providing research experiences to diverse students, as well as generating data useful for interdisciplinary courses teaching teamwork, social media analysis, and human-machine teaming. Finally, the findings can help emergency managers better train their volunteers who comb through social media using their understanding of the local knowledge and built environment to help machines see new patterns in data. Hence, this project supports NSF's mission to promote the progress of science and to advance the nation's health, prosperity, and welfare by articulating the unique value that both humans and computers bring that can lead to better decisions during disasters. The goal of this research is to better understand the real-time decisions that human annotators make under different environmental constraints, and how those contribute to the learning of Artificial Intelligence (AI) models. Under time constraints and information overload, human decision-making capabilities are limited; yet, humans still have a unique ability to understand the contextual references to the structures in the built environment that machines cannot recognize. For example, the meaning of the tweet, ?Memorial is overloaded,? -- which means the hospital, called Memorial, is out of beds for patients ?- can be lost on AI systems that lack the knowledge of the built environment. This example demonstrates the value that humans in the loop offer in a human-AI teaming context. <br/><br/>This research focuses on capturing the ephemeral data from a variety of social media sources and our two research thrusts include: 1) online observations of Community Emergency Response Team (CERT) volunteers and a manager (a collaborator on this project) using think-aloud and cognitive interviewing strategies to reveal the real-time mental models used to make coding decisions for annotation tasks; and 2) an empirical analysis of different sampling algorithms for active (machine) learning paradigms to develop a typology of machine errors under diverse contexts that affect the quality of human decision making for annotation. This research will generate design guidelines that bridge the gap between the mechanisms used for real-time data processing with AI models and the understanding of context contributed by a human user teaming with the AI models. Using theories of human decision-making combined with knowledge of how AI functions, this project provides a real-time, mid-disaster examination of 1) how humans understand, process, and interpret social media messages, and 2) how to refine AI algorithms to optimize active learning paradigm. This understanding will provide a theoretical framework enabling future research to develop protocols to optimize human-AI teaming by using concepts such as motivation and information theory. This work can help emergency managers conduct better training of their CERT volunteers and other annotators and provide clearer guidelines for how to communicate the unique value that humans bring to the annotation process for AI systems. Both our protocols and developed understanding of how humans interact with AI systems will be helpful for global health organizations, local and state-level disaster decision-makers, as well as provide direction for the vast CERT network in the United States.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	24498.0	USD
407	Dr Cynthia Fu	King's College London	Institute of Psychiatry	2009-04-15	2010-04-14	Application of conformal predictors to functional magnetic resonance imaging research	Currently, there are no neurobiological markers for diagnosis or prediction of clinical response for psychiatric disorders used in clinical practice. Neuroimaging studies have revealed significant, and often wide-spread, functional and structural cerebral abnormalities in several psychiatric disorders. An essential step towards a clinical application would require a quantitative measure of patterns of brain activation that distinguishes patients from healthy individuals. This entails a shift in the data analysis from focusing on differences between groups to classifying whether an individual belongs to group A or group B. Machine learning methods provide a key analysis tool in developing such quantitative classification for psychiatric disorders. Our preliminary data show significant potential for the functional neuroanatomy of affective and cognitive features as a neurobiological marker for the diagnosis and prognosis in depression, bipolar disorder and schizophrenia. A major limitation of current analysis though is the lack of confidence intervals in the data output. In this project, we propose a new collaboration with the originators of support vector machine analysis and clinical neuroimaging researchers. A computer science post-doctoral researcher will hop into clinical neuroimaging research to help build and adapt machine learning methods to the analysis of neuroimaging data. The project is an essential step towards the development of neurobiological markers in psychiatric disorders.	Medical Research Council	Research Grant	99973.0	GBP
408	Dr Sanguinetti	University of Edinburgh	None	2012-10-01	2017-10-01	Machine learning for computational science:statistical and formal modelling of biological systems	Computational modelling is changing the face of science. Many complex systems can be understood as embodied computational systems performing distributed computations on a massive scale. Biology is the discipline where these ideas find their most natural application: cells can be viewed as input/ output devices, with proteins and organelles behaving as finite state machines performing distributed computations inside the cell. This led to the influential framework of cell as computation, and the successful deployment of formal verification and analysis on models of biological systems. This paradigm shift in our understanding of biology has been possible due to the increasingly quantitative experimental techniques being developed in experimental biology. Formal modelling techniques, however, do not have mechanisms to directly include the information obtained from experimental observations in a statistically consistent way. This difficulty in relating the experimental and theoretical developments in biology is a central problem: without incorporating observations, it is extremely difficult to obtain reliable parametrisations of models. More importantly, it is impossible to assess the confidence of model predictions. This means that the central scientific task of falsifying hypotheses cannot be performed in a statistically meaningful way, and that it is very difficult to employ model predictions to rationally plan novel experiments.In this project we will build and develop machine learning tools for continuous time stochastic processes to obtain a principled treatment of the uncertainty at every step of the modelling pipeline. We will use and extend probabilistic programming languages to fully automate the inference tasks, and link to advanced modelling languages to allow formal analysis tools to be deployed in a data modelling framework. We will pursue twoapplications to fundamental problems in systems biology, guaranteeing impact on exciting scientific questions.	European Research Council	Starting Grant	1421944.0	EUR
409	Dr Nicholas Myers	University of Oxford	None	2017-01-01	2021-01-01	Dynamic cortical networks for cognitive flexibility	This project will test the neural basis of cognitive flexibility. Cognitive flexibility allows us to change the rules governing our behaviour to fit the current context. Flexibility is important because we need it even for common tasks, such as changing our normal route home to stop by the supermarket. Prefrontal cortex (PFC) is necessary for cognitive flexibility: damage leads to severe impairments. However, the functional mechanism is largely unknown. I propose that flexible rule switches are implemented through dynamic changes in functional connectivity within the PFC and across the brain. Connectivity sub-selects a local PFC ensemble and links it to appropriate input and output regions, ensuring that new input triggers a state-dependent cascade of neural activation that underpins context-appropriate action selection. I will test whether oscillatory synchronization within PFC and across context-relevant areas is central to this dynamic coding of flexible rule switches by combining multivariate analysis and computational modeling with recordings from macaques and humans (intracranial recordings and MEG). Both dynamic coding and synchronization are fundamental building blocks of neural coding. Therefore, synthesizing these ideas in a coherent framework would be of wide interest in systems neuroscience and psychology.	Wellcome Trust	Sir Henry Wellcome Postdoctoral Fellowship	250000.0	GBP
410	Miranda Lynch	Hauptman-Woodward Medical Research Institute Inc	None	2020-05-01	2021-04-30	RAPID IIBR Informatics Computational methods for utilizing SARS-Cov2 sequence and structure data in predicting host-pathogen protein-protein interactions	Biological Sciences - The award to Hauptman-Woodward Medical Research Institute supports research into machine learning approaches to understand the interactions of SARS-COV-2 proteins. The researchers will combine information from the viral genome with other data on protein structures to predict protein interactions. This research affords significant societal benefits by providing important information about the virus biology. The research may also contribute to the identification of potential therapeutic compounds. An early stage researcher will participate extensively in the project as part of training activities. Software and data from the studies will be shared in public repositories, published in peer-reviewed journals, and presented at scientific meetings.<br/><br/>Researchers supported by this award will develop machine learning based computational tools for prediction of protein-protein interactions (PPI) in the infectious disease setting involving host proteins and viral pathogen proteins. Computational tools that can leverage immediately arising data sources to advance experimental work on the virus can make a major and immediate impact on pandemic response. Support vector machine classifiers and Bayesian inferential methods will be used to develop machine learning models that incorporate both genomic and structural information to better understand and predict protein interactions. The goal in creating computational tools to understand the host-pathogen interface is to contribute basic information on protein interactions that dictate the mechanisms of virus entry into cells and modes of transmission of viral pathogens. Methods developed in this proposal will be valuable in future situations where rapid information development about an emerging pathogen is required.<br/><br/>This RAPID award is made by the Division of Biological Infrastructure (DBI) using funds from the Coronavirus Aid, Relief, and Economic Security (CARES) Act.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	199816.0	USD
411	Dr Samir Bhatt	Imperial College School of Medicine	None	2019-04-01	2021-03-31	Unravelling and predicting the spatiotemporal structure of infectious disease outbreaks	Developing effective methods to model outbreak disease dynamics that can accurately forecast and predict over various spatiotemporal scales is a fundamental challenge in infection control. Statistical methods in this area have been dominated by individual-based and mechanistic models that are often cumbersome and difficult to apply in predictive scenarios. In contrast, probabilistic frameworks that both model infectiousness and draw from highly predictive deep learning frameworks have been rarely explored. In this grant, we will apply, and further develop a class of inhomogeneous, self-exciting, point processes that jointly capture both the spatiotemporal risk of primary infection and the secondary infection network structure. These spatiotemporal models will incorporate the self-exciting, environmental/demographic and latently varying drivers, and make use of advanced approximate inference to allow for tractable computation. Using these processes, we will explore what optimal forecasting performance can be expected from state-of-the-art machine learning methods and investigate what parts of the predictive model account for this performance, i.e. can we apportion the variance explained to the self-exciting versus latent factors. We will further investigate whether it is possible to exploit genetic information and embed these approaches in the standard suite of phylodynamic methods. We will apply these developed methods to historical outbreak data across a range of diseases and both qualitatively and quantitatively examine the differences.	The Academy of Medical Sciences	Springboard Round 4	99994.63	GBP
412	Miss Yidian Gao	University of Birmingham	None	2020-07-01	2022-06-30	ENIGMA Antisocial Behavior: Multimodal neuroimaging of conduct disorder	Conduct Disorder (CD) is a psychiatric disorder that begins in childhood or adolescence and characterised by behaviours that violate social norms and others’ rights, such as physical aggression towards other humans or animals, theft, and property damage. With a prevalence of ~2-2.5%, CD is associated with a broad range of negative outcomes and places a disproportionate burden on our healthcare, legal, educational and social welfare systems. The 2010 Global Burden of Disease study reported that CD is one of the leading causes of disability in many world regions, even when considered against mental disorders that continue throughout the lifespan such as autism spectrum disorder and physical illness such as HIV/AIDS. However, and paradoxically, CD is one of the least widely-recognised and studied psychiatric disorders. Indeed, CD frequently goes undiagnosed and untreated, most likely due to the misconception that youths with CD do not suffer from a mental health disorder, but, instead, are merely ‘behaving badly’. Meta-analytic evidence from functional and structural magnetic resonance imaging studies on CD have shown abnormal neural responses and reductions in grey matter in several cortical and subcortical regions critical for emotion processing and regulation, reinforcement-based decision-making, executive functions and empathy. CD has also been associated with abnormalities in white matter. These neuroimaging data support the view that CD is a neurodevelopmental disorder, but this evidence base suffers from important limitations. First, inconsistent findings and the lack of replication are common because most studies had small sample sizes, increasing the risk for false positives and false negatives, and few of them had the statistical power to account for the heterogeneity of CD in terms of clinical subtypes and sex. Second, no structural study has combined different modalities and complementary metrics to understand CD and its subtypes across sexes and development stages. The proposed project will use advanced computational methods on the world’s largest neuroimaging dataset of CD assembled by the ENIGMA Antisocial Behavior group. Two large-scale meta-analyses examining: i) grey matter and ii) white matter abnormalities will be conducted. Combining all available imaging metrics, this project will also use machine learning to predict CD diagnosis, test how well our predictive models of CD generalise across diverse cohorts and characterise the heterogeneity within CD. This project will significantly advance our understanding of the neural substrates underlying CD and how heterogeneity within CD might influence structural brain abnormalities, which may ultimately identify valid targets for treatment.	The Academy of Medical Sciences	Newton International Fellowship	92187.0	GBP
413	Prof. Ulrike Tillmann	University of Oxford	None	None	2022-06-30	Application driven Topological Data Analysis	Modern science and technology generates data at an unprecedented rate. A major challenge is that this data is often complex, high dimensional, may include temporal and/or spatial information. The "shape" of the data can be important but it is difficult to extract and quantify it using standard machine learning or statistical techniques. For example, an image of blood vessels near a tumor looks very different than an image of healthy bloodvessels; statistics alone cannot quantify this shape because it is the shape that matters. The focus of this proposal is to study the shape of data, through the development of new mathematics and algorithms, and build on existing data science techniques in order to obtain and interpret the shape of data. A theoretical field of mathematics that enables the study of shapes is topology. The ability to compute the shape (its topology) of complicated shapes is only possible with advanced mathematics and algorithms. The field known as topological data analysis (TDA), enables one to use topology to study the shape of data, such as loops in a blood vessel network. In particular, an algorithm within TDA known as persistent homology, provides a topological summary of the shape of the data (e.g., features such as holes) at multiple scales. A key success of persistent homology is the ability to provide robust results, even if the data are noisy. There are theoretical and computational challenges in the application of these algorithms to large scale, real-world data. The aim of this project is to build on current persistent homology tools, extending it theoretically, computationally, and adapting it for practical applications. Our core team is composed of experts in pure and applied mathematicians, computer scientists, and statisticians whose combined expertise covers cutting edge pure mathematics, mathematical modeling, algorithm design and data analysis. This core team will work closely with our collaborators in a range of scientific and industrial domains. Some of the application challenges we have set out include: Can we detect a tumor by looking at the shape of images of blood vessels? Can we design new materials by looking at the shape of molecules using topology? How can we design such molecules? Can we detect anomalies in security data? And importantly, how can we accelerate algorithms to obtain topological characteristics of data in real time?	UK Research and Innovation	Research Grant	2847111.0	GBP
414	ARALIA SYSTEMS LIMITED	ARALIA SYSTEMS LIMITED	None	None	2022-06-30	PHOTOMETRIC STEREO IMAGING USING A SMART PHONE	The project provides a low cost photometric stereo illumination device and associated software that enables a smart phone to capture and process images revealing a high resolution 3D image of a surface. The images can be transmitted to a remote location for expert analysis. The method of surface reconstruction is protected by patents held by the University of Strathclyde Institute of Photonics. The photometric stereo images aid diagnosis of dermatological conditions by means of tele-medicine. The same 3D technique is also used in non-destructive testing, security and surveying applications. The simplicity and low cost of the device ensures that they may be readily distributed whenever necessary. The project also includes facilities for archiving, displaying and processing images through the application of Machine Learning. The illumination device and associated software will be available to the public by Q2 2021 .	UK Research and Innovation	Research Grant	47856.0	GBP
415	RAZORSECURE LIMITED	RAZORSECURE LIMITED	None	None	2022-06-30	Real time measurement of UK Rail Passengers to enable social distancing during a pandemic	The UK is currently experiencing severe disruption due to the Covid-19 lockdown, and ending the lockdown in a controlled way is vital to the UK's economic future. Public transport is critical to getting key workers to their jobs as well as for the wider UK economy to function efficiently. However, given the requirements under social distancing, the overcrowding of people on public transport could lead to faster transmission of Covid-19 leading to a potential second wave or aiding a future outbreak. RazorSecure provides cyber security intrusion and anomaly detection using machine learning to give real time visibility of networks onboard UK trains. We propose to extend the data we currently collect and produce new visualisations to give real time data regarding overcrowding of public transport to allow for more active management of social distancing while transiting the UK transport network. As a direct, actionable item, guards would be given an application that will allow them to inform passengers that a particular carriage is less crowded and operators would have a real-time dashboard to review crowding.	UK Research and Innovation	Research Grant	49854.0	GBP
416	LB PARSONS LIMITED	LB PARSONS LIMITED	None	None	2022-06-30	TutorHero - a revolution in primary tutoring	TutorHero is a Software as a Service (SaaS) product which automates the process of identifying knowledge gaps and developing individualised learning plans for tutees, guiding them to interactive video content which is most useful to them. Using machine learning to assess students, forms a consistent map of students' weak areas allowing the platform to automatically flag misconceptions that require 1-to-1 tutor-to-student intervention. This fully automated aspect of the system is referred to as "TutorBot". No other platform is able to provide consistently refined leaning plans and flag manual interventions at scale. The COVID-19 pandemic has hit education hard across the globe with 1.53 billion learners out of school (UNESCO) and 184 country-wide school closures, impacting 87.6% of the world's total enrolled learners. If left unaddressed, interruptions to education can have long term implications -- especially for the most vulnerable. TutorHero aims to address this quickly and at scale. In the short term, the platform will be tailored to helping UK students in Y5&6 fill knowledge gaps and re-join their level of competency as these students are in a critical stage of their education, due to transition from primary to secondary education, over 250 interactive videos will be available on launch. TutorBot periodically assesses students, creating a feedback loop which constantly measures and directs learning efforts, adjusting the students learning path based on their current understanding. Human tutors are not redundant though, TutorHero acts predominantly as a force multiplier, students are expected to receive 1-to-1 'live' support online to get the unique input and reinforcement they require in order to learn effectively for 5% of their learning. This 5 month project will develop and test TutorHero, ultimately producing an MVP to showcase its capabilities to target customers, parents and schools. After this project, the team intends to rapidly deploy the product to live environments and sign up the first users within 2-4 weeks. By rethinking how tutoring is delivered and developing TutorBot, the platform is able to deliver high-quality individual tutoring 75% cheaper than traditional alternatives, directing 95% of learning to prerecorded reusable content, this opens the door to households who have previously been unable to afford tutoring, creating new demand. Initially focussed on the UK educational system, the underlying technology has the potential to be integrated/adapted to suit any education system globally making global education more resilient to disruption and bringing tutoring into the 21st Century.	UK Research and Innovation	Research Grant	47149.0	GBP
417	EMTEC CORPORATION LIMITED	EMTEC CORPORATION LIMITED	None	None	2022-06-30	Emtec De-Centralised Contact Tracking Project	EMTEC is collaborating with a medical team at Le Bonheur Hospital, Memphis, Tennessee to develop a contact proximity tracking application which can be used by hospitals and other organisations to manage the impact of COVID-19 and other infectious diseases. The EMTEC software development team has extensive experience of vehicle tracking using GNSS location data and Bluetooth and will be able to deploy people tracking technology onto its existing cloud-based platform using apps installed on mobile phones. The project team is developing analysis methods that can identify users, localise them based on triangulation with the aid of Wifi signals inside buildings and then applying machine learning methods to build a true contact graph with probabilities. For example, not only staff in contact with COVID-19 patients will be high risk but also the people that interact with them. The immediate goal of the contact tracking is to be able to trace back all high-risk contacts when a new infection is determined and implement targeted testing. Contact tracking is a critical technology to manage staff levels and keep hospitals and other companies operational while managing risk. The project has an essential priority on establishing and observing the privacy protection issues required by management and staff. The privacy protection analysis will be based on USA Fair Information Practice Principles (FIPPS) and European General Data Protection Regulation (GDPR) to ensure global viability. The solution will be ready for wider global community deployment by September 2020 .	UK Research and Innovation	Research Grant	49827.0	GBP
418	Univ.Prof. Dipl.Ing. Dr. Markus VINCZE	Vienna University of Technology	None	2003-12-15	2006-11-14	Cognitive Vision - A Key Technology for Personal Assistance - Coordination Project	Each of us might have encountered the situation to desperately search for a personal item or a location in an unknown environment. At present there is no technical solution for such an assistive system. The newly granted Joint Research Project Cognitive Vision attempts to find first solutions in this direction. A human shall be supported with a system that can not only find things, but that can understand the relationship between the human activities and objects involved. This understanding of new information and new knowledge is the key aspect of the cognitive approach to computer vision. The solution proposed is based on a trans-disciplinary approach. It integrates partners from theoretical computer science (TU Graz), neuroscience (Max-Planck-Institut Tübingen), artificial intelligence (öFAI, Wien), machine learning (MU Leoben), user engineering (CURE, Wien) and different areas of computer vision and pattern recognition (ACIN &amp; PRIP TU Wien, EMT &amp; ICG TU Graz and Joanneum Research Graz). One aspect of the project is to investigate the relations of the different brain regions in visual cortex. While individual functions of these regions are relatively well studied, new methods of screening brain functions enable deeper insights that contradict present hypotheses. It could be shown that human vision profits enormously from expectations in a given situation. For example, objects in an atypical environment are spotted much more quickly than in the expected environment. Using this analysis of the only working vision system we will develop computer models to describe objects under different conditions, for example, different illumination, shape, scale, clutter and occlusion, and to describe the relationships between objects and the environment. A particular emphasis is on learning these models and relationships. In the same way one shows a new object to a child, we want to relieve the user from the present exhaustive learning phases. Another aspect of the research work is the analysis of the interrelations of the different seeing functions, namely, mechanisms to guide attention, the detection and identification of objects, the prediction of motions and intentions of the user, the integration of knowledge of the present situation, and the creation of an appropriate system reaction. The coordination of these functions is resolved using an agent/based optimisation of the utility to the system's functioning. The techniques devised will be implemented in prototype systems. In a user study it will be evaluated how the expectations are met or not to further improve system performance. The objective of the next three years is to track and predict where objects are moved to and where locations can be found. A user could then ask the system where her mug is or where a specific shop is when entering unknown parts of a city. In both cases the user would be assisted and guided to the location.	Austrian Science Fund FWF	National Research Networks NFN	None	None
419	Dr Florian Markowetz	University of Cambridge	None	2014-03-01	2019-02-28	Computational Biology Laboratory	Recent advances in biotechnology have produced a wealth of genomic data, which capture a variety of complementary cellular features. While these data promise to yield key insights into molecular biology and medicine, much of the information present remains underutilized because of the lack of scalable approaches for detecting signals across large, diverse data sets. A proper framework for capturing these numerous snapshots of complementary phenomena under a variety of conditions can provide the holistic view necessary for developing relevant and precise systems-level hypotheses of new drug targets and disease mechanisms. My research is concerned with developing statistical and mathematical models of complex biological systems and analyzing large-scale molecular data. My research interests range from the analysis of microarray data in clinical settings to inference of cellular networks from high-throughput gene perturbation screens and integration of heterogeneous data sources using machine learning techniques and probabilistic graphical models Research Directions at the Cambridge Research Institute My goal is to continue research on computational and statistical analysis of high-throughput data. In my lab at the Institute, I aim to develop comprehensive descriptions of genetic systems of cellular controls, including: 1. regulation of cell differentiation and development, and 2. controls whose failure may lead to developmental defects or genetic disorders, such as cancer. Together with my group, I will investigate the structure and function of biological regulatory networks and their relationship to disease mechanisms and drug targets. This includes an investigation of topological and functional units in regulatory networks as well as time-dependent or condition-specific alterations. In the immediate future, my lab will work in collaboration with the Ponder and Caldas groups on projects in breast cancer genetics and genomics, which aim to identify key drivers of disease by integrating genome-wide data from SNP, array CGH, gene expression, and microRNA profiling studies.	Cancer Research UK	SEB - Institute Group Award	None	None
420	Dr Jennifer Bizley	University College London	Ear Institute	2016-06-20	2016-08-12	Neural mechanisms underlying complex sound identification	The aim of the project is to better understand how brain processes complex sound information by measuring responses of cortical neurons (nerve cells) to artificial vowel sounds. The student will construct artificial network of neurons called the convolutional neural networks to make sense of sound identity from neural responses. Dataset has already been collected from 8 ferrets. Student has strong computational and programming skills and experience in programmes needed to analyse the data such as MATLAB and machine learning. Student will be supervised by Dr Stephen Town (Pauline Ashley grant holder) who collected the primary electrophysiology data. The work is feasible for a summer student as the primary data (neural responses to pure tones, single and multi-formant vowels in anesthetised and behaving ferrets) has already been collected and formatted for analysis. Dr Bizley has also developed some basic models with which to analyse data, and from which the student can build and develop his own ideas with support and assistance as necessary.	Action on Hearing Loss	Summer studentship	1600.0	GBP
421	Dr Parashkev Nachev	University College London	None	2010-07-01	2013-12-31	Automated high-dimensional outcome prediction in stroke.	Stroke is the leading cause of adult disability in the UK at an estimated overall annual cost of ?7 billion. Alarmingly, clinical outcomes in stroke are not improving as fast as conditions of similar aetiology. A major cause is the difficulty in providing targeted care in a patient group with such hugely diverse requirements: indeed, the government predicts that better organisation of care can both save lives and optimize resource allocation. We therefore propose to develop a system for predicting clinical outcomes so as to provide advance information on the optimal clinical management of each patient. Our solution automated brain image analysis with high-dimensional machine-learning inference exploits the fine scale functional specialization of the brain, capturing the relation between the pattern of brain damage and clinical outcome at very high resolution. As our pilot data demonstrate, this approach permits much greater predictive power than is offered by current techniques which all rely on crude, global features such as the volume of damaged brain or its rough location and yet adds minimal resource overhead because it uses routinely acquired clinical data. Our proposal seeks to develop this technology to the point of direct clinical application.	Wellcome Trust	Translation Award	392444.0	GBP
422	Dr Parashkev Nachev	University College London	None	2014-09-15	2018-02-01	Automatic anomaly detection for brain imaging triage and classification	Modern brain imaging generates many thousands of data observations per patient, yet its clinical impact remains determined only by the summary points in a radiologist's verbal report. This information gap shows that we are not fully exploiting all potentially relevant clinical information from this expensively acquired data. Our technology will seek dramatically to reduce this gap within current clinical pathways by applying novel machine-learning algorithms to routine brain imaging data, with the aim of automatically extracting rich, high-dimensional information of clinical utility. The system will deliver automatic quantification of the anomaly of each data point of an image to assist radiological reporting and automated outcome prediction based on disease patterns and an anomaly score for the whole image to aid radiological triage and resource/performance management. Our goal is to demonstrate the feasibility, robustness, clinical, and managerial value of the approach using a large dataset of routine clinical brain imaging, delivering a pilot system translatable into a full clinical product. Merely by adding an inexpensive layer of computation to existing pathways, the system should improve report fidelity and optimise radiological triage and management, while creating a scalable new platform for facilitating big data' approaches to major neurological disorders.	Wellcome Trust	Health Innovation Challenge Fund Award	1088636.0	GBP
423	Dr Rudolf Cardinal	University of Cambridge	None	2018-03-31	2021-03-31	MICA: Mental Health Data Pathfinder: University of Cambridge, Cambridgeshire & Peterborough NHS Foundation Trust, and Microsoft	With strong NHS partnerships and recent contributions to national mental health (MH) informatics, we shall add novel methods, epidemiology and phenotyping to the MH Platform. We envisage a modular pipeline that de-identifies MH data; supports flexible consent for sharing/contact; and links MH, cognitive, physical, psychosocial and biomarker data. Project (P) 1. Our open-source tools de-identify clinical records to create CPFT’s Research Database, supporting research and participation. We shall extend them to generate anonymised subsets and link data from consenting patients across MH/community services, acute care, and research organizations, including from existing deeply phenotyped longitudinal cohorts. We emphasize rigorous interface standards and NHS governance over identifiable/pseudonymised data. We shall collaborate on a national natural language processing framework, allowing NHS/research organizations to generate structured data from free text. P2. We have created novel open-source neuropsychiatric assessment software. We shall extend it for broad and integrated NHS and research use. This will take automated cognitive testing into routine clinical practice. As a bold but tractable exemplar with research and clinical applications, we shall use it to apply electronic diagnostic algorithms and neuropsychiatric phenotyping, and link these detailed data to clinical records and biomarkers that include immunophenotyping. P3. We shall apply P1 tools to a public health crisis: the premature death of those with serious mental illness. We shall link MH, national and acute Trust data and use machine learning to develop early predictors of mortality. P4. We shall democratize MH research though broad consultation on generic tiered consent models for data-sharing and participation, by giving the research database direct clinical interfaces, and by enhancing data visualization to help clinicians and service users develop research and the NHS improve local services.	Medical Research Council	P&Cs	1496194.0	GBP
424	Andreas Gschwind	Department of Genetics Stanford University School of Medicine	Department of Genetics Stanford University School of Medicine	2017-10-01	2019-03-31	Dissecting the regulatory landscape of the human genome	A large number of genetic variants linked to phenotypic changes are located in the non-coding regions of the genome, suggesting that their effects are most likely the result of changes in gene expression regulation. Expression quantitative trait locus (eQTL) analyses allow finding of regulatory genetic variants, which are linked to changes in gene expression. However, the regulatory elements perturbed by the genetic variants must be identified to fully understand these mechanisms. I propose to develop a computational framework to predict enhancers and their target genes based on genome-wide chromatin and gene expression data in an eQTL study setting. First, a set of high-confidence enhancers in human lympoblastoid cell lines (LCL) will be created from published literature and available databases. A machine-learning algorithm will then be trained based on posttranslational histone modifications, transcription factor binding and DNA sequence conservation at these enhancers. This model will then be used to predict genome-wide enhancers in additional 47 LCLs. Furthermore, data on detected eQTLs and dynamics in gene expression and chromatin variability will be used to associate the predicted enhancers to target genes, thus deciphering the cis-regulatory network around eQTL genes and pinpointing candidate regulatory elements that are perturbed by genetic variants.	Swiss National Science Foundation	Early Postdoc.Mobility	None	None
425	Huldrych Fritz Günthard	University of Zurich	Klinik für Infektionskrankheiten und Spitalhygiene Universitätsspital Zürich	2015-05-01	2018-04-30	HIV-1 Transmission in Switzerland: viral transmission traits, superinfection and drug resistance	This translational research project is a continuation of SNF 130865. We aim to unravel traits of HIV transmission in three conceptually different situations of high clinical relevance: transmission leading to de novo infection (Aim 1), spread of HIV between infected individuals (conferred to as superinfection (SI); Aim 2) and transmission of drug resistant virus (Aim 3). The proposed studies are based on two renowned longitudinal studies with extensive biobanks: The Swiss HIV Cohort and the Zurich Primary HIV-1 infection study (ZPHI). AIM 1. Here we will determine whether specific genotypic and phenotypic viral traits of transmitted/founder viruses (T/F) exist. Characterization of T/F viruses, the earliest virus population that emerges in a newly infected individual, is of high interest as understanding their transmis-sion pathways may open avenues for prophylaxis and treatment. Current data on T/F virus features led to intriguing in-sights, but no definitive picture of genetic and phenotypic traits of T/F viruses has emerged. A limitation of previous studies was that features of T/F viruses had to be compared to unrelated viruses from chronically infected patients as transmitting individuals were in most cases not identified. Here using phylogenetically linked T/F viruses and their transmitters we will be able to study phylogenetically linked transmitter-recipient pairs. Thus far we identified 79 acutely HIV infected (recipients) and 107 chronically infected individuals with genetically related HIV strains which are their likely transmitters. Plasma samples close to estimated time of infection will be chosen for virus genomic analysis from transmitters and recipients to retrieve full length HIV-genomes employing Next Generation Sequencing (NGS) followed by haplotype reconstruction. T/F virus will be compared to variants present in the transmitter regarding, length, specific mutations, deletions/insertions, glycosylation sites, charge and frequency to define whether stochastic or non-stochastic transmission occurs. If genotypic traits are identified, gene transfer and mutagenesis experiments will be performed followed by phenotypic analysis to discern if indeed signifying characteristics of T/F viruses exist. To this end we will compare transmitter and T/F viruses for features implicated in shaping transmission including replication capacity, sensitivity to neutralizing antibodies and entry inhibitors, entry kinetics and interferon sensitivity. AIM 2: Here we will systematically explore frequency and risk factors for HIV-1 superinfection in the SHCS and ZPHI. A first phylogenetic screen based on pol sequences has revealed 150-312 potential SI cases. By retrieving longitudinal plasma samples before patients went on antiretroviral therapy we will seek to confirm SI by full length NGS and define approximate time points of SI events. In a detailed virus genomic analysis we aim to reconstruct haplotypes, study recombination events. A specific emphasis of our studies is on determining risk factors for acquiring SI using detailed patient, disease and host genomic data available. Viral fitness of initial circulating and superinfecting strains will be computed using machine learning techniques. To test whether SI is prevented by neutralizing antibody responses, those will be compared among superinfected and non-superinfected individuals. Finally, viral setpoint of cases and controls will be compared to determine the impact of SI on disease progression. AIM 3: Here we will investigate transmission of HIV-1 drug resistance mutations (TDR) within the SHCS, specifically focussing on the non-B compared to the subtype B epidemic, newer drugs, and reversion rates of TDR. We will study TDR prevalence over time for B and non- B subtypes in all drug naives and, specifically, in recently infected individuals. We will particularly focus on newer drugs. In patients with TDR we will determine reversion rates for specific TDR and fitness cost by taking into account the pol genotypic backbone indepen-dently of TDR. Furthermore, by performing phylogenetic analysis we will study whether there are differences in transmission dynamics between B- and non-B subtype TDR. This analysis will reveal whether TDR in the non-B subtypes is increasing as would be expected due to the recent, wide spread roll out of antiretroviral drugs in developing countries.	Swiss National Science Foundation	Project funding (special)	834000.0	CHF
426	Jan Gralla	University of Berne	Institut für Diagnostische und Interventionelle Neuroradiologie Inselspital	2017-10-01	2020-09-30	Stroke treatment goes personalized: Gaining added diagnostic yield by computer-assisted treatment selection (the STRAY-CATS project)	Stroke is the second most frequent cause of death and a major cause of disability in industrial countries: in patients who survive, stroke is frequently associated with high socioeconomic costs due to persistent disability. In clinical practice, advanced neuroimaging techniques are increasingly employed for a quick, reliable diagnosis and stratification for therapy. Tissue-at-risk estimation is frequently performed by MRI, with the infarct core being identified as an area of restricted diffusion on diffusion-weighted magnetic resonance imaging (DWI-MRI). The surrounding severly hypoperfused and potentially salvageable tissue tissue (i.e. the “penumbra”) is characterized by its delay in arterial transit time using perfusion-weighted MRI. The clinical image interpretation is routinely performed as a visual analysis done by neuroradiologists and/or neurological stroke experts.There is class I evidence that intravenous thrombolysis is a safe and effective therapy within an estimated time frame of 4.5 h after stroke onset. Very recently, four prospective studies demonstrated the superiority of mechanical thrombectomy in proximal vessel occlusions within a time frame of 6 h after stroke onset. Mechanical thrombectomy has thus become the treatment option of choice to achieve an early and sustained revascularization of proximally occluded vessels in specialized stroke centres2. The recent advent of mechanical thrombectomy has now raised an urgent question that needs to be answered: “can we predict advantageous tissue survival if mechanical thrombectomy is successfully applied compared to the natural course of disease in the presence of sufficient vs. insufficient collaterals?” The availability of a safe, reproducible and reliable information about the expected tissue salvage would allow not only to select patients that would benefit from mechanical thrombectomy, it would further allow to select patients for revascularization in a time window that exceeds 6 h if sufficient collateral flow enables sustained tissue survival. It is essential that indicators for further success of endovascular therapy can be calculated as soon after admission as possible, in order to save as much of the brain tissue as possible: '*time is brain*'. Computer-assisted and automated tissue segregation of the infarct core and salvageable penumbra using compound information from multimodal MRI offers a novel and robust standardized solution to this problem: while simple thresholding based on perfusion and diffusion imaging provide only a crude estimate of the tissue at risk, machine-learning approaches based on multimodal MR data overcome the limited accuracy of linear analyses. The proposed machine-learning approach incorporates thus two separate goals, i) to quantify penumbral collateral flow in the acute emergency setting and ii) to identify fingerprints that disentangle salvageable vs. non-salvageable tissue based on machine learning in a “big data” approach based on multiparametric imaging. We will provide means for i) by transforming the interpretation of image features into an interpretation of the underlying stationary flow field. This will allow us to combine information of all available MR imaging data, to quantify the collateral blood flow in the individual patient before and during intervention, and to compare 4D flow patterns at a population level. We will ii) build on our existing predictive models of stroke outcome, incorporating FLAIR and SWI maps and making use of the 'big data' that have been acquired during the last years in more than 1000 patients that underwent intraarterial thrombolysis or thrombectomy. Our overall goal is to investigate if, given sufficient training data, predictive maps of the infarction can improve on the current 'penumbra' concept as a tool for identifying patients who will have a favourable response to reperfusion therapy.	Swiss National Science Foundation	Project funding (Div. I-III)	474000.0	CHF
427	Kerstin Jost	Other Hospitals	None	2017-06-01	2017-07-31	NEWS - Newborn Early Warning Signs	Sepsis and meningitis are major causes of morbidity and mortality in theneonatal population. Despite vigilant clinical assessment of infants in the neonatalintensive care unit (NICU), diagnosis of sepsis and necrotizing enterocolitis (NEC) oftendoes not occur until an infant has significant hemodynamic compromise. Analysis of heart rae variability becomes more and more relevant in predicting outcomes over short and long time. Thus decription of apnea, bradycardia and desaturation (ABD-events) are of major importance to predict future potentially life-threatening events. Combining biomarker screening with predictive monitoring of physiologic markers for assessing risk of sepsis or NEC and for detection of early-stage illness could prevent progression to severe illness and shock.The neonatal intensive care unit's database for surveillance and storage ofcardiorespiratory parameters (Clinisoft®), allows us to prospectively characterizedevelopment of ABD-events over time.To examine the contribution of infection, acute and chronic inflammation, indevelopment of cardiorespiratory dysfunction there are ongoing prospective studies ofterm and premature infants at the NICU and paediatric intensive care units at the Karolinska University Hospital Solna. There cardiorespiratory recordings (Clinisoft®) of ABD- events are correlated with routine inflammatory biomarkers & medical records. We then further examine how physiomarkers (ABD-events) & biomarkers may act as Newborn Early Warning Signs (NEWS) for infection, inflammation and need for increased therapeutic interventions. In this project, our objective is to develop machine learning based methods for using low frequency labeled data (Clinisoft) in conjunction with the high frequency unlabeled data. Using pattern recognition we develop better physiomarkers (cardiorespiratory indexes) as NEWS that will help to predict short-term outcome and enable rapid therapeutic interventions.	Swiss National Science Foundation	International short research visits	6300.0	CHF
428	Matthias Guckenberger	University of Zurich	Klinik für Nuklearmedizin und Radiotherapie Universitätsspital Zürich	2017-08-01	2020-07-31	Radiomics as biomarker in multi-modality treatment of locally advanced non-small cell lung cancer	Radiomics is defined as the use of quantitative image analysis algorithms for calculation of a comprehensive set of image phenotypes also called image biomarkers. In contrast to conventional radiological image analysis, this methodology is a) objective and observer-independent and b) allows for a comprehensive description of all available information within medical images. Radiomics is therefore considered as a potential addition to the efforts currently undertaken in the field of precision medicine: to achieve a comprehensive analysis of the cancer phenotype in order to adjust the treatment to the patient-individual cancer characteristics.The aim of this project is to establish and to use comprehensive radiomics analyses in CT and FDG-PET images for outcome modelling. Prior to all image analyses, the radiomics algorithms will be evaluated regarding their robustness against non-standardized image acquisition and image reconstruction parameters. In addition, a model for quantification of loco-regional tumor spread will be established and its prognostic and predictive value will be compared to the conventional staging system. Machine learning algorithms will be established to correlate the large amount of radiomics biomarkers with clinical outcome parameters. The radiomics methodology will be tested based on images acquired within the randomized SAKK 16-00 study of multi-modality treatment for locally advanced non-small cell lung cancer (NSCLC). Radiomics biomarkers of pre-treatment CT and FDG-PET images, or post induction therapy images and changes of radiomics parameters between these two time points will be analysed. Radiomics parameters will be correlated with available histo-pathological tumor characteristics, primary (event-free survival) and secondary (overall survival, response to induction therapy, failure pattern, pulmonary toxicity) study endpoints.It is the hypothesis, that radiomics analyses will enable us to build better and more accurate prognostic models than the ones currently based on the TNM system as well as predictive models for identification of patients, who might benefit from neoadjuvant radiochemotherapy instead of neoadjuvant chemotherapy, only.The radiomics methodology and the machine learning algorithms will be evaluated in cancer patients suffering from NSCLC, a disease with currently very poor prognosis. It is planned to evaluate radiomics and the machine learning algorithms in other cancer sites as well. Additionally, the application of radiomics and the machine learning algorithms are not restricted to Oncology but can maybe successfully used in other medical questions.	Swiss National Science Foundation	Project funding (Div. I-III)	427191.0	CHF
429	Avinash Ramyead	Brain Imaging and EEG Laboratory San Francisco VA Medical Center University of California, San Francisco	Brain Imaging and EEG Laboratory San Francisco VA Medical Center University of California, San Francisco	2016-03-01	2017-08-31	Neural Oscillations as Predictors of Psychosis	Aims:This study will attempt to predict the transition to psychosis on a landmark sample whose size is unmatched by any other study in the world. The study design of the North American Prodrome Longitudinal Study 2 (NAPLS-2) allows to investigate brain activity in clinical high risk (CHR) individuals longitudinally (repeatedly over time) and observe whether the anomalies identified at baseline worsen over time thereby leading to psychosis. Owing to the rich and varied set of experimental paradigms assessed in NAPLS 2, the proposed project will allow identifying neurophysiological paradigms that are most sensitive to conversion to psychosis. These paradigms could subsequently be selectively implemented in early detection clinics in Switzerland.Methodology:We will assess 242 Healthy Controls (HC), 199 CHR individuals who did not convert to psychosis (CHR-NP) and 72 CHR individuals who converted to psychosis (CHR-P) on three different EEG paradigms collected as part of NAPLS-2. NAPLS-2 is a consortium of eight universities (including prestigious universities such as Harvard, Yale and UCLA) with the largest CHR sample in the field and allows for advanced analyses and statistical power that cannot be performed in single-site studies. In particular, we will assess neural oscillations during the (1) visual and (2) auditory oddball paradigms, along with the (3) mismatch negativity response. Analyses will include: assessing neural oscillations using time-frequency analyses, phase locking value, and lagged phase synchronization across frontal and temporal regions. We will also make use of advanced machine learning algorithms (artificial intelligence) to identify multivariate patterns of brain activity predictive of transition to psychosis.Hypotheses:•Compared to both CHR-NP and HC, CHR-P individuals will demonstrate altered theta activity during both the P3a and P3b response during context-updating processes elicited by oddball target and novel stimuli.•During the P3a and P3b response, CHR-P individuals will have reduced frontal-temporal phase synchronization of theta neural oscillations compared to both CHR-NP and HC due to lower grey matter volume in both of these brain regions.•The auditory oddball paradigm will yield markers more predictive of conversion to psychosis than the visual oddball paradigm.•Compared to both CHR-NP and HC, CHR-P individuals will demonstrate lower early theta activity during the MMN response that will be associated with lower MMN amplitude.•Following the deviant tone, CHR-P individuals will have reduced frontal-temporal phase synchronization of theta neural oscillations compared to both CHR-P and HC due to lower grey matter volume in both of these brain regions.•In CHR-P and CHR-NP individuals, aberrant frontal-temporal phase-synchronization and lower theta oscillations following deviant stimuli in the MMN paradigm will be associated with psychotic symptoms and neuropsychological deficits.•Variation in brain structural (acquired via MRI) and functional data (acquired via EEG) among CHR individuals will be predictive of the individualized transition to psychosis.Expected value of the project:Currently in Switzerland, about 32,000 people are affected by schizophrenia and the average cost per patient has been estimated to be about EUR 39,000 in the year 2012 alone. Therefore, the early detection of psychosis potentially leading to enhanced treatment approaches will not only benefit the national economy in the long run but also help the patients and their families to get ready for a possible transition to psychosis. An early detection could allow for an early intervention, that is, the patients could undergo mild treatments such as a psychological intervention or administration of low-dosage antipsychotic medication. This study is unique as it is the first to investigate, repeatedly over time, a rich and varied set of experimental paradigms on the largest sample of CHR individuals worldwide. The main findings could help clarify whether brain abnormalities identified at baseline worsen overtime and allow for the individualized prediction of transition to psychosis.	Swiss National Science Foundation	Early Postdoc.Mobility	None	None
430	Reinhard Furrer	University of Zurich	Abteilung Veterinär Epidemiologie Vetsuisse-Fakultät Universität Zürich	2012-01-01	2015-07-31	Developing Bayesian Networks as a tool for Zoonotic Systems Epidemiology	A primary objective of many zoonotic epidemiological studies is to investigate hypothesized relationships between covariates of interest, and one or more outcome variables, through analyses of appropriate data. Typically, the biological, epidemiology and behavioural processes which generated this data are highly complex, resulting in multiple correlations/dependencies between covariates and also between outcome variables. Standard epidemiological and statistical approaches cannot adequately describe such inter-dependent multi-factorial relationships. Bayesian Network (BN) modelling is a generic and well established data mining/machine learning methodology, which has been demonstrated in other fields of study to be ideally suited to such analyses. The accessibility, however, of this methodology to epidemiologists is severely limited due to the sheer breadth and diversity of zoonotic epidemiological data, which is outside the established application areas of BN modelling. Two key challenges exist, one technical and one epidemiological. Firstly, no appropriate software exists for fitting the types of BN models necessary for analysing zoonotic epidemiological data, where complexities such as grouped/overdispersed/correlated observations are ubiquitous. This project will develop easy-to-use software to allow ready access to BN modelling to epidemiological practitioners, which is essential in order to make the crucial transition from merely a technically attractive methodology, to an approach which is actually used in practice. Secondly, to demonstrate and promote the use of this methodology in zoonotic epidemiology, relevant and high quality exemplar case studies will be developed showing objectively, situations in which BN models can offer the most added value, relative to existing standard statistical and epidemiological methods. Through the project's collaborators a diverse range of zoonotic data are available for analyses, including cross-sectional and longitudinal studies of antimicrobial resistance in Escherichia coli in farmed pigs in Canada, along with a wide range of different parasite field studies including Echinococcus multilocularis, Taenia, Mesocestoides, Uncinaria and Toxocara collected across eastern Europe and central Asia. This project will deliver a range of peer-reviewed publications comprising both methods orientated papers, and pathogen focused studies. The final deliverable of the project will be to provide a valuable addition to the quantitative skills base within veterinary science, by providing PhD level training in applied computational epidemiology of direct relevance to both zoonotic and animal disease research.	Swiss National Science Foundation	Project funding (Div. I-III)	193569.0	CHF
431	Susanne Wegener	University of Zurich	Neurologische Klinik Universitätsspital Zürich	2017-09-01	2021-08-31	Predicting outcome after stroke: take a look at the other side	Despite improvements in primary prophylaxis and acute recanalization treatments, stroke remains one of the leading causes of death and disability worldwide. In order to achieve the best outcome possible for the individual patient, therapies have to be administered rapidly. However, the longer the time from symptom onset, the lower the efficacy and the higher the risk of treatment side effects. Although brain imaging is the mainstay of acute stroke diagnostics, current imaging strategies that aim to predict therapeutic success or failure in acute stroke patients remain insufficient. Here, we propose a novel prediction approach that is based on immediate and long-term vascular adaptations affecting the contralateral side of stroke. From data obtained through animal models of stroke and imaging in patients with proximal vessel occlusions, contralateral cerebral blood flow (CBF) appears to be particularly suited to predict clinical benefit from recanalization therapies. Contralateral CBF and related perfusion parameters may indicate the ability of the individual to withstand longer durations of ischemia. In the experimental part of the project, we will use a thrombin-injection stroke model that does not artificially impact collateral supply. Reperfusion will be achieved through intravenous injection of recombinant tissue plasminogen activator (rtPA). To assess CBF and ischemic tissue damage, repeated magnetic resonance imaging (MRI) combined with positron emission tomography (PET) will be performed during ischemia, after reperfusion and in the chronic phase of stroke along with behavioral assessments. In the same stroke model, processes influencing CBF on the microvascular level will be directly observed using advanced optical imaging methods. Structural adaptations of the microvascular bed as well as gene and protein expression profiles contralateral to stroke will be analyzed in brain samples. In the clinical part of the project, we will analyze stroke patient imaging data in relation to clinical outcome. In addition to a traditional region-of interest (ROI) based analysis we will apply a novel, “unbiased” machine learning algorithm to extract relevant outcome predictors from patient imaging data.Using a translational approach we aim for a mechanistic characterization of the concept of contralateral flow changes in stroke, and will generate and apply imaging predictors to clinical patient data. With the multidisciplinary study proposed here, I envision i) to deepen the understanding of the basic mechanisms regulating brain perfusion after ischemic stroke, and ii) to improve therapeutic decision-making in acute stroke patients.	Swiss National Science Foundation	SNSF Professorships	1509881.0	CHF
432	Tilo Gschwind	Department of Neurosurgery Stanford University	Department of Neurosurgery Stanford University	2017-11-01	2019-04-30	Behavioral Biomarker for Temporal Lobe Epilepsy	The mechanistic bases of temporal lobe epilepsy (TLE) are not well understood. A major impediment to progress towards evidence-based, rigorous preclinical, translational research into the TLE is that the experimental approach often requires labor-intensive 24/7 video-EEG monitoring of seizures and rests on the inherently subjective scoring of behavioral seizure phenotypes by human observers along the Racine scale.The aim of the proposed research is to explore the transformative potential of state of the art machine learning (ML)-assisted 3D video analysis to phenotype mice with acquired epilepsy in an automated and high-throughput manner (Aim 1) and to correlate TLE-specific neuronal circuit activity with subtle behavioral dynamics that are not captured by current technology (Aim 2). The central idea rests on the discovery that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales that are arranged according to specific rules (“grammar”) that can be detected without observer bias by a combined 3D imaging (Kinect™) and ML method. The ML-assisted 3D video analysis technology will be adopted for epilepsy research to test if there are TLE-specific behavioral syllables and associated transition probabilities that might not be discernable by a human observer. In addition, it will be determine if behavioral syllables in chronic TLE are invariant between animal models of TLE. In order to comply with current standards of research into TLE, the presence or absence of TLE will be determined using conventional 24/7 video-EEG (vEEG) recordings and analysis. Synchronous acquisition of vEEG and 3D video will be used to assess if aberrant neuronal network activity is associated with the expression of specific behavioral syllables. Intervene upon local seizures or interictal spikes using closed-loop optogenetics will help to verify if these TLE-specific behavioral syllables are related to the certain hippocampal ensemble activity.	Swiss National Science Foundation	Early Postdoc.Mobility	None	None
433	Dr James Cole	University College London	Computer Science	2019-10-07	2021-03-31	Modelling brain ageing using neuroimaging to improve brain health in older adults	Older age is associated with cognitive decline, decreased well-being and increased risk of neurodegenerative disease and dementia. Fostering healthier 'brain ageing' would benefit for society by reducing these risks. However, the factors that specifically affect the brain are uncertain and brain ageing does not affect people uniformly. Hence, I have developed a neuroimaging-based biomarker of brain ageing, that quantifies individual deviation from healthy brain ageing; brain-predicted age difference (brain-PAD). I have shown that brain-PAD relates to cognitive performance, the presence of neurological disease and predicts future cognitive decline and dementia. Brain-PAD also relates to physiological ageing and predicts mortality risk in older adults, showing its utility as surrogate measure of future neurological and general health. Here, I will use brain-PAD to identify the genetic and environmental factors that influence brain ageing. This will provide mechanistic insights into causes of poor brain health and inform clinical efforts to promote healthier brains as people age. I will achieve this by measuring brain-PAD in the UK Biobank. This unprecedentedly large study currently includes high-resolution, multi-modality neuroimaging data from over 19,000 adults aged >40. Using the detailed demographic, behavioural, physiological, medical and genetic information collected from this cohort, I will: 1) Identify personal (age, sex), lifestyle and environmental (e.g., diet, smoking) factors that correlate with brain-PAD. 2) Determine genetic factors relating to brain-PAD, resulting in a polygenic risk score for brain ageing. 3) Explore gene-environment interactions in relation to brain-PAD, moving towards personalised risk assessments for poorer brain health during ageing. 4) Design a machine-learning software tool for estimating brain-predicted age at a regional level or in different components of brain structure and function.	Medical Research Council	Fellowship	113938.0	GBP
434	Dr Sylvane Desrivieres	King's College London	Social Genetic and Dev Psychiatry Centre	2019-09-01	2022-08-31	Establishing causal relationships between biopsychosocial predictors and correlates of eating disorders and their mediation by neural pathways	This project aims to identify early biomarkers of eating disorders (EDs) by applying Big Data methods to the rich database derived from a representative population of adolescents and a clinical sample of emerging adults with a current or previous ED diagnosis. First, we investigate causality of ED risk factors in the IMAGEN population cohort of n=2000 male and female adolescents followed-up at ages 14, 16, 19 and 23 years. We will investigate how biopsychosocial correlates and environmental risk factors such as adverse life events will influence these relationships and how their effects may be mediated by alterations in neural networks. Next, we will use machine learning procedures based on cross-validated regularised logistic regression combining neuroimaging, genomic and psychometric data modalities to identify correlates of EDs and select the features that best classify individuals who endorse ED symptoms along with those who endorse no ED symptoms at any time point. To identify predictors of ED symptoms, we will use age 14 IMAGEN data to compare individuals who developed ED symptoms over time (symptoms absent at age 14 but present at later ages), or those who recovered (symptoms present at age 14, not at later ages) to those who never developed symptoms. Finally, we will select the most predictive and easily applicable components of our comprehensive profile for validation in a clinical sample. These will be patients aged 18-25, with a 1st episode of DSM-5 AN or BN at first assessment (baseline) and followed-up with a second (after 2-years) assessment as well as patients fully recovered from a AN or BN diagnosis (n = 50 /diagnosis). All groups will be assessed through standardised protocols in a way identical to IMAGEN. This paradigmatic multimodal approach, in which neuroimaging may provide added value compared with the existing standard assessments, may yield potential application for early and differential ED diagnoses.	Medical Research Council	Research Grant	507739.0	GBP
435	Dr Alastair Droop	University of Leeds	School of Medicine	2018-02-14	2019-04-07	Facilitating Deep Learning with Domain-Specific Knowledge	Although a good conceptual fit, current methods in deep learning do not perform particularly well on biological data. One reason for this is the paucity of samples: we simply do not have enough data to train a neural network of sufficient size or complexity to learn the intricacies of our input datasets. Although we have many fewer biological samples, we have a much richer understanding of the underlying structure of the observations, as we have extensive prior knowledge about the interactions between genes. I am planning to use this rich prior knowledge to enhance the efficiency of the training process in two ways: 1) Appropriate data embedding A common technique in ML is to transform the input data into a form that is easier for the neural network to train upon (embedding). For example, high-dimensional data could be reduced using PCA to a lower dimensional form before use, thus removing unnecessary noise before training. I propose to develop similar methods using the large body of expertise in transcriptomic data analysis in Leeds to define suitable embedding strategies for preprocessing the input datasets. 2) Biologically appropriate network topologies A standard neural network consists of several hidden layers of neurones connected (both inside and between layers) in a regular manner. I propose a similar approach to learning gene expression analysis in which we use the vast amount of prior knowledge available in online repositories (such as the Gene Ontology, KEGG and String) to build intermediate neural network layers that model the known biological pathways and interactions in the data. This way, the ML approach does not need to learn these already-known interactions.	Medical Research Council	Fellowship	286050.0	GBP
436	Dr DAVID HUGHES	University of Liverpool	Institute of Translational Medicine	2017-11-15	2020-11-14	Variational Approximation Approaches for Efficient Clinical Predictions	Methodology Development: The project will involve four distinct stages. In the first 9 months of the fellowship I will derive MFVB approximations for MGLMMs. Current MFVB methods for mixed models only consider a single longitudinal marker. I will derive the MFVB approximations for continuous, binary and count longitudinal variables when jointly modelled in a MGLMM. During months 9-21 of the fellowship I will derive MFVB approximations for joint models of multiple longitudinal markers of different types and time-to-event data. I propose using the MGLMM methodology developed in Stage 1 and combining it with a proportional hazards model (as is standard in joint modelling). I will derive the approximations to the hazard model in order to approximate the full likelihood. I will perform substantial assessment of the utility of the MFVB methods I develop. Specifically I will assess (i) the accuracy of the model parameter estimates compared to alternative joint model methodology (MCMC or frequentist approaches), (ii) the speed of model fitting (iii) the gain in fitting models to large datasets compared to using only a small subsample of the patients. The performance of the MFVB joint model will assessed using various real datasets including both large and smaller datasets and through rigorous simulation analysis. Months 22-30 of this fellowship would be used to derive dynamic predictions from the multivariate joint models derived in the previous Workstage. This will allow dynamic predictions of a patient's risk of experiencing an event that can be updated each time new information is available. Software Development: The final 6 months of the fellowship will be used to develop user friendly code to fit the models developed during the first 3 stages. I will create functions in R to calculate MGLMMs and multivariate joint models as well as functions to assess predictive accuracy and graphically represent the predictions. These functions will be freely available R package.	Medical Research Council	Fellowship	257981.0	GBP
437	Dr Emmanouela Repapi	University of Oxford	Weatherall Inst of Molecular Medicine	2018-04-01	2022-10-28	Novel methods for the integration of high dimensional single cell proteomic and RNA data to understand cell populations in development and disease.	A methodology will be developed for the integration of single cell RNA-Sequencing (scRNA-Seq) and CyTOF data using novel machine learning techniques. I will be using an autoencoder, a technique that is widely used in machine learning, to extract the structure of data from populations of cells analysed with both technologies. In more detail, I will be using the python library TensorFlow, which is one of the most commonly used tools for deep learning, to analyse in parallel the scRNA-Seq and CyTOF data and use the data structure from each to disassociate cell heterogeneity from technical variability. In addition, this approach will ensure that the right normalization has been performed and will take into account batch effects arising from the different technologies, and potentially also from the experimental design. It is important to note that cell populations observed in one of the two technologies will also be reported separately to account for biological variation between transcriptomics and proteomics data. This approach is subsequently going to be used 1) to identify cell subpopulations and 2) to study cell fate in differentiation processes. The data will be acquired from collaborations in the WIMM and I will be working closely with the groups that have produced it to ensure accurate interpretation. Finally, I will be creating a visualisation tool to facilitate the interpretation of the results by both computational and bench scientists. I plan to use WebGL, which allows the use of 3D graphics in web pages with increased speed for data heavy applications. This approach will enable the visualisation of millions of cells. This will be implemented using python packages such as Plotly and Vispy, which can help create a WebGL application from python objects.	Medical Research Council	Fellowship	326906.0	GBP
438	Dr Jacqueline Scholl	University of Oxford	Experimental Psychology	2016-07-01	2021-06-30	Understanding the neural and cognitive mechanisms of attributional styles and credit assignment in depression	Depression is the most common mental illness. In the past, depression has been linked to negative biases in perception, attention or memory. In particular, cognitive theories of depression have suggested negative attributional styles as the root cause of depression. However, the cognitive and neural mechanisms underlying this are not yet known. Recent advances in computational cognitive neuroscience have put forward quantitative descriptions of credit assignment, i.e. learning about the causes of events. I propose to investigate the cognitive and neural mechanisms of different aspects of credit assignment and test whether it can be used to provide an account of neural activity and behaviour associated with attributional styles in depression. I will compare the behaviour of depressed patients with non-depressed participants and measure the neural mechanisms associated with the behaviour. The experiments I propose, focus on 1) how positive or negative events are attributed, to either to the self, environmental features or remain unassigned, 2) how attributions are made to the self or other people and how this information influences social decisions, 3) how emotional responses (as opposed to simpler, more concrete outcomes) are attributed, and how they might, if they unattributed or incorrectly attributed, interfere with other behaviours. To address these questions, I will combine approaches from cognitive neuroscience and psychology. To characterize the behavioural effects, approaches will include computational modelling using approaches from machine learning, Bayesian optimal learning theory and hierarchical modelling. The neural mechanisms and changes in depression will be probed using computational analyses of functional magnetic resonance imaging (fMRI) data involving modelling and pattern classification techniques. The causal involvement of the areas identified using fMRI will be further probed using transcranial direct current stimulation (tDCS).	Medical Research Council	Fellowship	460831.0	GBP
439	Ms Esra Suel	Imperial College London	School of Public Health	2018-02-14	2021-02-13	Application of deep learning to heterogeneous open data for measuring urban environment and health	Recent advances in deep learning methods have achieved unprecedented improvements in accuracy on multiple visual tasks such as object recognition and classification. While previously unused large-scale data is gaining importance in public health research, recent technical developments mostly focused on advanced spatial machine learning and statistics methods while integration of deep learning techniques have been largely unexplored. The overall goal of my fellowship research is to leverage these advanced methods to answer important questions in environment and health research. Specifically, convolutional neural networks will be trained using satellite and street view imagery to extract outcomes of health and its environmental/social determinants. Transfer learning and class specific saliency maps will be used for post-hoc model visualisation. A combined analysis of models trained for multiple outcomes will be conducted to study overlaps and deviations. Secondly, joint use of mobile phone and image data as predictors will be explored for improving model performance. New methods of data integration will be developed to enable the use of multiple big data sources as predictors in a unified modelling framework. Finally, transferability of deep learning models trained on data from one city to other geographies will be evaluated; adaptation techniques to facilitate transferability will be explored.	Medical Research Council	Fellowship	331573.0	GBP
440	Dr Honghan Wu	University of Edinburgh	Centre of Population Health Sciences	2018-02-14	2021-02-13	Deriving an actionable patient phenome from healthcare data	For objective 1, at the data layer, my research will focus on a semantic phenome model that is able to detect/correct erroneous and inconsistent phenotypes, associate accurate contextual and temporal information with each phenotype mention and also support rule based reasoning to complete missing data. For objective 2, I will be devising and applying artificial intelligence models to derive unknown clinical knowledge from large scale, longitudinal and interlinked phenome data. potential use cases include predicting outcomes of septic shock treatments within intensive care units; predicting unknown adverse drug reactions in depression patients with comorbidities; subtyping atrial fibrillation to deliver tailored care. For objective 3, my research will provide actionable suggestions in clinical settings with applications of clinical trial recruitment and automated alerting for ensuring patient safety. Key challenges to be tackled here include how to make action suggestions explainable and reliable. This project aims to deliver enabling technologies for The University of Edinburgh's HDR UK focus including deriving and applying health-related phenotypes at scale; computational tools for genetic and environmental risk prediction and causal inference. It will develop national leadership, partnerships, and interdisciplinary skills and capacity through the development of semantic computation infrastructure on top of deep and accurate patient phenome data, which if successful, can be disseminated to a wide range of healthcare service providers nationally/internationally and achieve high impact in research and patient care.	Medical Research Council	Fellowship	315181.0	GBP
441	Dr George Gordon	University of Cambridge	None	2017-04-01	2019-03-31	Shedding light on cancer using nanoplasmonic metapixels	Background: Histopathology of biopsied tissue is the gold standard for diagnosis and grading of most cancers but the biopsy process is traumatic, introduces delays and is not practical for widespread early screening. Advanced optical imaging modalities hold promise for faster and less invasive methods of diagnosis, grading and precision treatment of cancer, particularly for early detection and surgical tumour margin identification. Examples include fluorescence imaging, Raman spectroscopy and polarimetric imaging. Each modality interrogates a different set of tissue properties and provides limited discrimination, but when many of these are combined, a multimodal approach, high diagnostic accuracy is achieved. This is typically achieved in a research setting, as several instruments can be applied sequentially, but in routine clinical practice this introduces unacceptable costs in terms of the instruments needed and procedure time. Further, movement occurring between changes of modality makes co-registration of images inaccurate, limiting the ability to overlay multiple tissue properties for augmented real-time vision. Aims: We propose to develop a unified multimodal optical imaging paradigm that can control all properties of light: wavelength, spatial profile, polarisation and phase. By activating different properties of illumination light and detector filtering in quick succession, we aim to develop a single system that can be dynamically reconfigured to implement many different types of imaging in a compact, low-cost fashion with high co-registration between modalities. Methods: We plan to construct a prototype using a technology we have recently developed: nanoplasmonic metapixels. A metapixel is a structure built from metal nanostructures that are small enough (~30nm) that their geometry controls the wavelength, polarisation and phase of light. We can make large arrays of metapixels that can be incorporated into existing projectors (for illumination) and image sensors. How the results will be used: A successful prototype demonstration will pave the way for numerous new research avenues and commercialisation opportunities. The reduced time and cost of multimodal imaging could enable larger screening programmes for improved early detection. The highly multimodal co-registered datasets collected could be used to develop advanced machine learning algorithms for improving cancer diagnosis. Finally, the multimodal datasets could be visualised using augmented reality systems for real-time diagnosis and improved surgical tumour resection. There is a strong base of UK companies working on the latter two aspects, creating significant commercialisation opportunities. Together, these advances will lead to improved diagnosis, treatment and hence outcome for cancer patients.	Cancer Research UK	Pioneer Award Committee - Pioneer Award	None	None
442	Dr Anastasia Angelopoulou	University of Westminster	None	2018-10-01	2020-03-31	Automated Diagnostic Toolkit for Dementia in Ageing Deaf Users of British Sign Language (BSL)	Sign languages are natural languages, used by Deaf communities, not derived from or related to the spoken languages of the surrounding hearing communities. They are articulated by the face and body as well as the hands [1] in an envelope of space in front of the signer's body, used for syntactic and semantic purposes. The Deaf population receives unequal access to diagnosis and care for acquired neurological impairments [2,3,4]. Neurocognitive screening designed for signers promises significant progress in detection of impairments. The only existing screening test for this population uses video stimulus material and requires video-recording of responses, and relies on the availability of clinical specialists with fluency in BSL for its administration and interpretation as part of providing a firm diagnosis of dementia [5]. In order to overcome the above limitations, the main objective of the BSL Automated Recognition of Dementia project is to develop and validate an automated screening toolkit for dementia based on machine learning approaches such as pattern recognition and pattern discovery, as well as piloting the mapping between extracted patterns and computational cognitive models (e.g., cognitive maps for spatial memory). These approaches will be based on processing of manual /facial actions [6, 7, 8] in terms of identifying features of the sign space and the facial expressions of BSL users of speakers as a key to identifying dementia. In particular, our approach will rely on secondary data, related with the analysis of sign language, to be used to understand differences in the envelope of sign space and movements of the face (e.g., patients with dementia may use a restricted sign space and limited facial expressions compared to healthy Deaf controls [9]). A training set of individual and age-related variations in the patterns of manual/facial actions of healthy BSL users will be compared against patterns that can be clustered as atypical (e.g., differences in the spatial envelope that defines normal signing behaviour, including differences in facial actions). For this purpose, the planned tests are seeking answers to the following questions: 1. Whether a newly emerged pattern is, indeed, atypical, by considering a) patterns which are not characteristically found in healthy age-matched controls; b) an unusual pattern of signing space and facial expression. 2. Whether such patterns are associated with specific cognitive models of memory, e.g., cognitive maps, indicative of dementia. 3. Whether the training dataset is likely to introduce any algorithmic bias in machine learning.	The Dunhill Medical Trust	Research Project & Programme Grants	65173.09	GBP
443	Dr Ardan Patwardhan	European Bioinformatics Institute	None	2018-10-01	2023-09-30	EMDB: dealing with the cryo-EM data deluge	Decades of research (rewarded with the 2017 Nobel Prize in Chemistry) have led to revolutionary developments in the field of cryo-electron microscopy (cryo-EM), with further improvements underway (phase plates, robotics). The Wellcome Trust and other funders have recognised the importance of cryo-EM and made substantial investments in infrastructure. These developments together cause a vast increase in the amount and diversity of experimental data emanating from molecular and cellular structural studies. EMDB (Electron Microscopy Data Bank), maintained by EMBL-EBI with international partners, is the single global archive of 3D cryo-EM reconstructions. This project will address major archiving challenges caused by the rapid growth of the cryo-EM field. Its aims are: 1. Handling the increasing volume, complexity and diversity of EM data depositions. 2. Data enrichment and validation - by enriching EMDB entries with biological annotations, expanding the volume of biologically-annotated segmentations in EMDB by exploiting crowd-sourcing initiatives and machine-learning techniques and developing and maintaining validation tools and resources for EMDB. 3. Enabling effective use of EMDB data - by developing new and improved web-based resources for searching, analysing and visualising EMDB data and developing tools and resources that facilitate the use of EMDB data by other bioinformatics resources.	Wellcome Trust	Biomedical Resources Grant	1291058.0	GBP
444	Dr Mercedes Bunz	King's College London	None	2019-01-15	2020-07-14	Public data, private collaborator: Will machine learning relocate medical knowledge?	This study focuses on the transformations in the creation and ownership of medical knowledge that result from applications of machine learning (ML). In medical image recognition, ML applications are currently being developed and tested to assist in diagnostics. These developments are often carried out as collaborations between public and private sectors, with public medical institutions providing data and medical domain knowledge, and private technology companies providing ML expertise. However, the algorithms implemented in these tools are typically proprietary, trade secrets that underlie the competitive advantage of the companies that develop and operate them. There consequently limited transparency into and access to the medical knowledge that they generate. This knowledge is thus privatised in the sense that it is encapsulated within closed software that forms part of the IPR of a private company. This study analyses such risks of privatisation and the role of open data in medical research. By comparing cases of ML applications in Ophthalmology, by conducting semi-structured interviews with stakeholders and organising two participatory workshops, the project will examine the role of data ownership and explore measures that allow medical knowledge to be kept in the public realm while still attracting private collaborations for ML applications.	Wellcome Trust	Seed Award in H&SS	57307.0	GBP
445	Assoz. Prof. Dr. Klaus SCHÖFFMANN	University of Klagenfurt	None	2019-04-01	2023-03-31	Surgical Quality Assessment in Gynecologic Laparoscopy	Endoscopic surgeries require specific psychomotor skills that are difficult to learn and teach, and typically result in prolonged learning curves. These psychomotor skills have direct impact on the performance of the surgery, especially in a field with complex operation techniques. In order to assess surgical quality objectively, medical experts currently record the entire surgery on video and inspect and analyze the unedited video footage in a post-operative session for the occurrence of technical errors, according to some standardized rating scheme. Several studies have shown that such post-operative analysis of errors and the reporting of them to the responsible surgeons can significantly improve their performance over time and lead to better surgical quality, especially for young surgeons. However, currently the surgical quality assessment (SQA) process is so tedious and time-consuming that many surgeons/clinicians cannot afford to perform such error ratings, which is very unfortunate since their application would improve surgical quality and patient outcome. The main reason for the high effort is the fact that it is performed without any special error rating software, but with common software video players and manually edited checklists, where surgeons enter timestamps of corresponding relevant scenes in the video. This renders SQA currently not only a very time-consuming process, but also a very error-prone one. In this research project we want to address this issue and find out how we can make surgical quality assessment (SQA) more efficient through automatic video content analysis and, hence, more feasible. More specifically, for the field of gynecologic laparoscopy we want to investigate to what extent current methods of machine learning and content-based video retrieval can support SQA (i.e., optimize the entire process through automatic classification and retrieval of technical errors). For that purpose, we will evaluate deep learning approaches as well as video content description and similarity search. We consider this research project as a pioneering work in the interdisciplinary overlap of computer- and medical science, which will investigate fundamental research questions that should provide the basis for future computer-aided SQA. We expect that our research results will help to significantly facilitate the currently cumbersome and error-prone SQA process, and hence enable more surgeons to actually perform error ratings. We expect this project even to contribute to improve surgical education in the long run (through higher penetration of the SQA process – due to lower time effort), and thereby raise surgical quality itself. Project results and their later application in appropriate software tools could help surgeons to keep track of their surgical actions in a novel, highly efficient way, and thus help them to avoid technical errors. This will not only save valuable time of medical experts and increase the performance of quality assessment, but also contribute to surgical risk management and quality control.	Austrian Science Fund FWF	01 Stand-Alone Projects	388542.0	EUR
446	Prof. Jukka CORANDER	University of Oslo	None	2017-08-01	2022-07-31	Scalable inference algorithms for Bayesian evolutionary epidemiology	Advances in sequencing technologies are currently providing an unprecedented opportunity to a detailed discovery of the mechanisms involved in the evolution and spread of microbes causing human infectious disease. Simultaneously the developers of statistical methods face an enormous challenge to cope with the wealth of data brought by this opportunity. We have very recently demonstrated the ability of our advanced computational approaches to deliver breakthroughs in understanding pathogen evolution and transmission in numerous highlight results published in Science, PNAS and top-ranking Nature journals. The rise of microbial Big Data gives a promise of a giant leap in making causal discoveries, however, the existing statistical methods are neither able to cope with the size and complexity of the emerging data sets nor designed to answer the novel biological questions they enable. To fulfil the promise of giant leaps SCARABEE will leverage scalable inference methods by a unique combination of machine learning algorithms and Bayesian statistical models for evolutionary epidemiology. We focus on central biological questions about adaptation, epistasis, genome evolution and transmission of microbes causing infectious disease. The Big Data combined with the novel inference methods will make it possible to answer a multitude of important questions that remain currently intractable. Through our close collaboration with the leading research centres in infectious disease epidemiology and genomics we expect the SCARABEE project to considerably advance understanding of the evolution and transmission of numerous pathogens that pose a major threat to human health, which will be important for reducing their disease burden in the future. Large-scale biological data will be used to benchmark the developed methods, which will be made publicly available as free software packages to benefit the wide community of microbiologists and infectious disease epidemiologists.	European Research Council	Advanced Grant	2499961.0	EUR
447	Dr Ghaith Aljayyoussi	Liverpool School of Tropical Medicine	Tropical Disease Biology’	2019-01-01	2021-12-31	Development of PK/PD Model Platforms to Support the Optimal Deployment of New Drug Combinations for the Treatment of Malaria	The mathematical prediction of drug combination activity against malaria remains to be a challenging area of research. While previous models have been successful in generating meaningful predictions from pre-clinical single drug activity, the prediction of clinical outcomes from drug combination activity in-vitro and in-vivo has resulted in limited success. This is due to the complex nature of the malaria life cycle and the various mechanisms of action of various drugs within different parts of this life cycle. The variety of disease models used to assess the activity of drugs and drug combinations adds an extra layer of complexity where current standard models are unable to consolidate data of different classes (e.g. metabolic activity in in-vitro and parasite reduction rates in an in-vivo assay). We propose here to develop a novel model that has the ability to consolidate drug activity data from different disease models and that can interpret the drugs' activity within the context of their mechanism of action within the parasite's life cycle. This is categorically different from using standard PKPD combination methods (e.g. Loewe, Bliss or Gaddum non-interaction reference, which are methods that don't account for the presence of several sub populations with different susceptibility to drug action). Additionally, we will use advanced methods of machine learning and artificial neural networks to consolidate the complexity of drug combination activity within different disease models. This will allow for using larger amounts of data to inform clinical predictions rather than being limited to one source of data such as the SCID mouse model. The predictions generated from this model would then be validated against existing clinical data and would be used to generate new drug combination regimens that can potentially be tested in the malaria human challenge model or in naturally infected patients in the future.	Medical Research Council	Fellowship	292947.0	GBP
448	Professor Ben Bridgewater	Manchester University NHS Fdn Trust	None	2019-02-14	2019-12-12	ISCF HDRUK DIH Sprint Exemplar: Using a digital transformation approach to drive improved clinical outcomes for patient with heart failure	Around 2,500 patients in GM with heart failure have implantable devices (pacemakers or defibrillators) which already transmit data onto a cloud platform (including thoracic impedance, arrhythmia burden, percentage of pacing, diurnal heart rate variability and patient activity). Our industry, academic and NHS partners will use an existing algorithm to detect early deterioration in these patients from the data flows. These insights will drive in near real time into a new operating model for treating heart failure at home. The sprint aims to demonstrate improved outcomes for patients and the health economy, by preventing hospital admissions. We will use the data to demonstrate the efficacy of the intervention, and run machine learning algorithms to improve prediction. We will use real world evidence and artificial intelligence (AI) to look for missed opportunities for implantable devices (for both therapeutic and diagnostic purposes) and accelerate the deployment of devices to a wider population suitable for these treatments. Our sprint will deliver a reproducible model for digital transformation to support the life sciences (LS) product lifecycle management processes. City region commissioning in GM (which acts under delegated financial control) is a key partner in our consortium, giving opportunities for rapid scale-up of detected benefits to population and industry benefit.	Medical Research Council	P&Cs	338068.0	GBP
449	Dr. Pascal SCHÖTTLE	Management Center Innsbruck	None	2019-01-01	2021-12-31	Game Over Eva(sion): Securing Deep Learning with Game Theory	The project "Game Over Eva(sion): Securing Deep Learning with Game Theory" aims at finding theoretical foundations for deep learning classifiers robust to evasion attacks. Given the popularity of classifiers based on deep learning, not only in scientific research but also in practice, it is not surprising that recently various vulnerabilities of these classifiers were discovered. The most severe in our opinion is the existence of so-called adversarial examples: slightly modified benign objects that get misclassified with a very high probability and confidence. In terms of adversarial machine learning, these examples constitute so-called evasion attacks. Surprisingly, a soon to be published (at this year’s IEEE Euro S&P conference) Systematization-of-knowledge article by leading researchers in the field of machine and deep learning completely disregards considering the competition between an attacker against a deep learning classifier and its defender from the point of game theory. Game theory is already widespread in many areas dealing with security, even “non-deep” adversarial machine learning. We are very aware of the key difficulty in applying game theory to deep learning, which is to find the right level of complexity of the analytical models such that they are tractable for game-theoretic solution concepts, but at the same time do not degenerate the learning problem to instances that do not require deep networks. Still, we plan to address this research gap in a number of innovative ways: a) by systematizing the knowledge of adversarial machine learning from the game-theoretic point of view, including insights from adversarial classification and adversarial signal processing; b) by identifying how existing approaches, such as adversarial re-training and the detection of adversarial examples, fit into game theoretical concepts; and c) by implementing the key properties of our theoretical findings in practical deep learning classifiers and comparing them in terms of accuracy and robustness to state of the art neural network classifiers. The project is a co-operation between the University of Innsbruck and Czech Technical University in Prague. The Austrian project leader will be Dr. Pascal Schöttle, who specialized in the application of game theory in security-sensitive domains. On the Czech side, Ing. Tomáš Pevny´ Ph.D, and Ass. Prof. Branislav Bosansky, both experienced in game theory, machine learning and network security will lead the project. The project team as a whole has been applying machine learning to security problems for more than ten years and published extensively, among others on game theory and security.	Austrian Science Fund FWF	02 International programmes	354137.49	EUR
450	Univ.Prof. Dr. Philip WALTHER	University of Vienna	None	2019-03-01	2023-02-28	Quantum Information Systems Beyond Classical Capabilities	After two decades of intensive experimental and theoretical research in quantum science, we have now reached a new era of quantum technologies. Several scenarios have been identified for which quantum information processing outperforms its classical analogue. Moreover, various implementations have demonstrated reliable control and operation of around ten qubits. Despite these efforts and advances, we are still very far away from a full-fledged quantum device mastering several thousand qubits. On the road towards such a quantum device, theory and experiment need to work together closely in a joint focused effort to tackle the challenges ahead. The main challenge and thus the main aim for the SFB Beyond C is to identify applications of and methods for quantum information systems beyond classical capabilities. This is the regime of demonstrated quantum superiority – when a quantum device outperforms any classical device for a certain problem class. Our consortium spans the various areas of quantum information science that are required for this task and will apply its theoretical and experimental expertise towards the sub-goals of (i) precise control of up to 20 qubits for quantum computing, (ii) the realization of a quantum simulator using up to 50 qubits, (iii) the operation of quantum secure data processing, (iv) the derivation of new algorithms suitable for medium-size quantum processors, (v) the development and implementation of quantum machine learning protocols, (vi) the realization of hybrid quantumclassical and hybrid quantum-quantum systems, (vii) and the verification and validation methods for medium-sized quantum processors. We will build on three implementation platforms, photons, trapped ions, and superconducting quantum circuits and will combine them as needed to transcend the limitations of any individual one. Experiments using photons will focus on the generation and manipulation of highly entangled multipartite states, and their usage in quantum computation and quantum communication. With trapped ions and superconducting qubits we will realize the medium sized quantum computers, and run the quantum protocols, verification tools, and quantum machine learning algorithms developed by the theory groups. These developments will rely on methods drawn from quantum information, quantum optics and condensed matter physics. Our consortium combines the expertise of seven experimental physics groups led by G. Kirchmair, T. Monz, G. Weihs (University of Innsbruck), Ch. Roos (IQOQI Innsbruck), J. Fink (IST Austria), Ph. Walther (University of Vienna), R. Ursin (IQOQI Vienna) and six theory groups led by J. I. Cirac (MPQ, Garching, Germany), H. Briegel, B. Kraus, W. Lechner (University of Innsbruck), C. Brukner, F. Verstraete (University of Vienna). All of us have made ground-breaking contributions to quantum science in the past and we will apply our joint effort towards laying the basis for future quantum technologies. Beyond C will not only foster the collaboration and synergies among the consortium, but also strongly promote the next generation of researchers and enhance public awareness of Austria’s pioneering role in quantum science.	Austrian Science Fund FWF	03 Special Research Programmes (SFB)	533694.0	EUR
451	Dr Anahid Basiri	University College London	Centre for Advanced Spatial Analysis	2019-05-01	2020-05-31	Indicative Data: Extracting 3D Models of Cities from Unavailability and Degradation of Global Navigation Satellite Systems (GNSS)	3-Dimensional (3D) models of cities are beneficial or even essential for many applications, including urban planning/development, energy demand/consumption modelling, emergency evacuation and responses, lighting simulation, cadastre and land use modelling, flight simulation, positioning and navigation (particularly for autonomous cars in urban canyons and disabled users requiring accessibility), and Building Information Modelling (BIM). Despite the importance of the 3D models, they are not available or being updated frequently for many areas/cities. This can be due to the process of generating and updating (by current technologies such as LiDAR (Light Detection and Ranging)) being computationally and financially expensive, time-consuming, and requiring frequent updates due to the dynamic nature of cities. This fellowship will propose and implement a crowdsourcing-based approach to create accurate 3D models from the free to use and globally available data of Global Navigation Satellite Systems (GNSS). The effects of urban features, such as buildings and trees, on GNSS signals, i.e. signal blockage and obstruction, and attenuation, will help to recognise the shape, size, and materials of urban features, through the application of statistical, machine learning (ML) and artificial intelligence (AI) techniques. The use of freely accessible raw GNSS data, which can be accessed on any current Android device, will enable the production of up to date 3D models at no or low cost, of particular value in developing regions where these models are not currently available. GNSS is the most widely used positioning technique because of free-to-use, privacy-preserving, and globally available signals. However, GNSS signals can be blocked, reflected and/or attenuated by objects, e.g. trees, buildings, walls and windows. While blockage, attenuation and reflection of GNSS signals are common in urban canyons and indoors, making the positioning unreliable, inaccurate or impossible, the affected received signals can act as an indicator of the structure of the surrounding environments. This means, for example, if the signals are blocked or attenuated, then the size and shape of the obstacles or the type of media/material the signals have gone through or been reflected by can be understood. This needs the precise locations of satellites, and the receiver, and also predicted signal strength level at each location and time. The crowdsource-based framework, i.e. a mobile app for data capture and a web mapping application for upload of GNSS raw data, will allow the project to have well-distributed data both in space and time. This will ultimately lead to higher quality (more spatially and temporally accurate, complete, precise) 3D models. However due to the complexity of data, as neither the receiving mobile devices nor the broadcasting satellites are fixed, some novel data mining techniques, based on already existing statistical, ML, and AI techniques, need to be developed during this fellowship. They will handle the high volume, the velocity of change, and the complexity of the spatio-temporal GNSS raw data with high levels of veracity. The spatio-temporal patterns will be used for creating and updating the 3D models of cities at a high level of detail (LoDs), i.e. approximating the façade and the building materials, e.g. windows, from which the signals are reflected or have gone through. The 3D models will feed into 3D-mapping aided GNSS positioning (and integrated with other signals e.g. WiFi) which can ultimately provide more continuous and accurate GNSS positioning in urban canyons and indoors. This fellowship will provide a novel perspective which perceives lack and degradation of data as an "indicative" source of data, which can be re-applied by other disciplines. The success of this fellowship will help me to establish myself as an internationally recognised leader in the area of spatial data science.	Medical Research Council	Fellowship	968363.0	GBP
452	Dr James Lea	University of Liverpool	Geography and Planning	2019-05-01	2023-04-30	Ice sheet and glacier stability in a warming world: Projecting future iceberg and sea level risks via rapid modelling and satellite image analysis	This fellowship will transform our understanding of how the ice sheets and glaciers at both poles will contribute to future sea level change, and anticipate future iceberg risks impacting the people, businesses and governments in these regions. Building on my recent work (Lea, 2018), significant cloud computing resources will be used to facilitate automated analysis of the unprecedented volume of Arctic and Antarctic satellite imagery that is generated every day. This is the first time that analysis at such scales will be undertaken, and would be otherwise unachievable using current glacier monitoring approaches. Using results from this real-time updated analysis, a combination of new physically based and empirically based machine learning models will provide the first global assessment of glacier stability and framework to monitor this. This will allow significant improvements to short (<1 year) and long term (decadal) plans for infrastructure, industry projects and security as Arctic sea ice declines and both poles undergo major environmental changes. These factors are especially important for the UK as it impacts: - The environment and security of UK administered territories in Antarctica and the Southern Ocean. - UK business making informed decisions on future project viability in polar regions, where icebergs pose a major hazard to shipping and infrastructure such as ports, rigs and subsea pipelines. - The anticipated opening of the Northwest and Northeast Passage trade routes, offering UK business opportunities to significantly reduce the length and environmental impact of shipping. The future viability of these routes due to sudden glacier retreat and changing iceberg risks will have major implications for future UK supply chains between the Pacific and Atlantic Oceans. The UN Intergovernmental Panel on Climate Change have highlighted that the stability of marine terminating ice margins is a major uncertainty in global sea level change projections, and by extension iceberg risk. The existing barriers to achieving a global assessment of glacier stability are that: - Current approaches to data collection (even for individual glaciers) can be extremely time intensive. - The considerable computational power required by numerical models of glacier stability limits researchers to exploring only a few potential future scenarios. Consequently only a handful of the 100s-1000s of these glaciers at each pole have been studied in detail, leaving our knowledge of future glacier and ice sheet stability woefully incomplete and poorly constrained. This fellowship's innovative image and stability analyses will directly address these challenges. Ensuring that these novel findings have impact is built in as a key objective of this fellowship. Support from project partners will allow substantial and rarely achievable levels of engagement with the UK Government on objectives highlighted in the Foreign and Commonwealth Office's recent publication 'Beyond the Ice: UK policy towards the Arctic' (2018), including: Projecting global influence; Protecting people and the environment; and Promoting prosperity. Three stakeholder events spanning the fellowship will also allow UK business to directly highlight their key concerns and help direct the generation of data products. These will be designed to allow UK business to make better informed decisions on the viability of ongoing and future projects in the polar regions. Informed decision making relating to infrastructure at key locations is also in the UK's long term interest for the successful development of future trade routes. To this end, a three month placement at the Greenland Government's geoscience consultancy (Asiaq Greenland Survey) and regular trips as part of fieldwork to Greenland's largest city and deepwater port, Nuuk, will allow regular engagement with policymakers and industry at a pivotal location for the future development of the Northwest Passage shipping route.	Medical Research Council	Fellowship	805992.0	GBP
453	Dr Maria Secrier	University College London	None	2019-06-17	2021-06-17	Quantitative evaluation of gene dosage effects in the Ras/ERK and PI3K/mTOR pathways on metastatic transformation of oesophageal cancer	Distant metastases account for ~90% of cancer-related deaths, but our understanding of the determinants of this process is limited. I propose to elucidate early genomic mechanisms that enable cells to acquire a metastatic phenotype, with focus on allelic imbalance resulting from copy number changes and the underlying genomic instability. I have previously characterized the implications of genomic amplifications of receptor tyrosine kinases and downstream pathways (MAPK/ERK/PI3K) in the progression of oesophageal adenocarcinoma, a cancer with frequent metastases and prevalent genomic instability. Recent studies have highlighted similar gene dosage effects in KRAS promoting metastasis in pancreatic cancer, and a more general role for genomic instability in accelerating metastatic spread. This study proposes to explore the involvement of such alterations in local invasion in oesophageal adenocarcinoma using whole-genome and RNA sequencing data from primary tumours of this type. I aim to: (1) characterize gene dosage effects and co-dependencies at genomic/transcriptional level in the Ras/MAPK and PI3K/AKT pathways; (2) understand the mutational processes generating such alterations; (3) employ machine learning to identify features in 1) and 2) that are predictive of cellular invasion in this cancer. This integrated framework will highlight pathway vulnerabilities during metastatic onset that may be targetable in the clinic.	Wellcome Trust	Seed Award in Science	99983.0	GBP
454	U-FLOOR TECHNOLOGIES LTD	U-FLOOR TECHNOLOGIES LTD	None	None	2021-06-17	OptimisAir - Air quality control combined with behaviourial science	Occupants' daily activities make up 35% of the factors leading to indoor air-pollution  [UCL,2018 ]. In the face of COVID-19 we are expecting people to spend much more time in their homes which has two serious knock-on effects: 1) occupants experience longer exposure to indoor pollutants, increasing the risk of respiratory illnesses; 2) Poor IAQ is linked to COPD, asthma, stroke & heart diseases -- all of which are underlying health conditions, increasing the risk of severe illness from covid-19, putting further pressure on the NHS. To address this challenge we are now developing OptimisAir: an integrated 'Indoor air quality management system' that helps Registered Social Landlords reducing their maintenance costs through automated airflow control combined with AI-based activity-recognition and nudge-techniques to reduce the root cause of poor indoor air quality. It uses IoT-enabled sensors to monitor indoor pollutants and utilises game-changing technologies (machine-learning, activity-recognition, 'nudge'/behavioural sciences) to tackle an age-old problem: poor indoor air quality, dampness and draughts in homes. The outcome of the project creates a novel, patented system at an extremely competitive cost.	UK Research and Innovation	Research Grant	49703.0	GBP
455	ELECTRONIC MEDIA SERVICES LIMITED	ELECTRONIC MEDIA SERVICES LIMITED	None	None	2021-06-17	Conquering COVID in Construction – a safe, managed return to site for construction workers	The IHS Markit purchasing managers' index for UK construction dropped to 39.3 last month from 52.6 the previous month, the lowest reading in more than 10 years. The UK construction sector employs 2.4m workers many of whom are self-employed and are unable to benefit from the Treasury's Furlough Scheme. The sector is a significant contributor to the UK's economic activity producing about 6 per cent of the country's total economic output. The vision for the project is an easy to use health check and tracking app that will give the worker and their employer a simple red/green check of their ability to work. This would enable the industry to end the lockdown, re-engage the predominately self-employed workforce and restart economic activity in a significant sector. The red/green advice from the app would be based on: 1 . Daily self-declared monitoring of general health and especially of any symptoms specific to COVID-19 . These declarations will be performed even when the user is self-isolating. 2 . A tracking feature that would record the user's location while at work and who else they have been in contact with (e.g. < 5 metres separation). 3 . Alerting when there are too many people too close together. 4 . Occupancy of any welfare units, so they can self-time their breaks to minimise unnecessary contacts. 5 . Alerting of the user when a co-worker who they have been in contact with is developing symptoms or who has tested positive for COVID-19 . 6 . Machine Learning-based algorithm to track the development of symptoms in the workforce. The app would have a dashboard for the employer showing who is currently on-site, real-time hot spots showing where workers are congregating so they can be instructed to disperse, a list of staff who have reported symptoms or have tested positive, a list of staff who should be self-isolating because they may have come into contact with another infected member of staff, potential return dates for self-isolating staff plus a list of staff who have tested positive for antibodies and may be immune to re-infection. Both China and South Korea have demonstrated the benefit of using tracking and contact tracing to reduce the spread of COVID-19 . Therefore, the proposed system can be part of an industry-led approach that will help the global construction sector to safely return to work.	UK Research and Innovation	Research Grant	49882.0	GBP
456	DEEP RENDER LTD	DEEP RENDER LTD	None	None	2021-06-17	AI-based Image-As-Video Streaming	Deep Render Ltd is a London based deep-tech start-up developing the next generation of AI-based media compression algorithms. Our proprietary and patented technology is at the forefront of machine learning research. Deep Render is combining the fields of artificial intelligence, statistics and information theory to unlock the fundamental limits of image and video compression: The human eye is the best data compressor known to humanity - with compression ratios at least 2,000 times better than everything developed to date. Our Biological Compression approach approximates the neurological processes of the human eye through a non-linear, learning-based approach, thereby creating a novel class of highly efficient compression algorithms. We are world leaders in this domain, and our unique, AI-based image compression technology is already providing a 75% efficiency gain over the best previous compression standards. As global data consumption is growing exponentially with more than 80% of traffic being Image/Video, Deep Render's AI-based compression technology is vital to bypass broadband constraints. The outbreak of COVID-19 has now accelerated this growth, as a result of the crisis, internet usage has increased significantly. In particular, the demand for live-streaming and video-chat services. Therefore we want to apply our already working image compression codec to live-video streaming. The outcome of the project is to extend our image compression codec to an image-as-video live-streaming codec, at least 75% more efficient than the current state-of-the-art. Our target customers are the live video chat services (Zoom, Skype, Microsoft Teams), as well as the entertainment industry, including live streaming platforms (Twitch, Facebook, Instagram, YouTube). Our value proposition is easy to understand. By making file sizes 75% smaller, we directly increase the bandwidth supply of the internet for live-streaming by a factor of 4 . Increasing the bandwidth supply by making file sizes smaller, is magnitudes more value- and time-efficient than increasing the bandwidth supply through rewiring the globe with progressively more fibre-cables. Deep Render is going to help create a new age in which bandwidth constraints are a problem of the past. As a result of COVID 19 solving this problem has gained more importance and Deep Render is determined to create a fast solution.	UK Research and Innovation	Research Grant	50000.0	GBP
457	V2G EVSE LIMITED	V2G EVSE LIMITED	None	None	2021-06-17	Covid-19 eHealth Data Acquisition Unit (COVeHealth)	The UK is currently in "lock down" due to the novel coronavirus pandemic. Before putting the currently locked down country back to work we need to: 1) Reduce the incidence of cases to reduce the burden on the NHS to more normal levels 2) Once that is achieved, we need to prevent the virus from catching fire a second time To reduce the risk of a second wave, we need to develop tools to enable us to: a) Preemptively identify early stage Covid-19 sufferers b) Use these tools to guard the borders of spaces (hospitals, homes, shops, workplaces, shopping malls, schools, universities etc.) The World Health Organization's message is that we must **"Find, isolate, test and treat every case to break the chains of Covid transmission."** Covid-19 screening tests are currently performed at a modest distance by a health worker using a "no touch" infrared thermometer to detect the tell tale fever. The other common symptom indicative of Covid-19 is the persistent dry cough, detected by the characteristic sound. What is desperately needed, both in the UK and around the World, is a way of performing screening for early stage Covid-19 symptoms remotely. With DfT seed funding V2G EVSE have developed a low cost "smart" 0G to 5G enabled communications controller with a wide range of input/output, currently configured to monitor and control an electric vehicle charging station and securely communicate with a cloud based management system. We will repurpose our existing technology by connecting the controller to a microphone and infra-red camera, then use novel machine learning algorithms to detect the characteristic cough and fever of Covid-19 sufferers. This will allow us to create an installed or hand held device that can be used to identify those with potential Covid-19 symptoms. Since our existing hardware is effectively the internals of a smartphone with no touch screen but more versatile communications, including Bluetooth, we are also ideally placed to participate in the recently announced Apple/Google track/trace initiative. The COVeHealth project will develop proof of concept prototypes of a "commercial" version suitable for use at the entrance to public spaces and an alternative low-cost "domestic" version for use hand held or in confined spaces.	UK Research and Innovation	Research Grant	None	None
458	OKEO LIMITED	OKEO LIMITED	None	None	2021-06-17	OKEO - COVID-19 financial modelling	OKEO is a London-based challenger credit card company that uses Open Banking data and machine learning to provide young adults with access to affordable credit. OKEO proposes to develop innovative affordability and credit risk models using current "crisis data" to help OKEO lend money to financially excluded young adults (aged between 20 to 30 years old), self-employed contractors and gig economy workers at low rates during the pandemic. By utilising innovative data modelling and lending to critical sectors of the economy, OKEO's vision is to help meet the needs of financially excluded individuals and help stimulate the UK economy. OKEO is innovating now to respond to the financial needs of individuals brought on by COVID-19 and a weakened economy.	UK Research and Innovation	Research Grant	49815.0	GBP
459	Dr Hannah Mary Thomas T	Christian Medical College, Vellore	None	2020-01-01	2024-12-31	Radiomics based tumor phenotypes to predict individual risk and treatment response in head and neck cancer	Key goals and hypotheses:The key goal is to translate quantitative imaging based biomarkers (radiomic signature) into routine cancer care to support clinical decision-making. The hypothesis is Pre-treatment imaging-derived radiomics signature can accurately identify advanced head-and-neck cancer patients with higher risk of failure and poor survival. Rationale and justification: Radiomics based prediction models have a potential for universal implementation as a cost effective surrogate or replacement to genomics based biomarkers. It is necessary to standardize acquisition protocols for cancer imaging for radiomics feature extraction to correlate with outcome data to identify the ideal bio-marker. Translation of developed biomarkers for clinical implementation and adoption in future clinical trials in India is possible with the selected disease site. Study design: Prospective observational study design involving uniform image acquisition, radiomics feature extraction, development of outcome prediction model using machine learning approaches and validation of the model on a prospective clinical cohort before implementation into clinics. Impact: Successful completion of this fellowship will provide the initial investments required for clinical integration of radiomics processing and decision support platforms in India with the potential to significantly improve outcomes of patients with locally advanced cancers with personalized cancer care.	DBT/Wellcome Trust India Alliance	Early Career Fellowship	13521386	INR
460	Dr Rory Devine	University of Birmingham	None	2019-02-01	2021-01-31	Mindreading, Psychopathology and Social Adjustment in Middle Childhood	Approximately 10% of children aged between 6 and 12 have a diagnosable mental health disorder (Beardsmore, 2015). Mental health problems are the leading cause of disability in middle childhood and are linked to peer relationship problems and poor social adjustment at school (e.g., Erskine et al., 2015; Szekely et al., 2016). Our proof-of-concept study asks whether difficulties understanding others’ thoughts and feelings (or ‘mindreading’) explain why children with mental health problems in middle childhood experience adverse social outcomes. We adopt an innovative group-administered mindreading test to collect data from a large community sample of 8- to 12-year-old children to investigate the links between teacher-rated psychopathology symptoms (e.g., emotional problems, hyperactivity, aggression, autism traits), mindreading, and teacher- and peer-rated social adjustment. We apply a dimensional approach to investigate the specificity of the relations between mindreading and psychopathology, and the extent to which mindreading deficits contribute to social adjustment problems among children with psychopathology symptoms. We use machine learning to create an automated scoring procedure for rating children’s text-based responses to tests of mindreading. The project provides crucial evidence and new methods for a future longitudinal investigation of the developmental links between mental health problems, mindreading and social adjustment in middle childhood.	Wellcome Trust	Seed Award in Science	97109.0	GBP
461	Dr Brown	University of Lincoln	None	2020-09-07	2023-09-06	Towards an open-source, equipment-agnostic framework for automated welfare monitoring in the home cage	The moral implications of using mice and other higher animals in biomedical research has been a topic of debate for many years, and has steered various efforts towards minimising animal suffering. As the number of mice used in biomedical research continues to rise, there is greater emphasis than ever on approaches to refine husbandry protocols and humane endpoints to ensure that welfare concerns are dealt with swiftly and efficiently. Home cage monitoring has been proposed as a means capturing animal behaviour through the light and dark phases so that welfare deficits might be captured without the need for human intervention. Several commercial and non-commercial systems have been designed to capture video footage (and other data) of mice that offer several advantages over conventional experimental designs: (1) behaviours can be captured in a familiar, enriched environment; (2) observations are not confounded by novel apparatus or human experimenters; (3) it serves as a permanent digital record; and (4) video data are amenable to automated image analysis techniques. The challenge that remains in the context of HCA is the ability to analyse video footage in a manner that is fully-automated, comprehensive, robust, and computationally efficient. Under this proposal, the successful studentship awardee will develop a solution to the problem of automated HCA based on deep learning; a state-of-the-art approach to computer vision problems that utilises computational models inspired by the human visual cortex. The technique will be based on the "anomaly detection", whereby a model is initially trained to capture the range of possible behaviours exhibited by mice under normal circumstances (i.e., without welfare deficits). The methods works by learning to produce a set of visual and motion features that describe the behaviours of the mice, and then having the same model attempt to "reconstruct" the input clip from the features. In doing so, the model is forced to capture only key information about normal behaviour. Given that video clips depicting welfare deficits are visually different normal behaviors by definition, the model will be less capable of representing those data. Dr James Brown will be the primary supervisor of this work, who has a strong record of interdisciplinary research involving mouse models. He has previously worked with the Mary Lyon Centre - a collaborator on this project - on development 3D image analysis techniques for mouse embryo phenotyping. He has recently published several high-impact articles on machine learning techniques for the diagnosis of retinal disease, and is currently seeking approval from the US Food & Drug Administration. Prof Xujiong Ye will co-supervise this project, bringing more than 20 years' experience in computer vision and medical image analysis in both industry and academia. The methods outlined in this proposal align well recent work published Prof Ye on the development of algorithms to track and assess the welfare of farmyard pigs from top-down video footage.	National Centre for the Replacement, Refinement and Reduction of Animals in Research	Studentship	90000.0	GBP
462	Dr Paul Kirk	University of Cambridge	None	2019-07-10	2023-03-31	Statistical and Machine learning approaches for molecular precision medicine and beyond	A well-established goal of precision medicine is to identify and characterise disease subtypes, since these may be associated with differential prognoses and/or treatment responses. The existence of subtypes may be suggestive of the existence of multiple aetiologies or pathobiological mechanisms, with each subtype corresponding to a distinct disease-causing process or combination of processes. For diseases in which multiple disease-causing processes are operative within or upon each patient, recent research has highlighted how the identification of signatures associated with each process can also benefit precision medicine. In this context, signatures are detectable patterns that are the imprint of each causal process; e.g. characteristic genomic changes in cancer associated with distinct mutational processes, accumulated over time. Both subtype discovery and signature identification require the deconvolution of mixed signals, whether at the patient cohort level (subtype discovery) or within each patient (signature identification). We will undertake to develop a comprehensive suite of widely applicable analysis methods, implemented in open-source software, for the deconvolution of heterogeneity, and – working with clinical and wet-lab collaborators – demonstrate their utility in application areas where they will add value, and have the greatest impact. A particular methodological challenge that will be addressed within our research programme will be how best to integrate diverse sources of molecular and other information, using both novel statistical models and probabilistic machine learning approaches. Our work may be divided into 3 subthemes: (i) probabilistic discovery of disease subtypes and signatures; (ii) the analysis of electronic health records (EHRs) to define multimorbidity clusters; and (iii) modelling heterogeneity in the analysis of ’omics datasets. We have strong collaborations with teams across the Cambridge Biomedical Campus, particularly within the Cambridge Institute of Therapeutic Immunology & Infectious Disease (CITIID), the Cancer Research UK Cambridge Institute (CRUK-CI), and the Cambridge Centre for Proteomics (CCP), as well as within the MRC Biostatistics Unit (BSU). Particular applications of our work include molecular characterisation of high grade serous ovarian cancer (HGSOC); pan-cancer proteomic characterisation; understanding sub-cellular protein localisation; and the development of clustering methods for genetic summary data.	Medical Research Council	Unit	None	None
463	Dr Alexandra Young	King's College London	Neuroimaging	2019-09-16	2022-09-15	Identifying the genetic architecture of brain health and disease in the presence of heterogeneity and multi-morbidity	Alzheimer's disease and other forms of dementia are known to be highly complex conditions; phenotypes vary substantially across individuals, the majority of individuals have multiple chronic health conditions, and a wide range of genetic and lifestyle factors have been implicated in disease risk. However, the contribution and interaction of different mechanisms to produce distinct forms of Alzheimer's disease is not well understood. A complete understanding of how genetics, multi-morbidity and lifestyle factors give rise to heterogeneity in disease phenotype is crucial for developing targeted multi-faceted treatments and lifestyle interventions, as well as for identifying who they will benefit. In this fellowship I propose to develop new statistical approaches that can identify clusters of individuals with common disease trajectories and characterise how genetic factors and co-morbidities alter disease progression patterns. I propose to develop methods that can provide improved statistical power for detecting associations by (i) using machine-learning to bring together subjects at different disease stages to characterise heterogeneous trajectories across the full disease time course, enabling early stage subjects to be assigned to a subgroup trajectory; (ii) developing techniques that can cluster imaging, genetic and multi-morbidity information, particularly by jointly leveraging the structure of genetic and phenotypic information in combination. I will apply these techniques to provide new insights into variability in trajectories of the two most common forms of dementia, Alzheimer's disease and Parkinson's disease, and aging, which is the biggest risk factor for dementia and a key confound to distinguishing dementia at early disease stages. I will then test whether these imaging genetics profiles of health and disease can be used to screen for Alzheimer's disease and Parkinson's disease in population studies.	Medical Research Council	Fellowship	309164.0	GBP
464	Dr Jonathan Bedford	University of Oxford	None	None	2022-09-15	New-onset atrial fibrillation in critically ill patients: risk factors and outcomes	What is Atrial Fibrillation? Atrial fibrillation (AF) is a problem with the heart's electrical system that causes an irregular heartbeat. It makes the heart less efficient at pumping blood around the body and can result in a very fast heart rate. Atrial fibrillation also increases the risk of blood clots forming in the heart. These can cause strokes if they travel to the brain. AF in the community is different to AF on the intensive care unit (ICU) AF is the most common electrical heart problem in the UK. Why people develop AF outside hospital is well understood, as are the problems that AF causes in these people. AF can also start when a person becomes very unwell. Around 10% of patients treated on an intensive care unit (ICU) will develop AF for the first time during their ICU stay. This is called new-onset AF. Each year roughly 17,000 people being treated in ICUs in the UK will develop this problem. We do not understand what causes new-onset AF (NOAF) on the ICU NOAF in patients treated on an ICU may be triggered by many different factors. These may include: The normal body reactions to infection and injury. Altered levels of salts in the blood (electrolytes). Certain treatments or procedures commonly used in ICUs, such as large drip lines in the neck.We need to know how big a risk ICU-related NOAF is to patientsWe do not have a clear understanding of all the long-term risks associated with NOAF developing in a patient treated in an ICU. This is because studies in this area are either small or based on limited information. In addition, we know very little about how things like heart rate and blood pressure are affected when NOAF starts in a patient treated on an ICU, and how this affects other organs in the body. NOAF on the ICU may be associated with short and long-term problems Limited studies suggest that NOAF may make patients treated on ICUs more unstable and more likely to die whilst on ICU. Even patients that have AF for a short time whilst on the ICU seem to be at higher risk of dying or having a stroke in hospital. NOAF starting while a patient is in an ICU may also cause long-term problems. These patients may end up with permanent AF. They may also be more likely to die following discharge from hospital. However, larger and more detailed studies are required to work out these risks in detail. My research will help answer these questions My research will use four large databases containing anonymised clinical records of patients treated in ICUs in the UK and America. Studying these databases will allow me to: Understand what makes patients likely to develop NOAF and whether some of the risks are avoidable. Use these risks to predict who will develop NOAF on an ICU. Investigate how NOAF on the ICU affects patients' blood pressure and organ function. Accurately estimate the effect of NOAF on survival on ICU, in the hospital after discharge from ICU and after discharge home. This will include the impact of NOAF duration and whether it persists to ICU discharge.This work will, for the first time, identify avoidable risk factors for NOAF and measure its effect on patients' blood pressure and organ function whilst in ICU. Understanding what triggers NOAF will help clinicians prevent this important condition. Properly understanding future risks is essential to decide on appropriate screening and treatment. Both are needed to improve outcomes in this vulnerable group of patients treated on ICUs.	National Institute for Health Research (Department of Health)	Full Grant	367243.0	GBP
465	Dr Norman Poh	University of Surrey	Computing Science	2015-09-01	2017-07-12	Modelling and Predicting CKD Progression	OBJECTIVE: An overarching objective of this research is to revisit the problem of modelling the progression of Chronic Kidney Disease (CKD) using state-of-the-art machine learning techniques and methodologies. The proposed approach differs from the conventional ones in the following ways: It emphasizes prediction over explanation; (2) builds customized statistical models over generic but covariates-adjusted model; (3) exploits the entire patient history rather than using pre-selected variables; and, (4) explores data-driven stratification over disease-centric stratification. INNOVATIONS: Specifically, we propose a mixture model approach to predicting key variables in CKD such as estimated Glomerular Filtration Rate (eGFR), Albumin:creatinine ratio (ACR), and Blood Pressure (BP). In addition, we also explore a novel data-driven patient stratification methodology. Last but not least, as part of the process in modelling eGFR, we also propose to develop a risk model for Acute Kidney Injury (AKI) based on all available historic data from a patient record. ADVANTAGES: The potential advantages of the proposed method include: (1) better tailoring of the method to patient subgroups via data-driven stratification; (2) ability to exploit many more variables that are specific to each patient stratum; (3) ability to predict eGFR and ACR that can be used in conjunction with guidelines-based prescribing; (4) ability to predict Acute Kidney Injury. OUTPUTS: The main outputs of this proposal are: (1) patient-tailored eGFR predictor, (2) patient-tailored ACR predictor, (3) probabilistic AKI estimator, and (4) data-driven patient stratification. By patient tailoring, we understand that the model is capable of considering additional variables that are specific to a patient stratum.	Medical Research Council	Research Grant	519780.0	GBP
466	Professor Nigel Collier	University of Cambridge	Linguistics	2015-11-13	2018-11-28	PheneBank: automatic extraction and validation of a database of human phenotype-disease associations in the scientific literature	PheneBank will exploit state of the art text mining (TM) together with existing ontological resources to collect fragmented biological results about the phenotypic profiles of human diseases and integrate this into a machine understandable semantic database and tool set for use by the clinical and scientific communities in their workflows. TM will be used to automatically extract phenotype, disease and gene terms from the full text scientific literature and harmonise these to ontological resources. Importantly, we will exploit grammatical parsing (the BLLIP parser) for recovering discontinuous terms and then a de-compositional approach in which the elements of the complex phenotype terms are individually linked to ontologies (e.g. Gene Ontology: processes, UBERON for structures). Harmonisation will explore learn-to-rank techniques to optimize concept selection from an array of tools such as cTAKES/MetaMap. Following this, typed relations between terms will be filtered using a range of machine learning classifiers on grammatical parse trees. Domain adaptation techniques will be tested for both term and relation extraction. Validation will follow standard protocols for text mining, including construction of a gold standard annotated corpus of 5000 sentences sampled from cited literature with a focus on rare human diseases. Phenotypic profiles will be built from strongly associated and related terms (e.g. phenotype-disease) by exploring a range of measures (e.g. Jaccard index, Information Content). Validation will use existing expert curated profiles in the OMIM and OrphaNet databases. Additionally we will explore the cross-species harmonisation of the human phenotype terms to closely associated mouse phenotypes. This will take place through conceptual mappings of PheneBank terms to the HPO and MP. The semantic database will include phenotypes and associated links for querying, navigation and download in a variety of formats (OWN/RDF/JSON).	Medical Research Council	Research Grant	464013.0	GBP
467	Dr Krishnarajah Nirantharakumar	University of Birmingham	Institute of Applied Health Research	2020-06-01	2020-11-30	Multimorbid Pregnancy: Determinants, Clusters, Consequences and Trajectories (MuM-PreDiCCT)	Our vision is to characterise multimorbidity (MM) in pregnant women and then investigate the consequences of MM. To do so we will use electronic medical records, birth cohort and clinical trials data from across the four nations in the UK. We will work to develop harmonious definitions of variables and linkage algorithms to ensure comparable methods across the datasets. We will describe the proportion of women affected by MM and prevalence of each combinations of morbidities. We will apply clustering and trajectory methods to identify clusters and sequence dependent clusters. Then we will investigate if MM status and clusters differ by age, deprivation, ethnicity, parity, body mass index and lifestyle factors. By identifying the characteristics of patients within these clusters, we will be able to develop preventive interventions. We will then study how MM pregnancy impacts on the health of mothers and offspring. Initially we will use established consensus methods to develop a core outcome set for MM pregnancy research. Then we will determine the rates of these outcomes in both mothers and offspring based on their MM status and then based on prescription combinations they have received. Findings will help to monitor and prevent adverse outcomes. Findings will also help improve safe prescribing during pregnancy. Our previous work has demonstrated that pregnancy related complications are associated with future morbidities. Using this information and other covariates we will use bio-statistical and machine learning methods to develop and validate prediction models for long-term outcomes. This is expected to help with prevention and early identification of future morbidities. Finally to improve maternity services, a mixed methods study will be conducted with patients and health professionals to understand current service provision and their limitations. This will then lead to co-designing of pathways for pregnant women with MM.	Medical Research Council	Research Grant	100396.0	GBP
468	Krzysztof Janowicz	University of California-Santa Barbara	None	2020-05-15	2020-10-31	RAPID: COVIDGeoGraph ? A Geographically Integrated Cross-Domain Knowledge Graph for Studying Regional Disruptions	Office of the Director - This COVID-19 RAPID research program will develop a geographically integrated knowledge graph to support data scientists and decision-makers in industry and the government in taking region-specific steps towards reopening the country. Towards this goal, the project will combine data from themes as diverse as transportation, social distancing measures, demographic and environmental factors, as well as economic impacts. Knowledge graphs are contextualization technologies. They enable their users to gain a more holistic understanding of complex social and scientific questions by providing actionable insights from neighboring disciplines. For instance, making decisions about local economies and food systems require an understanding of the frequently changing social distancing measures, traffic control and restrictions including neighboring regions, demographic factors, and the percentage of recovered citizens. The project will work together with industry partners to understand how graphed knowledge can be utilized in their forecasting models. Finally, the project will reach out to other knowledge graphs to jointly form an open knowledge network related to COVID-19.<br/><br/> More technically, we will utilize a stack of open source technologies and international standards to develop a highly integrated Linked Data-based knowledge graph that combines cross-domain data across different geographic scales and types of places. We will utilize machine learning technologies to learn graph embeddings for predicting links within our graph as well as alignments to other graphs by using places such as cities or counties as points of integration. We will also provide the functionality to collaborate with the broader schema.org effort. We are particularly interested in studying how to represent and align COVID-19 data that is currently being reported at different geographic scales and aggregates, thereby fostering interoperability and breaking up data silos. We will work directly with our industry partners on engineering (spatially-explicit) features from our and external graphs. These features will be integrated into industry downstream forecasting models with a particular focus on food systems. Finally, We will utilize the expertise of our partners in creating visual data dashboards to better communicate our findings.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	90658.0	USD
469	Constantine Kontokosta	New York University	None	2020-05-01	2021-04-30	RAPID: Computational Modeling of Contact Density and Outbreak Estimation for COVID-19 Using Large-scale Geolocation Data from Mobile Devices	Engineering - The outbreak of COVID-19 has highlighted both the growing global risk of emerging pandemics and the urgent need for enhanced data-driven tools to identify, contain, and mitigate their effects, particularly in dense urban areas. There has been increasing attention given to locational data from smartphones as a way to enhance epidemiological modeling and predict outbreak progression, transmission, and exposure risk. When combined with artificial intelligence or machine learning algorithms, these high resolution data have the potential to vastly improve the granularity and precision of infection and hospitalization estimates. However, the use of locational data raises serious social, ethical, and technical challenges. Trade-offs between the potential public health benefits and the impacts for privacy and civil liberties have started to be debated in earnest within the context of the current pandemic, especially in light of increasing use of these data by private companies to promote targeted advertisements, evaluate retail consumer behavior, and model travel demand, among other applications. Furthermore, the use of these data in the public interest is undermined by an incomplete understanding of the representativeness and bias embedded in these data, particularly in relation to under-represented and vulnerable communities. What is not yet known is the extent of this bias in locational data and how the public health benefits of using these data diminish with spatial and temporal aggregation, which could help to minimize privacy concerns in the collection and use of these data. To address these questions, this project will develop computational models derived from large-scale locational data to (1) estimate the exposure density across a range of temporal (hourly, daily, etc.) and spatial (census block, neighborhood, etc.) scales, which will enable officials and researchers to evaluate and predict transmission rates in a particular area; (2) measure and evaluate the extent and effectiveness of social (physical) distancing efforts over time and comparatively within and across counties and cities, as well as understand the disparate impacts on vulnerable communities and populations; and (3) measure the extent of disease spread based on movement and travel patterns between neighborhoods and communities, which will support predictions of the spatial-temporal patterns of disease outbreak and identify ?at-risk? locations based on the aggregated mobility trajectories for areas were infections have been identified or suspected. <br/><br/>The project team is particularly concerned with how shelter-in-place orders and exposure risk disproportionately impact low-income and minority communities, and the implications of potential bias in locational data in assessing socioeconomic variations. The project will assess how the usefulness of these models for epidemiologists and public health officials varies with spatial aggregation (e.g. is neighborhood level data superior to county level data) and temporal aggregation (e.g. is a near-real-time model superior to daily or weekly timescales) and provide quantitative performance assessments that can be used for collective decision-making on the trade-offs between health benefits and privacy risk. Project outputs will be made open-source and publicly available as appropriate.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	199958.0	USD
470	Jeannette Wing	Columbia University	None	2020-05-15	2020-10-31	RAPID: COVID Information Commons (CIC)	Office of the Director - This project will create a COVID Information Commons (CIC) website to facilitate knowledge sharing and collaboration across various COVID research efforts, especially focusing on all the NSF-funded COVID Rapid Response Research (RAPID) projects. The CIC will serve as a resource for researchers as well as decision-makers from government, academia, not-for-profit and industry to leverage each other's findings, and invest in and accelerate the most promising research to mitigate the broad societal impacts of the COVID-19 pandemic. It will also serve as a model for integrated knowledge sharing and collaboration on other public health challenges, in benefit to society. Projects will be able to enter and publish information about their efforts in ways that are most relevant and user-friendly for a variety of potential stakeholders from academia, industry, government, and non-profit sectors. Information will be organized in multiple ways, for example, by research topics areas and by geography. In addition to information from NSF COVID-19 RAPID projects, the COVID Information Commons will incorporate coronavirus-related information from NSF Open Knowledge Network projects, as well as from other NSF research projects in general. <br/><br/>The COVID Information Commons will utilize information science methods to bring together information about the collection of COVID-19 RAPID projects funded by the National Science Foundation. A wide array of research efforts are underway to study the impacts of the pandemic in fields as far ranging as biophysics, social justice/inequity, behavioral science, public health, supply chains, and risk management. The CIC will semantically link information across projects to provide a more holistic view across distinct efforts, including efforts such as the COVID projects in the NSF Open Knowledge Network. The resulting, concise, curated, integrated resource will provide insight into NSF-funded COVID RAPID projects and facilitate collaborations among such efforts. These objectives will be achieved using information science approaches to 1) compile a comprehensive list of NSF COVID RAPID awards, along with relevant details for each project, 2) link to any publicly available data sets and data feeds, 3) organize the information and data feeds, for example, by categories of research areas and/or geography, using a meta-data schema developed for the resource and existing taxonomy and semantic frameworks; 4) design and develop a web portal to allow project teams to publish their data, or links to the data, and present project information in ways that are most relevant and user friendly for researchers in academia, industry, and government; 5) integrate the schema.org COVID-19 annotated data to enable more effective identification, retrieval, and integration of relevant data. A Minimum Viable Product for the website will be developed first, working with stakeholders in the community to prioritize features and add new functionality. In addition to the Information Commons, the project will also assess the effort and feasibility of implementing a data and model commons?to share datasets as well as data-driven models, such as machine learning models related to COVID-19.<br/><br/>This RAPID award is made by the Convergence Accelerator program in the Office of Integrative Activities with funds from the Coronavirus Aid, Relief, and Economic Security (CARES) Act.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	200000.0	USD
471	Natalia Trayanova	Johns Hopkins University	None	2020-05-01	2021-04-30	RAPID: Prediction of Cardiac Dysfunction in COVID-19 Patients Using Machine Learning	Engineering - Recent reports demonstrate the critical influence of COVID-19 on the cardiovascular system, with up to 20% of COVID-19 patients suffering acute cardiac injury. Approaches to identify COVID-19 patients at risk for cardiac dysfunction have not yet been developed, and no alerting clinical parameters are available to address the impending decline of cardiac function and mortality. The goal of this project is to develop a machine learning approach to identify COVID-19 patients at risk for cardiac dysfunction and sudden cardiac death. Utilizing such an approach will provide early warning and enable the delivery of early goal-directed therapy, reducing mortality and optimizing allocation of resources. The machine learning classifier is to be distributed to any interested healthcare institution, to augment their ability to successfully treat patients. This project also provides fundamental new scientific knowledge: how COVID-19-related cardiac injury could result in cardiac dysfunction and sudden cardiac death. Such knowledge is of paramount importance in the fight against COVID-19 and the post-disease adverse effects on human health. <br/><br/>Features that will serve as input into the machine learning classifier will be extracted from both time series (ECG, cardiac-specific laboratory values, continuously-obtained vital signs) and imaging data (CT, echocardiography). Data will be collected from patients admitted to Johns Hopkins Hospital and Johns Hopkins Health System; other hospitals in the Chesapeake area; and potetially hospitals in NYC, with a confirmed diagnosis of COVID-19 based on nucleic acid or polymerase chain reaction testing. We will develop a time-varying risk score that will determine the posterior probability of hemodynamically-significant cardiac disease outcome within 24 hours of certain time points. For new patients, the model will be used to perform a baseline prediction which will be updated in a Bayesian fashion each time new data becomes available.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	195621.0	USD
472	Arshad Kudrolli	Clark University	None	2020-05-15	2021-04-30	RAPID: Predicting Coronavirus Disease (COVID-19) Impact with Multiscale Contact and Transmission Mitigation	Mathematical and Physical Sciences - Nontechnical Abstract: <br/>The rapid spread of new coronavirus SARS-CoV-2, which causes Coronavirus Disease (covid-19), requires a multidisciplinary mitigation strategy from the clinical to physical host-to-host transmission modelling. Data is required on the transmission of pathogen carrying airborne mucosalivary droplets and aerosols generated during normal breathing, talking, sneezing, and coughing. Synthetic exhalations will be measured leveraging advanced prototyping to obtain data needed to model the spread of covid-19, and the efficacy of personal protection devices and face coverings fabricated with various weaves and materials will be tested. Physical data related to temperature, humidity, and airflow on survival and dispersion of exhalations will be obtained. The data will be integrated using supervised machine learning methods, mathematical network simulations, and epidemiological data to develop an individual-based method that can give pandemic management results. Physical data will be published on transmission rates, including wearing of personal protective equipment and face coverings with various weaves, to inform mitigation strategies to alleviate covid-19 pandemic. Interactive Web based resources will be used for immediate broad dissemination of data and learning outcomes on covid-19 to the public, in addition to peer reviewed publications and training post-doctoral and undergraduate researchers in methods leading to pandemic mitigation.<br/><br/>Technical Abstract:<br/>The mode of transmission and extent of environmental contaminations on the outbreak of the Coronavirus Disease 2019 (covid-19), while sharing features with severe acute respiratory syndrome and other infectious diseases, remains unknown. This project will address fundamental rheology-matched metrics of transport and survival of airborne exhalation droplets and aerosols that carry coronavirus and on surfaces needed as input parameters for modeling mitigation. Impact of personal protective equipment on individual prognosis, with physical data related to temperature, humidity, and airflow-dependent dispersion distance of pathogen bearing viscoelastic droplets corresponding to breathing, sneezing, and coughing, will be obtained. The impact of the measured transmission rates on the spread and recurrence will be investigated with epidemiological data integrated with deep learning to implement a scalable, individual-based, stochastic, spatial model. Resulting peer-reviewed publications will serve as trusted source for calculation of covid-19 transmissibility and personal protection strategies. Post-doctoral and undergraduate researchers versed in fluid dynamics, soft matter physics, and network simulations will be trained toward mitigating infectious disease spread.<br/><br/>This Rapid Response Research (RAPID) grant supports research that will result in spatiotemporal mucosalivary droplet transmission range data required to develop covid-19 mitigation network methods with funding from the CARES Act managed by the Condensed Matter Physics Program in the Division of Materials Research of the Mathematical and Physical Sciences Directorate.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	200000.0	USD
473	Jurij Leskovec	STANFORD UNIVERSITY	None	2020-05-01	2021-04-30	RAPID: Collaborative Research: Computational Drug Repurposing for COVID-19	Computer and Information Science and Engineering - With the disruptive nature of the COVID-19 pandemic, effective treatments could save the lives of severely ill patients, protect individuals with a high risk of infection, and reduce the time patients spend in hospital beds. However, there are currently no effective treatments for COVID-19. Traditional methodologies take years to develop and test compounds from scratch. Machine learning provides promising new approaches to repurpose drugs that are safe and already approved for other diseases. This project will develop a machine learning toolset to expedite the development of safe and effective medicines for COVID-19. The toolset will rapidly identify safe repurposing opportunities for approved and experimental drugs. It will predict whether treatments may have therapeutic effects in COVID-19 patients, allowing the identification of drugs and drug cocktails that are safe and plentiful enough to treat a substantial number of patients. By putting tools in the hand of practitioners, the activities in this project will have an immediate impact. They will result in actionable predictions that are accurate and interpretable. <br/><br/>Recently, the principal investigators have developed a series of machine learning tools to identify drug repurposing opportunities. Building on foundational previous work, in this project, the principal investigators will first build a large COVID-19 focused knowledge graph that will capture fundamental and COVID-19-specific biological knowledge. The graph learning methods will be adapted to identify safe drugs and drug cocktails for COVID-19. To predict the safety of cocktails with two or more drugs, the methods will generalize to an exponentially large space of high-order drug combinations. In addition to drug safety, efficacy is a crucial endpoint for drug development. The project will develop a novel graph neural network (GNN) method to identify efficacious drug repurposing opportunities, even for diseases, such as COVID-19, that do not yet have any drug treatments and thereby, no label, supervised information. The method will predict what drugs and drug combinations may have a therapeutic effect on COVID-19. Finally, the principal investigators will integrate the developed tools into a complete, explainable framework that will generate predictions, provide explanations, and incorporate human feedback into the machine learning loop. This project will provide new, open tools for rapid drug repurposing that will be relevant for COVID-19 and other emerging pathogens. Additionally, the project will provide unique opportunities for multi-disciplinary curriculum development, training and advising, and professional activities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	100000.0	USD
474	Javier Arsuaga	University of California-Davis	None	2020-05-01	2021-04-30	RAPID: Using Data Science and Biophysical Models to Address the COVID-19 Pandemic	Mathematical and Physical Sciences - COVID-19, the disease caused by the SARS-CoV-2 coronavirus, is at the center of one of the most dangerous pandemics the world has ever known. As it spreads through the Human population the virus mutates producing proteins that can lead to higher infection rates (infectivity), and an increased ability to cause severe disease (virulence). This project will predict the most likely mutations of the virus by combining methods from machine learning, mathematics and biophysics. Specifically, the proteins resulting from viral mutations will be experimentally synthesized, and their infectivity and virulence will be tested by the project team through a collaboration with researchers in industry. This project benefits from unprecedented access to genomic data compiled on SARS-CoV-2, combined with a rich set of novel tools developed through interdisciplinary advances in data science, mathematics, and biophysics. The results of this project will build a pipeline capable of assisting the development of vaccines and drugs against COVID-19 while simultaneously advancing the fields of machine learning and mathematical virology. The project team is led by mathematicians, molecular biologists and biotechnology experts working in an interdisciplinary and collaborative setting. Students and postdoctoral researchers will be trained and will participate in publicly disseminating the findings and results of the project.<br/><br/> <br/>The SARS-CoV-2 coronavirus is believed to have originated as a bat virus and to have evolved through a combination of sequence mutations, recombination, and natural selection to be infectious in human hosts. Some of the most relevant sequence variations occurred in the S gene encoding the Spike (S) protein. As SARS-CoV-2 spreads through the Human population, mutations of the S gene can potentially increase viral infectivity and virulence. Within the framework of an evolutionary algorithm, the PIs will combine graph theory, topological data analysis, and computational biophysics to characterize the most likely mutations of the S protein. This powerful interdisciplinary approach will draw upon existing experimental data from SARS-CoV-2. The PIs will collaborate with an industrial partner to experimentally design the peptides corresponding to those predicted sequences, and use binding affinity assays and cryo-electron microscopy to test binding of the peptides to the human receptor (ACE2). The resulting pipeline will help us better understand the evolutionary landscape of viral proteins and will assist researchers in the development of anti-viral drugs and vaccines. Future extensions of this work will increase our understanding of how viruses are transmitted across species and propagate in humans. The project will provide multi-disciplinary student and postdoctoral training. The PIs will broadly disseminate their results, as well as the data they collect and software they design.<br/><br/>With this award, the Mathematical Biology Program in the Division of Mathematical Sciences and the Chemistry of Life Processes Program in the Division of Chemistry are supporting Drs. Arsuaga, Rodriguez, and Vazquez from University of California-Davis to study genomic variations of the SARS-CoV-2 viral spike (S) protein and predict the expansion range of transmission in Human populations.<br/><br/>This grant is being awarded using funds made available by the Coronavirus Aid, Relief, and Economic Security (CARES) Act supplemental funds allocated to MPS.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.	National Science Foundation	Research Grant	199998.0	USD
475	Dr Peter Charlton	Cambridge, University of	Department of Public Health and Primary Care	None	None	Using clinical and consumer devices to enhance screening for atrial fibrillation	This work will develop new methods to screen for atrial fibrillation by establishing criteria for analysing cardiovascular signals from clinical and consumer devices using our signal processing techniques and machine learning. Atrial fibrillation (AF) is associated with a fivefold increase in stroke risk, and yet is undiagnosed in 425,000 people in England; screening could be enhanced through rhythm monitoring in daily life, although criteria are yet to be established for targeted screening. The proposed project will analyse cardiovascular signals acquired in AF screening studies to develop evidence for targeted AF screening using clinical and consumer devices. I will analyse wristband photoplethysmogram signals and reference ECG signals in order to establish criteria for detecting possible AF from everyday wearables. I will combine AF risk factors with baseline ECG characteristics in order to establish criteria for identifying patients who are unlikely to exhibit AF during home rhythm monitoring. I will conduct a prospective study in order to assess the acceptability and performance of approaches for home rhythm monitoring. The criteria for use in AF screening, and the accompanying datasets and algorithms, will be made available to enhance screening and support future research into using wearable data to inform anticoagulation decisions.	British Heart Foundation	Fellowship	251475.0	GBP
476	Dr James Kinross	Imperial College London	None	2018-12-01	2021-11-30	iEndoscope: Colonoscopy Using Rapid Evaporative Ionization Mass Spectrometry (REIMS) for precision phenotyping of colonic adenomas and early colorectal cancer.	The research plan will be delivered across five parallel work packages. WP1 Instrument development: We will perform precision manufacturing in collaboration with our partners at Waters and Medwork. i) Snare and energy deployment &ndash; We will optimised the snare design and standard operating procedures for safe and efficient deployment using ex vivo synthetic simulators. ii) Aspiration of aerosol during colonoscopy: For the efficient analysis of tissue in the presence of fluid from the colon or endoscope we will develop a Venturi air-jet pump with momentum-selective capture of particles , eliminating direct contact between the patient and the mass spectrometer. We will create a device ready for clinical feasibility testing. WP2 Data collection and feasibility testing: 1. ex vivo analysis. A mass spectral database will be created by analysing over 300 biobanked specimens collected as part of our ongoing research activities. All polyps will be sent for H+E staining by an independent histopathologist and molecular phenotyping using the Cancer Hotspot Panel v2. 2. in vivo analysis: The device will be prospectively tested in 73 patients undergoing elective colonoscopy for endoscopic mucosal resection (EMR) for high-risk polyps (>1cm) with a primary endpoint of diagnostic accuracy for detecting dysplasia in adenomas. Endoscopists will be blinded to the data, and machine performance will be benchmarked against NBI and multispectral imaging techniques. We will perform feasibility testing to assess barriers to clinical trials, safety and patient recruitment and establish the diagnostic accuracy to power a prospective trial. WP3 Competitor analysis: 1. Systematic review of competing technologies: We have previously reviewed margin detection technologies in breast cancer, and this methodology will be adapted for use with endoscopy. 2: Multispectral imaging: Fresh ex vivo polyps analysed by the iEndoscope will undergo analysis using DRS and ESS to generate a comparative diagnostic sensitivity analysis. We will develop a novel probe that incorporates both REIMS and imaging analysis using DRS, ESS and Fluorescence spectroscopy for seamless in-vivo use during the prospective phase. 3. Narrow Band Imaging: The primary outcome measure will be diagnostic accuracy for dysplasia detection in adenomas. Clinical staff will undergo training to standardise analysis. A qualitative questionnaire will be given to staff to assess machine stability and performance. WP4 Data storage, processing, analysis and interpretation. Data will be curated using an SQL database on a dedicated, secure computer. Suitable data processing workflows will be developed, and will include mass recalibration, profile alignment and peak picking and normalisation protocols. The statistical integration of the mass spectra with clinical, histological and molecular metadata will be performed using various uni- and multi-variate statistical techniques such as canonical correlation and partial least squares analyses. This approach will identify associations between metabolites and clinical and molecular variables. Bayesian approaches will also be used to update the classification probabilities as more data becomes available throughout the length of the study. Determination of tissue classes and molecular subtypes will be performed using a panel of machine learning techniques with appropriate controls for leave-one-patient-out cross-validation to prevent over-fitting of statistical models. Data visualisation tools will be created. WP5 Economic analysis and service delivery: Foundational work will be performed as follows: 1) the development of a methodological framework for this and future research on the impact of the iEndoscope and imaging technology in endoscopy, encompassing cost-effectiveness and feasibility analysis. 2) A prospective health resource utilization study to estimate the comparative economic costs of existing techniques, which will be used to establish cost-benefit thresholds. 3). We will develop a business plan for appropriate development of the iEndoscope	National Institute for Health Research (Department of Health)	Full Grant	1123767.0	GBP
477	Dr Francesco Del Galdo	University of Leeds	None	2019-10-01	2021-09-30	An Artificial Intelligence enhanced, Mobile based Technology to Emposer patients in Collecting Visible Biomarkers -AIMTEC VB	Recent progress in the field of Artificial Intelligence (AI) is boosting the feasibility of personalised care, carrying both the promise of improved patients’ outcomes and the burden of increased volume of data to be acquired and analysed. Automated systems to “triage” patient care reducing healthcare costs are proving popular and successful (e.g. Babylon Health improving patient access to healthcare, and increasing efficiency for clinicians and administrators). Our “Artificial Intelligence enhanced, Mobile based Technology to Empower patients in Collecting Visible Biomarkers” project aims to empower patients affected or at risk of developing Scleroderma (SSc) or Psoriatic Arthritis (PsA) by collecting images corresponding to the site of their symptoms. Low-cost photographic recordings from ubiquitous devices will validate the proof of concept of a mobile phone-based technology. Following an extreme phenotype approach, images collected from the most severe and the most benign groups of patients with Raynaud’s and Psoriasis, will be used to train an AI algorithm and identify key signals and differences in discrete aspects of the imagery. The software will then be released for beta testing adoption by patient charities and included in data collection infrastructures in the two conditions. The project will build on the collaboration between Leeds NIHR Biomedical Research Centre (BRC) and Arthronica ltd. The Leeds BRC is currently funded to implement stratified medicine approaches based on patient phenotyping in both SSc and PsA. The existing infrastructure will secure patient access and engagement and will in turn, benefit for the AI data set in the stratified medicine modelling. Arthronica ltd will provide expertise and resources for optimization and training of the AI algorithms used in this study. Main objectives: to determine the proof of concept of a mobile phone-based technology for preliminary self-assessment and inform a route to widely deployable dissemination to empower patients in taking active role in “triage” screening for severe disease and reduce healthcare cost burden; to devise a mobile phone-based tool that will enrich the deep patient phenotyping dataset of the NIHR BRC, currently lacking in patient reported images, and aid stratified intervention approaches. AIMTEC VB project vision aligns with VA mission through: The short-term vision: to establish proof of concept feasibility of a tool to enhance the engagement of patients in establishing personalised medicine approaches without increasing the burden to the NHS. The long-term vision: to improve our understanding and ultimately the clinical outcome of autoimmune diseases through personalised and prevention approaches. For this purpose, we propose to address the following key technical challenges: create of a low-computational visual mobile-based technology to process images uploaded from patients; build a visual tracker that is robust enough to work in the presence of different skin tones, rings, tattoos, and skin lesions; identify a predictive statistical model of disease severity based on deep neural networks models that will directly learn from the data uploaded from patients.	Versus Arthritis	Transitional Awards	89999.09	GBP
478	Dr Sherif Gonem	University of Nottingham	School of Medicine	2020-01-01	2022-06-30	Detecting clinical deterioration in respiratory hospital patients using machine learning	Background and aims: Early warning scores are composite scores based on routinely measured clinical observations such as pulse, blood pressure and respiratory rate. They are designed to detect deteriorating patients in hospital but currently used scoring systems lack sensitivity and specificity in patients with respiratory conditions. We aim to understand how early warning scores perform in a real-world setting in respiratory patients, and to develop and validate an improved scoring system for this patient group. Research methods: Stage 1: We will survey all alerts triggered by a high early warning score in respiratory in-patients at Nottingham University Hospitals NHS Trust over a 3-month period. We will determine through case note review what investigations and interventions were performed as a result of the referrals. This will be used to develop a coding system for common events and interventions. Stage 2: Clinical observation data will be extracted from hospital systems for the approximately 22,000 admissions to adult respiratory medicine services from 2015-19. 1000 cases in which the emergency team was called at least once will be clinically annotated with reference to the case notes to capture clinically significant events requiring an intervention. The cases will be anonymised and split into a training dataset (750 cases) and a validation dataset (250 cases). Stage 3: The training dataset will be analysed using machine learning methods including logistic regression, support vector machines and anomaly detection in order to develop novel diagnostic models for detecting clinical deterioration in respiratory patients. The best performing diagnostic models will be tested using the validation dataset and their performance compared with the currently used National Early Warning Score. The area under the receiver operating characteristic curve will be the primary measure of diagnostic accuracy.	Medical Research Council	Research Grant	158835.0	GBP
479	Dr Guillaume Hennequin	Computational and Biological Learning Lab Department of Engineering University of Cambridge	Computational and Biological Learning Lab Department of Engineering University of Cambridge	2014-08-01	2016-01-31	Fast but not furious: rapid Bayesian inference in balanced cortical circuits	Sensory perception is fast in human, and nonetheless almost Bayes-optimal. I propose a theoretical approach to this puzzle in which circuit mechanisms for fast dynamics (which I have explored as part of my PhD thesis) are related to the speed of perception, for wich the computational aspects are cast in the framework of probabilistic Bayesian inference. The host laboratory has recently collected experimental evidence for a sampling-based representation of posterior uncertainty in the cortex. We are thus combining methods from machine learning and statistical physics to understand how inference via sampling can be performed through the collective dynamics of large ensembles of neurons. The project has expected outcomes both in the field of machine learning and in neuroscience.	Swiss National Science Foundation	Advanced Postdoc.Mobility	None	None
480	Matthias Guckenberger	University of Zurich	Klinik für Nuklearmedizin und Radiotherapie Universitätsspital Zürich	2017-08-01	2020-07-31	Radiomics as biomarker in multi-modality treatment of locally advanced non-small cell lung cancer	Radiomics is defined as the use of quantitative image analysis algorithms for calculation of a comprehensive set of image phenotypes also called image biomarkers. In contrast to conventional radiological image analysis, this methodology is a) objective and observer-independent and b) allows for a comprehensive description of all available information within medical images. Radiomics is therefore considered as a potential addition to the efforts currently undertaken in the field of precision medicine: to achieve a comprehensive analysis of the cancer phenotype in order to adjust the treatment to the patient-individual cancer characteristics.The aim of this project is to establish and to use comprehensive radiomics analyses in CT and FDG-PET images for outcome modelling. Prior to all image analyses, the radiomics algorithms will be evaluated regarding their robustness against non-standardized image acquisition and image reconstruction parameters. In addition, a model for quantification of loco-regional tumor spread will be established and its prognostic and predictive value will be compared to the conventional staging system. Machine learning algorithms will be established to correlate the large amount of radiomics biomarkers with clinical outcome parameters. The radiomics methodology will be tested based on images acquired within the randomized SAKK 16-00 study of multi-modality treatment for locally advanced non-small cell lung cancer (NSCLC). Radiomics biomarkers of pre-treatment CT and FDG-PET images, or post induction therapy images and changes of radiomics parameters between these two time points will be analysed. Radiomics parameters will be correlated with available histo-pathological tumor characteristics, primary (event-free survival) and secondary (overall survival, response to induction therapy, failure pattern, pulmonary toxicity) study endpoints.It is the hypothesis, that radiomics analyses will enable us to build better and more accurate prognostic models than the ones currently based on the TNM system as well as predictive models for identification of patients, who might benefit from neoadjuvant radiochemotherapy instead of neoadjuvant chemotherapy, only.The radiomics methodology and the machine learning algorithms will be evaluated in cancer patients suffering from NSCLC, a disease with currently very poor prognosis. It is planned to evaluate radiomics and the machine learning algorithms in other cancer sites as well. Additionally, the application of radiomics and the machine learning algorithms are not restricted to Oncology but can maybe successfully used in other medical questions.	Swiss National Science Foundation	Project funding (Div. I-III)	427191.0	CHF
481	Avinash Ramyead	Brain Imaging and EEG Laboratory San Francisco VA Medical Center University of California, San Francisco	Brain Imaging and EEG Laboratory San Francisco VA Medical Center University of California, San Francisco	2016-03-01	2017-08-31	Neural Oscillations as Predictors of Psychosis	Aims:This study will attempt to predict the transition to psychosis on a landmark sample whose size is unmatched by any other study in the world. The study design of the North American Prodrome Longitudinal Study 2 (NAPLS-2) allows to investigate brain activity in clinical high risk (CHR) individuals longitudinally (repeatedly over time) and observe whether the anomalies identified at baseline worsen over time thereby leading to psychosis. Owing to the rich and varied set of experimental paradigms assessed in NAPLS 2, the proposed project will allow identifying neurophysiological paradigms that are most sensitive to conversion to psychosis. These paradigms could subsequently be selectively implemented in early detection clinics in Switzerland.Methodology:We will assess 242 Healthy Controls (HC), 199 CHR individuals who did not convert to psychosis (CHR-NP) and 72 CHR individuals who converted to psychosis (CHR-P) on three different EEG paradigms collected as part of NAPLS-2. NAPLS-2 is a consortium of eight universities (including prestigious universities such as Harvard, Yale and UCLA) with the largest CHR sample in the field and allows for advanced analyses and statistical power that cannot be performed in single-site studies. In particular, we will assess neural oscillations during the (1) visual and (2) auditory oddball paradigms, along with the (3) mismatch negativity response. Analyses will include: assessing neural oscillations using time-frequency analyses, phase locking value, and lagged phase synchronization across frontal and temporal regions. We will also make use of advanced machine learning algorithms (artificial intelligence) to identify multivariate patterns of brain activity predictive of transition to psychosis.Hypotheses:•Compared to both CHR-NP and HC, CHR-P individuals will demonstrate altered theta activity during both the P3a and P3b response during context-updating processes elicited by oddball target and novel stimuli.•During the P3a and P3b response, CHR-P individuals will have reduced frontal-temporal phase synchronization of theta neural oscillations compared to both CHR-NP and HC due to lower grey matter volume in both of these brain regions.•The auditory oddball paradigm will yield markers more predictive of conversion to psychosis than the visual oddball paradigm.•Compared to both CHR-NP and HC, CHR-P individuals will demonstrate lower early theta activity during the MMN response that will be associated with lower MMN amplitude.•Following the deviant tone, CHR-P individuals will have reduced frontal-temporal phase synchronization of theta neural oscillations compared to both CHR-P and HC due to lower grey matter volume in both of these brain regions.•In CHR-P and CHR-NP individuals, aberrant frontal-temporal phase-synchronization and lower theta oscillations following deviant stimuli in the MMN paradigm will be associated with psychotic symptoms and neuropsychological deficits.•Variation in brain structural (acquired via MRI) and functional data (acquired via EEG) among CHR individuals will be predictive of the individualized transition to psychosis.Expected value of the project:Currently in Switzerland, about 32,000 people are affected by schizophrenia and the average cost per patient has been estimated to be about EUR 39,000 in the year 2012 alone. Therefore, the early detection of psychosis potentially leading to enhanced treatment approaches will not only benefit the national economy in the long run but also help the patients and their families to get ready for a possible transition to psychosis. An early detection could allow for an early intervention, that is, the patients could undergo mild treatments such as a psychological intervention or administration of low-dosage antipsychotic medication. This study is unique as it is the first to investigate, repeatedly over time, a rich and varied set of experimental paradigms on the largest sample of CHR individuals worldwide. The main findings could help clarify whether brain abnormalities identified at baseline worsen overtime and allow for the individualized prediction of transition to psychosis.	Swiss National Science Foundation	Early Postdoc.Mobility	None	None
482	Reinhard Furrer	University of Zurich	Abteilung Veterinär Epidemiologie Vetsuisse-Fakultät Universität Zürich	2012-01-01	2015-07-31	Developing Bayesian Networks as a tool for Zoonotic Systems Epidemiology	A primary objective of many zoonotic epidemiological studies is to investigate hypothesized relationships between covariates of interest, and one or more outcome variables, through analyses of appropriate data. Typically, the biological, epidemiology and behavioural processes which generated this data are highly complex, resulting in multiple correlations/dependencies between covariates and also between outcome variables. Standard epidemiological and statistical approaches cannot adequately describe such inter-dependent multi-factorial relationships. Bayesian Network (BN) modelling is a generic and well established data mining/machine learning methodology, which has been demonstrated in other fields of study to be ideally suited to such analyses. The accessibility, however, of this methodology to epidemiologists is severely limited due to the sheer breadth and diversity of zoonotic epidemiological data, which is outside the established application areas of BN modelling. Two key challenges exist, one technical and one epidemiological. Firstly, no appropriate software exists for fitting the types of BN models necessary for analysing zoonotic epidemiological data, where complexities such as grouped/overdispersed/correlated observations are ubiquitous. This project will develop easy-to-use software to allow ready access to BN modelling to epidemiological practitioners, which is essential in order to make the crucial transition from merely a technically attractive methodology, to an approach which is actually used in practice. Secondly, to demonstrate and promote the use of this methodology in zoonotic epidemiology, relevant and high quality exemplar case studies will be developed showing objectively, situations in which BN models can offer the most added value, relative to existing standard statistical and epidemiological methods. Through the project's collaborators a diverse range of zoonotic data are available for analyses, including cross-sectional and longitudinal studies of antimicrobial resistance in Escherichia coli in farmed pigs in Canada, along with a wide range of different parasite field studies including Echinococcus multilocularis, Taenia, Mesocestoides, Uncinaria and Toxocara collected across eastern Europe and central Asia. This project will deliver a range of peer-reviewed publications comprising both methods orientated papers, and pathogen focused studies. The final deliverable of the project will be to provide a valuable addition to the quantitative skills base within veterinary science, by providing PhD level training in applied computational epidemiology of direct relevance to both zoonotic and animal disease research.	Swiss National Science Foundation	Project funding (Div. I-III)	193569.0	CHF
483	Susanne Wegener	University of Zurich	Neurologische Klinik Universitätsspital Zürich	2017-09-01	2021-08-31	Predicting outcome after stroke: take a look at the other side	Despite improvements in primary prophylaxis and acute recanalization treatments, stroke remains one of the leading causes of death and disability worldwide. In order to achieve the best outcome possible for the individual patient, therapies have to be administered rapidly. However, the longer the time from symptom onset, the lower the efficacy and the higher the risk of treatment side effects. Although brain imaging is the mainstay of acute stroke diagnostics, current imaging strategies that aim to predict therapeutic success or failure in acute stroke patients remain insufficient. Here, we propose a novel prediction approach that is based on immediate and long-term vascular adaptations affecting the contralateral side of stroke. From data obtained through animal models of stroke and imaging in patients with proximal vessel occlusions, contralateral cerebral blood flow (CBF) appears to be particularly suited to predict clinical benefit from recanalization therapies. Contralateral CBF and related perfusion parameters may indicate the ability of the individual to withstand longer durations of ischemia. In the experimental part of the project, we will use a thrombin-injection stroke model that does not artificially impact collateral supply. Reperfusion will be achieved through intravenous injection of recombinant tissue plasminogen activator (rtPA). To assess CBF and ischemic tissue damage, repeated magnetic resonance imaging (MRI) combined with positron emission tomography (PET) will be performed during ischemia, after reperfusion and in the chronic phase of stroke along with behavioral assessments. In the same stroke model, processes influencing CBF on the microvascular level will be directly observed using advanced optical imaging methods. Structural adaptations of the microvascular bed as well as gene and protein expression profiles contralateral to stroke will be analyzed in brain samples. In the clinical part of the project, we will analyze stroke patient imaging data in relation to clinical outcome. In addition to a traditional region-of interest (ROI) based analysis we will apply a novel, “unbiased” machine learning algorithm to extract relevant outcome predictors from patient imaging data.Using a translational approach we aim for a mechanistic characterization of the concept of contralateral flow changes in stroke, and will generate and apply imaging predictors to clinical patient data. With the multidisciplinary study proposed here, I envision i) to deepen the understanding of the basic mechanisms regulating brain perfusion after ischemic stroke, and ii) to improve therapeutic decision-making in acute stroke patients.	Swiss National Science Foundation	SNSF Professorships	1509881.0	CHF
