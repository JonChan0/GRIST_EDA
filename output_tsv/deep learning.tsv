0    Professor Stuart David    Diamond Light Source Ltd    2018-10-01    2021-09-30    SuRVoS Workbench: Enhanced machine learning for segmentation across structural biology    None    Wellcome Trust    Biomedical Resources Grant    605412.0GBP
1    Professor Bath Philip    Nottingham,University of    2018-10-01    2021-09-30    Assessment of modern machine learning methods and conventional statistical regression techniques in diagnosis and prediction of outcome after acute stroke using big data    None    British Heart Foundation    Biomedical Resources Grant    145079.0GBP
2    Professor L. Barreto Mauricio    Fiocruz (Oswaldo Cruz Foundation)    2020-04-01    2021-09-30    The risk of a chronic clinical condition following a previous hospitalisation by a psychiatric disorder: a linkage nationwide study in Brazil    None    Medical Research Council    P&Cs    161780.0GBP
3    Professor Lotery Andrew    University of Southampton    2019-01-01    2024-01-01    Deciphering AMD by deep phenotyping and machine learning    None    Wellcome Trust    Collaborative Award in Science    3980169.0GBP
4    Professor Akerman Colin    University of Oxford    2014-06-01    2015-05-31    A biologically inspired algorithm for training deep neural networks    'In machine learning, deep neural networks are powerful computer-based models that use layers of computational units. Current commercial applications for these models include a wide array of software tasks such as image classification, identification of potential drugs, market predictions and speech recognition. Network models must be ‘trained’ using data, and their success hinges critically on the quality of the learning algorithm that is employed. We have recently discovered a novel, biologically inspired algorithm for training deep neural networks that is simpler to implement, more flexible and finds better solutions than existing techniques on bench-mark tests. Thus, our system has the potential to improve performance widely across the many fields that make use of machine learning in software tasks. Furthermore, the simplicity and flexibility of our method means that it could be more easily exploited in hardware devices such as mobile phones and cameras. The central aim of this proposal is to move our new algorithm to a stage where it is ready for commercialization. To do this we plan to accomplish two main areas of work. First, we will research the optimal way to employ our algorithm, establish its performance on a comprehensive set of industry-accepted bench-mark tasks, and compile our research into a manuscript for publication in a leading machine learning journal. Second, we will secure any arising intellectual property in line with the preliminary US patent application that we have already filed, assess application of the algorithm to the different commercial sectors identified through market research, and generate commercial interest in the technology through targeted marketing to relevant companies. This plan of work will confirm the innovation potential of our new algorithm and will establish the technical and commercial feasibility of our discovery.'    European Research Council    Proof-of-Concept Grant    146761.0EUR
5    Univ.Prof. Dr. UHL Andreas    University of Salzburg    2019-10-01    2022-09-30    Tools for the Generation of Synthetic Biometric Sample Data    Current day biometric recognition and digitized forensics research struggles with a problem severely impeding progress in these security relevant fields: Large scale datasets of biometric data would be required to allow for flexible and timely assessments, but these are missing due to various reasons, amongst them privacy concerns. The latter have increased with the EU GDPR to an extend that even well established standardization bodies like NIST in the USA removed a large part of their publically available datasets before the GDPR became effective in May 2018. To solve this problem and address the attached data quality dimensions (quantitative as well as qualitative concerns), we will research methods allowing for the generation of large-scale sets of plausible and realistic synthetic data to enable reproducible, flexible and timely biometric and forensic experimental assessments not only compliant with the hunger for data we see with modern day techniques but also with EU data protection legislation. To achieve our goals, the work in this project follows two distinct solution approaches: The first (data adaptation) takes existing biometric / forensic samples, adapts them to reflect certain acquisition conditions (sensorial, physiological as well as environmental variability), and (if required by the application context) conducts context sensitive control of privacy attributes. The second approach (synthesizing) creates completely artificial samples from scratch according to specified sensorial, physiological as well as environmental variability. The practical work in the project is focused on digitized forensic (latent) fingerprints as well as on the two biometric modalities fingerprint (FP) and vascular data of hand and fingers (i.e. hand- and finger-vein images) (HFV). The theoretical and methodological concepts and empirical findings will be generalized, to discuss the potential benefits of the research performed also for other modalities (esp. in face recognition). From a methodological viewpoint, adapting samples to specific acquisition conditions may be seen as a domain adaptation process. To achieve this, we employ recent supervised and unsupervised generative deep learning techniques for data synthesis on the one hand; on the other hand we establish more traditional, model-based image processing pipelines using interactive guided image manipulations that are generalized to an arbitrary sample number. Also, the control of privacy attributes for samples is interpreted as a domain shift operation, removing privacy relevant data attributes by shifting the sample data to a domain in which these attributes are changed. Back-to-back, also model-based techniques will be investigated to remove privacy carrying sample-attributes from the data while keeping the identity carrying ones. All investigated techniques will be exemplary applied to generating data for investigating (i) robustness of hand- and finger-vein recognition schemes (exemplary selected for biometric recognition), (ii) presentation attack artifacts (exemplary selected for biometric recognition and digitized forensics), and (iii) digital dactyloskopy (exemplary selected digitized forensics). The project will be organised as an international project conducted by two groups at Magdeburg (Germany) and Salzburg (Austria) Universities, respectively, which are lead by Prof. Jana Dittmann (for the German side) and Prof. Andreas Uhl (for the Austrian side).    Austrian Science Fund FWF    Proof-of-Concept Grant    431951.73EUR
6    Professor Mechelli Andrea    King's College London    2018-04-01    2020-04-01    Using deep learning technology to make individualised inferences in brain-based disorders    Current day biometric recognition and digitized forensics research struggles with a problem severely impeding progress in these security relevant fields: Large scale datasets of biometric data would be required to allow for flexible and timely assessments, but these are missing due to various reasons, amongst them privacy concerns. The latter have increased with the EU GDPR to an extend that even well established standardization bodies like NIST in the USA removed a large part of their publically available datasets before the GDPR became effective in May 2018. To solve this problem and address the attached data quality dimensions (quantitative as well as qualitative concerns), we will research methods allowing for the generation of large-scale sets of plausible and realistic synthetic data to enable reproducible, flexible and timely biometric and forensic experimental assessments not only compliant with the hunger for data we see with modern day techniques but also with EU data protection legislation. To achieve our goals, the work in this project follows two distinct solution approaches: The first (data adaptation) takes existing biometric / forensic samples, adapts them to reflect certain acquisition conditions (sensorial, physiological as well as environmental variability), and (if required by the application context) conducts context sensitive control of privacy attributes. The second approach (synthesizing) creates completely artificial samples from scratch according to specified sensorial, physiological as well as environmental variability. The practical work in the project is focused on digitized forensic (latent) fingerprints as well as on the two biometric modalities fingerprint (FP) and vascular data of hand and fingers (i.e. hand- and finger-vein images) (HFV). The theoretical and methodological concepts and empirical findings will be generalized, to discuss the potential benefits of the research performed also for other modalities (esp. in face recognition). From a methodological viewpoint, adapting samples to specific acquisition conditions may be seen as a domain adaptation process. To achieve this, we employ recent supervised and unsupervised generative deep learning techniques for data synthesis on the one hand; on the other hand we establish more traditional, model-based image processing pipelines using interactive guided image manipulations that are generalized to an arbitrary sample number. Also, the control of privacy attributes for samples is interpreted as a domain shift operation, removing privacy relevant data attributes by shifting the sample data to a domain in which these attributes are changed. Back-to-back, also model-based techniques will be investigated to remove privacy carrying sample-attributes from the data while keeping the identity carrying ones. All investigated techniques will be exemplary applied to generating data for investigating (i) robustness of hand- and finger-vein recognition schemes (exemplary selected for biometric recognition), (ii) presentation attack artifacts (exemplary selected for biometric recognition and digitized forensics), and (iii) digital dactyloskopy (exemplary selected digitized forensics). The project will be organised as an international project conducted by two groups at Magdeburg (Germany) and Salzburg (Austria) Universities, respectively, which are lead by Prof. Jana Dittmann (for the German side) and Prof. Andreas Uhl (for the Austrian side).    Wellcome Trust    Innovator Award    421871.0GBP
7    Professor Ananiadou Sophia    The University of Manchester    2009-09-01    2012-08-31    Automated Biological Event Extraction from the Literature for Drug Discovery    In establishing drug target confidence, it is essential to have evidence of the type of relationship between the target and key protein-bioprocesses. However, the primary starting point for target choice, and the context for interpretation of all pre-clinical observations is the literature. Text mining (TM) is ideally suited to support the discovery of reliable drug targets. But for TM systems to help researchers understand the role proteins play in biological processes, they have to extract, normalise and identify the context of complex relationships between genes, diseases and their underlying bioprocesses. Our TM techniques will recognise diverse surface forms in text describing bioprocesses and will link them with events and the proteins associated with them. Our methods are based on a combination of advanced semantic text mining (deep parsing, named entity recognition) and machine learning techniques, as we shall automatically identify events (involving proteins) such as decrease [in concentration], phosphorylation, ubiquitination, etc. Bioprocesses such as angiogenesis are composed of individual events described in the literature. We propose to identify these bioprocesses automatically and to link them with the associated events. A combination of kernel methods with knowledge resources and annotated texts (evaluated by biologists) will be used to automatically learn how bioprocesses underlying higher level processes are linked with which events. We shall concentrate on angiogenesis as an example. We shall thereby produce and make available a text mining service for researchers working in drug discovery. Both the software tools used for event extraction as well as the annotated texts used for training purposes will be made available. Co-funded by EPSRC under the RCUK Cross-Council Funding Agreement.    Biotechnology and Biological Sciences Research Council    Industrial (IPA)    288468.0GBP
8    Professor Gale Christopher    Leeds, University of    2009-09-01    2012-08-31    Predicting patient-level new onset atrial fibrillation from population-based nationwide electronic health records: A precision medicine investigation using artificial intelligence    In establishing drug target confidence, it is essential to have evidence of the type of relationship between the target and key protein-bioprocesses. However, the primary starting point for target choice, and the context for interpretation of all pre-clinical observations is the literature. Text mining (TM) is ideally suited to support the discovery of reliable drug targets. But for TM systems to help researchers understand the role proteins play in biological processes, they have to extract, normalise and identify the context of complex relationships between genes, diseases and their underlying bioprocesses. Our TM techniques will recognise diverse surface forms in text describing bioprocesses and will link them with events and the proteins associated with them. Our methods are based on a combination of advanced semantic text mining (deep parsing, named entity recognition) and machine learning techniques, as we shall automatically identify events (involving proteins) such as decrease [in concentration], phosphorylation, ubiquitination, etc. Bioprocesses such as angiogenesis are composed of individual events described in the literature. We propose to identify these bioprocesses automatically and to link them with the associated events. A combination of kernel methods with knowledge resources and annotated texts (evaluated by biologists) will be used to automatically learn how bioprocesses underlying higher level processes are linked with which events. We shall concentrate on angiogenesis as an example. We shall thereby produce and make available a text mining service for researchers working in drug discovery. Both the software tools used for event extraction as well as the annotated texts used for training purposes will be made available. Co-funded by EPSRC under the RCUK Cross-Council Funding Agreement.    British Heart Foundation    Industrial (IPA)    188229.0GBP
9    Professor Schumann Gunter    King's College London    2016-10-01    2021-09-30    Brain network based stratification of mental illness    To reduce the burden of mental disorders it is a formidable aim to identify widely applicable disease markers based on neural processes, which predict psychopathology and allow for targeted interventions. We will generate a neurobehavioural framework for stratification of psychopathology by characterising links between network properties of brain function and structure and reinforcement–related behaviours, which are fundamental components of some of the most prevalent mental disorders, major depression, alcohol use disorder and ADHD. We will assess if network configurations define subtypes within and if they correspond to comorbidity across these diagnoses. We will identify discriminative data modalities and characterize predictors of future psychopathology. To identify specific neurobehavioural clusters we will carry out precision phenotyping of 900 patients with major depression, ADHD and alcohol use disorders and 300 controls, which we will investigate with innovative deep machine learning methods derived from artifical intelligence research. Development of these methods will optimize exploitation of a wide range of assessment modalities, including functional and structural neuroimaging, cognitive, emotional as well as environmental measures. The neurobehavioural clusters resulting from this analysis will be validated in a longitudinal population-based imaging genomics cohort, the IMAGEN sample of over 2000 participants spanning the period from adolescence to adulthood and integrated with information generated from genomic and imaging-genomic meta-analyses of >300.000 individuals. By targeting specific neural processes the resulting stratification markers will serve as paradigmatic examples for a diagnostic classification, which is based upon quantifiable neurobiological measures, thus enabling targetted early intervention, identification of novel pharmaceutical targets and the establishment of neurobehaviourally informed endpoints for clinical trials.    European Research Council    Advanced Grant    3394215.0GBP
10    Dr Mah Yee-Haur    King's College London    2019-09-09    2022-09-08    Clinical outcome modelling of rapid dynamics in acute stroke with joint-detail, continuous, remote, body motion analysis    To reduce the burden of mental disorders it is a formidable aim to identify widely applicable disease markers based on neural processes, which predict psychopathology and allow for targeted interventions. We will generate a neurobehavioural framework for stratification of psychopathology by characterising links between network properties of brain function and structure and reinforcement–related behaviours, which are fundamental components of some of the most prevalent mental disorders, major depression, alcohol use disorder and ADHD. We will assess if network configurations define subtypes within and if they correspond to comorbidity across these diagnoses. We will identify discriminative data modalities and characterize predictors of future psychopathology. To identify specific neurobehavioural clusters we will carry out precision phenotyping of 900 patients with major depression, ADHD and alcohol use disorders and 300 controls, which we will investigate with innovative deep machine learning methods derived from artifical intelligence research. Development of these methods will optimize exploitation of a wide range of assessment modalities, including functional and structural neuroimaging, cognitive, emotional as well as environmental measures. The neurobehavioural clusters resulting from this analysis will be validated in a longitudinal population-based imaging genomics cohort, the IMAGEN sample of over 2000 participants spanning the period from adolescence to adulthood and integrated with information generated from genomic and imaging-genomic meta-analyses of >300.000 individuals. By targeting specific neural processes the resulting stratification markers will serve as paradigmatic examples for a diagnostic classification, which is based upon quantifiable neurobiological measures, thus enabling targetted early intervention, identification of novel pharmaceutical targets and the establishment of neurobehaviourally informed endpoints for clinical trials.    Medical Research Council    Research Grant    219833.0GBP
11    Dr Droop Alastair    University of Leeds    2018-02-14    2019-04-07    Facilitating Deep Learning with Domain-Specific Knowledge    To reduce the burden of mental disorders it is a formidable aim to identify widely applicable disease markers based on neural processes, which predict psychopathology and allow for targeted interventions. We will generate a neurobehavioural framework for stratification of psychopathology by characterising links between network properties of brain function and structure and reinforcement–related behaviours, which are fundamental components of some of the most prevalent mental disorders, major depression, alcohol use disorder and ADHD. We will assess if network configurations define subtypes within and if they correspond to comorbidity across these diagnoses. We will identify discriminative data modalities and characterize predictors of future psychopathology. To identify specific neurobehavioural clusters we will carry out precision phenotyping of 900 patients with major depression, ADHD and alcohol use disorders and 300 controls, which we will investigate with innovative deep machine learning methods derived from artifical intelligence research. Development of these methods will optimize exploitation of a wide range of assessment modalities, including functional and structural neuroimaging, cognitive, emotional as well as environmental measures. The neurobehavioural clusters resulting from this analysis will be validated in a longitudinal population-based imaging genomics cohort, the IMAGEN sample of over 2000 participants spanning the period from adolescence to adulthood and integrated with information generated from genomic and imaging-genomic meta-analyses of >300.000 individuals. By targeting specific neural processes the resulting stratification markers will serve as paradigmatic examples for a diagnostic classification, which is based upon quantifiable neurobiological measures, thus enabling targetted early intervention, identification of novel pharmaceutical targets and the establishment of neurobehaviourally informed endpoints for clinical trials.    Medical Research Council    Fellowship    286050.0GBP
12    Dr Long Yang    Newcastle University    2018-02-14    2019-06-30    Intelligent Healthcare Systems for Large-scale Populations    To reduce the burden of mental disorders it is a formidable aim to identify widely applicable disease markers based on neural processes, which predict psychopathology and allow for targeted interventions. We will generate a neurobehavioural framework for stratification of psychopathology by characterising links between network properties of brain function and structure and reinforcement–related behaviours, which are fundamental components of some of the most prevalent mental disorders, major depression, alcohol use disorder and ADHD. We will assess if network configurations define subtypes within and if they correspond to comorbidity across these diagnoses. We will identify discriminative data modalities and characterize predictors of future psychopathology. To identify specific neurobehavioural clusters we will carry out precision phenotyping of 900 patients with major depression, ADHD and alcohol use disorders and 300 controls, which we will investigate with innovative deep machine learning methods derived from artifical intelligence research. Development of these methods will optimize exploitation of a wide range of assessment modalities, including functional and structural neuroimaging, cognitive, emotional as well as environmental measures. The neurobehavioural clusters resulting from this analysis will be validated in a longitudinal population-based imaging genomics cohort, the IMAGEN sample of over 2000 participants spanning the period from adolescence to adulthood and integrated with information generated from genomic and imaging-genomic meta-analyses of >300.000 individuals. By targeting specific neural processes the resulting stratification markers will serve as paradigmatic examples for a diagnostic classification, which is based upon quantifiable neurobiological measures, thus enabling targetted early intervention, identification of novel pharmaceutical targets and the establishment of neurobehaviourally informed endpoints for clinical trials.    Medical Research Council    Fellowship    193284.0GBP
13    Dr Repapi Emmanouela    University of Oxford    2018-04-01    2022-10-28    Novel methods for the integration of high dimensional single cell proteomic and RNA data to understand cell populations in development and disease.    To reduce the burden of mental disorders it is a formidable aim to identify widely applicable disease markers based on neural processes, which predict psychopathology and allow for targeted interventions. We will generate a neurobehavioural framework for stratification of psychopathology by characterising links between network properties of brain function and structure and reinforcement–related behaviours, which are fundamental components of some of the most prevalent mental disorders, major depression, alcohol use disorder and ADHD. We will assess if network configurations define subtypes within and if they correspond to comorbidity across these diagnoses. We will identify discriminative data modalities and characterize predictors of future psychopathology. To identify specific neurobehavioural clusters we will carry out precision phenotyping of 900 patients with major depression, ADHD and alcohol use disorders and 300 controls, which we will investigate with innovative deep machine learning methods derived from artifical intelligence research. Development of these methods will optimize exploitation of a wide range of assessment modalities, including functional and structural neuroimaging, cognitive, emotional as well as environmental measures. The neurobehavioural clusters resulting from this analysis will be validated in a longitudinal population-based imaging genomics cohort, the IMAGEN sample of over 2000 participants spanning the period from adolescence to adulthood and integrated with information generated from genomic and imaging-genomic meta-analyses of >300.000 individuals. By targeting specific neural processes the resulting stratification markers will serve as paradigmatic examples for a diagnostic classification, which is based upon quantifiable neurobiological measures, thus enabling targetted early intervention, identification of novel pharmaceutical targets and the establishment of neurobehaviourally informed endpoints for clinical trials.    Medical Research Council    Fellowship    326906.0GBP
14    Ms Suel Esra    Imperial College London    2018-02-14    2021-02-13    Application of deep learning to heterogeneous open data for measuring urban environment and health    To reduce the burden of mental disorders it is a formidable aim to identify widely applicable disease markers based on neural processes, which predict psychopathology and allow for targeted interventions. We will generate a neurobehavioural framework for stratification of psychopathology by characterising links between network properties of brain function and structure and reinforcement–related behaviours, which are fundamental components of some of the most prevalent mental disorders, major depression, alcohol use disorder and ADHD. We will assess if network configurations define subtypes within and if they correspond to comorbidity across these diagnoses. We will identify discriminative data modalities and characterize predictors of future psychopathology. To identify specific neurobehavioural clusters we will carry out precision phenotyping of 900 patients with major depression, ADHD and alcohol use disorders and 300 controls, which we will investigate with innovative deep machine learning methods derived from artifical intelligence research. Development of these methods will optimize exploitation of a wide range of assessment modalities, including functional and structural neuroimaging, cognitive, emotional as well as environmental measures. The neurobehavioural clusters resulting from this analysis will be validated in a longitudinal population-based imaging genomics cohort, the IMAGEN sample of over 2000 participants spanning the period from adolescence to adulthood and integrated with information generated from genomic and imaging-genomic meta-analyses of >300.000 individuals. By targeting specific neural processes the resulting stratification markers will serve as paradigmatic examples for a diagnostic classification, which is based upon quantifiable neurobiological measures, thus enabling targetted early intervention, identification of novel pharmaceutical targets and the establishment of neurobehaviourally informed endpoints for clinical trials.    Medical Research Council    Fellowship    331573.0GBP
15    Dr Schneider Philipp    University of Southampton    2019-01-16    2022-01-16    Foundations for routine 3D X-ray histology    To reduce the burden of mental disorders it is a formidable aim to identify widely applicable disease markers based on neural processes, which predict psychopathology and allow for targeted interventions. We will generate a neurobehavioural framework for stratification of psychopathology by characterising links between network properties of brain function and structure and reinforcement–related behaviours, which are fundamental components of some of the most prevalent mental disorders, major depression, alcohol use disorder and ADHD. We will assess if network configurations define subtypes within and if they correspond to comorbidity across these diagnoses. We will identify discriminative data modalities and characterize predictors of future psychopathology. To identify specific neurobehavioural clusters we will carry out precision phenotyping of 900 patients with major depression, ADHD and alcohol use disorders and 300 controls, which we will investigate with innovative deep machine learning methods derived from artifical intelligence research. Development of these methods will optimize exploitation of a wide range of assessment modalities, including functional and structural neuroimaging, cognitive, emotional as well as environmental measures. The neurobehavioural clusters resulting from this analysis will be validated in a longitudinal population-based imaging genomics cohort, the IMAGEN sample of over 2000 participants spanning the period from adolescence to adulthood and integrated with information generated from genomic and imaging-genomic meta-analyses of >300.000 individuals. By targeting specific neural processes the resulting stratification markers will serve as paradigmatic examples for a diagnostic classification, which is based upon quantifiable neurobiological measures, thus enabling targetted early intervention, identification of novel pharmaceutical targets and the establishment of neurobehaviourally informed endpoints for clinical trials.    Wellcome Trust    Technology Development Grant    1135071.0GBP
16    Professor Barman Sarah    Kingston University    2018-11-15    2020-11-14    Classification of oral lesions using deep learning for early detection of oral cancer    To reduce the burden of mental disorders it is a formidable aim to identify widely applicable disease markers based on neural processes, which predict psychopathology and allow for targeted interventions. We will generate a neurobehavioural framework for stratification of psychopathology by characterising links between network properties of brain function and structure and reinforcement–related behaviours, which are fundamental components of some of the most prevalent mental disorders, major depression, alcohol use disorder and ADHD. We will assess if network configurations define subtypes within and if they correspond to comorbidity across these diagnoses. We will identify discriminative data modalities and characterize predictors of future psychopathology. To identify specific neurobehavioural clusters we will carry out precision phenotyping of 900 patients with major depression, ADHD and alcohol use disorders and 300 controls, which we will investigate with innovative deep machine learning methods derived from artifical intelligence research. Development of these methods will optimize exploitation of a wide range of assessment modalities, including functional and structural neuroimaging, cognitive, emotional as well as environmental measures. The neurobehavioural clusters resulting from this analysis will be validated in a longitudinal population-based imaging genomics cohort, the IMAGEN sample of over 2000 participants spanning the period from adolescence to adulthood and integrated with information generated from genomic and imaging-genomic meta-analyses of >300.000 individuals. By targeting specific neural processes the resulting stratification markers will serve as paradigmatic examples for a diagnostic classification, which is based upon quantifiable neurobiological measures, thus enabling targetted early intervention, identification of novel pharmaceutical targets and the establishment of neurobehaviourally informed endpoints for clinical trials.    Medical Research Council    Research Grant    146920.0GBP
17    Assoz. Prof. Dr. SCHÖFFMANN Klaus    University of Klagenfurt    2019-04-01    2023-03-31    Surgical Quality Assessment in Gynecologic Laparoscopy    Endoscopic surgeries require specific psychomotor skills that are difficult to learn and teach, and typically result in prolonged learning curves. These psychomotor skills have direct impact on the performance of the surgery, especially in a field with complex operation techniques. In order to assess surgical quality objectively, medical experts currently record the entire surgery on video and inspect and analyze the unedited video footage in a post-operative session for the occurrence of technical errors, according to some standardized rating scheme. Several studies have shown that such post-operative analysis of errors and the reporting of them to the responsible surgeons can significantly improve their performance over time and lead to better surgical quality, especially for young surgeons. However, currently the surgical quality assessment (SQA) process is so tedious and time-consuming that many surgeons/clinicians cannot afford to perform such error ratings, which is very unfortunate since their application would improve surgical quality and patient outcome. The main reason for the high effort is the fact that it is performed without any special error rating software, but with common software video players and manually edited checklists, where surgeons enter timestamps of corresponding relevant scenes in the video. This renders SQA currently not only a very time-consuming process, but also a very error-prone one. In this research project we want to address this issue and find out how we can make surgical quality assessment (SQA) more efficient through automatic video content analysis and, hence, more feasible. More specifically, for the field of gynecologic laparoscopy we want to investigate to what extent current methods of machine learning and content-based video retrieval can support SQA (i.e., optimize the entire process through automatic classification and retrieval of technical errors). For that purpose, we will evaluate deep learning approaches as well as video content description and similarity search. We consider this research project as a pioneering work in the interdisciplinary overlap of computer- and medical science, which will investigate fundamental research questions that should provide the basis for future computer-aided SQA. We expect that our research results will help to significantly facilitate the currently cumbersome and error-prone SQA process, and hence enable more surgeons to actually perform error ratings. We expect this project even to contribute to improve surgical education in the long run (through higher penetration of the SQA process – due to lower time effort), and thereby raise surgical quality itself. Project results and their later application in appropriate software tools could help surgeons to keep track of their surgical actions in a novel, highly efficient way, and thus help them to avoid technical errors. This will not only save valuable time of medical experts and increase the performance of quality assessment, but also contribute to surgical risk management and quality control.    Austrian Science Fund FWF    01 Stand-Alone Projects    388542.0EUR
18    Dr Robinson Emma    King's College London    2019-03-01    2021-02-28    What makes your mind unique? Tailoring brain network models to individuals to enhance predictions of neurological development and disease.    Endoscopic surgeries require specific psychomotor skills that are difficult to learn and teach, and typically result in prolonged learning curves. These psychomotor skills have direct impact on the performance of the surgery, especially in a field with complex operation techniques. In order to assess surgical quality objectively, medical experts currently record the entire surgery on video and inspect and analyze the unedited video footage in a post-operative session for the occurrence of technical errors, according to some standardized rating scheme. Several studies have shown that such post-operative analysis of errors and the reporting of them to the responsible surgeons can significantly improve their performance over time and lead to better surgical quality, especially for young surgeons. However, currently the surgical quality assessment (SQA) process is so tedious and time-consuming that many surgeons/clinicians cannot afford to perform such error ratings, which is very unfortunate since their application would improve surgical quality and patient outcome. The main reason for the high effort is the fact that it is performed without any special error rating software, but with common software video players and manually edited checklists, where surgeons enter timestamps of corresponding relevant scenes in the video. This renders SQA currently not only a very time-consuming process, but also a very error-prone one. In this research project we want to address this issue and find out how we can make surgical quality assessment (SQA) more efficient through automatic video content analysis and, hence, more feasible. More specifically, for the field of gynecologic laparoscopy we want to investigate to what extent current methods of machine learning and content-based video retrieval can support SQA (i.e., optimize the entire process through automatic classification and retrieval of technical errors). For that purpose, we will evaluate deep learning approaches as well as video content description and similarity search. We consider this research project as a pioneering work in the interdisciplinary overlap of computer- and medical science, which will investigate fundamental research questions that should provide the basis for future computer-aided SQA. We expect that our research results will help to significantly facilitate the currently cumbersome and error-prone SQA process, and hence enable more surgeons to actually perform error ratings. We expect this project even to contribute to improve surgical education in the long run (through higher penetration of the SQA process – due to lower time effort), and thereby raise surgical quality itself. Project results and their later application in appropriate software tools could help surgeons to keep track of their surgical actions in a novel, highly efficient way, and thus help them to avoid technical errors. This will not only save valuable time of medical experts and increase the performance of quality assessment, but also contribute to surgical risk management and quality control.    The Academy of Medical Sciences    Springboard Round 3    99641.68GBP
19    Dr. SCHÖTTLE Pascal    Management Center Innsbruck    2019-01-01    2021-12-31    Game Over Eva(sion): Securing Deep Learning with Game Theory    The project "Game Over Eva(sion): Securing Deep Learning with Game Theory" aims at finding theoretical foundations for deep learning classifiers robust to evasion attacks. Given the popularity of classifiers based on deep learning, not only in scientific research but also in practice, it is not surprising that recently various vulnerabilities of these classifiers were discovered. The most severe in our opinion is the existence of so-called adversarial examples: slightly modified benign objects that get misclassified with a very high probability and confidence. In terms of adversarial machine learning, these examples constitute so-called evasion attacks. Surprisingly, a soon to be published (at this year’s IEEE Euro S&P conference) Systematization-of-knowledge article by leading researchers in the field of machine and deep learning completely disregards considering the competition between an attacker against a deep learning classifier and its defender from the point of game theory. Game theory is already widespread in many areas dealing with security, even “non-deep” adversarial machine learning. We are very aware of the key difficulty in applying game theory to deep learning, which is to find the right level of complexity of the analytical models such that they are tractable for game-theoretic solution concepts, but at the same time do not degenerate the learning problem to instances that do not require deep networks. Still, we plan to address this research gap in a number of innovative ways: a) by systematizing the knowledge of adversarial machine learning from the game-theoretic point of view, including insights from adversarial classification and adversarial signal processing; b) by identifying how existing approaches, such as adversarial re-training and the detection of adversarial examples, fit into game theoretical concepts; and c) by implementing the key properties of our theoretical findings in practical deep learning classifiers and comparing them in terms of accuracy and robustness to state of the art neural network classifiers. The project is a co-operation between the University of Innsbruck and Czech Technical University in Prague. The Austrian project leader will be Dr. Pascal Schöttle, who specialized in the application of game theory in security-sensitive domains. On the Czech side, Ing. Tomáš Pevny´ Ph.D, and Ass. Prof. Branislav Bosansky, both experienced in game theory, machine learning and network security will lead the project. The project team as a whole has been applying machine learning to security problems for more than ten years and published extensively, among others on game theory and security.    Austrian Science Fund FWF    02 International programmes    354137.49EUR
20    Dr Droop Alastair    Wellcome Trust Sanger Institute    2019-04-08    2021-02-13    Facilitating Deep Learning with Domain-Specific Knowledge    The project "Game Over Eva(sion): Securing Deep Learning with Game Theory" aims at finding theoretical foundations for deep learning classifiers robust to evasion attacks. Given the popularity of classifiers based on deep learning, not only in scientific research but also in practice, it is not surprising that recently various vulnerabilities of these classifiers were discovered. The most severe in our opinion is the existence of so-called adversarial examples: slightly modified benign objects that get misclassified with a very high probability and confidence. In terms of adversarial machine learning, these examples constitute so-called evasion attacks. Surprisingly, a soon to be published (at this year’s IEEE Euro S&P conference) Systematization-of-knowledge article by leading researchers in the field of machine and deep learning completely disregards considering the competition between an attacker against a deep learning classifier and its defender from the point of game theory. Game theory is already widespread in many areas dealing with security, even “non-deep” adversarial machine learning. We are very aware of the key difficulty in applying game theory to deep learning, which is to find the right level of complexity of the analytical models such that they are tractable for game-theoretic solution concepts, but at the same time do not degenerate the learning problem to instances that do not require deep networks. Still, we plan to address this research gap in a number of innovative ways: a) by systematizing the knowledge of adversarial machine learning from the game-theoretic point of view, including insights from adversarial classification and adversarial signal processing; b) by identifying how existing approaches, such as adversarial re-training and the detection of adversarial examples, fit into game theoretical concepts; and c) by implementing the key properties of our theoretical findings in practical deep learning classifiers and comparing them in terms of accuracy and robustness to state of the art neural network classifiers. The project is a co-operation between the University of Innsbruck and Czech Technical University in Prague. The Austrian project leader will be Dr. Pascal Schöttle, who specialized in the application of game theory in security-sensitive domains. On the Czech side, Ing. Tomáš Pevny´ Ph.D, and Ass. Prof. Branislav Bosansky, both experienced in game theory, machine learning and network security will lead the project. The project team as a whole has been applying machine learning to security problems for more than ten years and published extensively, among others on game theory and security.    Medical Research Council    Fellowship    185651.0GBP
21    Dr Gurdasani Deepti    Wellcome Trust Sanger Institute    2018-02-14    2019-06-25    Predictive analytics of integrated genomic and clinical data using machine learning and complex statistical approaches    The project "Game Over Eva(sion): Securing Deep Learning with Game Theory" aims at finding theoretical foundations for deep learning classifiers robust to evasion attacks. Given the popularity of classifiers based on deep learning, not only in scientific research but also in practice, it is not surprising that recently various vulnerabilities of these classifiers were discovered. The most severe in our opinion is the existence of so-called adversarial examples: slightly modified benign objects that get misclassified with a very high probability and confidence. In terms of adversarial machine learning, these examples constitute so-called evasion attacks. Surprisingly, a soon to be published (at this year’s IEEE Euro S&P conference) Systematization-of-knowledge article by leading researchers in the field of machine and deep learning completely disregards considering the competition between an attacker against a deep learning classifier and its defender from the point of game theory. Game theory is already widespread in many areas dealing with security, even “non-deep” adversarial machine learning. We are very aware of the key difficulty in applying game theory to deep learning, which is to find the right level of complexity of the analytical models such that they are tractable for game-theoretic solution concepts, but at the same time do not degenerate the learning problem to instances that do not require deep networks. Still, we plan to address this research gap in a number of innovative ways: a) by systematizing the knowledge of adversarial machine learning from the game-theoretic point of view, including insights from adversarial classification and adversarial signal processing; b) by identifying how existing approaches, such as adversarial re-training and the detection of adversarial examples, fit into game theoretical concepts; and c) by implementing the key properties of our theoretical findings in practical deep learning classifiers and comparing them in terms of accuracy and robustness to state of the art neural network classifiers. The project is a co-operation between the University of Innsbruck and Czech Technical University in Prague. The Austrian project leader will be Dr. Pascal Schöttle, who specialized in the application of game theory in security-sensitive domains. On the Czech side, Ing. Tomáš Pevny´ Ph.D, and Ass. Prof. Branislav Bosansky, both experienced in game theory, machine learning and network security will lead the project. The project team as a whole has been applying machine learning to security problems for more than ten years and published extensively, among others on game theory and security.    Medical Research Council    Fellowship    319508.0GBP
22    Dr Wright David    Queen's University of Belfast    2018-02-14    2021-02-13    Data driven public health approaches for diabetic retinopathy and age-related macular degeneration    The project "Game Over Eva(sion): Securing Deep Learning with Game Theory" aims at finding theoretical foundations for deep learning classifiers robust to evasion attacks. Given the popularity of classifiers based on deep learning, not only in scientific research but also in practice, it is not surprising that recently various vulnerabilities of these classifiers were discovered. The most severe in our opinion is the existence of so-called adversarial examples: slightly modified benign objects that get misclassified with a very high probability and confidence. In terms of adversarial machine learning, these examples constitute so-called evasion attacks. Surprisingly, a soon to be published (at this year’s IEEE Euro S&P conference) Systematization-of-knowledge article by leading researchers in the field of machine and deep learning completely disregards considering the competition between an attacker against a deep learning classifier and its defender from the point of game theory. Game theory is already widespread in many areas dealing with security, even “non-deep” adversarial machine learning. We are very aware of the key difficulty in applying game theory to deep learning, which is to find the right level of complexity of the analytical models such that they are tractable for game-theoretic solution concepts, but at the same time do not degenerate the learning problem to instances that do not require deep networks. Still, we plan to address this research gap in a number of innovative ways: a) by systematizing the knowledge of adversarial machine learning from the game-theoretic point of view, including insights from adversarial classification and adversarial signal processing; b) by identifying how existing approaches, such as adversarial re-training and the detection of adversarial examples, fit into game theoretical concepts; and c) by implementing the key properties of our theoretical findings in practical deep learning classifiers and comparing them in terms of accuracy and robustness to state of the art neural network classifiers. The project is a co-operation between the University of Innsbruck and Czech Technical University in Prague. The Austrian project leader will be Dr. Pascal Schöttle, who specialized in the application of game theory in security-sensitive domains. On the Czech side, Ing. Tomáš Pevny´ Ph.D, and Ass. Prof. Branislav Bosansky, both experienced in game theory, machine learning and network security will lead the project. The project team as a whole has been applying machine learning to security problems for more than ten years and published extensively, among others on game theory and security.    Medical Research Council    Fellowship    279158.0GBP
23    Prof. NEUPERT Titus    University Of Zurich    2018-01-01    2022-12-31    New paradigms for correlated quantum matter: Hierarchical topology, Kondo topological metals, and deep learning    Discovering, classifying and understanding phases of quantum matter is a core goal of condensed matter physics. Next to the notion of symmetry breaking phases, the concept of topological phases of matter is a prevailing theme of recent research. Topological phases are envisioned for various applications due to their universal and robust properties, such as protected conducting boundary modes, and provoke fundamental questions about the nature of many-body quantum states by providing the basis for exotic quasiparticles. In this ERC research project, I propose several new topological phases and novel numerical approaches for studying and classifying the most sought-after topological phases of matter. Concretely, I propose the concept of three-dimensional hierarchical topological insulators, which, in contrast to the known topological phases, do not posses gapless surface, but protected gapless edge modes. Moreover, I plan to study topological metals arising in strongly correlated Kondo systems, going beyond the current paradigm of considering topological metals that arise in the absence of electronic correlations. Furthermore, I propose to make the analogous step for topological superconductors, which have been studied as free models to search for Majorana quasiparticles: For the first time, I want to explore strongly interacting systems that realize the more powerful parafermion quasiparticles with numerical techniques. Finally, in a cross-disciplinary and exploratory sub-project, I will employ methods of deep neural networks to classify strongly correlated quantum phases using supervised learning combined with a technique called deep dreaming. Each of these sub-projects has the potential to make a paradigm-changing contribution to the study of strongly correlated and topological states of quantum matter and the combination of them allows to take advantage of synergy effects and a balance between high-risk and definitely feasible key developments.    European Research Council    Starting Grant    1362401.0EUR
24    Dr Lilaonitkul Watjana    University College London    2018-02-14    2021-02-13    Artificial Intelligence in Medical Treatment Decisions and Diagnosis    Discovering, classifying and understanding phases of quantum matter is a core goal of condensed matter physics. Next to the notion of symmetry breaking phases, the concept of topological phases of matter is a prevailing theme of recent research. Topological phases are envisioned for various applications due to their universal and robust properties, such as protected conducting boundary modes, and provoke fundamental questions about the nature of many-body quantum states by providing the basis for exotic quasiparticles. In this ERC research project, I propose several new topological phases and novel numerical approaches for studying and classifying the most sought-after topological phases of matter. Concretely, I propose the concept of three-dimensional hierarchical topological insulators, which, in contrast to the known topological phases, do not posses gapless surface, but protected gapless edge modes. Moreover, I plan to study topological metals arising in strongly correlated Kondo systems, going beyond the current paradigm of considering topological metals that arise in the absence of electronic correlations. Furthermore, I propose to make the analogous step for topological superconductors, which have been studied as free models to search for Majorana quasiparticles: For the first time, I want to explore strongly interacting systems that realize the more powerful parafermion quasiparticles with numerical techniques. Finally, in a cross-disciplinary and exploratory sub-project, I will employ methods of deep neural networks to classify strongly correlated quantum phases using supervised learning combined with a technique called deep dreaming. Each of these sub-projects has the potential to make a paradigm-changing contribution to the study of strongly correlated and topological states of quantum matter and the combination of them allows to take advantage of synergy effects and a balance between high-risk and definitely feasible key developments.    Medical Research Council    Fellowship    313016.0GBP
25    Professor Lotery Andrew    University of Southampton    2019-01-01    2024-01-01    Deciphering AMD by deep phenotyping and machine learning    None    Wellcome Trust    Collaborative Award in Science    3980169.0GBP
26    Professor Lotery Andrew    University of Lincoln    2020-09-07    2023-09-06    Towards an open-source, equipment-agnostic framework for automated welfare monitoring in the home cage    The moral implications of using mice and other higher animals in biomedical research has been a topic of debate for many years, and has steered various efforts towards minimising animal suffering. As the number of mice used in biomedical research continues to rise, there is greater emphasis than ever on approaches to refine husbandry protocols and humane endpoints to ensure that welfare concerns are dealt with swiftly and efficiently. Home cage monitoring has been proposed as a means capturing animal behaviour through the light and dark phases so that welfare deficits might be captured without the need for human intervention. Several commercial and non-commercial systems have been designed to capture video footage (and other data) of mice that offer several advantages over conventional experimental designs: (1) behaviours can be captured in a familiar, enriched environment; (2) observations are not confounded by novel apparatus or human experimenters; (3) it serves as a permanent digital record; and (4) video data are amenable to automated image analysis techniques. The challenge that remains in the context of HCA is the ability to analyse video footage in a manner that is fully-automated, comprehensive, robust, and computationally efficient. Under this proposal, the successful studentship awardee will develop a solution to the problem of automated HCA based on deep learning; a state-of-the-art approach to computer vision problems that utilises computational models inspired by the human visual cortex. The technique will be based on the "anomaly detection", whereby a model is initially trained to capture the range of possible behaviours exhibited by mice under normal circumstances (i.e., without welfare deficits). The methods works by learning to produce a set of visual and motion features that describe the behaviours of the mice, and then having the same model attempt to "reconstruct" the input clip from the features. In doing so, the model is forced to capture only key information about normal behaviour. Given that video clips depicting welfare deficits are visually different normal behaviors by definition, the model will be less capable of representing those data. Dr James Brown will be the primary supervisor of this work, who has a strong record of interdisciplinary research involving mouse models. He has previously worked with the Mary Lyon Centre - a collaborator on this project - on development 3D image analysis techniques for mouse embryo phenotyping. He has recently published several high-impact articles on machine learning techniques for the diagnosis of retinal disease, and is currently seeking approval from the US Food & Drug Administration. Prof Xujiong Ye will co-supervise this project, bringing more than 20 years' experience in computer vision and medical image analysis in both industry and academia. The methods outlined in this proposal align well recent work published Prof Ye on the development of algorithms to track and assess the welfare of farmyard pigs from top-down video footage.    National Centre for the Replacement, Refinement and Reduction of Animals in Research    Studentship    90000.0GBP
27    Prof. NEUPERT Titus    University Of Zurich    2018-01-01    2022-12-31    New paradigms for correlated quantum matter: Hierarchical topology, Kondo topological metals, and deep learning    Discovering, classifying and understanding phases of quantum matter is a core goal of condensed matter physics. Next to the notion of symmetry breaking phases, the concept of topological phases of matter is a prevailing theme of recent research. Topological phases are envisioned for various applications due to their universal and robust properties, such as protected conducting boundary modes, and provoke fundamental questions about the nature of many-body quantum states by providing the basis for exotic quasiparticles. In this ERC research project, I propose several new topological phases and novel numerical approaches for studying and classifying the most sought-after topological phases of matter. Concretely, I propose the concept of three-dimensional hierarchical topological insulators, which, in contrast to the known topological phases, do not posses gapless surface, but protected gapless edge modes. Moreover, I plan to study topological metals arising in strongly correlated Kondo systems, going beyond the current paradigm of considering topological metals that arise in the absence of electronic correlations. Furthermore, I propose to make the analogous step for topological superconductors, which have been studied as free models to search for Majorana quasiparticles: For the first time, I want to explore strongly interacting systems that realize the more powerful parafermion quasiparticles with numerical techniques. Finally, in a cross-disciplinary and exploratory sub-project, I will employ methods of deep neural networks to classify strongly correlated quantum phases using supervised learning combined with a technique called deep dreaming. Each of these sub-projects has the potential to make a paradigm-changing contribution to the study of strongly correlated and topological states of quantum matter and the combination of them allows to take advantage of synergy effects and a balance between high-risk and definitely feasible key developments.    European Research Council    Starting Grant    1362401.0EUR
28    Dr Lilaonitkul Watjana    University College London    2018-02-14    2021-02-13    Artificial Intelligence in Medical Treatment Decisions and Diagnosis    Discovering, classifying and understanding phases of quantum matter is a core goal of condensed matter physics. Next to the notion of symmetry breaking phases, the concept of topological phases of matter is a prevailing theme of recent research. Topological phases are envisioned for various applications due to their universal and robust properties, such as protected conducting boundary modes, and provoke fundamental questions about the nature of many-body quantum states by providing the basis for exotic quasiparticles. In this ERC research project, I propose several new topological phases and novel numerical approaches for studying and classifying the most sought-after topological phases of matter. Concretely, I propose the concept of three-dimensional hierarchical topological insulators, which, in contrast to the known topological phases, do not posses gapless surface, but protected gapless edge modes. Moreover, I plan to study topological metals arising in strongly correlated Kondo systems, going beyond the current paradigm of considering topological metals that arise in the absence of electronic correlations. Furthermore, I propose to make the analogous step for topological superconductors, which have been studied as free models to search for Majorana quasiparticles: For the first time, I want to explore strongly interacting systems that realize the more powerful parafermion quasiparticles with numerical techniques. Finally, in a cross-disciplinary and exploratory sub-project, I will employ methods of deep neural networks to classify strongly correlated quantum phases using supervised learning combined with a technique called deep dreaming. Each of these sub-projects has the potential to make a paradigm-changing contribution to the study of strongly correlated and topological states of quantum matter and the combination of them allows to take advantage of synergy effects and a balance between high-risk and definitely feasible key developments.    Medical Research Council    Fellowship    313016.0GBP
29    Dr Sanderson Theo    The Francis Crick Institute    2017-06-01    2021-05-31    Revealing the systems biology of malaria with a super-resolution atlas of the Plasmodium parasite    Discovering, classifying and understanding phases of quantum matter is a core goal of condensed matter physics. Next to the notion of symmetry breaking phases, the concept of topological phases of matter is a prevailing theme of recent research. Topological phases are envisioned for various applications due to their universal and robust properties, such as protected conducting boundary modes, and provoke fundamental questions about the nature of many-body quantum states by providing the basis for exotic quasiparticles. In this ERC research project, I propose several new topological phases and novel numerical approaches for studying and classifying the most sought-after topological phases of matter. Concretely, I propose the concept of three-dimensional hierarchical topological insulators, which, in contrast to the known topological phases, do not posses gapless surface, but protected gapless edge modes. Moreover, I plan to study topological metals arising in strongly correlated Kondo systems, going beyond the current paradigm of considering topological metals that arise in the absence of electronic correlations. Furthermore, I propose to make the analogous step for topological superconductors, which have been studied as free models to search for Majorana quasiparticles: For the first time, I want to explore strongly interacting systems that realize the more powerful parafermion quasiparticles with numerical techniques. Finally, in a cross-disciplinary and exploratory sub-project, I will employ methods of deep neural networks to classify strongly correlated quantum phases using supervised learning combined with a technique called deep dreaming. Each of these sub-projects has the potential to make a paradigm-changing contribution to the study of strongly correlated and topological states of quantum matter and the combination of them allows to take advantage of synergy effects and a balance between high-risk and definitely feasible key developments.    Wellcome Trust    Sir Henry Wellcome Postdoctoral Fellowship    250000.0GBP
30    MSc BSc REISENHOFER Rafael    University of Vienna    2018-10-15    2020-10-14    Depth and Discriminability in Deep Learning Architectures    Deep neural networks have recently provided astounding results in a wide range of classification and regression tasks. This has sparked a renewed interest in the rigorous mathematical analysis of deep neural network architectures with the goal of uncovering the underlying principles that facilitate their groundbreaking success. Recent fundamental results already provide a better understanding of the relationship between depth and expressive power as well as a detailed analysis of the approximation properties of deep neural networks. It was also shown that certain types of convolutional neural networks exhibit desirable invariance properties such as stability with respect to small deformations. The present proposal aims at a mathematical investigation of another important property of a deep learning architecture, namely its discriminatory behavior. In most classification tasks, different classes are intertwined in a complex manner in the input space. In order to succeed, the realization of a deep neural network needs to disentangle those classes such that they can be separated in the corresponding feature space. Our goal is to better understand how the depth and other characteristics of a neural network influence its discriminatory power in the sense that they facilitate a clear separation of signal classes. Eventually, we aim to prove statements that quantify the discriminative power of a deep learning architecture with respect to distinct classes of signals as a function of depth and properties of the corresponding signals. The classification behavior of a neural network is mostly determined by its invariance properties on one side and its discriminatory properties on the other side. We will thus focus our investigation on a special class of convolutional neural networks, so-called scattering networks, for which substantial results regarding invariance and stability have already been established. We furthermore aim to utilize that when considering the modulus squared as a non-linearity, the output of each layer in a scattering network can be explicitly written as a cascade of autocorrelations in the frequency domain. In the initial phase of the project, we will investigate the discriminatory properties of scattering architectures with respect to simple template signal classes, such as signals that are sparse in the time or frequency domain. We then aim to extend our analysis to signal classes that resemble the structure of practical machine learning tasks in the sense that they are defined by shifts and time-frequency deformations of single prototype signals. Eventually, we aim to translate our theoretical findings into applicable guidelines regarding the optimal design of deep learning architectures for specific classification tasks. The research will primarily be conducted by the applicant (Rafael Reisenhofer) on a full-time basis. The work of the applicant will be supported by the invaluable expertise of the co-applicant (Philipp Grohs).    Austrian Science Fund FWF    Sir Henry Wellcome Postdoctoral Fellowship    156140.0EUR
31    Assoz. Prof. Dr. SCHÖFFMANN Klaus    University of Klagenfurt    2018-10-01    2021-09-30    Relevance Detection of Ophthalmic Surgery Videos    In this project, we want to investigate fundamental research questions in the field of postoperative analysis of ophthalmic surgery videos (OSVs). More precisely, three research objectives are covered: (1) Classification of OSV segments - is it possible to improve upon the state-of-the-art in automatic content classification and content segmentation of OSVs, focusing on regular and irregular operation phases? (2) Relevance prediction and relevance-driven compression - how accurately can the relevance of OSV segments be determined automatically for educational, scientific, and documentary purposes (as medical experts would do), and what compression efficiency can be achieved for OSVs when considering relevance as an additional modality? (3) Analysis of common irregularities in OSVs for medical research - we address three quantitative medical research questions related to cataract surgeries, such as: is there a statistically significant difference in duration or complication rate between cataract surgeries showing intraoperative pupil reactions and those showing no such pupil reactions? We plan to perform these investigations using data acquisition, data modelling, video content analysis, statistical analysis, and state-of-the-art machine learning methods - such as content classifiers based on deep learning. The proposed methods will be evaluated on annotated video datasets ("ground truth") created by medical field experts during the project. Beyond developing novel methods for solving the abovementioned research problems, project results are expected to have innovative effects in the emerging interdisciplinary field of automatic video-based analysis of ophthalmic surgeries. In particular, research results of this project will enable efficient permanent video documentation of ophthalmic surgeries, allowing to create OSV datasets relevant for medical education, training, and research. Moreover, archives of relevant OSVs will enable novel postoperative analysis methods for medical research questions - such as causes for irregular operation phases, for example. The research project will be a cooperation between computer scientists of AAU Klagenfurt (conducted by Prof. Klaus Schöffmann, supported and advised by Dr. Mario Taschwer and Prof. Laszlo Böszörmenyi) and ophthalmic surgeons and researchers at Klinikum Klagenfurt (Dr. Doris Putzgruber-Adamitsch, Dr. Stephanie Sarny, Prof. Yosuf El-Shabrawi).    Austrian Science Fund FWF    Sir Henry Wellcome Postdoctoral Fellowship    379635.38EUR
32    Assoz. Prof. Dr. SCHÖFFMANN Klaus    University of Texas at Dallas    2020-05-01    2021-04-30    RAPID: Collaborative Research: Operational COVID-19 Forecasting with Multi-Source Information    Mathematical and Physical Sciences - This project aims to develop a new deep learning predictive platform for COVID-19 transmission, integrating multi-source information under model and data uncertainties. In contrast to other viruses such as influenza, SARS, and MERS, COVID-19 differs in a number of ways, including uncertainties in response to weather conditions, history of the disease, as well as the effectiveness of responses from public health officials or from the general public. An important aspect is to integrate multi-source data such as official reports, atmospheric variables, and social media data into operational biosurveillance and real-time prediction of COVID-19. The proposed biosurveillance framework will be used to forecast COVID-19 dynamics and to enhance mitigation strategies. In addition, it could also be applicable to tracking many other infectious diseases, thereby contributing to security of our society as a whole. Furthermore, the project will build innovative connections within and across mathematical biology, statistics, and deep learning, with a strong focus on interdisciplinary graduate research training.<br/><br/>As the main forecasting framework, the widely used Susceptible-Exposed-Infected-Recovered (SEIR) dynamic models can accurately describe the disease dynamics, but only with precise knowledge of disease parameters, which can take a long time to accurately estimate. Deep learning algorithms can potentially have superior predictive ability, but they require extensive training. Another key challenge in the statistical modeling of these events is how to timely and systematically integrate multiple sources of surveillance, anecdotal, and other health-related information under uncertainty. The proposed new predictive approach is based on the interaction between multiple data sources, dynamical SEIR models, and deep learning algorithms. The key idea is to view simulation SEIR models as ?surrogate? pre-trainers for the deep learning models, resulting in less real data needed to retrain the predictive model to reflect ?real world? COVID-19 progression. Deep learning predictive models can then be used for making predictions about the future COVID-19 dynamics, which can be compared to the predictions made by the original SEIR model. Depending on which mathematical model makes better predictions, another model can be updated with the better prediction as inputs, thereby representing reinforcement learning from both data and the best mathematical model. As a result, the new predictive framework will allow one to assess impacts of the immediate responses such as declaration of a national emergency, a school closing, or a quarantine, and can be considered as a step toward interpretable AI for COVID-19 biosurveillance.<br/><br/>This grant is being awarded using funds made available by the Coronavirus Aid, Relief, and Economic Security (CARES) Act supplemental funds allocated to MPS.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    National Science Foundation    Research Grant    80169.0USD
33    Assoz. Prof. Dr. SCHÖFFMANN Klaus    Research Triangle Institute    2020-05-01    2021-04-30    RAPID: Collaborative Research: Operational COVID-19 Forecasting with Multi-Source Information    Mathematical and Physical Sciences - This project aims to develop a new deep learning predictive platform for COVID-19 transmission, integrating multi-source information under model and data uncertainties. In contrast to other viruses such as influenza, SARS, and MERS, COVID-19 differs in a number of ways, including uncertainties in response to weather conditions, history of the disease, as well as the effectiveness of responses from public health officials or from the general public. An important aspect is to integrate multi-source data such as official reports, atmospheric variables, and social media data into operational biosurveillance and real-time prediction of COVID-19. The proposed biosurveillance framework will be used to forecast COVID-19 dynamics and to enhance mitigation strategies. In addition, it could also be applicable to tracking many other infectious diseases, thereby contributing to security of our society as a whole. Furthermore, the project will build innovative connections within and across mathematical biology, statistics, and deep learning, with a strong focus on interdisciplinary graduate research training.<br/><br/>As the main forecasting framework, the widely used Susceptible-Exposed-Infected-Recovered (SEIR) dynamic models can accurately describe the disease dynamics, but only with precise knowledge of disease parameters, which can take a long time to accurately estimate. Deep learning algorithms can potentially have superior predictive ability, but they require extensive training. Another key challenge in the statistical modeling of these events is how to timely and systematically integrate multiple sources of surveillance, anecdotal, and other health-related information under uncertainty. The proposed new predictive approach is based on the interaction between multiple data sources, dynamical SEIR models, and deep learning algorithms. The key idea is to view simulation SEIR models as ?surrogate? pre-trainers for the deep learning models, resulting in less real data needed to retrain the predictive model to reflect ?real world? COVID-19 progression. Deep learning predictive models can then be used for making predictions about the future COVID-19 dynamics, which can be compared to the predictions made by the original SEIR model. Depending on which mathematical model makes better predictions, another model can be updated with the better prediction as inputs, thereby representing reinforcement learning from both data and the best mathematical model. As a result, the new predictive framework will allow one to assess impacts of the immediate responses such as declaration of a national emergency, a school closing, or a quarantine, and can be considered as a step toward interpretable AI for COVID-19 biosurveillance.<br/><br/>This grant is being awarded using funds made available by the Coronavirus Aid, Relief, and Economic Security (CARES) Act supplemental funds allocated to MPS.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    National Science Foundation    Research Grant    89755.0USD
34    Assoz. Prof. Dr. SCHÖFFMANN Klaus    Clark University    2020-05-15    2021-04-30    RAPID: Predicting Coronavirus Disease (COVID-19) Impact with Multiscale Contact and Transmission Mitigation    Mathematical and Physical Sciences - Nontechnical Abstract: <br/>The rapid spread of new coronavirus SARS-CoV-2, which causes Coronavirus Disease (covid-19), requires a multidisciplinary mitigation strategy from the clinical to physical host-to-host transmission modelling. Data is required on the transmission of pathogen carrying airborne mucosalivary droplets and aerosols generated during normal breathing, talking, sneezing, and coughing. Synthetic exhalations will be measured leveraging advanced prototyping to obtain data needed to model the spread of covid-19, and the efficacy of personal protection devices and face coverings fabricated with various weaves and materials will be tested. Physical data related to temperature, humidity, and airflow on survival and dispersion of exhalations will be obtained. The data will be integrated using supervised machine learning methods, mathematical network simulations, and epidemiological data to develop an individual-based method that can give pandemic management results. Physical data will be published on transmission rates, including wearing of personal protective equipment and face coverings with various weaves, to inform mitigation strategies to alleviate covid-19 pandemic. Interactive Web based resources will be used for immediate broad dissemination of data and learning outcomes on covid-19 to the public, in addition to peer reviewed publications and training post-doctoral and undergraduate researchers in methods leading to pandemic mitigation.<br/><br/>Technical Abstract:<br/>The mode of transmission and extent of environmental contaminations on the outbreak of the Coronavirus Disease 2019 (covid-19), while sharing features with severe acute respiratory syndrome and other infectious diseases, remains unknown. This project will address fundamental rheology-matched metrics of transport and survival of airborne exhalation droplets and aerosols that carry coronavirus and on surfaces needed as input parameters for modeling mitigation. Impact of personal protective equipment on individual prognosis, with physical data related to temperature, humidity, and airflow-dependent dispersion distance of pathogen bearing viscoelastic droplets corresponding to breathing, sneezing, and coughing, will be obtained. The impact of the measured transmission rates on the spread and recurrence will be investigated with epidemiological data integrated with deep learning to implement a scalable, individual-based, stochastic, spatial model. Resulting peer-reviewed publications will serve as trusted source for calculation of covid-19 transmissibility and personal protection strategies. Post-doctoral and undergraduate researchers versed in fluid dynamics, soft matter physics, and network simulations will be trained toward mitigating infectious disease spread.<br/><br/>This Rapid Response Research (RAPID) grant supports research that will result in spatiotemporal mucosalivary droplet transmission range data required to develop covid-19 mitigation network methods with funding from the CARES Act managed by the Condensed Matter Physics Program in the Division of Materials Research of the Mathematical and Physical Sciences Directorate.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    National Science Foundation    Research Grant    200000.0USD
35    Dr Rolinski Michal    University of Bristol    2019-03-01    2021-02-28    Tracking motoric progression in established and prodromal Parkinson's disease    Mathematical and Physical Sciences - Nontechnical Abstract: <br/>The rapid spread of new coronavirus SARS-CoV-2, which causes Coronavirus Disease (covid-19), requires a multidisciplinary mitigation strategy from the clinical to physical host-to-host transmission modelling. Data is required on the transmission of pathogen carrying airborne mucosalivary droplets and aerosols generated during normal breathing, talking, sneezing, and coughing. Synthetic exhalations will be measured leveraging advanced prototyping to obtain data needed to model the spread of covid-19, and the efficacy of personal protection devices and face coverings fabricated with various weaves and materials will be tested. Physical data related to temperature, humidity, and airflow on survival and dispersion of exhalations will be obtained. The data will be integrated using supervised machine learning methods, mathematical network simulations, and epidemiological data to develop an individual-based method that can give pandemic management results. Physical data will be published on transmission rates, including wearing of personal protective equipment and face coverings with various weaves, to inform mitigation strategies to alleviate covid-19 pandemic. Interactive Web based resources will be used for immediate broad dissemination of data and learning outcomes on covid-19 to the public, in addition to peer reviewed publications and training post-doctoral and undergraduate researchers in methods leading to pandemic mitigation.<br/><br/>Technical Abstract:<br/>The mode of transmission and extent of environmental contaminations on the outbreak of the Coronavirus Disease 2019 (covid-19), while sharing features with severe acute respiratory syndrome and other infectious diseases, remains unknown. This project will address fundamental rheology-matched metrics of transport and survival of airborne exhalation droplets and aerosols that carry coronavirus and on surfaces needed as input parameters for modeling mitigation. Impact of personal protective equipment on individual prognosis, with physical data related to temperature, humidity, and airflow-dependent dispersion distance of pathogen bearing viscoelastic droplets corresponding to breathing, sneezing, and coughing, will be obtained. The impact of the measured transmission rates on the spread and recurrence will be investigated with epidemiological data integrated with deep learning to implement a scalable, individual-based, stochastic, spatial model. Resulting peer-reviewed publications will serve as trusted source for calculation of covid-19 transmissibility and personal protection strategies. Post-doctoral and undergraduate researchers versed in fluid dynamics, soft matter physics, and network simulations will be trained toward mitigating infectious disease spread.<br/><br/>This Rapid Response Research (RAPID) grant supports research that will result in spatiotemporal mucosalivary droplet transmission range data required to develop covid-19 mitigation network methods with funding from the CARES Act managed by the Condensed Matter Physics Program in the Division of Materials Research of the Mathematical and Physical Sciences Directorate.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    The Academy of Medical Sciences    Research Grant    29512.0GBP
36    Professor Kaiser Marcus    Newcastle University    2019-04-01    2022-03-31    Modelling dementia progression based on machine learning and simulations    Mathematical and Physical Sciences - Nontechnical Abstract: <br/>The rapid spread of new coronavirus SARS-CoV-2, which causes Coronavirus Disease (covid-19), requires a multidisciplinary mitigation strategy from the clinical to physical host-to-host transmission modelling. Data is required on the transmission of pathogen carrying airborne mucosalivary droplets and aerosols generated during normal breathing, talking, sneezing, and coughing. Synthetic exhalations will be measured leveraging advanced prototyping to obtain data needed to model the spread of covid-19, and the efficacy of personal protection devices and face coverings fabricated with various weaves and materials will be tested. Physical data related to temperature, humidity, and airflow on survival and dispersion of exhalations will be obtained. The data will be integrated using supervised machine learning methods, mathematical network simulations, and epidemiological data to develop an individual-based method that can give pandemic management results. Physical data will be published on transmission rates, including wearing of personal protective equipment and face coverings with various weaves, to inform mitigation strategies to alleviate covid-19 pandemic. Interactive Web based resources will be used for immediate broad dissemination of data and learning outcomes on covid-19 to the public, in addition to peer reviewed publications and training post-doctoral and undergraduate researchers in methods leading to pandemic mitigation.<br/><br/>Technical Abstract:<br/>The mode of transmission and extent of environmental contaminations on the outbreak of the Coronavirus Disease 2019 (covid-19), while sharing features with severe acute respiratory syndrome and other infectious diseases, remains unknown. This project will address fundamental rheology-matched metrics of transport and survival of airborne exhalation droplets and aerosols that carry coronavirus and on surfaces needed as input parameters for modeling mitigation. Impact of personal protective equipment on individual prognosis, with physical data related to temperature, humidity, and airflow-dependent dispersion distance of pathogen bearing viscoelastic droplets corresponding to breathing, sneezing, and coughing, will be obtained. The impact of the measured transmission rates on the spread and recurrence will be investigated with epidemiological data integrated with deep learning to implement a scalable, individual-based, stochastic, spatial model. Resulting peer-reviewed publications will serve as trusted source for calculation of covid-19 transmissibility and personal protection strategies. Post-doctoral and undergraduate researchers versed in fluid dynamics, soft matter physics, and network simulations will be trained toward mitigating infectious disease spread.<br/><br/>This Rapid Response Research (RAPID) grant supports research that will result in spatiotemporal mucosalivary droplet transmission range data required to develop covid-19 mitigation network methods with funding from the CARES Act managed by the Condensed Matter Physics Program in the Division of Materials Research of the Mathematical and Physical Sciences Directorate.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    Medical Research Council    Research Grant    304844.0GBP
37    Ao. Prof. Dr. KWITT Roland    University of Salzburg    2019-08-01    2022-07-31    Deep Homological Learning    Topological data analysis (TDA), implemented via persistent homology, has gained considerable research interest over the past years, not least as it allows to capture topological (and geometrical) characteristics of data that are not easily extractable by existing methods. However, aside from using persistent homology as an exploratory tool for data analysis, its use as an additional data source for learning, or as a means to study learning problems, is still limited. The goal of this project, Deep Homological Learning, is to develop novel and theoretically well-founded approaches to bridge the gap between TDA, persistent homology in particular, and recent advances in learning with deep neural networks. This not only includes (1) leveraging information offered by persistent homology as an additional data source for learning, but also (2) to learn filtrations for persistent homology from data and (3) to use concepts from algebraic topology to study neural network architectures, their capacity and learning progress. Advances along these directions (1) will contribute to the theoretical foundation of learning with persistent homology and (2) will eventually lead to stronger guidelines for neural network design, informed by topological measures of dataset and network complexity. The principal investigator (PI) responsible for this project is Roland Kwitt (Department of Computer Science, University of Salzburg). Collaborations are planned with Marc Niethammer (UNC Chapel Hill), Ulrich Bauer (TU Munich) and Peter Bubenik (UF Gainesville).    Austrian Science Fund FWF    Stand-Alone Projects    238512.75EUR
38    Ao. Prof. Dr. KWITT Roland    DEEP RENDER LTD    2019-08-01    2022-07-31    AI-based Image-As-Video Streaming    Deep Render Ltd is a London based deep-tech start-up developing the next generation of AI-based media compression algorithms. Our proprietary and patented technology is at the forefront of machine learning research. Deep Render is combining the fields of artificial intelligence, statistics and information theory to unlock the fundamental limits of image and video compression: The human eye is the best data compressor known to humanity - with compression ratios at least 2,000 times better than everything developed to date. Our Biological Compression approach approximates the neurological processes of the human eye through a non-linear, learning-based approach, thereby creating a novel class of highly efficient compression algorithms. We are world leaders in this domain, and our unique, AI-based image compression technology is already providing a 75% efficiency gain over the best previous compression standards. As global data consumption is growing exponentially with more than 80% of traffic being Image/Video, Deep Render's AI-based compression technology is vital to bypass broadband constraints. The outbreak of COVID-19 has now accelerated this growth, as a result of the crisis, internet usage has increased significantly. In particular, the demand for live-streaming and video-chat services. Therefore we want to apply our already working image compression codec to live-video streaming. The outcome of the project is to extend our image compression codec to an image-as-video live-streaming codec, at least 75% more efficient than the current state-of-the-art. Our target customers are the live video chat services (Zoom, Skype, Microsoft Teams), as well as the entertainment industry, including live streaming platforms (Twitch, Facebook, Instagram, YouTube). Our value proposition is easy to understand. By making file sizes 75% smaller, we directly increase the bandwidth supply of the internet for live-streaming by a factor of 4\. Increasing the bandwidth supply by making file sizes smaller, is magnitudes more value- and time-efficient than increasing the bandwidth supply through rewiring the globe with progressively more fibre-cables. Deep Render is going to help create a new age in which bandwidth constraints are a problem of the past. As a result of COVID 19 solving this problem has gained more importance and Deep Render is determined to create a fast solution.    UK Research and Innovation    Stand-Alone Projects    50000.0GBP
39    Ao. Prof. Dr. KWITT Roland    George Washington University    2020-05-01    2021-04-30    RAPID: A novel platform for data integration and deep learning on COVID-19    Biological Sciences - The COVID-19 pandemic, caused by the SARS-CoV-2 virus, has fundamentally changed the world, and yet its ultimate impact is unknown. While China has experienced a slowdown in new cases, infections in the US continue to rise and are threatening to exceed our health care system?s capacity. Tests capacities are limited compared to the need, hospital services are becoming overwhelmed, and critical supplies are in shortage. There is a diversity of efforts currently ongoing to develop both new treatments as well as vaccine strategies to combat COVID-19. Yet, we know from experience, the virus will evolve solutions to both host immune systems and intervention strategies. In order to diminish both the short-term and long-term impacts of COVID-19, it is essential to develop robust, repeatable, and accessible tools to integrate and analyze the diversity of data becoming available in the face of the COVID-19 pandemic. The development of a platform to characterize the dynamic nature of mutations in the virus and testing for associations with clinical variables and biomarkers is an essential broader impact and will help in making informed predictions of health outcomes such as the stage of the severity of the disease and efficacy of treatment. Additionally, this project provides professional development opportunities for early career researchers.<br/><br/>Advances in omics technologies provide a broad and deep range of genotypic and phenotypic data to integrate with clinical phenotypes. Machine learning techniques such as clustering using phylogenetic distance and Deep Neural Networks (DNNs) are suitable techniques to link these DNA level changes to clinical metadata for human disease prediction, diagnosis, and therapeutics. This project develops tools within an open-source platform for documented, repeatable analyses that can be conducted in real-time allowing integration of data from patients with new treatments/vaccines strategies. This deep learning bioinformatics platform will allow the prioritization of genes associated with outcome predictors, including health, therapeutic, and vaccine outcomes, as well as inform improved DNA tests for predicting disease status and severity. The computational tools developed in this study will provide the research community and health professionals with comprehensive and generic approaches for characterizing the dynamics of genotype/phenotype associations in viruses. Such tools allow healthcare professionals and researchers to address specific properties of viruses such as frequency and location of mutations across the viral genome. When added to other clinical and epidemiological data, such information could help pave the way to better treatments or a vaccine. The developed platform will provide a venue for robust, open, repeatable analyses of COVID-19 as more and more data become available.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    National Science Foundation    Research Grant    200000.0USD
40    Dr Seymour Ben    University of Cambridge    2013-04-01    2018-09-30    Mechanisms of endogenous analgesia.    The programme will address how two distinct mechanisms of endogenous analgesia control activity in the brainstem periaqueductal grey. I aim to provide an account in computational terms, in order to specify the precise decision algorithms (rules) by which they operate. First I address the mechanism by which predictions reduce pain, by exploring precisely what information within a prediction controls pain perception. Specifically, I will test Bayesian models against competing accounts. Brain i maging will be used to determine how this is implemented in forebrain structures, and if/how they modulate activity in the periaqueductal grey. Second, I address the mechanism by which escape under threat reduces pain. Here I propose a theoretical analysis of controllability in escape/avoidance learning, building on my existing Reinforcement Learning framework. I will implement evolutionary simulations designed to show whether pain modulation emerges as an intrinsic reward to guide escape. On the basis of this, I will test model predictions (behaviourally) and their implementation (using fMRI), using an active versus passive escape learning paradigm. Finally, I will use deep brain stimulation to provide convergent evidence of how these mechanisms depend on the periaqueductal grey, looking for a statistical interaction between stimulation and endogenous analgesia.    Wellcome Trust    Intermediate Clinical Fellowship    722829.0GBP
41    Dr Seymour Ben    VAMSTAR LIMITED    2013-04-01    2018-09-30    AI-powered COVID-19 supplier risk index and demand planning toolkit    For health systems to better prepare and plan for the months ahead, Vamstar will create a risk-based framework to understand supply chain gaps and the evolving demand at a hospital-level in the UK and EU. The objective of the risk scoring matrix and the Demand-Planning-Toolkit is to focus on the most vulnerable parts of the health systems in Europe and facilitate decision making as quickly as possible. With the supply risk framework, we will be able to predict changes in the overall demand for various essential products and services needed to manage a crisis like COVID-19 and direct the focus of suppliers towards the most needed parts of the care delivery. Combining this with the Demand-Planning-Toolkit, Vamstar will be able to assess which suppliers have fulfilled a current order in the market and make predictions about when they will become fully production-ready to sell again. Additionally, the risk scoring framework and Demand-Planning-Toolkit will help stakeholders in the care delivery chain quickly assess countries that have developed or are developing preventative infrastructure and share the findings. This framework and connected real-time supply chain analytics will ensure that in the future such crises are managed with a more proactive strategy vs a reactive supply chain approach currently prevalent in our health systems. By analysing this dataset through artificial intelligence, we want to understand the Pandemic-Supply-Risk both from a macro (ability) and micro (willingness) levels needed to manage a pandemic like COVID-19\. This toolkit includes necessary items such as face masks but also digital platforms that will aid in patient and population health management across these countries as it undergoes a rapid transformation. Vamstar offers a data science powered platform for predicting and matching public contracts in healthcare and will create an automated "pandemic preparedness toolkit" specifically by using supply chain risk scoring matrix so as to focus on the most vulnerable parts of the health systems affected by the COVID-19 pandemic. It will leverage EU and UK data on public and private tendering, pricing sources and economic annual datasets to do this. Machine learning (ML) and deep learning will be used for tasks such as predicting ongoing list of suppliers with spare capacity, the date of shortages, and prices of key supplies. These predictions and analysis will form part of reports and an autonomous dashboard that will benefit the NHS hospitals and healthcare suppliers.    UK Research and Innovation    Intermediate Clinical Fellowship    49794.0GBP
42    Professor Gabbay Mark    NHS Liverpool CCG    2019-10-01    2024-09-30    NIHR Applied Research Collaboration North West Coast    For health systems to better prepare and plan for the months ahead, Vamstar will create a risk-based framework to understand supply chain gaps and the evolving demand at a hospital-level in the UK and EU. The objective of the risk scoring matrix and the Demand-Planning-Toolkit is to focus on the most vulnerable parts of the health systems in Europe and facilitate decision making as quickly as possible. With the supply risk framework, we will be able to predict changes in the overall demand for various essential products and services needed to manage a crisis like COVID-19 and direct the focus of suppliers towards the most needed parts of the care delivery. Combining this with the Demand-Planning-Toolkit, Vamstar will be able to assess which suppliers have fulfilled a current order in the market and make predictions about when they will become fully production-ready to sell again. Additionally, the risk scoring framework and Demand-Planning-Toolkit will help stakeholders in the care delivery chain quickly assess countries that have developed or are developing preventative infrastructure and share the findings. This framework and connected real-time supply chain analytics will ensure that in the future such crises are managed with a more proactive strategy vs a reactive supply chain approach currently prevalent in our health systems. By analysing this dataset through artificial intelligence, we want to understand the Pandemic-Supply-Risk both from a macro (ability) and micro (willingness) levels needed to manage a pandemic like COVID-19\. This toolkit includes necessary items such as face masks but also digital platforms that will aid in patient and population health management across these countries as it undergoes a rapid transformation. Vamstar offers a data science powered platform for predicting and matching public contracts in healthcare and will create an automated "pandemic preparedness toolkit" specifically by using supply chain risk scoring matrix so as to focus on the most vulnerable parts of the health systems affected by the COVID-19 pandemic. It will leverage EU and UK data on public and private tendering, pricing sources and economic annual datasets to do this. Machine learning (ML) and deep learning will be used for tasks such as predicting ongoing list of suppliers with spare capacity, the date of shortages, and prices of key supplies. These predictions and analysis will form part of reports and an autonomous dashboard that will benefit the NHS hospitals and healthcare suppliers.    National Institute for Health Research (Department of Health)    Intermediate Clinical Fellowship    9000000.0GBP
43    Dr Wagstyl Konrad    University of Cambridge    2019-08-05    2023-08-05    Deep Learning of Cerebral Cortex Microstructure    For health systems to better prepare and plan for the months ahead, Vamstar will create a risk-based framework to understand supply chain gaps and the evolving demand at a hospital-level in the UK and EU. The objective of the risk scoring matrix and the Demand-Planning-Toolkit is to focus on the most vulnerable parts of the health systems in Europe and facilitate decision making as quickly as possible. With the supply risk framework, we will be able to predict changes in the overall demand for various essential products and services needed to manage a crisis like COVID-19 and direct the focus of suppliers towards the most needed parts of the care delivery. Combining this with the Demand-Planning-Toolkit, Vamstar will be able to assess which suppliers have fulfilled a current order in the market and make predictions about when they will become fully production-ready to sell again. Additionally, the risk scoring framework and Demand-Planning-Toolkit will help stakeholders in the care delivery chain quickly assess countries that have developed or are developing preventative infrastructure and share the findings. This framework and connected real-time supply chain analytics will ensure that in the future such crises are managed with a more proactive strategy vs a reactive supply chain approach currently prevalent in our health systems. By analysing this dataset through artificial intelligence, we want to understand the Pandemic-Supply-Risk both from a macro (ability) and micro (willingness) levels needed to manage a pandemic like COVID-19\. This toolkit includes necessary items such as face masks but also digital platforms that will aid in patient and population health management across these countries as it undergoes a rapid transformation. Vamstar offers a data science powered platform for predicting and matching public contracts in healthcare and will create an automated "pandemic preparedness toolkit" specifically by using supply chain risk scoring matrix so as to focus on the most vulnerable parts of the health systems affected by the COVID-19 pandemic. It will leverage EU and UK data on public and private tendering, pricing sources and economic annual datasets to do this. Machine learning (ML) and deep learning will be used for tasks such as predicting ongoing list of suppliers with spare capacity, the date of shortages, and prices of key supplies. These predictions and analysis will form part of reports and an autonomous dashboard that will benefit the NHS hospitals and healthcare suppliers.    Wellcome Trust    Sir Henry Wellcome Postdoctoral Fellowship    300000.0GBP
44    Ao. Prof. Dr. HOLZINGER Andreas    Medical University of Graz    2019-11-04    2022-11-03    A Reference Model of Explainable AI for the Medical Domain    Towards A Reference Model of Explainable AI for the Medical Domain Andreas Holzinger December, 27, 2018 The progress of statistical machine learning methods has made AI increasingly successful. Deep learning exceeds human performance even in the medical domain. However, their full potential is limited by the difficulty to generate the underlying explanatory structures. The central problem is that they are regarded as "black-boxes" and even if we understand the mathematical principles, they lack an explicit declarative knowledge representation. A motivation for this project are rising legal and privacy issues. This does not imply a ban on automatic learning approaches or an obligation to explain everything all the time, however, there must be a possibility to make results re-traceable on demand - understandable by a human domain expert. We learned of a variety of technical solutions which are currently in development, which could help explain AI/ML systems and their decisions. Transparent algorithms could appropriately enhance trust of medical professionals, thereby raising acceptance of machine learning. Recently, the Google AI team emphasized the significance of research in explainable AI, the importance of Human-Computer Interaction (HCI) research for Knowledge Discovery from Data (KDD), and the urgent need for a research framework around the field of interpretability. In our ongoing research collaboration "Machine learning for diagnosis of colorectal cancer" with the Google AI group and the Institute of Pathology (Ethics Vote Medical University Graz 30-184 ex17/18) a training data set for AI/ML in digital pathology has been generated. As agreed with our colleagues at the Google AI group, we have now the chance to use machine learning algorithms developed in this context for our test environment; in return we will research towards making their algorithms explainable for our domain experts, who have the benefits of using the results for their medical teaching. This project will focus on but is not limited to digital pathological data and context. The advantage of this project is working with real-world data (under full ethics/data protection regulations) together with medical experts. This project will provide important contributions to the international research community in the following ways: evidence in various methods of explainability and novel methods and urgently needed tools for benchmarking and evaluation; Moreover, the contributions gained in this project can be used generally for reverse-engineering human learning and cognitive development and specifically to engineer more human like machine learning systems. All outcomes of this project will be made openly available to the international research community.    Austrian Science Fund FWF    Stand-Alone Projects    392773.5EUR
45    Ao. Prof. Dr. HOLZINGER Andreas    University of Cambridge    2018-10-01    2021-09-30    Moving the Adverse Outcome Pathways Framework towards Practical Utility by Integrating Compound Profiling Data and Using Deep Learning    Despite a significant investment in in vitro and in vivo screening, clinical safety concerns are still a major cause of compounds being withdrawn from the development process. A lack of mechanistic understanding of safety findings, combined with sparse data sets, restricts the development of approaches capable of predicting earlier potential safety concerns for new chemical entities. It is often unclear whether these are truly surprise events or, with hindsight, could actually have been predicted based on the available data at the time. This failure to detect early signals of safety issues may arise due to problems at the interface between three main components of predictive analysis: observer, data and technology. In this work we propose to employ novel mathematical approaches to data representation and modelling, such as deep learning, of the processes that lead to an adverse outcome in order to reduce or eliminate events of this type. Data will be compiled from within AZ and GSK and shared via Lhasa Limited Ltd, with the student having access to both data sources for model generation. Depending on the adverse event considered, we will either compile AOP frameworks for adverse events, and/or use deep learning approaches for cases where only observational data is available, and hence extend current AOP frameworks where indicated. In particular, nodes in deep networks can be interpreted with respect to their contribution to output toxicity, and hence information for AOPs can be derived from them. The current project will involve GSK and AstraZeneca as industrial partners, with the charity Lhasa Ltd. as an 'honest broker', to exchange and pool compound profiling data for model generation. This framework is currently already being established in the context of the Cambridge Alliance on Medicines Safety (CAMS), and it hence improves significantly upon previous analyses which were based either on public data, or data from only a single source. A pilot study on Structural Cardiotoxicity has already been completed and it is currently being written up for publication, proving the viability and benefit of exchanging data for safety prediction in this framework. We now would like to broaden the approach to other adverse events where data is available. This proposal directly puts into practice recommendations published recently, and it represents an advancement over previous approaches (such as eTox) in being able to have broader access to internal safety data from two major pharmaceutical companies in the UK, AstraZeneca and GSK, shared under confidentiality agreements via a Trusted Broker, Lhasa. This means that all biological data will be made available in the context of the project, including experimental protocols, quantitative data on exposure of compounds, and additional target-based and biological profiling information of compounds can be used in this project. Hence, we expect that the combination of access to data, and the utilization of state-of-the-art machine learning methods, will enhance our ability to predict drug safety and toxicity events considerably. Increasing our understanding of the molecular mechanisms by which compounds can cause adverse events will lead to the implementation of much improved in silico and in vitro screens to detect safety risks will avoid unnecessary investments in preclinical and clinical studies.    National Centre for the Replacement, Refinement and Reduction of Animals in Research    Studentship    90000.0GBP
46    Mr Smith Keith    University of Edinburgh    2018-02-14    2021-02-13    Developing network methodologies for disease classification    Despite a significant investment in in vitro and in vivo screening, clinical safety concerns are still a major cause of compounds being withdrawn from the development process. A lack of mechanistic understanding of safety findings, combined with sparse data sets, restricts the development of approaches capable of predicting earlier potential safety concerns for new chemical entities. It is often unclear whether these are truly surprise events or, with hindsight, could actually have been predicted based on the available data at the time. This failure to detect early signals of safety issues may arise due to problems at the interface between three main components of predictive analysis: observer, data and technology. In this work we propose to employ novel mathematical approaches to data representation and modelling, such as deep learning, of the processes that lead to an adverse outcome in order to reduce or eliminate events of this type. Data will be compiled from within AZ and GSK and shared via Lhasa Limited Ltd, with the student having access to both data sources for model generation. Depending on the adverse event considered, we will either compile AOP frameworks for adverse events, and/or use deep learning approaches for cases where only observational data is available, and hence extend current AOP frameworks where indicated. In particular, nodes in deep networks can be interpreted with respect to their contribution to output toxicity, and hence information for AOPs can be derived from them. The current project will involve GSK and AstraZeneca as industrial partners, with the charity Lhasa Ltd. as an 'honest broker', to exchange and pool compound profiling data for model generation. This framework is currently already being established in the context of the Cambridge Alliance on Medicines Safety (CAMS), and it hence improves significantly upon previous analyses which were based either on public data, or data from only a single source. A pilot study on Structural Cardiotoxicity has already been completed and it is currently being written up for publication, proving the viability and benefit of exchanging data for safety prediction in this framework. We now would like to broaden the approach to other adverse events where data is available. This proposal directly puts into practice recommendations published recently, and it represents an advancement over previous approaches (such as eTox) in being able to have broader access to internal safety data from two major pharmaceutical companies in the UK, AstraZeneca and GSK, shared under confidentiality agreements via a Trusted Broker, Lhasa. This means that all biological data will be made available in the context of the project, including experimental protocols, quantitative data on exposure of compounds, and additional target-based and biological profiling information of compounds can be used in this project. Hence, we expect that the combination of access to data, and the utilization of state-of-the-art machine learning methods, will enhance our ability to predict drug safety and toxicity events considerably. Increasing our understanding of the molecular mechanisms by which compounds can cause adverse events will lead to the implementation of much improved in silico and in vitro screens to detect safety risks will avoid unnecessary investments in preclinical and clinical studies.    Medical Research Council    Fellowship    276418.0GBP
47    Dr Fujita Andre    University of Sao Paulo    2018-03-31    2020-03-20    A model-based graph clustering approach for autism stratification    Autism spectrum disorder (ASD) is usually diagnosed by behavioral analyses and currently there is no objective test. Even the latest computational methods (e.g. support vector machine and deep learning) based on analyses of bloodoxygen-level dependent (BOLD) signal yield classification accuracies of about 60 to 70%, which are unsatisfactory for clinical use. However, if we focus on a group of individuals sharing a specific phenotype, we obtain better results, probably because there is more than one “type” of ASD. Thus, our main goal is to stratify the ASD into subgroups, not by the direct analysis of the BOLD signal as it is usually done, but by the functional brain network (FBN) based on the BOLD signal. The rationale is that ASD can be explained by the differences in how neurons interact. However, there are at least three technical drawbacks with this approach: (i) to the best of our knowledge, there is no method to cluster FBNs (note that this problem is different of the clustering of the vertices of the network as done by the spectral clustering algorithm); (ii) even individuals belonging to the same group present different FBNs (intrinsic fluctuation), which makes the analysis using standard computational methods unfruitful; and (iii) confounders such as age, gender, and other clinical parameters may affect the clustering structure. To overcome these problems, we will represent the FBNs as random graphs and assume that probabilistic models (e.g. Watts-Strogatz and Barabási-Albert models) generate the FBNs. Then, we will define that FBNs generated by the same model belong to the same group while FBNs generated by different models belong to different groups (similar to the Gaussian mixture model). Confounders’ effects will be removed by covarying the probabilistic distributions. We hope this stratification contribute for a better understanding of the mechanisms underlying ASD. To develop this method, Dr. Fujita of USP contacted Dr. Mourao-Miranda of UCL to complement his expertise in classification methods. Dr. Fujita works on statistical methods on graphs while Dr. Mourao-Miranda is specialist in machine learning with applications in psychiatric disorders. To train Dr. Fujita’s group in the field of machine learning, the partners will organize two courses, one at UCL and another at USP. Moreover, two Ph.D. candidates from USP will be sent for six months each one to UCL to study cutting-edge classification techniques. This project is essential to obtain novel insights, solidify this cooperation, and improve the quality of this research.    The Academy of Medical Sciences    Newton Advanced Fellowship    61814.0GBP
48    Professor Zaikin Alexey    University College London    2019-01-15    2022-01-14    HSM: Construction of graph-based network longitudinal algorithms to identify screening and prognostic biomarkers and therapeutic targets (GBNLA)    Autism spectrum disorder (ASD) is usually diagnosed by behavioral analyses and currently there is no objective test. Even the latest computational methods (e.g. support vector machine and deep learning) based on analyses of bloodoxygen-level dependent (BOLD) signal yield classification accuracies of about 60 to 70%, which are unsatisfactory for clinical use. However, if we focus on a group of individuals sharing a specific phenotype, we obtain better results, probably because there is more than one “type” of ASD. Thus, our main goal is to stratify the ASD into subgroups, not by the direct analysis of the BOLD signal as it is usually done, but by the functional brain network (FBN) based on the BOLD signal. The rationale is that ASD can be explained by the differences in how neurons interact. However, there are at least three technical drawbacks with this approach: (i) to the best of our knowledge, there is no method to cluster FBNs (note that this problem is different of the clustering of the vertices of the network as done by the spectral clustering algorithm); (ii) even individuals belonging to the same group present different FBNs (intrinsic fluctuation), which makes the analysis using standard computational methods unfruitful; and (iii) confounders such as age, gender, and other clinical parameters may affect the clustering structure. To overcome these problems, we will represent the FBNs as random graphs and assume that probabilistic models (e.g. Watts-Strogatz and Barabási-Albert models) generate the FBNs. Then, we will define that FBNs generated by the same model belong to the same group while FBNs generated by different models belong to different groups (similar to the Gaussian mixture model). Confounders’ effects will be removed by covarying the probabilistic distributions. We hope this stratification contribute for a better understanding of the mechanisms underlying ASD. To develop this method, Dr. Fujita of USP contacted Dr. Mourao-Miranda of UCL to complement his expertise in classification methods. Dr. Fujita works on statistical methods on graphs while Dr. Mourao-Miranda is specialist in machine learning with applications in psychiatric disorders. To train Dr. Fujita’s group in the field of machine learning, the partners will organize two courses, one at UCL and another at USP. Moreover, two Ph.D. candidates from USP will be sent for six months each one to UCL to study cutting-edge classification techniques. This project is essential to obtain novel insights, solidify this cooperation, and improve the quality of this research.    Medical Research Council    Research Grant    469754.0GBP
49    Dr. TASCHNER-MANDL Sabine    St. Anna Children's Cancer Research Institute    2019-04-01    2022-03-31    LIQUIDHOPE Advancing Liquid Biopsies for Neuroblastoma    Neuroblastoma (NB) accounts for 11% of all cancer-related deaths in children. Despite considerable international efforts to improve treatment, including anti-GD2-directed immunotherapy, long-term survival of high-risk patients remains below 40%. Liquid biopsies, blood and bone marrow (BM), have the power to revolutionize clinical care for children with high-risk NB by reflecting precise disease status at any time during treatment and are a less invasive source of biomarkers for patient monitoring and therapeutic decision-making. At diagnosis >95% of patients with high-risk NB have disseminated tumor cells (DTC) in the BM. As BM is a frequent site of relapse, we have investigated the predictive power of DTCs and identified genomic markers predicting relapse and associated expression signatures. Preliminary data indicate that failure to clear BM of DTCs by the end of induction treatment is highly predictive for poor survival. Additional genetic marker analysis of cell-free tumor (ct)DNA in blood and bone marrow plasma provided important information complementing current response- and minimal residual disease assessment. We hypothesize that implementing our established enumeration and biomarker characterization techniques for DTCs in BM and plasma-based ctDNA will improve outcome prediction, patient monitoring and secondary treatment selection. Within LIQUIDHOPE, CCRI aims to accelerate transfer of liquid biopsy approaches into the clinic and overcome current hurdles in (1) therapy response assessment, (2) MRD-monitoring and (3) actionable immuno-therapy target identification, and, among all partners, define a best marker/analysis combination for patient monitoring. Our investigations are geared toward developing diagnostics to guide personalized decision making for therapy selection and alterations in treatment. CCRI will monitor therapy response by detecting DTCs in BM taken at several time points (diagnosis, mid- and end-induction therapy, after myeloablative, radio- or immunotherapy). DTC clearance from BM at time points after induction therapy will be evaluated for their predictive power (n=85; SIOPEN-HR-NBL-1 trial). Biomarker expression (GD2/CD56/PD-L1 on DTCs, PD1/PD-L1 on BM stromal cells) will be assessed retrospectively (n=20) and validated prospectively (n=20, same time points) for predictive value for monitoring therapy response. BM cytospin slides are immunolabeled and scanned by the Metafer4/RCDetect automated imaging system. To detect heterogeneous biomarker expression on DTCs, raw microscopic images are processed by an analysis pipeline using deep-learning algorithms and visualization tools. Cell-based MRD data will be validated with RQ-PCR and ctDNA-based MRD detection techniques. This approach is likely to minimize the need for surgical biopsies and could better reflect tumor dynamics, intra-tumor heterogeneity and drug sensitivities over time, and greatly contribute to personalized treatment. Taschner-Mandl, young PI at the CCRI, has participated in/coordinated inter-/national projects addressing NB pathogenesis, novel therapies and diagnostics. In close collaboration with CCRI’s clinical trial unit and embedded in a multidisciplinary team, she will be supported by a bioimaging/deep learning specialist (Kromp) and a biologist (PhD candidate).    Austrian Science Fund FWF    02 International programmes    254138.5EUR
50    Ao. Prof. Dr. HOLZINGER Andreas    Medical University of Graz    2019-11-04    2022-11-03    A Reference Model of Explainable AI for the Medical Domain    Towards A Reference Model of Explainable AI for the Medical Domain Andreas Holzinger December, 27, 2018 The progress of statistical machine learning methods has made AI increasingly successful. Deep learning exceeds human performance even in the medical domain. However, their full potential is limited by the difficulty to generate the underlying explanatory structures. The central problem is that they are regarded as "black-boxes" and even if we understand the mathematical principles, they lack an explicit declarative knowledge representation. A motivation for this project are rising legal and privacy issues. This does not imply a ban on automatic learning approaches or an obligation to explain everything all the time, however, there must be a possibility to make results re-traceable on demand - understandable by a human domain expert. We learned of a variety of technical solutions which are currently in development, which could help explain AI/ML systems and their decisions. Transparent algorithms could appropriately enhance trust of medical professionals, thereby raising acceptance of machine learning. Recently, the Google AI team emphasized the significance of research in explainable AI, the importance of Human-Computer Interaction (HCI) research for Knowledge Discovery from Data (KDD), and the urgent need for a research framework around the field of interpretability. In our ongoing research collaboration "Machine learning for diagnosis of colorectal cancer" with the Google AI group and the Institute of Pathology (Ethics Vote Medical University Graz 30-184 ex17/18) a training data set for AI/ML in digital pathology has been generated. As agreed with our colleagues at the Google AI group, we have now the chance to use machine learning algorithms developed in this context for our test environment; in return we will research towards making their algorithms explainable for our domain experts, who have the benefits of using the results for their medical teaching. This project will focus on but is not limited to digital pathological data and context. The advantage of this project is working with real-world data (under full ethics/data protection regulations) together with medical experts. This project will provide important contributions to the international research community in the following ways: evidence in various methods of explainability and novel methods and urgently needed tools for benchmarking and evaluation; Moreover, the contributions gained in this project can be used generally for reverse-engineering human learning and cognitive development and specifically to engineer more human like machine learning systems. All outcomes of this project will be made openly available to the international research community.    Austrian Science Fund FWF    Stand-Alone Projects    392773.5EUR
51    Ao. Prof. Dr. HOLZINGER Andreas    DEEP RENDER LTD    2019-11-04    2022-11-03    AI-based Image-As-Video Streaming    Deep Render Ltd is a London based deep-tech start-up developing the next generation of AI-based media compression algorithms. Our proprietary and patented technology is at the forefront of machine learning research. Deep Render is combining the fields of artificial intelligence, statistics and information theory to unlock the fundamental limits of image and video compression: The human eye is the best data compressor known to humanity - with compression ratios at least 2,000 times better than everything developed to date. Our Biological Compression approach approximates the neurological processes of the human eye through a non-linear, learning-based approach, thereby creating a novel class of highly efficient compression algorithms. We are world leaders in this domain, and our unique, AI-based image compression technology is already providing a 75% efficiency gain over the best previous compression standards. As global data consumption is growing exponentially with more than 80% of traffic being Image/Video, Deep Render's AI-based compression technology is vital to bypass broadband constraints. The outbreak of COVID-19 has now accelerated this growth, as a result of the crisis, internet usage has increased significantly. In particular, the demand for live-streaming and video-chat services. Therefore we want to apply our already working image compression codec to live-video streaming. The outcome of the project is to extend our image compression codec to an image-as-video live-streaming codec, at least 75% more efficient than the current state-of-the-art. Our target customers are the live video chat services (Zoom, Skype, Microsoft Teams), as well as the entertainment industry, including live streaming platforms (Twitch, Facebook, Instagram, YouTube). Our value proposition is easy to understand. By making file sizes 75% smaller, we directly increase the bandwidth supply of the internet for live-streaming by a factor of 4\. Increasing the bandwidth supply by making file sizes smaller, is magnitudes more value- and time-efficient than increasing the bandwidth supply through rewiring the globe with progressively more fibre-cables. Deep Render is going to help create a new age in which bandwidth constraints are a problem of the past. As a result of COVID 19 solving this problem has gained more importance and Deep Render is determined to create a fast solution.    UK Research and Innovation    Stand-Alone Projects    50000.0GBP
52    Dr Wagner Siegfried    University College London    2020-01-20    2023-01-19    Retinal bioimaging for neurodegenerative and cardiovascular diseases    Deep Render Ltd is a London based deep-tech start-up developing the next generation of AI-based media compression algorithms. Our proprietary and patented technology is at the forefront of machine learning research. Deep Render is combining the fields of artificial intelligence, statistics and information theory to unlock the fundamental limits of image and video compression: The human eye is the best data compressor known to humanity - with compression ratios at least 2,000 times better than everything developed to date. Our Biological Compression approach approximates the neurological processes of the human eye through a non-linear, learning-based approach, thereby creating a novel class of highly efficient compression algorithms. We are world leaders in this domain, and our unique, AI-based image compression technology is already providing a 75% efficiency gain over the best previous compression standards. As global data consumption is growing exponentially with more than 80% of traffic being Image/Video, Deep Render's AI-based compression technology is vital to bypass broadband constraints. The outbreak of COVID-19 has now accelerated this growth, as a result of the crisis, internet usage has increased significantly. In particular, the demand for live-streaming and video-chat services. Therefore we want to apply our already working image compression codec to live-video streaming. The outcome of the project is to extend our image compression codec to an image-as-video live-streaming codec, at least 75% more efficient than the current state-of-the-art. Our target customers are the live video chat services (Zoom, Skype, Microsoft Teams), as well as the entertainment industry, including live streaming platforms (Twitch, Facebook, Instagram, YouTube). Our value proposition is easy to understand. By making file sizes 75% smaller, we directly increase the bandwidth supply of the internet for live-streaming by a factor of 4\. Increasing the bandwidth supply by making file sizes smaller, is magnitudes more value- and time-efficient than increasing the bandwidth supply through rewiring the globe with progressively more fibre-cables. Deep Render is going to help create a new age in which bandwidth constraints are a problem of the past. As a result of COVID 19 solving this problem has gained more importance and Deep Render is determined to create a fast solution.    Medical Research Council    Fellowship    227704.0GBP
53    Dr Wagner Siegfried    University of California-San Diego    2020-05-01    2021-04-30    RAPID: Explainable Machine Learning for Analysis of COVID-19 Chest CT    Computer and Information Science and Engineering - In December 2019, it was discovered that a widely contagious pneumonia was caused by a new coronavirus infection now named COVID-19. The primary test for detection of the virus is real-time polymerase chain reaction (RT-PCR) with sensitivity of approximately 71% in some studies. However, this test may require several days to provide a result. Perhaps more importantly, imaging with x-ray or computed tomography (CT) are required to confirm pneumonia, which is the principal cause of death, as it leads to acute respiratory distress syndrome (ARDS). Recent studies have shown sensitivity of chest CT for approximately 98% for COVID-19 pneumonia and could provide immediate results but currently require human interpretation. Given the need for rapid, more accurate diagnosis, this project will use, adapt, and evaluate explainable machine learning techniques to diagnosis of COVID-19 pneumonia. This project will improve the understanding of mechanisms of COVID-19 and will help mitigate its impacts.<br/><br/>Viral nucleic acid detection using real-time polymerase chain reaction (RT-PCR) is the primary method for diagnosis of COVID-19 infection, which has rapidly spread worldwide as a global pandemic. Sensitivity of this test for COVID-19 infection has been estimated at approximately 71% in some studies and may require several days for a result. X-ray and CT imaging are complementary technologies that allow diagnosis of COVID-19 pneumonia, which can evolve to acute respiratory distress syndrome (ARDS) -- the principal cause of death in patients with COVID-19 infection. Especially early in the course of the disease, chest CT has multiple advantages over RT-PCR yielding results more quickly and is already widely deployed, but requires expert radiologist interpretation. The number of chest CTs may rapidly exceed the speed and capacity of already strained radiologists. An explainable machine learning algorithm may address this disadvantage to expedite the interpretation of chest CT and assist rapid triage of patients to the ICU, inpatient ward, monitoring unit, or home self-quarantine. Machine learning algorithms, specifically those leveraging deep convolutional neural networks (deep learning), have the potential for facilitating even more rapid diagnosis within minutes. This project seeks to validate the use of explainable deep learning methods to adjust diagnostic operating points for multiple applications, including (a) disease screening, (b) disease staging and prognostication, and (c) evaluation of treatment response.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    National Science Foundation    Research Grant    101643.0USD
54    Dr Wagner Siegfried    University of Texas at Austin    2020-05-15    2021-04-30    RAPID: Methods for Reconstructing Disease Transmissions from Viral Genomic Data with Application to COVID-19    Computer and Information Science and Engineering - The coronavirus causing COVID-19 was first detected in humans in November 2019 and rapidly developed into a pandemic. There is an urgent need to enhance the ability to precisely track and predict spread of the disease. However, analysis of classical epidemiological data such as the time of testing and lengths of exposure provides limited insight. This Rapid Response Research (RAPID) project aims to enable discovery of disease transmission patterns based on analysis of genomic data, provide accurate identification of transmission clusters, and enable detection of critical nodes in a network of pathogen hosts while also providing insight into pathogen-mutation processes that occur during the spread of the disease.<br/><br/>The specific aims of this project are to: (1) Develop methods for the inference of a network of hosts based on genomic information about viral pathogens infecting them. In particular, this research thrust is focused on the reconstruction of a weighted directed graph whose nodes represent hosts and edge weights reflect evolutionary distance between corresponding pathogens. (2) Develop methods for the discovery of transmission clusters and identification of critical nodes in the host network. The focus of this research thrust is on deep-learning algorithms for the identification of transmission clusters, and discovery of the host network nodes that played a pivotal role in the disease outbreak. (3) Relying on the developed methods, analyze publicly available COVID-19 datasets. The results of the outlined work are expected to have an immediate impact on the understanding of the coronavirus transmission and spread.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    National Science Foundation    Research Grant    100000.0USD
55    Dr Wagner Siegfried    University of Pittsburgh    2020-07-01    2021-06-30    RAPID: In-Home Automated and Non-Invasive Evaluation of COVID-19 Infection with Commodity Smartphones    Computer and Information Science and Engineering - A key to combat the Coronavirus Disease (COVID-19) pandemic is to prevent the pandemic from overloading the public healthcare system, so that sufficient medical resources could be available for hospitalized patients. This project will develop new mobile sensing and Artificial Intelligence (AI) techniques for in-home evaluation of COVID-19 infection in order to pursue automated and non-invasive screening of potential viral disease carriers. It aims to timely identify negative cases caused by other diseases with similar symptoms, and hence avoids unnecessary hospital visits as many as possible. <br/><br/>The proposed techniques will use commodity smartphones to measure the changes of humans? airway mechanics, which are uniquely correlated to COVID-19 infection. These measurements build on acoustic sensing with smartphones? built-in speakers and microphones. First, new acoustic waveforms will be designed to minimize acoustic signal distortion in human airways. Second, new signal processing techniques will be developed for accurate measurements. Third, deep learning techniques will be used to develop generic models that depict the core characteristics of airway mechanics. These techniques will be evaluated by lab testing and experiments with student volunteers. This research will enable identifying false positives of COVID-19 infection out of the clinic and could contribute to the containment of the virus spread and damage. The proposed technologies will be applicable to a wide variety of commodity smartphones and could also be used in daily practice with handmade mouthpieces. Broader impacts will also result from a variety of education and outreach activities. New courses will be developed to incorporate the outcome of this research, and the research outcome will be disseminated through technology transfer to industry. The outcome of this project, including source codes and collected data from student volunteers, will be maintained at the project repository (http://www.pitt.edu/~weigao/research_COVID19.html) for at least five years, and will be made available to the public community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    National Science Foundation    Research Grant    200000.0USD
56    Dr Wagner Siegfried    University of Illinois at Chicago    2020-05-15    2021-04-30    III: RAPID: Stay-at-home attitudes and their impact on the COVID-19 pandemic    Computer and Information Science and Engineering - The rapid spread of the novel SARS-CoV-2 coronavirus has paralyzed societies and strained health care systems, with a rising death toll and severe economic consequences. Stay-at-home orders around the globe have been embraced by some and protested by others. At the same time, little is known about the spectrum of attitudes towards these orders and people's justifications for following or resisting them. This research will develop algorithms for analyzing stay-at-home attitudes on social media, connecting these attitudes to pandemic impact through a novel visual representation that takes geographical location and socioeconomic context into account. This research will bring greater awareness to the public about the role of values that protect life in public discourse and their influence on citizens' appraisal of policies that affect their own well-being. Shared values, beliefs, and understandings build the social cohesion and cooperation needed to build greater economic prosperity. The results of this project will help policy makers craft more persuasive public health directives to enhance public health.<br/><br/>Framing--highlighting certain aspects of an issue or event--can have a significant impact on the formation of perspective. To address the complexity of modern information networks, this project will develop algorithms that automatically detect frames propagated through social media. It focuses on value frames because people use those values to justify a position and issues can be re-framed accordingly to appeal to and change the opinions of target audiences. Creating the first dataset of its kind, this project will collect and annotate tweets that include stay-at-home attitudes and core value frames. Current state-of-the-art approaches to detecting attitudes in tweets are limited to binary or ternary classification of either sentiment (positive, negative, neutral) or language type (abusive versus "normal"). By bringing together state-of-the-art deep learning models with models that have more explanatory power, this project will devise a novel methodology for identifying values frames in microblogs that takes advantage of semantic and discourse structure information. By enabling statistical computing and analysis over geospatial data, for which few techniques exist currently, this research will make it possible to analyze datasets at multiple levels of spatial aggregation and to compare temporal and spatial differences to enhance participation and promote positive public health outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    National Science Foundation    Research Grant    99338.0USD
57    Dr Wagner Siegfried    University of Maryland College Park    2020-05-15    2021-04-30    RAPID: Advanced Topic Modeling Methods to Analyze Text Responses in COVID-19 Survey Data    Computer and Information Science and Engineering - As the COVID-19 pandemic continues, public and private organizations are deploying surveys to inform responses and policy choices. Survey designs using multiple choice responses are by far the most common -- "open ended" questions, where survey participants provide a longer-form written response, are used far less. This is true despite the fact that when you allow people to provide unconstrained spoken or text responses, it is possible to obtain richer, fine-grained information clarifying the other responses, as well as useful ?bottom up? information that the survey designers did not know to ask for. A key problem is that analyzing the unstructured language in open-ended responses is a labor-intensive process, creating obstacles to using them especially when speedy analysis is needed and resources are limited. Computational methods can help, but they often fail to provide coherent, interpretable categories, or they can fail to do a good job connecting the text in the survey with the closed-end responses. This project will develop new computational methods for fast and effective analysis of survey data that includes text responses, and it will apply these methods to support organizations doing high-impact survey work related to COVID-19 response. This will improve these organizations? ability to understand and mitigate the impact of the COVID-19 pandemic.<br/><br/>This project?s technical approach builds on recent techniques bringing together deep learning and Bayesian topic models. Several key technical innovations will be introduced that are specifically geared toward improving the quality of information available in surveys that include both closed- and open-ended responses. A common element in these approaches is the extension of methods commonly used in supervised learning settings, such as task-based fine-tuning of embeddings and knowledge distillation, to unsupervised topic modeling, with a specific focus on producing diverse, human-interpretable topic categories that are well aligned with discrete attributes such as demographic characteristics, closed-end responses, and experimental condition. Project activities include assisting in the analysis of organizations' survey data, conducting independent surveys aligned with their needs to obtain additional relevant data, and the public release of a clean, easy to use computational toolkit facilitating more widespread adoption of these new methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    National Science Foundation    Research Grant    176785.0USD
58    Dr Wagner Siegfried    University of British Columbia    2020-05-15    2021-04-30    Augmented Discovery of Potential Inhibitors of SARS-CoV-2 3CL Protease    The COVID-19 epidemic is causing serious or even fatal respiratory tract infections around the city of Wuhan, China and other countries. The urgent situation is pressing the global community to respond rapidly together to develop a vaccine or small molecule drug to inhibit viral infection. We have recently established a powerful Deep-Learning accelerated Docking pipeline to virtually screen a commercial 1.3-billion-compound library in a matter of one week--compared to the three years with previous programs. We have applied this novel algorithm to identify 1000 quality "candidate" compounds to inhibit the SARS-CoV-2 main protease (3CLpro) which is uniquely critical for the viral life cycle. We will screen these compounds with a high throughput screening biochemical assay and then evaluate these hits using a cell-based SARS-CoV-2 viral replication assay in a Canadian Containment Level 3 facilty at University of British Columbia. In addition we will use X-ray crystallography to refine the protease 3D crystal structure to accelerate the development of COVID-19 therapeutic drug development. Our research program will significantly contribute to global response to the COVID-19 outbreak by rapidly identifying small anti-viral drug molecules in an extremely condensed timeframe. Our expertise, facilities, and capabilities in cutting-edge Artificial Intelligence, inhibitor modeling, X-ray crystallography, coronavirus protease inhibition, human viral pathogen research, and anti-viral therapeutics are world class. Our first application this month of "Deep Docking" enabled the screening of 1.3B commercially available compounds against the essential SARS-CoV-2 protease, in 1 week compared to the 3 years of conventional docking. This accomplishment coupled with fast tracking anti-viral assays at UBC and high resolution 3D structure characterization provide our team, Canadians and global colleagues an enormous head start on developing an anti-viral therapeutic for COVID-19    Canadian Institutes of Health Research    Research Grant    999000.0CAD
59    Dr Wagner Siegfried    Helmholtz Zentrum München, Germany    2020-05-15    2021-04-30    RiPCoN    Rapid interaction profiling of 2019-nCoV for network-based deep drug- repurpose learning (DDRL)    European Commission    Research Grant    999000.0CAD
60    Dr Bhatt Samir    Imperial College School of Medicine    2019-04-01    2021-03-31    Unravelling and predicting the spatiotemporal structure of infectious disease outbreaks    Rapid interaction profiling of 2019-nCoV for network-based deep drug- repurpose learning (DDRL)    The Academy of Medical Sciences    Springboard Round 4    99994.63GBP
61    Dr. Dutilh Bastiaan Elie    UNIVERSITEIT UTRECHT    2020-05-01    2025-04-30    Predicting the evolution of complex phage-host interactions    What determines if a phage can infect a host? This question arises as we work to understand the ecological roles of the hundreds of thousands of unknown viruses that I and others have discovered around the world. Phages are the most abundant life forms on Earth with important applications in medicine and biotechnology and far-ranging effects on microbial community functioning in all environments. Phage-host interactions (PHI) are an emergent trait that depends on the complex integration of factors like their taxonomic identity, the environment, and phage- and host-encoded proteins. With DiversiPHI, I propose a research program to unravel PHI by 1) measuring, 2) modelling, and 3) experimentally testing these diverse factors to develop a predictive understanding of host-range evolution. I will first measure a range of evolutionary, ecological, and molecular factors contributing to PHI at high resolution using newly developed computational tools that exploit high-throughput datasets from thousands of natural environments around the world. Next, I will apply deep learning to integrate these measurements to simultaneously (i) quantify the relative importance and complex inter-dependencies of the different factors, and (ii) create a unique predictive model of host-range evolution. To complement these in silico predictions, I will develop an experimental evolution setup that tests the effect of the different PHI factors on host-range evolution in vitro. Little is known about the abundant phages and their role in shaping our microbial world. DiversiPHI will vastly elevate this understanding and contribute new fundamental knowledge on how species-species interactions evolve in complex environments. Moreover, I will provide valuable new analysis tools to the community and consolidate my strong international reputation as a pioneering researcher in the cross-disciplinary field encompassing microbial ecology, virology, metagenomics, bioinformatics, and computer learning.    European Research Council    Consolidator Grant    2000000.0EUR
62    Dr. HOLZAPFEL Andre    The Austrian Research Institute for Artificial Intelligence (OFAI)    2016-04-01    2016-09-30    A deeper understanding of common elements in musical rhythm    When listening to an unfamiliar style of music, we attempt to tap the beat and to synchronise with the rhythm, a process that enables us to interpret the structure of what we hear. This process is made possible by properties of music encountered in cultures throughout the whole world. In this project, we aim to identify such common properties in musical rhythm and their culturally dependent interpretation by applying a novel multidisciplinary methodology that combines the perspectives of music information retrieval (MIR) and ethnomusicology. Our insights into common elements of musical rhythm will be shaped into unitary models for the analysis of temporal structure in the musics of the world. Such models represent an important contribution to temper the existing bias towards Western music in MIR research, and can contribute to systems that can cope with a larger cultural diversity of music. In this very moment, the epoch-making development of deep learning gives us the tool to explore the borders and potentials of machine learning in application to music as a cultural expression. We will approach discovering common elements by answering important research questions from ethnomusicology with the help of innovative unitary models that combine deep learning and Bayesian modelling. Deep learning enables the discovery of low-level common signal properties, and Bayesian models enable for inclusion of expert knowledge and culturally dependent high-level interpretation. Our developed models will offer perspectives for a fair and balanced music recommendation and distribution in digital platforms and offer radically novel scientific perspectives on music analysis within engineering and humanities. Our project will promote a deeper understanding of music that suits the needs of a new digital age and indicates ways to connect musicians and listeners across cultural borders.    Austrian Science Fund FWF    Lise Meitner Programme    159620.0EUR
63    Dr. HOLZAPFEL Andre    University of Cambridge    2018-10-01    2021-09-30    Moving the Adverse Outcome Pathways Framework towards Practical Utility by Integrating Compound Profiling Data and Using Deep Learning    Despite a significant investment in in vitro and in vivo screening, clinical safety concerns are still a major cause of compounds being withdrawn from the development process. A lack of mechanistic understanding of safety findings, combined with sparse data sets, restricts the development of approaches capable of predicting earlier potential safety concerns for new chemical entities. It is often unclear whether these are truly surprise events or, with hindsight, could actually have been predicted based on the available data at the time. This failure to detect early signals of safety issues may arise due to problems at the interface between three main components of predictive analysis: observer, data and technology. In this work we propose to employ novel mathematical approaches to data representation and modelling, such as deep learning, of the processes that lead to an adverse outcome in order to reduce or eliminate events of this type. Data will be compiled from within AZ and GSK and shared via Lhasa Limited Ltd, with the student having access to both data sources for model generation. Depending on the adverse event considered, we will either compile AOP frameworks for adverse events, and/or use deep learning approaches for cases where only observational data is available, and hence extend current AOP frameworks where indicated. In particular, nodes in deep networks can be interpreted with respect to their contribution to output toxicity, and hence information for AOPs can be derived from them. The current project will involve GSK and AstraZeneca as industrial partners, with the charity Lhasa Ltd. as an 'honest broker', to exchange and pool compound profiling data for model generation. This framework is currently already being established in the context of the Cambridge Alliance on Medicines Safety (CAMS), and it hence improves significantly upon previous analyses which were based either on public data, or data from only a single source. A pilot study on Structural Cardiotoxicity has already been completed and it is currently being written up for publication, proving the viability and benefit of exchanging data for safety prediction in this framework. We now would like to broaden the approach to other adverse events where data is available. This proposal directly puts into practice recommendations published recently, and it represents an advancement over previous approaches (such as eTox) in being able to have broader access to internal safety data from two major pharmaceutical companies in the UK, AstraZeneca and GSK, shared under confidentiality agreements via a Trusted Broker, Lhasa. This means that all biological data will be made available in the context of the project, including experimental protocols, quantitative data on exposure of compounds, and additional target-based and biological profiling information of compounds can be used in this project. Hence, we expect that the combination of access to data, and the utilization of state-of-the-art machine learning methods, will enhance our ability to predict drug safety and toxicity events considerably. Increasing our understanding of the molecular mechanisms by which compounds can cause adverse events will lead to the implementation of much improved in silico and in vitro screens to detect safety risks will avoid unnecessary investments in preclinical and clinical studies.    National Centre for the Replacement, Refinement and Reduction of Animals in Research    Studentship    90000.0GBP
64    Mr Smith Keith    University of Edinburgh    2018-02-14    2021-02-13    Developing network methodologies for disease classification    Despite a significant investment in in vitro and in vivo screening, clinical safety concerns are still a major cause of compounds being withdrawn from the development process. A lack of mechanistic understanding of safety findings, combined with sparse data sets, restricts the development of approaches capable of predicting earlier potential safety concerns for new chemical entities. It is often unclear whether these are truly surprise events or, with hindsight, could actually have been predicted based on the available data at the time. This failure to detect early signals of safety issues may arise due to problems at the interface between three main components of predictive analysis: observer, data and technology. In this work we propose to employ novel mathematical approaches to data representation and modelling, such as deep learning, of the processes that lead to an adverse outcome in order to reduce or eliminate events of this type. Data will be compiled from within AZ and GSK and shared via Lhasa Limited Ltd, with the student having access to both data sources for model generation. Depending on the adverse event considered, we will either compile AOP frameworks for adverse events, and/or use deep learning approaches for cases where only observational data is available, and hence extend current AOP frameworks where indicated. In particular, nodes in deep networks can be interpreted with respect to their contribution to output toxicity, and hence information for AOPs can be derived from them. The current project will involve GSK and AstraZeneca as industrial partners, with the charity Lhasa Ltd. as an 'honest broker', to exchange and pool compound profiling data for model generation. This framework is currently already being established in the context of the Cambridge Alliance on Medicines Safety (CAMS), and it hence improves significantly upon previous analyses which were based either on public data, or data from only a single source. A pilot study on Structural Cardiotoxicity has already been completed and it is currently being written up for publication, proving the viability and benefit of exchanging data for safety prediction in this framework. We now would like to broaden the approach to other adverse events where data is available. This proposal directly puts into practice recommendations published recently, and it represents an advancement over previous approaches (such as eTox) in being able to have broader access to internal safety data from two major pharmaceutical companies in the UK, AstraZeneca and GSK, shared under confidentiality agreements via a Trusted Broker, Lhasa. This means that all biological data will be made available in the context of the project, including experimental protocols, quantitative data on exposure of compounds, and additional target-based and biological profiling information of compounds can be used in this project. Hence, we expect that the combination of access to data, and the utilization of state-of-the-art machine learning methods, will enhance our ability to predict drug safety and toxicity events considerably. Increasing our understanding of the molecular mechanisms by which compounds can cause adverse events will lead to the implementation of much improved in silico and in vitro screens to detect safety risks will avoid unnecessary investments in preclinical and clinical studies.    Medical Research Council    Fellowship    276418.0GBP
65    Dr Fujita Andre    University of Sao Paulo    2018-03-31    2020-03-20    A model-based graph clustering approach for autism stratification    Autism spectrum disorder (ASD) is usually diagnosed by behavioral analyses and currently there is no objective test. Even the latest computational methods (e.g. support vector machine and deep learning) based on analyses of bloodoxygen-level dependent (BOLD) signal yield classification accuracies of about 60 to 70%, which are unsatisfactory for clinical use. However, if we focus on a group of individuals sharing a specific phenotype, we obtain better results, probably because there is more than one “type” of ASD. Thus, our main goal is to stratify the ASD into subgroups, not by the direct analysis of the BOLD signal as it is usually done, but by the functional brain network (FBN) based on the BOLD signal. The rationale is that ASD can be explained by the differences in how neurons interact. However, there are at least three technical drawbacks with this approach: (i) to the best of our knowledge, there is no method to cluster FBNs (note that this problem is different of the clustering of the vertices of the network as done by the spectral clustering algorithm); (ii) even individuals belonging to the same group present different FBNs (intrinsic fluctuation), which makes the analysis using standard computational methods unfruitful; and (iii) confounders such as age, gender, and other clinical parameters may affect the clustering structure. To overcome these problems, we will represent the FBNs as random graphs and assume that probabilistic models (e.g. Watts-Strogatz and Barabási-Albert models) generate the FBNs. Then, we will define that FBNs generated by the same model belong to the same group while FBNs generated by different models belong to different groups (similar to the Gaussian mixture model). Confounders’ effects will be removed by covarying the probabilistic distributions. We hope this stratification contribute for a better understanding of the mechanisms underlying ASD. To develop this method, Dr. Fujita of USP contacted Dr. Mourao-Miranda of UCL to complement his expertise in classification methods. Dr. Fujita works on statistical methods on graphs while Dr. Mourao-Miranda is specialist in machine learning with applications in psychiatric disorders. To train Dr. Fujita’s group in the field of machine learning, the partners will organize two courses, one at UCL and another at USP. Moreover, two Ph.D. candidates from USP will be sent for six months each one to UCL to study cutting-edge classification techniques. This project is essential to obtain novel insights, solidify this cooperation, and improve the quality of this research.    The Academy of Medical Sciences    Newton Advanced Fellowship    61814.0GBP
66    Professor Zaikin Alexey    University College London    2019-01-15    2022-01-14    HSM: Construction of graph-based network longitudinal algorithms to identify screening and prognostic biomarkers and therapeutic targets (GBNLA)    Autism spectrum disorder (ASD) is usually diagnosed by behavioral analyses and currently there is no objective test. Even the latest computational methods (e.g. support vector machine and deep learning) based on analyses of bloodoxygen-level dependent (BOLD) signal yield classification accuracies of about 60 to 70%, which are unsatisfactory for clinical use. However, if we focus on a group of individuals sharing a specific phenotype, we obtain better results, probably because there is more than one “type” of ASD. Thus, our main goal is to stratify the ASD into subgroups, not by the direct analysis of the BOLD signal as it is usually done, but by the functional brain network (FBN) based on the BOLD signal. The rationale is that ASD can be explained by the differences in how neurons interact. However, there are at least three technical drawbacks with this approach: (i) to the best of our knowledge, there is no method to cluster FBNs (note that this problem is different of the clustering of the vertices of the network as done by the spectral clustering algorithm); (ii) even individuals belonging to the same group present different FBNs (intrinsic fluctuation), which makes the analysis using standard computational methods unfruitful; and (iii) confounders such as age, gender, and other clinical parameters may affect the clustering structure. To overcome these problems, we will represent the FBNs as random graphs and assume that probabilistic models (e.g. Watts-Strogatz and Barabási-Albert models) generate the FBNs. Then, we will define that FBNs generated by the same model belong to the same group while FBNs generated by different models belong to different groups (similar to the Gaussian mixture model). Confounders’ effects will be removed by covarying the probabilistic distributions. We hope this stratification contribute for a better understanding of the mechanisms underlying ASD. To develop this method, Dr. Fujita of USP contacted Dr. Mourao-Miranda of UCL to complement his expertise in classification methods. Dr. Fujita works on statistical methods on graphs while Dr. Mourao-Miranda is specialist in machine learning with applications in psychiatric disorders. To train Dr. Fujita’s group in the field of machine learning, the partners will organize two courses, one at UCL and another at USP. Moreover, two Ph.D. candidates from USP will be sent for six months each one to UCL to study cutting-edge classification techniques. This project is essential to obtain novel insights, solidify this cooperation, and improve the quality of this research.    Medical Research Council    Research Grant    469754.0GBP
67    Dr. TASCHNER-MANDL Sabine    St. Anna Children's Cancer Research Institute    2019-04-01    2022-03-31    LIQUIDHOPE Advancing Liquid Biopsies for Neuroblastoma    Neuroblastoma (NB) accounts for 11% of all cancer-related deaths in children. Despite considerable international efforts to improve treatment, including anti-GD2-directed immunotherapy, long-term survival of high-risk patients remains below 40%. Liquid biopsies, blood and bone marrow (BM), have the power to revolutionize clinical care for children with high-risk NB by reflecting precise disease status at any time during treatment and are a less invasive source of biomarkers for patient monitoring and therapeutic decision-making. At diagnosis >95% of patients with high-risk NB have disseminated tumor cells (DTC) in the BM. As BM is a frequent site of relapse, we have investigated the predictive power of DTCs and identified genomic markers predicting relapse and associated expression signatures. Preliminary data indicate that failure to clear BM of DTCs by the end of induction treatment is highly predictive for poor survival. Additional genetic marker analysis of cell-free tumor (ct)DNA in blood and bone marrow plasma provided important information complementing current response- and minimal residual disease assessment. We hypothesize that implementing our established enumeration and biomarker characterization techniques for DTCs in BM and plasma-based ctDNA will improve outcome prediction, patient monitoring and secondary treatment selection. Within LIQUIDHOPE, CCRI aims to accelerate transfer of liquid biopsy approaches into the clinic and overcome current hurdles in (1) therapy response assessment, (2) MRD-monitoring and (3) actionable immuno-therapy target identification, and, among all partners, define a best marker/analysis combination for patient monitoring. Our investigations are geared toward developing diagnostics to guide personalized decision making for therapy selection and alterations in treatment. CCRI will monitor therapy response by detecting DTCs in BM taken at several time points (diagnosis, mid- and end-induction therapy, after myeloablative, radio- or immunotherapy). DTC clearance from BM at time points after induction therapy will be evaluated for their predictive power (n=85; SIOPEN-HR-NBL-1 trial). Biomarker expression (GD2/CD56/PD-L1 on DTCs, PD1/PD-L1 on BM stromal cells) will be assessed retrospectively (n=20) and validated prospectively (n=20, same time points) for predictive value for monitoring therapy response. BM cytospin slides are immunolabeled and scanned by the Metafer4/RCDetect automated imaging system. To detect heterogeneous biomarker expression on DTCs, raw microscopic images are processed by an analysis pipeline using deep-learning algorithms and visualization tools. Cell-based MRD data will be validated with RQ-PCR and ctDNA-based MRD detection techniques. This approach is likely to minimize the need for surgical biopsies and could better reflect tumor dynamics, intra-tumor heterogeneity and drug sensitivities over time, and greatly contribute to personalized treatment. Taschner-Mandl, young PI at the CCRI, has participated in/coordinated inter-/national projects addressing NB pathogenesis, novel therapies and diagnostics. In close collaboration with CCRI’s clinical trial unit and embedded in a multidisciplinary team, she will be supported by a bioimaging/deep learning specialist (Kromp) and a biologist (PhD candidate).    Austrian Science Fund FWF    02 International programmes    254138.5EUR
68    Professor Hogg Claire    Royal Brompton and Harefield NHS Foundation Trust    2019-03-01    2021-02-28    Improving Primary Ciliary Dyskinesia diagnosis using artificial intelligence.    Neuroblastoma (NB) accounts for 11% of all cancer-related deaths in children. Despite considerable international efforts to improve treatment, including anti-GD2-directed immunotherapy, long-term survival of high-risk patients remains below 40%. Liquid biopsies, blood and bone marrow (BM), have the power to revolutionize clinical care for children with high-risk NB by reflecting precise disease status at any time during treatment and are a less invasive source of biomarkers for patient monitoring and therapeutic decision-making. At diagnosis >95% of patients with high-risk NB have disseminated tumor cells (DTC) in the BM. As BM is a frequent site of relapse, we have investigated the predictive power of DTCs and identified genomic markers predicting relapse and associated expression signatures. Preliminary data indicate that failure to clear BM of DTCs by the end of induction treatment is highly predictive for poor survival. Additional genetic marker analysis of cell-free tumor (ct)DNA in blood and bone marrow plasma provided important information complementing current response- and minimal residual disease assessment. We hypothesize that implementing our established enumeration and biomarker characterization techniques for DTCs in BM and plasma-based ctDNA will improve outcome prediction, patient monitoring and secondary treatment selection. Within LIQUIDHOPE, CCRI aims to accelerate transfer of liquid biopsy approaches into the clinic and overcome current hurdles in (1) therapy response assessment, (2) MRD-monitoring and (3) actionable immuno-therapy target identification, and, among all partners, define a best marker/analysis combination for patient monitoring. Our investigations are geared toward developing diagnostics to guide personalized decision making for therapy selection and alterations in treatment. CCRI will monitor therapy response by detecting DTCs in BM taken at several time points (diagnosis, mid- and end-induction therapy, after myeloablative, radio- or immunotherapy). DTC clearance from BM at time points after induction therapy will be evaluated for their predictive power (n=85; SIOPEN-HR-NBL-1 trial). Biomarker expression (GD2/CD56/PD-L1 on DTCs, PD1/PD-L1 on BM stromal cells) will be assessed retrospectively (n=20) and validated prospectively (n=20, same time points) for predictive value for monitoring therapy response. BM cytospin slides are immunolabeled and scanned by the Metafer4/RCDetect automated imaging system. To detect heterogeneous biomarker expression on DTCs, raw microscopic images are processed by an analysis pipeline using deep-learning algorithms and visualization tools. Cell-based MRD data will be validated with RQ-PCR and ctDNA-based MRD detection techniques. This approach is likely to minimize the need for surgical biopsies and could better reflect tumor dynamics, intra-tumor heterogeneity and drug sensitivities over time, and greatly contribute to personalized treatment. Taschner-Mandl, young PI at the CCRI, has participated in/coordinated inter-/national projects addressing NB pathogenesis, novel therapies and diagnostics. In close collaboration with CCRI’s clinical trial unit and embedded in a multidisciplinary team, she will be supported by a bioimaging/deep learning specialist (Kromp) and a biologist (PhD candidate).    National Institute for Health Research (Department of Health)    Full Grant    341942.0GBP
69    Dr Vougas Konstantinos    DeepMed IO Limited    2019-03-01    2020-02-29    Development of a Deep Learning powered software for automating the Nottingham Grading System for rapid, accurate and reproducible breast cancer grading    We propose to build a deep-learning powered system for the automatic, accurate and objective determination of the Nottingham Grading System (NGS) being derived after analysing the total of the tissue section present in the digitised Whole Slide Image. Whole slide images will be produced from tumours from 400 patients (1 slide per patient). These tumour samples are already available through the MCRC Biobank sample archive. Notably MCRC Biobank is already a DeepMed IO collaborator and offers a complete service including sample retrieval, processing and digitisation. The number of patients is selected in order to capture the large morphological diversity present in breast cancer given its various cancer types and the different stages of each type. Our extensive know-how along with the proprietary technology-transfer (patents application are currently being drafted) from the development of the metastasis detection module through SBRI funding (see Company info) will allow us to build models that deliver state of the art performance after robust model validation. The models will then be incorporated in the form of a deep learning module to the Computer Aided Diagnosis system for digital pathology that we are currently developing (see company info) which has been classed as a &quot;Software as a Medical Device Class IIa&quot;. The key enabling technology for our solution is digital pathology which is implemented into clinical practice by WSI scanners and storage infrastructure developed by vendors such as Phillips, Leica and Roche. According to a UK wide survey in 2017 more than 60% of histopathology labs in the UK had access to digital pathology infrastructure and this percentage is constantly rising. It has been demonstrated that other European countries follow the same trend as well. In terms of enabling technology adoption, it seems that the timing is favorable for the development of our solution.    National Institute for Health Research (Department of Health)    Full Grant    149450.0GBP
70    Professor Jefferson Emily    University of Dundee    2019-08-01    2024-07-31    MICA: InterdisciPlInary Collaboration for efficienT and effective Use of clinical images in big data health care RESearch: PICTURES    We propose to build a deep-learning powered system for the automatic, accurate and objective determination of the Nottingham Grading System (NGS) being derived after analysing the total of the tissue section present in the digitised Whole Slide Image. Whole slide images will be produced from tumours from 400 patients (1 slide per patient). These tumour samples are already available through the MCRC Biobank sample archive. Notably MCRC Biobank is already a DeepMed IO collaborator and offers a complete service including sample retrieval, processing and digitisation. The number of patients is selected in order to capture the large morphological diversity present in breast cancer given its various cancer types and the different stages of each type. Our extensive know-how along with the proprietary technology-transfer (patents application are currently being drafted) from the development of the metastasis detection module through SBRI funding (see Company info) will allow us to build models that deliver state of the art performance after robust model validation. The models will then be incorporated in the form of a deep learning module to the Computer Aided Diagnosis system for digital pathology that we are currently developing (see company info) which has been classed as a &quot;Software as a Medical Device Class IIa&quot;. The key enabling technology for our solution is digital pathology which is implemented into clinical practice by WSI scanners and storage infrastructure developed by vendors such as Phillips, Leica and Roche. According to a UK wide survey in 2017 more than 60% of histopathology labs in the UK had access to digital pathology infrastructure and this percentage is constantly rising. It has been demonstrated that other European countries follow the same trend as well. In terms of enabling technology adoption, it seems that the timing is favorable for the development of our solution.    Medical Research Council    Research Grant    2851878.0GBP
71    Dr Walsh Simon    Imperial College of Science, Technology and Medicine    2019-02-01    2024-01-31    Fibrotic lung disease on high-resolution computed tomography: predicting disease behaviour using computer algorithms.    We propose to build a deep-learning powered system for the automatic, accurate and objective determination of the Nottingham Grading System (NGS) being derived after analysing the total of the tissue section present in the digitised Whole Slide Image. Whole slide images will be produced from tumours from 400 patients (1 slide per patient). These tumour samples are already available through the MCRC Biobank sample archive. Notably MCRC Biobank is already a DeepMed IO collaborator and offers a complete service including sample retrieval, processing and digitisation. The number of patients is selected in order to capture the large morphological diversity present in breast cancer given its various cancer types and the different stages of each type. Our extensive know-how along with the proprietary technology-transfer (patents application are currently being drafted) from the development of the metastasis detection module through SBRI funding (see Company info) will allow us to build models that deliver state of the art performance after robust model validation. The models will then be incorporated in the form of a deep learning module to the Computer Aided Diagnosis system for digital pathology that we are currently developing (see company info) which has been classed as a &quot;Software as a Medical Device Class IIa&quot;. The key enabling technology for our solution is digital pathology which is implemented into clinical practice by WSI scanners and storage infrastructure developed by vendors such as Phillips, Leica and Roche. According to a UK wide survey in 2017 more than 60% of histopathology labs in the UK had access to digital pathology infrastructure and this percentage is constantly rising. It has been demonstrated that other European countries follow the same trend as well. In terms of enabling technology adoption, it seems that the timing is favorable for the development of our solution.    National Institute for Health Research (Department of Health)    Full Grant    1053348.0GBP
72    Dr Christensen-Jeffries Kirsten    King's College London    2019-11-01    2024-10-31    Development of 2D and 3D Ultrasound Super-Resolution (US-SR) Imaging for the Clinic    We propose to build a deep-learning powered system for the automatic, accurate and objective determination of the Nottingham Grading System (NGS) being derived after analysing the total of the tissue section present in the digitised Whole Slide Image. Whole slide images will be produced from tumours from 400 patients (1 slide per patient). These tumour samples are already available through the MCRC Biobank sample archive. Notably MCRC Biobank is already a DeepMed IO collaborator and offers a complete service including sample retrieval, processing and digitisation. The number of patients is selected in order to capture the large morphological diversity present in breast cancer given its various cancer types and the different stages of each type. Our extensive know-how along with the proprietary technology-transfer (patents application are currently being drafted) from the development of the metastasis detection module through SBRI funding (see Company info) will allow us to build models that deliver state of the art performance after robust model validation. The models will then be incorporated in the form of a deep learning module to the Computer Aided Diagnosis system for digital pathology that we are currently developing (see company info) which has been classed as a &quot;Software as a Medical Device Class IIa&quot;. The key enabling technology for our solution is digital pathology which is implemented into clinical practice by WSI scanners and storage infrastructure developed by vendors such as Phillips, Leica and Roche. According to a UK wide survey in 2017 more than 60% of histopathology labs in the UK had access to digital pathology infrastructure and this percentage is constantly rising. It has been demonstrated that other European countries follow the same trend as well. In terms of enabling technology adoption, it seems that the timing is favorable for the development of our solution.    Medical Research Council    Fellowship    1077817.0GBP
73    Dr Saxe Andrew    University of Oxford    2019-09-01    2024-08-31    Principles of Learning in Distributed Brain Networks    We propose to build a deep-learning powered system for the automatic, accurate and objective determination of the Nottingham Grading System (NGS) being derived after analysing the total of the tissue section present in the digitised Whole Slide Image. Whole slide images will be produced from tumours from 400 patients (1 slide per patient). These tumour samples are already available through the MCRC Biobank sample archive. Notably MCRC Biobank is already a DeepMed IO collaborator and offers a complete service including sample retrieval, processing and digitisation. The number of patients is selected in order to capture the large morphological diversity present in breast cancer given its various cancer types and the different stages of each type. Our extensive know-how along with the proprietary technology-transfer (patents application are currently being drafted) from the development of the metastasis detection module through SBRI funding (see Company info) will allow us to build models that deliver state of the art performance after robust model validation. The models will then be incorporated in the form of a deep learning module to the Computer Aided Diagnosis system for digital pathology that we are currently developing (see company info) which has been classed as a &quot;Software as a Medical Device Class IIa&quot;. The key enabling technology for our solution is digital pathology which is implemented into clinical practice by WSI scanners and storage infrastructure developed by vendors such as Phillips, Leica and Roche. According to a UK wide survey in 2017 more than 60% of histopathology labs in the UK had access to digital pathology infrastructure and this percentage is constantly rising. It has been demonstrated that other European countries follow the same trend as well. In terms of enabling technology adoption, it seems that the timing is favorable for the development of our solution.    Wellcome Trust    Sir Henry Dale Fellowship    771226.0GBP
74    Dr Saxe Andrew    Clemson University    2020-05-01    2021-04-30    RAPID: Automated discovery of COVID-19 related hypotheses using publicly available scientific literature    Computer and Information Science and Engineering - The vast amounts of biomedical information that accumulate in modern databases (such as MEDLINE of the National Library of Medicine) impose a great difficulty for efficient wide surveying by researchers who try to evaluate new information considering existing biomedical literature even when advanced information search engines are used. Automated hypotheses generation systems are designed to help scientists to overcome these difficulties and accelerate their research. The pandemic situation with COVID-19 is precisely one of the cases when such systems can play an extremely important role in coping with the coronavirus. Using two different AI approaches, we have developed two systems to discover plausible hypotheses in the biomedical domain. In this project, we will will deploy the COVID-19 customized hypothesis generation and knowledge discovery system, massively run it on any relevant to this research queries, and publish the results (including trained AI models, and discovered information) in the open domain for broad scientific community with the goal to accelerate the COVID-19 research. This work focuses heavily on addressing fundamental knowledge discovery questions by modeling and formulating scientific hypotheses using the publicly available information in the biomedical domain. However, in general, these methods are not restricted to any specific information domain, i.e., they can be broadly used to discover knowledge in texts. Although our experimental work will be related to COVID-19, the methods can be applied with some reservations to any literature-based analysis. For example, in the Materials Science Initiative, one of the goals is to establish a systematic understanding of the material properties and discover new materials which can be done by analyzing using the massive corpus of papers. In the legal world, identifying related patents can be done using a similar hypothesis modeling methodology.<br/><br/>In the heart of the proposed approach lies a big multi-modal and multi-relational semantic knowledge network of all biomedical objects extracted from a variety of heterogeneous databases of the National Library of Medicine. These objects include but are not limited to scientific papers, abstracts, keywords, phrases, elements of thesaurus, genes, proteins, mutations, pathways, diseases, and diagnoses. We will leverage two systems, namely MOLIERE and AGATHA, that are based on structural and deep learning, respectively. We will customize them using the rapidly updated dataset of new papers that has not been yet processed by the National Library of Medicine but already exists in the open domain such as in various preprint archives and reports. The MOLIERE system is based on the network analysis techniques applied on the graph constructed using the low-dimensional embedding of the papers with the result interpretation methods that are based on the probabilistic topic modeling. The AGATHA system processes texts at much finer granularity, and creates a semantic knowledge network using more accurate embedding techniques followed by the deep learning training for knowledge discovery. Two systems complement each other. While the AGATHA is of higher quality, the MOLIERE is more interpretable. A combination of both will be leveraged in this research.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.    National Science Foundation    Research Grant    104474.0USD
75    Dr Mah Yee-Haur    King's College London    2019-09-09    2022-09-08    Clinical outcome modelling of rapid dynamics in acute stroke with joint-detail, continuous, remote, body motion analysis    None    Medical Research Council    Research Grant    219833.0GBP
