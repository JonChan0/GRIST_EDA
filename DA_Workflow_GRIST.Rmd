---
title: "Data Analysis of Life Sciences Grants via GRIST API"
output: html_notebook
date: 2020-09-21
---
This project aims to source data about awarded grants in the life sciences and to conduct analysis on this data.

Data Source: Grants RESTFul (GRIST) API from Europe PMC
This provides coverage of funding from BBSRC UK; CRUK; NIHR; ERC; MRC UK; Wellcome Trust; WHO and more.

The ideal workflow will be like so:
1) Input search term
2) Python3's urllib will utilise GRIST API to spit out .json file for each 25 results from search term
3) SQLite3 database will be used to cache each .json file
4) Once all .json files have been cached, Python3 will run through each .json file & strip out details from each grant entry:
  a) Full Name
  b) Institution
  c) Start Date
  d) End Date
  e) Grant Title
  f) Grant Abstract
  h) Grant Source
  i) Grant Type
  j) Grant Worth + Currency
  
and store them in a Numpy array with each row reflecting separate ID i.e grant entry.

5) Once, Numpy array has been constructed as so, it will be converted to a csv named with the particular 'search term' used. which can then be read into a tibble in R.

6) Analysis of that particular 'search term' data can then be carried out to answer the following questions:
- Who is the most well-funded for that 'search term' & when?
- Which research institution is most well-funded for that 'search term' and when?
- How much money has that 'search term' been funded over the past 2,5,10 years?


7) Comparative analysis can also be conducted between tibbles for 'search terms'
- How much money per grant is awarded between the different 'search terms'?
- How much total money is awarded over the years for different 'search terms'?
- How many grants have been awarded over the years for different 'search terms'?

8) Data will be outputted in the form of a flexdashboard::flex_dashboard or Shiny web app.


```{r setup, include = FALSE}
library(tidyverse)
library(quantmod)
```

Note that before you run the following code for data analysis, you should have run the GRIST.py script to output .tsv files of interest to the folder ./output_tsv

The below code will import the .tsv files found within the ./output_tsv folder as individual tibbles.


```{r import}
filenames <- list.files("./output_tsv")

for (i in seq_along(filenames)){
  file <- str_extract(filenames[i],".+\\.") %>%
    str_extract(".+[^\\.]")
  
  tsv <- read_tsv(str_c("./output_tsv/",filenames[i]), 
                     col_names = c("ID","Name","Institution","Department", "Start Date","End Date","Title","Abstract", "Funder","Grant Type","Amount", "Currency"), 
                     col_types = "icccDDccccdc",
                     na="None",
                     quote="")
  
  intermediate <- file
  assign(intermediate,tsv)
  rm(tsv,file,intermediate) 
}
```


The below code will do some accessory work to compile all tibbles to iterate over all the tibbles & convert all currency values to GBP as per FX rates of `r Sys.time()`
The tsv files also seem to have duplicate rows for some so this will have to be resolved.

```{r acc}
search_terms <- vector("character",length(filenames))
for (i in seq_along(filenames)){
  search_terms[i] <- str_extract(filenames[i],".+\\.") %>%
    str_extract(".+[^\\.]")
}

currency_denoter <- function(amount_input,currency_input) { #Converts the currency for single row
  getFX(str_c(currency_input,"/GBP"),Sys.Date()-1)
  varname <- str_c(currency_input,"GBP")
  rate <- eval(parse(text=varname))
  gbp_out <- as.double(amount_input * rate[1,1])
  return(gbp_out)
}

currency_standardiser <- function(input_tb){
  standardised_rows <- input_tb %>%
    distinct(Abstract, .keep_all=TRUE) %>% #This is to remove duplicate rows
    filter(Currency != "GBP" & !is.na(Currency)) %>%
    mutate(Amount = map2_dbl(Amount,Currency,currency_denoter)) %>%
    mutate(Currency = "GBP")
  
  standardised_tb_V2 <- input_tb %>%
    distinct(Abstract, .keep_all=TRUE) %>% #This is to remove duplicate rows
    filter(Currency == "GBP" | is.na(Currency)) %>%
    full_join(standardised_rows) %>%
    arrange(ID)
}

for (i in seq_along(search_terms)){ #This code is horribly inefficient but it works so...
  relevant_tb <- eval(parse(text=str_c("`",search_terms[i],"`")))
  standardised_tb <- currency_standardiser(relevant_tb)
  assign(search_terms[i],standardised_tb)
  rm(standardised_tb,relevant_tb)
}
```



The below code will answer the question of **who are the x most well-funded PI ?** and **for the top x most well-funded PIs, what was the period of the grant & how much was each worth ?**.

It will answer this question for each of the search terms, outputting for each search term
1. A sorted bar chart of x PIs
2. A line graph of total grant money active at any one time for each of x most well-funded PIs.


```{r PI Analysis}

top_x_PIs <- function(input_tb,x_to_keep=length(input_tb)){
  top_PIs <- CRISPR %>%
    group_by(Name) %>% 
    mutate(Total_Amount = sum(Amount)) %>%
    select(2,13) %>%
    arrange(desc(Total_Amount)) %>%
    distinct(Name, .keep_all= TRUE) %>%
    ungroup()
  
  top_x <- slice_head(top_PIs, n=x_to_keep)
  #biggest_moneymaker <- str(top_x[[1]][[1]])
  #biggest_earnings <- str(top_x[[1]][[2]])
  tb_name <- deparse(substitute(input_tb))
  
  print(ggplot(top_x,aes(Total_Amount, reorder(Name, Total_Amount)))+
    geom_col() +
    labs(x="Total GBP Awarded",y="Name of PI", 
         title=str_c("Top",as.character(x_to_keep),"Well-Funded PIs for", tb_name, sep=" "), caption="Europe PMC GRIST API")
  )
  
  return()
}

total_running_money_top_x_PIs <- function(input_tb, x_to_keep = length(input_tb)){
  
   top_x_PIs <- input_tb %>%
    group_by(Name) %>%
    mutate(Total_Amount = sum(Amount)) %>%
    select(2,13) %>%
    arrange(desc(Total_Amount)) %>%
    distinct(Name, .keep_all= TRUE) %>%
    ungroup()
  
  top_x <- slice_head(top_x_PIs, n=n_to_keep)
  
  
  top_running_money_PIs <- input_tb %>%
    group_by(Name) %>%
    mutate(Total_Amount = sum(Amount)) %>%
    select(2,5:6,11,13) %>%
    arrange(desc(Total_Amount)) %>%
    distinct() %>%
    ungroup()

  top_x_amount <- semi_join(top_running_money_PIs, top_x, by="Name")
  
  #Given that there will be multiple rows for each PI, I need to get the actual number of rows to slice
  number_of_rows_for_top_x <- top_PIs %>%
    mutate(Total_Amount_Rank = rank(desc(Total_Amount))) %>%
    filter(Total_Amount_Rank <= x_to_keep)

  
  return(top_x_amount)
  #top_x <- slice_head(top_PIs, n=number_of_rows_for_top_x)
  
}

View(total_running_money_top_x_PIs(CRISPR,10))
```


