---
title: "Data Analysis of Life Sciences Grants via GRIST API"
output: html_notebook
date: 2020-09-21
---
This project aims to source data about awarded grants in the life sciences and to conduct analysis on this data.

Data Source: Grants RESTFul (GRIST) API from Europe PMC
This provides coverage of funding from BBSRC UK; CRUK; NIHR; ERC; MRC UK; Wellcome Trust; WHO and more.

The ideal workflow will be like so:
1) Input search term
2) Python3's urllib will utilise GRIST API to spit out .json file for each 25 results from search term
3) SQLite3 database will be used to cache each .json file
4) Once all .json files have been cached, Python3 will run through each .json file & strip out details from each grant entry:
  a) Full Name
  b) Institution
  c) Start Date
  d) End Date
  e) Grant Title
  f) Grant Abstract
  h) Grant Source
  i) Grant Type
  j) Grant Worth + Currency
  
and store them in a Numpy array with each row reflecting separate ID i.e grant entry.

5) Once, Numpy array has been constructed as so, it will be converted to a csv named with the particular 'search term' used. which can then be read into a tibble in R.
6) Analysis of that particular 'search term' data can then be carried out to answer the following questions:
- Who is the most well-funded for that 'search term' & when?
- Which research institution is most well-funded for that 'search term' and when?
- How much money has that 'search term' been funded in the past 2,5,10 years?


7) Comparative analysis can also be conducted between tibbles for 'search terms'
- How much money per grant is awarded between the different 'search terms'?
- How much total money is awarded over the years for different 'search terms'?
- How many grants have been awarded over the years for different 'search terms'?

8) Data will be outputted in the form of a flexdashboard::flex_dashboard or Shiny web app.


```{r setup, include = FALSE}
library(tidyverse)
```

Note that before you run the following code for data analysis, you should have run the GRIST.py script to output .tsv files of interest to the folder ./output_tsv

The below code will import the .tsv files found within the ./output_tsv folder as individual tibbles.


```{r import}
filenames <- list.files("./output_tsv")

file_trial <- read_tsv(str_c("./output_tsv/",filenames[1]), 
                     col_names = c("ID","Name","Institution","Department", "Start Date","End Date","Title","Abstract", "Funder","Grant Type","Amount"), 
                     col_types = "icccDDccccc",
                     na="None",
                     quote="")

for (i in seq_along(filenames)){
  file <- str_extract(filenames[i],".+\\.")
  file <- read_tsv(str_c("./output_tsv/",filenames[i]), 
                     col_names = c("ID","Name","Institution","Department", "Start Date","End Date","Title","Abstract", "Funder","Grant Type","Amount"), 
                     col_types = "icccDDccccc",
                     na="None")
}



```

